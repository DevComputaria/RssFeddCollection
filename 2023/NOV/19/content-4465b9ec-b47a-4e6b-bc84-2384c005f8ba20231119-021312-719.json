{"?xml":{"@version":"1.0","@encoding":"utf-8"},"rss":{"@version":"2.0","@xmlns:atom":"http://www.w3.org/2005/Atom","@xmlns:content":"http://purl.org/rss/1.0/modules/content/","@xmlns:dc":"http://purl.org/dc/elements/1.1/","@xmlns:media":"http://search.yahoo.com/mrss/","channel":{"title":"IEEE Spectrum","link":"https://spectrum.ieee.org/","description":"IEEE Spectrum","atom:link":{"@href":"https://spectrum.ieee.org/feeds/feed.rss","@rel":"self"},"language":"en-us","lastBuildDate":"Sat, 18 Nov 2023 19:00:02 -0000","image":{"url":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNjg4NDUyMC9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc2MzA3MTQzOX0.SxRBIud_XE2YWQFaIJD9BPB1w-3JsFhiRkJIIe9Yq-g/image.png?width=210","link":"https://spectrum.ieee.org/","title":"IEEE Spectrum"},"item":[{"title":"An After-School Program Teaches Teens Java and Python","link":"https://spectrum.ieee.org/program-teaches-teens-java-python","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/2-people-with-masks-on-sitting-in-at-a-desk-chatting-with-various-different-boxes-and-wires-around-them.jpg?id=50496333&width=1200&height=800&coordinates=0%2C0%2C0%2C162\"/><br/><br/><p style=\"\">After <a href=\"https://www.linkedin.com/in/vic-wintriss-946532181/\" rel=\"noopener noreferrer\" target=\"_blank\">Vic Wintriss</a> sold his sports-imaging company, <a href=\"https://www.weco.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Wintriss Engineering</a>, to his cofounders in 2006, the electrical engineer was looking for a project to keep himself busy. Wintriss Engineering, based in San Diego, makes smart cameras for sports imaging such as tracking golf balls and inspecting paper, textiles, and plastics. While discussing with his wife what his next career move should be, an idea suddenly came to him in the form of a vision.</p><p>“I’ll never forget it,” Wintriss recalls. “It said: ‘You’re going to teach<a href=\"https://www.java.com/en/download/help/whatis_java.html\" rel=\"noopener noreferrer\" target=\"_blank\"> Java</a> to kids in a nonprofit school.’ I didn’t even know Java.”</p><p style=\"\">At the age of 75 he went back to school to learn the programming language. After teaching the subject to teenagers at his church, in 2006 the IEEE life member established <a href=\"https://www.jointheleague.org/\" rel=\"noopener noreferrer\" target=\"_blank\">The League of Amazing Programmers</a>. The San Diego–based nonprofit after-school program teaches coding in Java and <a href=\"https://www.python.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Python</a> to students in Grades 5 to 12. The program offers 10 levels of coding, from beginner to advanced. It is the only one in the United States that awards the <a href=\"https://education.oracle.com/certification\" rel=\"noopener noreferrer\" target=\"_blank\">Oracle professional programming certificate</a> to high school students.</p><p style=\"\">The league was recently named <a href=\"https://www.delmartimes.net/news/story/2023-06-13/league-of-amazing-programmers-honored-at-state-capitol\" rel=\"noopener noreferrer\" target=\"_blank\">Nonprofit of the Year</a> by its California Assembly district’s representative, <a href=\"https://a77.asmdc.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Tasha Boerner</a>.</p><p style=\"\">“It was a privilege to recognize The League of Amazing Programmers for the critical work they are doing in my district to promote equity in our digital age,” Boerner said in a <a href=\"https://www.delmartimes.net/news/story/2023-06-13/league-of-amazing-programmers-honored-at-state-capitol\" rel=\"noopener noreferrer\" target=\"_blank\">news release</a> about the recognition. “Their dedication to helping our youth, especially girls and underrepresented communities, is transforming lives throughout San Diego.”</p><h2>Java, Python, and game design</h2><p>Wintriss, who is now 92, had some prior teaching experience. He was a Navy flight instructor and taught Sunday school classes for several years. To start fulfilling the Java vision he had, he began holding coding classes at the church. The course became so popular that he rented a larger space and bought more computers. Wintriss continued on his own until, he says, it became overwhelming.</p><p>That’s when he launched The League of Amazing Programmers. He retained professional programmers who volunteered their time to teach 90-minute weekly in-person and virtual classes seven days a week. The school’s monthly tuition is US $260, and tuition assistance is available.</p><p>This year 200 students are participating in the program. About half of them are from underserved communities, Wintriss says.</p><p class=\"pull-quote\">“The students who have completed the program have been amazing. The computer programs they write are just totally incredible.” <strong>—Vic Wintriss</strong></p><p style=\"\">The classes are held in the San Diego area, including at the <a href=\"https://www.sandiego.gov/public-library/locations/valencia-park-malcolm-x-library\" rel=\"noopener noreferrer\" target=\"_blank\">Valencia Park/Malcom X</a> and <a href=\"https://www.sandiego.gov/public-library/central-library\" rel=\"noopener noreferrer\" target=\"_blank\">Central</a> libraries and the <a href=\"https://digitalstartnorthcounty.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Digital Start North County</a> tech hobby store in Fallbrook. Its main campus is a Carmel Valley office building in northern San Diego.</p><p style=\"\">The league recently added an <a href=\"https://jtl.pike13.com/courses/313881\" rel=\"noopener noreferrer\" target=\"_blank\">Introduction to Game Design</a> class. <a href=\"https://www.jointheleague.org/summer-camp/\" rel=\"noopener noreferrer\" target=\"_blank\">Seasonal camps</a> on artificial intelligence, <a href=\"https://www.minecraft.net/en-us\" rel=\"noopener noreferrer\" target=\"_blank\">Minecraft</a> modification, and Web development are offered as well.</p><p style=\"\">“The students who have completed the program have been amazing,” Wintriss says. “The computer programs they write are just totally incredible.”</p><p style=\"\">The league’s students put their skills to work during the COVID-19 pandemic. They were taught how to design a <a href=\"https://www.jointheleague.org/2022/12/16/students-develop-low-cost-ventilator/\" rel=\"noopener noreferrer\" target=\"_blank\">low-cost emergency ventilator system</a> using a <a href=\"https://www.raspberrypi.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Raspberry Pi</a> computer and automated versions of manual bag-based resuscitator devices, commonly known as <a href=\"https://spectrum.ieee.org/diy-ventilators-for-covid19-could-be-a-vital-stopgap\" target=\"_self\">Ambu bags</a>. The compact, balloonlike bags have a soft air reservoir that can be squeezed by medical professionals to inflate a patient’s lungs.</p><h2>Oracle certification success</h2><p>More than 50 students have passed the Oracle Professional Programming Certificate exam, which is not easy for a high school student, Wintriss says. Students who take the exam are typically in the 11th grade.</p><p>Once students earn the certification, they can garner a high salary, Wintriss says.</p><p>“If you’ve got the Oracle certificate, any employer will hire you as a programmer without a college degree, although we encourage our students to go to college,” he says.</p><p>Some students have gotten part-time after-school programming jobs that pay about $60 per hour, he says. Former students who have landed a full-time job have told him they are earning more than $100,000 annually.</p><p>Wintriss says he hopes to expand the program to other states.</p><h2>A student testimonial</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"one person sitting  with a laptop in front of him and a tv hanging above hisheads on the wall\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"face5b89db8d15727894b711d5dced44\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"d692b\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/one-person-sitting-with-a-laptop-in-front-of-him-and-a-tv-hanging-above-hisheads-on-the-wall.jpg?id=50496369&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\" style=\"max-width: 100%;\">Sam Sharp has completed the after-school program’s Java course and plans to take the Oracle certificate exam. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">Vic Wintriss</small></p><p>One student who is attending the after-school program is 15-year-old Sam Sharp, an 11th grader at <a href=\"https://sdhs.sandiegounified.org/\" rel=\"noopener noreferrer\" target=\"_blank\">San Diego High School</a>. His parents signed him up for the program when he was 8.</p><p>“I’ve always been interested in computers,” Sharp says. “I’ve had this idea to make things that people are going to use in their daily lives. I figured that because everybody now does everything on their computers, I wanted to learn how to make things for computers.”</p><p>Sharp is at the Level 8 stage and has completed the Java course.</p><p>“It gave me a solid foundation for how programming works,” he says, “because it teaches you the object-oriented basics.” He is now learning JavaScript and working on more advanced programming projects such as developing games and publishing <a href=\"https://parakeet.games/\" rel=\"noopener noreferrer\" target=\"_blank\">Parakeet.Games</a>, a Web game aggregator.</p><p>He says the league’s program has taught him other skills such as creating a project from scratch, meeting deadlines, pacing himself, and leading teams. He also helps teach younger students the programming languages.</p><p>What appeals to him the most about the league’s curriculum, he says, is its “five seconds of fun” principle.</p><p>“The concept,” he says, “is that students should get five seconds of just pure fun from what they’ve made or programmed.”</p><p style=\"\">He says he intends to take the Oracle certificate exam, and he plans to pursue a college degree in computer programming.</p>"},"pubDate":"Sat, 18 Nov 2023 19:00:02 +0000","guid":"https://spectrum.ieee.org/program-teaches-teens-java-python","category":["Stem","Education","Ieee member news","Students","Type:ti"],"dc:creator":"Kathy Pretz","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/2-people-with-masks-on-sitting-in-at-a-desk-chatting-with-various-different-boxes-and-wires-around-them.jpg?id=50496333&width=980"}},{"title":"Video Friday: GR-1","link":"https://spectrum.ieee.org/video-friday-gr-1","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/humanoid-robot-pictured-in-foreground-with-arms-wide-open-two-other-humanoids-behind-it.jpg?id=50507050&width=1200&height=800&coordinates=181%2C0%2C182%2C0\"/><br/><br/><p>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at <em>IEEE Spectrum</em> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please <a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a> for inclusion.<br/></p><h5><a href=\"https://2023.ieee-humanoids.org/\">Humanoids 2023</a>: 12–14 December 2023, AUSTIN, TEXAS</h5><h5><a href=\"https://cybathlon.ethz.ch/en/events/challenges/Challenges-2024\">Cybathlon Challenges</a>: 2 February 2024, ZURICH, SWITZERLAND</h5><h5><a href=\"https://www.eurobot.org/\">Eurobot Open 2024</a>: 8–11 May 2024, LA ROCHE-SUR-YON, FRANCE</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><p>Fourier Intelligence has just announced the mass production of their GR-1 humanoid, and they’ve got at least a dozen of them.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"b4835aa39b6d91b92802e419d6a31b4f\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/BvFxD-8AhJA?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://robots.fourierintelligence.com/\">Fourier Intelligence</a> ]</p><p>Thanks, Ni Tao!</p><div class=\"horizontal-rule\"></div><blockquote><em>This collaborative work between researchers from the University of Southern Denmark and VISTEC introduces a biomorphic soft robotic skin for a hexapod robot platform, featuring a central pattern generator–based neural controller for generating respiratory-like motions on the skin. The design enables visuo-haptic nonverbal communication between humans and robots and improves the robot’s aesthetics by enhancing its biomorphic qualities.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"eb4c18fe7b98dec15b873775ec73afed\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/ioDlsNjLZ2I?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://ieeexplore.ieee.org/document/10309420\">Paper</a> ]</p><p>Thanks, Mads!</p><div class=\"horizontal-rule\"></div><blockquote><em>According to data from 2010, around 1.8 million people in the United States can’t eat on their own. Yet training a robot to feed people presents an array of challenges for researchers. A team led by researchers at the University of Washington created a set of 11 actions a robotic arm can make to pick up nearly any food attainable by fork. In tests with this set of actions, the robot picked up the foods more than 80 percent of the time, which is the user-specified benchmark for in-home use. The small set of actions allows the system to learn to pick up new foods during one meal.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"9f5e237322532cc4c15c6d24e61ffd80\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/6j2ymtDI8LI?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.washington.edu/news/2023/11/16/robot-assisted-feeding-meal-accessibility/\">UW</a> ]</p><p>Thanks, Stefan!</p><div class=\"horizontal-rule\"></div><p>If you watch enough robot videos, you get to know when a robot is being pushed in a way that’s easy to recover from, and when it’s actually being challenged. The end of this video shows IHMC’s Nadia getting pushed sideways against its planted foot, which necessitates a crossover step recovery.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"43f6cca87fd3f03e7ad726b7088becb0\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/aM-qb1yd5mU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://arxiv.org/pdf/2307.11968.pdf\">Paper</a> ] via [ <a href=\"https://robots.ihmc.us/nadia\">IHMC</a> ]</p><p>Thanks, Robert!</p><div class=\"horizontal-rule\"></div><p>Ayato Kanada, an assistant professor at Kyushu University, wants to build woodpecker-inspired Doc Ock tentacles. And when you’re a professor, you can just do that. </p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"e3678c371c425bf34e2e6b4b4fe6ba87\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/oNT-9RBxN8s?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>Also, woodpeckers are weird.</p><p>[ <a href=\"https://sites.google.com/view/ayato-kanada-en/home\">Ayato Kanada</a> ]</p><p>Thanks, Ayato!</p><div class=\"horizontal-rule\"></div><blockquote><em>Explore Tevel’s joint robotic fruit-harvesting pilot program with Kubota in this video, filmed during the 2023 apple harvest season in the Mazzoni Group’s orchards in Ferrara, Italy. Watch as our autonomous fruit-picking systems operate with precision, skillfully harvesting various apples in the idyllic Italian orchards.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"0ef15f5894a952853dada70ddd072b79\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/DPjTmyT4a8w?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.tevel-tech.com/\">Tevel</a> ]</p><div class=\"horizontal-rule\"></div><p>Understanding what’s an obstacle and what’s only obstacle-ish has always been tricky for robots, but Spot is making some progress here.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"10d095de79546ceb896f2cfe425231fd\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/pV7GxAFYuto?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://xiaoyi-cai.github.io/evora/\">EVORA</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>We tried to play Street Fighter 6 by teleoperating Reachy! Well, it didn’t go as planned, as Antoine won. But it was a pretty epic fight!</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"73e7def716f904470c46ae1963306c71\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/-uGTTjLuU68?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.pollen-robotics.com/\">Pollen Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>The key assets of a data center are the servers. While most of them are active in the server room, idle and new assets are stored in the IT warehouse. Focusing mainly on this IT warehouse, SeRo automates the inbound and outbound management of the data center’s assets.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"2650ab3a56c041f5fa011df04989e706\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/cLzzHE5eJt4?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.naverlabs.com/en/storyDetail/278\">Naver Labs</a> ]</p><div class=\"horizontal-rule\"></div><p>Humans can be so mean.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"e0b4bd5d336985f1301c6dba4f849b79\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Qw-GBXj0n_4?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.flexiv.com/en/technology/robot\">Flexiv</a> ]</p><div class=\"horizontal-rule\"></div><p>Interesting HRI with the flashing light on Spot here.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"32593d73b1324b7c7ef4aa3b79ca5914\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/XWP4scq95Eg?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://bostondynamics.com/products/spot/\">Boston Dynamics</a> ]</p><div class=\"horizontal-rule\"></div><p>Flying in circles with a big tank of gas really seems like a better job for a robot pilot than for a human one.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"48d8361bc952d774a697f443bf450838\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/jK8eOZpxte0?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.boeing.com/defense/mq25/\">Boeing</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>On 2 November 2023, at an event hosted by the Swiss Association of Aeronautical Sciences at ETH, Professor Davide Scaramuzza presented a comprehensive overview of our latest advancements in autonomous drone technology aimed at achieving human-level performance.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"bbe7c807f4c11b9606cedf37ececce55\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/vVataTRomsg?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://rpg.ifi.uzh.ch/\">UZH RPG</a> ]</p><div class=\"horizontal-rule\"></div>"},"pubDate":"Fri, 17 Nov 2023 23:04:03 +0000","guid":"https://spectrum.ieee.org/video-friday-gr-1","category":["Fourier intelligence","Nadia","University of washington","Video friday","Robotics","Humanoid robots","Quadruped robots","Drones","Robotic arm"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/humanoid-robot-pictured-in-foreground-with-arms-wide-open-two-other-humanoids-behind-it.jpg?id=50507050&width=980"}},{"title":"Radomes: Efficient 3D EM Simulation","link":"https://wipl-d.com/white-paper-radomes/","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/image.png?id=26851496&width=980\"/><br/><br/><p>Highly efficient implementation of Method-of-Moments (MoM) for radome simulations in WIPL-D suite is described in this comprehensive study. Sophisticated approximations rather than geometrical or physical optics (GO, PO) methods were used. Straightforward usage and effectiveness of in-house developed techniques along with efficient utilization of graphical processing units (GPU) are explained.</p><p><a href=\"https://wipl-d.com/white-paper-radomes/\" rel=\"noopener noreferrer\" target=\"_blank\">Download this free whitepaper now!</a></p>"},"pubDate":"Fri, 17 Nov 2023 20:05:12 +0000","guid":"https://wipl-d.com/white-paper-radomes/","category":["Gpu","Radomes","Simulation","Type:whitepaper","Wipl-d"],"dc:creator":"WIPL-D","media:content":{"@medium":"image","@type":"image/png","@url":"https://assets.rbl.ms/26851496/origin.png"}},{"title":"New Watch Motor Seeks to Outsmart the Smartwatch","link":"https://spectrum.ieee.org/quartz-watch","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-white-rubber-gloved-hand-holding-up-a-small-blue-circle-with-computer-chip-on-it.jpg?id=50463987&width=1200&height=800&coordinates=0%2C104%2C0%2C105\"/><br/><br/><p>Could the analog quartz wristwatch, a mainstay of the timepiece market for more than half a century, be headed finally for a high-tech makeover? A French startup, <a href=\"https://www.silmach.com/en\" rel=\"noopener noreferrer\" target=\"_blank\">SilMach</a>, in Besançon, France, is betting big that it is. The company has used silicon microelectromechanical systems (MEMS) to produce an entirely new wristwatch motor for analog watches that’s half the size and roughly three times as efficient in comparison with the standard stepper motor now used in wristwatches.</p><p>Really? Analog watches? Now? In the age of the smartwatch?</p><p>Time for a reality check: Quartz analog wristwatches actually accounted for <a href=\"https://blog.gitnux.com/wrist-watch-industry-statistics/\" rel=\"noopener noreferrer\" target=\"_blank\">close to three-quarters</a> of the market for conventional wristwatches in recent years, according to data compiled by the research firm Gitnux. And that overall market was valued at <a href=\"https://www.globenewswire.com/en/news-release/2023/05/02/2659107/0/en/Global-Watch-Market-Revenue-to-Touch-US-113-Billion-Rising-at-a-CAGR-Of-5-5-by-2033-States-Fact-MR.html\" rel=\"noopener noreferrer\" target=\"_blank\">US $66 billion</a> this year—slightly larger than the <a href=\"https://www.businesswire.com/news/home/20230227005460/en/Smart-Watch-Global-Market-Report-2023-Increasing-Health-Awareness-Among-Consumers-Bolsters-Growth---ResearchAndMarkets.com\" rel=\"noopener noreferrer\" target=\"_blank\">global market for smartwatches</a>, by some estimates.</p><p>And yet today’s analog quartz watches are technologically unchanged from the <a href=\"https://www.quartzwristwatch.org/history-of-the-first-quartz-wristwatch\" rel=\"noopener noreferrer\" target=\"_blank\">first quartz watches</a>, introduced 53 years ago by a Swiss consortium and by Japanese watchmaker <a href=\"https://www.seiko.co.jp/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Seiko</a>. Those watches, and today’s watches, used a kind of synchronous direct-current stepper motor called a <a href=\"https://en.wikipedia.org/wiki/Lavet-type_stepping_motor\" rel=\"noopener noreferrer\" target=\"_blank\">Lavet motor</a>, invented in 1936 by Marius Lavet, a French engineer.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"black rubber gloved hands putting a watch together\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"b7fee239bcbc932db79533db708b2e9a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"6c1b1\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/black-rubber-gloved-hands-putting-a-watch-together.jpg?id=50463988&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A technician assembles a TimeChanger wristwatch, the first to be equipped with MEMS motors.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">SilMach</small></p><p>The idea of using silicon MEMS to make a watch motor seized French engineer Patrice Minotti in 1996 while he was in Tokyo, heading a joint laboratory between France’s Centre National de la Recherche Scientifique and the University of Tokyo. “I was personally inspired by the very first IC-processed electrostatic motor, which was created a few years earlier by Richard Muller (UC Berkeley),” Minotti wrote in an e-mail. “This very first IC-based MEMS motor was an amazing laboratory demonstrator but wasn’t able, by far, to drive the hands of a wristwatch…. I imagined a new MEMS motor architecture that could be able to drastically amplify the driving torque of state-of-the-art electrostatic MEMS motors.”</p><p>The type of MEMS actuator the group began working with was the <a href=\"https://en.wikipedia.org/wiki/Comb_drive\" rel=\"noopener noreferrer\" target=\"_blank\">comb drive</a>. To understand how it works, imagine two combs with widely spaced teeth, facing each other with their teeth interleaved. Voltages applied to each comb set up an electrostatic attraction, or repulsion, that causes the combs to move toward, or away from, each other. To get rotational motion, levers and crankshafts are connected to the moving combs.</p><p style=\"\">One big challenge was that <em>2,000</em> such combs were needed to produce enough torque to move the hands of the watch directly, without any gearing. Another hurdle was the circuitry needed to get a 3-volt watch battery to produce the 110-V signals needed to power the electrostatic comb drives. In the current MEMS motor, this conversion is accomplished by an application-specific integrated circuit occupying just 2 millimeters square. It took nearly a decade to develop, starting in 2012, according to Pierre-François Louvigné, co-CEO of SilMach.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"a semicircle with rectangles on it with a blue hue \" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"1d70748cae23e6d2f4f6a45858312333\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"a5dfc\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-semicircle-with-rectangles-on-it-with-a-blue-hue.jpg?id=50463994&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A wafer containing drive units for the wristwatch motor was produced at a MEMS fab facility in France. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">SilMach</small></p><p>In 2016, the company entered into a joint venture, called TiMach, with Timex Group, the watchmaking giant. Timex provided expertise needed to tweak the design of the MEMS motors so that they could be fabricated in a form readily usable by watch manufacturers. In their current form, the motors (one for each hand of a watch) and all the other components of a watch can be soldered directly on to a single surface-mount printed circuit board.</p><p style=\"\">Such compactness and ease of integration is particularly advantageous for makers of hybrid smartwatches, such as <a href=\"https://www.withings.com/us/en/watches\" target=\"_blank\">Withings</a>, <a href=\"https://www.garmin.com/en-US/c/sports-fitness/fashion-hybrid-smartwatches/\" target=\"_blank\">Garmin</a>, <a href=\"https://www.citizenwatch.com/us/en/collection/cz-smart-hybrid/\" target=\"_blank\">Citizen</a>, <a href=\"https://www.fossil.com/en-us/watches/learn-more/hybrid-smartwatches/\" target=\"_blank\">Fossil</a>, and <a href=\"https://www.skagen.com/en-us/smartwatches/learn-more/gen-6-hybrid-smartwatches/\" target=\"_blank\">Skagen</a>. These watches have many of the functions of smartwatches—pulse and sleep monitoring, fitness tracking, Bluetooth communications, message displaying—along with physical hands, like a traditional analog watch and, of course, a motor. Because hybrid timepieces must combine that motor with a variety of electronic sensors and a display, the watches are typically quite large, and space inside the case is usually very tight.</p><p style=\"\"><span></span>SilMach is betting on the expansion of the market for these hybrid smartwatches, for which their motor is very well suited. “In a typical hybrid smartwatch, the Lavet motor occupies up to 70 percent of the inside of the case,” says Jean-Baptiste Carnet, SilMach’s other co-CEO. Thus the smaller size of the MEMs motors means much more room for other electronics and sensors, he notes. Or, the watches could finally be made compact enough to be worn by people with normal-size wrists.</p><p>In addition, the fact that the MEMS motors can be integrated directly with the other electronics simplifies manufacturing. “We think all watches, all wearables, will be fully electronic,” Louvigné declares.</p><p>The <a href=\"https://thetimechanger.com/en/thetimechanger-the-first-watch-in-the-world-powered-by-silicium-machinery/\" target=\"_blank\">first watch using the new motor</a> was recently offered as a limited edition on <a href=\"https://www.kickstarter.com/projects/thetimechanger/thetimechanger-1st-silicium-watch-numbered-edition?ref=7sdy6l\" target=\"_blank\">Kickstarter</a>, for €1,850. The company is also in discussions with several major watchmakers, Louvigné says, adding that the company would have further announcements at the Consumer Electronics Show (CES), in January.</p>"},"pubDate":"Fri, 17 Nov 2023 13:00:03 +0000","guid":"https://spectrum.ieee.org/quartz-watch","category":["Mems","Wristwatch","Smart watch","Mems"],"dc:creator":"Glenn Zorpette","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-white-rubber-gloved-hand-holding-up-a-small-blue-circle-with-computer-chip-on-it.jpg?id=50463987&width=980"}},{"title":"Ethernet is Still Going Strong After 50 Years","link":"https://spectrum.ieee.org/ethernet-ieee-milestone","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/close-up-of-ethernet-cable-with-clear-fibers-in-the-background.jpg?id=50494003&width=1200&height=800&coordinates=0%2C104%2C0%2C105\"/><br/><br/><p>The <a href=\"https://www.xerox.com/en-us\" rel=\"noopener noreferrer\" target=\"_blank\">Xerox</a> <a href=\"https://spectrum.ieee.org/xerox-parc\" target=\"_self\">Palo Alto Research Center</a> in California has spawned many pioneering computer technologies including the <a href=\"https://spectrum.ieee.org/xerox-alto\" target=\"_self\">Alto</a>—the first personal computer to use a graphical user interface—and the first laser printer.</p><p style=\"\">The PARC facility also is known for the invention of <a href=\"https://ethw.org/Ethernet\" rel=\"noopener noreferrer\" target=\"_blank\">Ethernet</a>, a networking technology that allows high-speed data transmission over coaxial cables. Ethernet has become the standard wired local area network around the world, and it is widely used in businesses and homes. It was honored this year as an <a href=\"https://ieeemilestones.ethw.org/Milestone-Proposal:Ethernet_Local_Area_Network_(LAN),_1973-1985\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Milestone</a>, a half century after it was born.</p><h2>Connecting PARC’s Alto computers</h2><p> Ethernet’s development began in 1973, when <a href=\"https://amturing.acm.org/award_winners/thacker_1336106.cfm\" rel=\"noopener noreferrer\" target=\"_blank\">Charles P. Thacker</a>—who was working on the design of the Alto computer—envisioned a network that would allow Altos to communicate with each other, as well as with laser printers and with PARC’s gateway to the <a href=\"https://ethw.org/ARPANET\" rel=\"noopener noreferrer\" target=\"_blank\">ARPANET</a>. PARC researcher <a href=\"https://ethw.org/Robert_M._Metcalfe\" rel=\"noopener noreferrer\" target=\"_blank\">Robert M. Metcalfe</a>, an IEEE Fellow, took on the challenge of creating the technology. Metcalfe soon was joined by computer scientist <a href=\"https://ethw.org/David_Boggs\" rel=\"noopener noreferrer\" target=\"_blank\">David Boggs</a>.</p><p>Metcalfe and Boggs had two criteria: The network had to be fast enough to support their laser printer, and it had to connect hundreds of computers within the same building.</p><p>The Ethernet design was inspired by the <a href=\"https://spectrum.ieee.org/alohanet-introduced-random-access-protocols-to-the-computing-world\" target=\"_self\">Additive Links On-line Hawaii Area network</a> (ALOHAnet), a radio-based system at the <a href=\"https://www.hawaii.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Hawai’i</a>. Computers transmitted packets, prefaced by the addresses of the recipients, over a shared channel as soon as they had information to send. If two messages collided, the computers that had sent them would wait a random interval and try again. </p><p style=\"\">Metcalfe outlined his proposal, then called the Alto Aloha Network, in a <a href=\"https://ieeemilestones.ethw.org/w/images/a/af/Ref1_PARC_Ethernet_Memo_1973.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">now-famous memo</a> to his colleagues. Using coaxial cables rather than radio waves would allow faster transmission of data and limit interference. The cables also meant that users could join or exit the network without having to shut off the entire system, Metcalfe said in a 2004 <a href=\"https://ethw.org/Oral-History:Robert_Metcalfe\" rel=\"noopener noreferrer\" target=\"_blank\">oral history</a> conducted by the <a href=\"https://www.ieee.org/about/history-center/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE History Center</a>.</p><p>“There was something called a cable television tap, which allows one to tap into a coax without cutting it,” Metcalfe said. “Therefore, [Boggs and I] chose coax as our means of communication. In [the] memo, I described the principles of operation—very distributed, no central control, a single piece of ‘ether.’”</p><p>Metcalfe and Boggs designed the first version of what is now known as Ethernet in 1973. It sent data at up to 2.94 megabits per second and was “fast enough to feed the laser printer and easy to send through the coax,” Metcalfe told the IEEE History Center.</p><p>A 9.5-millimeter thick and stiff coaxial cable was laid in the middle of a hall in the PARC building. The 500-meter cable had 100 transceiver nodes attached to it with N connectors, known as vampire taps. Each of the taps—small boxes with a hard shell—had two probes that “bit” through the cable’s outer insulation to contact its copper core. Thus new nodes could be added while existing connections were live.</p><p>Each vampire tap had a D-type connector socket in it, consisting of a plug with nine pins that matched to a socket with nine jacks. The sockets allowed Alto computers, printers, and file servers to attach to the network.</p><p>To enable the devices to communicate, Metcalfe and Boggs created the first high-speed network interface card (NIC)—a circuit board that is connected to a computer’s motherboard. It included what is now known as an Ethernet port.</p><p>The researchers changed the name from the original Alto Aloha Network to Ethernet to make it clearer that the system could support any computer. It reflected a comment Thacker had made early on, that “coaxial cable is nothing but captive ether,” PARC researcher <a href=\"https://amturing.acm.org/award_winners/kay_3972189.cfm\" rel=\"noopener noreferrer\" target=\"_blank\">Alan Kay</a> <a href=\"https://spectrum.ieee.org/xerox-parc\" target=\"_self\">recalled</a>.</p><p>Metcalfe, Boggs, Thacker, and <a href=\"https://amturing.acm.org/award_winners/lampson_1142421.cfm\" rel=\"noopener noreferrer\" target=\"_blank\">Butler W. Lampson</a> were granted a U.S. patent in 1978 for their invention.</p><p>They continued to develop the technology and, in 1980, PARC released Ethernet that ran at 10 Mb/s. The update was done in collaboration with researchers at <a href=\"https://www.intel.com/content/www/us/en/homepage.html\" rel=\"noopener noreferrer\" target=\"_blank\">Intel</a> and the <a href=\"https://en.wikipedia.org/wiki/Digital_Equipment_Corporation\" rel=\"noopener noreferrer\" target=\"_blank\">Digital Equipment Corp.</a> (DEC) to create a version of Ethernet for broad industry use, according to the Milestone entry.</p><h2>Becoming an IEEE standard</h2><p>Ethernet became commercially available in 1980 and quickly grew into the industry LAN standard. To provide computer companies with a framework for the technology, in June 1983 Ethernet was adopted as a standard by the <a href=\"https://grouper.ieee.org/groups/802/es-ecsg/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE 802 Local Area Network Standards Committee</a>.</p><p>Currently, the <a href=\"https://www.ieee802.org/#:~:text=The%20IEEE%20802%20LAN%2FMAN,them%20on%20a%20global%20basis.\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE 802</a> family consists of 67 published standards, with 49 projects under development. The committee works with standards agencies worldwide to publish certain IEEE 802 standards as international guidelines. </p><p>A plaque recognizing the technology will be displayed outside the PARC facility. It will read:</p><p><em>Ethernet wired LAN was invented at Xerox Palo Alto Research Center (PARC) in 1973, inspired by the ALOHAnet packet radio network and the ARPANET. In 1980 Xerox, DEC, and Intel published a specification for 10 Mbps Ethernet over coaxial cable that became the IEEE 802.3-1985 Standard. Later augmented for higher speeds, and twisted-pair, optical, and wireless media, Ethernet became ubiquitous in home, commercial, industrial, and academic settings worldwide.</em></p><p>Administered by the IEEE History Center and <a href=\"https://www.ieeefoundation.org/donate_history\" rel=\"noopener noreferrer\" target=\"_blank\">supported by donors</a>, the Milestone program recognizes outstanding technical developments around the world.</p>The <a href=\"https://ieeescv.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Santa Clara Valley Section</a> sponsored the nomination. The dedication ceremony is scheduled for 18 May at the PARC facility."},"pubDate":"Thu, 16 Nov 2023 19:00:03 +0000","guid":"https://spectrum.ieee.org/ethernet-ieee-milestone","category":["Ethernet","Ieee milestone","Xerox parc","Ieee history","Type:ti"],"dc:creator":"Joanna Goodrich","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/close-up-of-ethernet-cable-with-clear-fibers-in-the-background.jpg?id=50494003&width=980"}},{"title":"GM and Stellantis Back Rare-Earth-Free Permanent Magnet","link":"https://spectrum.ieee.org/permanent-magnet-motor","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-man-in-safety-goggles-looks-at-a-donut-shaped-piece-of-material-under-a-blue-light.jpg?id=50484301&width=1200&height=800&coordinates=0%2C0%2C0%2C155\"/><br/><br/><p>\n\tFor several years, the automobile industry has grappled with a straightforward question: Is it possible to produce a powerful, efficient, and mass-producible synchronous motor that contains no rare-earth elements at all? A newly announced partnership between \n\t<a href=\"https://www.gm.com/\" target=\"_blank\">General Motors</a> and the startup magnet company <a href=\"https://www.nironmagnetics.com/\" target=\"_blank\">Niron Magnetics</a> suggests a resounding “yes.”\n</p><p>\n\tThat was how the media reported it on 8 November, after GM Ventures, \n\t<a href=\"https://www.stellantis.com/en\" rel=\"noopener noreferrer\" target=\"_blank\">Stellantis</a> Ventures, and several other investors disclosed a US $33 million infusion into Niron’s iron-nitride magnet. At the same time, GM and Niron announced that they had agreed to form a strategic partnership to codevelop rare-earth-free permanent magnets “that can be used in future GM EVs.”\n</p><p>\n\tHowever, many experts in magnetics are doubtful. They question whether it’s possible to mass-manufacture an economical magnet free of rare earths that is strong and tough enough for EV propulsion.\n</p><p>\n<span></span>“There’s a compound there,” says <a href=\"https://www.physics.udel.edu/people/gabay\" target=\"_blank\">Alexander Gabay</a>, a researcher at the <a href=\"https://www.udel.edu/\" target=\"_blank\">University of Delaware</a>, referring to the iron nitride in the magnets being developed by Niron. But “it’s not intrinsically capable of making a good magnet. It’s that simple. This is well-known in the community.”\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A man in glasses stands next to a large piece of equipment consisting of a rounded circle with gauges and wires.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"a3a8ece9809907c824f5c7159c780671\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"b0fae\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-man-in-glasses-stands-next-to-a-large-piece-of-equipment-consisting-of-a-rounded-circle-with-gauges-and-wires.jpg?id=50486148&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Niron CEO Jonathan Rowntree stands in front of a chemical reactor used to produce the company’s iron-nitride compound.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Niron Magnetics</small></p><p>\n\tAutomakers have spent enormous sums in recent years preparing for a transportation future dominated by electric vehicles. Part of that preparation has focused on rare-earth elements. For every 100 kilowatts of peak power, an EV motor uses an average of 1.2 kilograms of neodymium-iron-boron permanent magnets, according to \n\t<a href=\"https://www.greencarcongress.com/2019/11/20191111-adamas.html\" target=\"_blank\">Adamas Intelligence</a>. And for automakers, there are two big problems associated with rare earths: Processing of the elements from ore has been a typically environmentally ruinous affair so far. And nearly 90 percent of processed rare earths come from China, which means a supply-chain dependence that spooks car companies in the United States, Japan, Europe, and Korea.\n</p><p>\n\t“Permanent-magnet design is a great opportunity for us to reduce our costs and environmental impact of our EV motors while also localizing our EV supply chain in North America,” said \n\t<a href=\"https://www.gmventures.com/site/us/en/gm-ventures/home/our-team/kai-daniels.html\" target=\"_blank\">Kai Daniels</a>, supervising principal at GM Ventures, at the November press conference announcing the partnership with Niron.\n</p><p>\n\tGM isn’t the only automaker on a hunt for rare-earth-free permanent magnets. Last March, Tesla’s director of power-train engineering caused a minor commotion by declaring that the company’s “next drive unit” included a permanent-magnet motor that would “not use any rare-earth elements at all.” But essentially all of the experts contacted by \n\t<em>IEEE Spectrum</em> <a href=\"https://spectrum.ieee.org/permanent-magnet-tesla\" target=\"_self\">dismissed the assertion</a> as wishful thinking.\n</p><p>\n\tThere are no simple principles of physics and chemistry that preclude the possibility of a powerful and durable permanent magnet that uses no rare-earth elements and whose magnetism survives at high temperatures. Indeed, such a magnet already exists—platinum cobalt (which often incorporates boron as well). However, the magnet is far too expensive for commercial use. It also requires cobalt, whose supply \n\t<a href=\"https://www.mining.com/web/investment-cobalt-fraught-problems-unlikely-bring-long-term-dividends/\" target=\"_blank\">is so fraught</a> that magnets incorporating the element make up <a href=\"https://link.springer.com/article/10.1007/s11837-022-05156-9/tables/2\" rel=\"noopener noreferrer\" target=\"_blank\">a relatively small percentage</a> of the permanent-magnet market.\n</p><p>\n\t“I call it the perversity of nature,” jokes \n\t<a href=\"https://www.ameslab.gov/directory/matthew-kramer\" rel=\"noopener noreferrer\" target=\"_blank\">Matthew Kramer</a>, Distinguished Scientist at <a href=\"https://www.ameslab.gov/\" rel=\"noopener noreferrer\" target=\"_blank\">Ames National Laboratory</a>, in Iowa. “The more expensive it is, the more toxic it is, the better the materials that will come out of it.”\n</p><p>\n\tAny permanent magnet must have a ferromagnetic element, such as iron or cobalt. To understand why, start with the basics: Permanent magnetism occurs in certain crystalline materials when the spins of electrons of some of the atoms in the crystal are forced to point in the same direction. The more of these aligned spins, the stronger the magnetism. For this, the ideal atoms are ones that have unpaired electrons swarming around the nucleus in what are known as \n\t<a href=\"https://winter.group.shef.ac.uk/orbitron/atomic_orbitals/3d/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">3d orbitals</a>. Iron has four unpaired 3d electrons, and cobalt, three.\n</p><p>\n\tBut unpaired 3d electrons aren’t quite enough for a really strong and practical permanent magnet. To get superlative performance, you need to space those atoms out in the crystalline lattice with certain atoms containing unpaired 4f electrons. These particular atoms all belong to the group of rare-earth elements.\n</p><p>\n\t“There are very interesting underlying physics associated with the rare earths that the other transition metals just don’t have,” explains Kramer. “And that involves those inner, 4f, electrons. It gives you the ability to have atoms that can sort of push the other transition metals further apart. Because the trick to getting a really good ferromagnet is, you need to get a lot of spins—but those spins all need to be separated in just the right distances relative to which transition metal you’re looking at [iron or cobalt].”\n</p><p>\n\tThe specific rare-earth elements are neodymium, praseodymium, samarium, and dysprosium. What that spacing does is provide a stable ferromagnetic structure in the crystal, which in turn promotes an inherent characteristic of the crystal called magnetic anisotropy. When the crystal of a magnetic material is relatively easy to magnetize along certain axes compared with others, the material is said to have strong magnetocrystalline anisotropy. This characteristic is essential for producing a good and useful permanent magnet, because without it the magnet cannot have what is known as high coercivity—the ability to resist demagnetization.\n</p><p>\n\t“Nature does not want the magnetization to be aligned in one direction; it wants it to break down into oppositely directed domains,” says Gabay. “That’s why you need strong anisotropy—to hold the magnetization in line,” he adds.\n</p><p>\n\tMagnetocrystalline anisotropy is the question mark hanging over Niron’s magnet, iron nitride. A practical measure of this type of anisotropy is its magnetic hardness, a “hard” material being defined as one that strongly resists demagnetization. \n\t<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S135964621500411X\" rel=\"noopener noreferrer\" target=\"_blank\">In a 2016 paper</a>, researchers at the University of Nebraska and Trinity College, Dublin, analyzed dozens of real and hypothetical permanent-magnet materials and came up with a parameter, <span style=\"font-family:Arial,sans-serif;\">κ</span>, to compactly indicate this hardness. They asserted that “by drawing the line for magnetic hardness at <span style=\"font-family:Arial,sans-serif;\">κ</span> = 1, the rule of thumb for possible success in compact permanent magnet development is that the material should be hard”—in other words, have a <span style=\"font-family:Arial,sans-serif;\">κ</span> greater than 1.\n</p><p>\n\tThe paper included a table of magnetic materials and their <span style=\"font-family:Arial,sans-serif;\">κ</span> values. The standard permanent magnet used in EV motors, neodymium iron boron, has a <span style=\"font-family:Arial,sans-serif;\">κ</span> of 1.54, according to this table. For iron nitride, the authors gave a <span style=\"font-family:Arial,sans-serif;\">κ</span> value of 0.53. (Neodymium-iron-boron magnets, by the way, were \n\t<a href=\"https://spectrum.ieee.org/the-men-who-made-the-magnet-that-made-the-modern-world\" target=\"_self\">invented in the early 1980s</a> separately by <a href=\"https://ieeetv.ieee.org/channels/ieee_awards/masato-sagawa-john-croat-interview-with-glenn-zorpette-ieee-vic-summit\" rel=\"noopener noreferrer\" target=\"_blank\">two groups of researchers</a>, one of which was at General Motors.)\n</p><p>\n\tIf Niron has found a way around the apparent anisotropy problem of iron nitride, they would of course carefully guard such immensely valuable intellectual property. The global market for neodymium magnets is well in the \n\t<a href=\"https://www.expertmarketresearch.com/reports/neodymium-iron-boron-magnet-market#:~:text=The%20global%20neodymium%2Diron%2Dboron,USD%2029.78%20billion%20by%202032.\" rel=\"noopener noreferrer\" target=\"_blank\">billions of dollars</a> per year and growing.\n</p><p>\n\tBut Gabay isn’t buying it. “In our field, the major gathering is called the \n\t<a href=\"https://uobevents.eventsair.com/repm2023/\" rel=\"noopener noreferrer\" target=\"_blank\">International Workshop on Rare-Earth and Future Permanent Magnets</a>. [At the <a href=\"https://www.bunting-berkhamsted.com/a-review-of-repm-2023/\" rel=\"noopener noreferrer\" target=\"_blank\">most recent one</a>, in September] Niron had a presentation, where they were saying a lot of words, but they never showed any data. People asked them to show <em>something</em>, but they never showed anything.”\n</p><p>\n\tAsked about the anisotropy issue with iron nitride, Niron’s chief technical officer, \n\t<a href=\"https://theorg.com/org/niron-magnetics/org-chart/frank-johnson\" rel=\"noopener noreferrer\" target=\"_blank\">Frank Johnson</a>, responded in an email: “The first reaction of many in the magnetics community is to say that iron nitride can’t act as a drop-in replacement for rare-earth magnets in EV motors. They are, of course, absolutely correct. Iron nitride is a new magnetic material with its own balance of properties. Making the most of a new material requires design optimization…. Partnering with world class e-machine designers, including those at investors GM and Stellantis, is the link between breakthrough material properties and the next generation of rare-earth-free motors.”\n</p><p>\n\tAt the November press conference, GM Ventures’ Daniels and two members of GM’s communications team declined to say when GM expected the iron-nitride magnets to be ready for use in a mass-market EV traction motor. But in an interview with<em> Spectrum</em> this past March, Niron’s executive vice president, <a href=\"https://theorg.com/org/niron-magnetics/org-chart/andy-blackburn\" rel=\"noopener noreferrer\" target=\"_blank\">Andy Blackburn</a>, suggested that magnets suitable for use in EV motors could be available as soon as 2025.\n</p>"},"pubDate":"Wed, 15 Nov 2023 20:30:02 +0000","guid":"https://spectrum.ieee.org/permanent-magnet-motor","category":["Rare earth elements","Electric motors","Permanent magnets","Permanent magnet motor"],"dc:creator":"Glenn Zorpette","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-man-in-safety-goggles-looks-at-a-donut-shaped-piece-of-material-under-a-blue-light.jpg?id=50484301&width=980"}},{"title":"How Will AI Affect the Semiconductor Industry?","link":"https://spectrum.ieee.org/how-will-ai-change-semiconductors","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-group-of-people-sitting-in-chairs-on-a-stage-talking-to-an-audience.jpg?id=50473038&width=1200&height=800&coordinates=248%2C0%2C0%2C0\"/><br/><br/><p>How is AI going to impact the business of making chips? A panel of semiconductor-company veterans tackled that question last week at Silicon Catalyst’s annual Semi Industry Forum, held in Menlo Park, Calif., on 9 November. The group speculated about how and when AI will upend the way chips are designed and just how strange a place the coming “AI wonderland” will turn out to be. (<a href=\"https://siliconcatalyst.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Silicon Catalyst</a> is <a href=\"https://spectrum.ieee.org/semiconductor-startups-get-their-own-accelerator\" target=\"_self\">a startup accelerator</a> focused on semiconductor companies.)</p><p>“We are entering an era of electronic design creation,” said <a href=\"https://www.amd.com/en.html\" rel=\"noopener noreferrer\" target=\"_blank\">AMD</a> senior vice president Ivo Bolsens. He predicted that AI will soon be able to flesh out most of a chip’s design from high-level specifications. However, he indicated, AI won’t be able to cover the last mile in the foreseeable future.</p><p>Bolsens used a recent trip to Austin as an analogy. “I fly to Austin, take a car to the parking lot of the office, then I walk into the building,” he said. “AI is the flying; it gets you quickly very close to where you need to be. From there, you have to have more traditional ways of doing things. That’s the opportunity AI delivers to chip designers. It just won’t take the last steps from parking lot to office.”</p><p class=\"pull-quote\">If you don’t think of [AI] as a paradigm break or something that can put you out of business, you’re in trouble.” <strong>—Deirdre Hanford, Synopsys</strong></p><p><a href=\"https://www.synopsys.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Synopsys</a>’s chief security officer, Deirdre Hanford, said her company is already “wrapping an AI harness around our [design] tools.” Throughout the industry, she said, “People are currently playing around to figure out where AI can be deployed in the chip design process.” (Synopsys unveiled its generative AI, <a href=\"https://news.synopsys.com/2023-11-15-Synopsys-Announces-Synopsys-ai-Copilot,-Breakthrough-GenAI-Capability-to-Accelerate-Chip-Design\" target=\"_blank\">Synopsys.ai Copilot</a>, a week after Hanford spoke.)</p><p>Moshe Gavrielov, former <a href=\"https://www.linkedin.com/company/xilinx/\" rel=\"noopener noreferrer\" target=\"_blank\">Xilinx</a> CEO and now a member of <a href=\"https://www.tsmc.com/english\" rel=\"noopener noreferrer\" target=\"_blank\">TSMC</a>‘s board of directors, was more specific. AI will soon be used, he indicated, for building <a href=\"https://spectrum.ieee.org/nmos\" target=\"_blank\">standard cell </a>libraries. Building such libraries is “very complex,” he said, “with a lot of corner cases. Computers can generate these libraries with less manpower, at a higher quality, and higher density.”</p><h2>AI Takes on Analog Circuit Design</h2><p>Gavrielov also pointed to the power of AI in dealing with analog circuitry. “AI can take analog libraries and move them from generation to generation [of technology] automatically; this used to be incredibly time consuming, error prone, and difficult.”</p><p>How soon is this change coming? “Benefits to the end customer will be very visible in a short time frame,” Gavrielov says. “There is a threshold, and once we cross that threshold the dam will burst, and it will be amazing to see the revolution in [chip] design that will happen.”</p><p>Gavrielov recalled the transition to electronic-design automation (EDA), the last big change in chip design. That transition, he says, was a 30-plus-year process. “I think the transition that AI will bring will happen in a third to a fifth of the time and will have a much bigger impact,” he said. “In five years, for sure in less than 10 years, design will be done in a very different way than today.”</p><p>But, assured Hanford, there’s no need for chip designers to panic.</p><p>“We will keep automating as an industry and it will accelerate,” she said, “but people, I don’t think our industry is facing the same threat as, say, paralegals; we will just move up in abstraction.”</p><h2>Reducing AI’s Carbon Footprint</h2><p>Looking at the effects of AI beyond its impact on the design process, moderator David French, Silicon Catalyst board member and CEO of <a href=\"https://sigmasense.com/\" rel=\"noopener noreferrer\" target=\"_blank\">SigmaSense</a>, asked the panelists to consider the impact of AI on the environment. He pointed out concerns about the energy consumed and carbon generated by the massive amounts of computing needed to create AI models.</p><p>“We have taken existing architectures and extrapolated from them to cater to the emerging needs of AI,” AMD’s Bolsens said. And “they are being used in an inefficient way, typically only exploiting 10 or 20 percent of the compute capabilities of the hardware [and] wasting a lot of power.”</p><p>“These are early innings, sloppy innings,” said Gavrielov.</p><p>Much can be done, Bolsens indicated. “The good thing about AI is that it is a narrow class of problems, in terms of characteristics of the compute it requires,” he said. “So new compute architectures will arise that take advantage of that to be more efficient.”</p><p>“And AI is not just about compute, it is about data,” Bolsens continued. “A lot of power consumed today is moving data to compute. So you will see solutions where you bring the compute to the data and new memory architectures where you bring compute to the memory, to avoid the power that goes into transferring the data around.”</p><h2>The AI Haves and Have-Nots</h2><p>The amount of computing power required to do AI research is causing a split between the haves (giant corporations) and the have-nots (universities and small startups). “A startup doesn’t have enough compute hours” to do AI research, Hanford said, pointing out that university computer resources usually aren’t enough either.</p><p>“If you really want to do research in this space, you have to go to Meta or Microsoft or have a very well-funded startup,” she said. “We should make sure that crazy research keeps getting done at universities,” she added, and that will require creating something like a national AI resource.</p><p>The trend toward open-source projects will help, Bolsens said. “That allows people to leverage work from others in the field.”</p><p>Hanford had a final warning for the audience of chip-company executives, entrepreneurs, and investors: “Every single group has to think about how AI will disrupt their mission or make them more productive. AI should change every function of an enterprise, large or small. If you don’t think of it as a paradigm break or something that can put you out of business, you’re in trouble.”</p>"},"pubDate":"Wed, 15 Nov 2023 16:26:29 +0000","guid":"https://spectrum.ieee.org/how-will-ai-change-semiconductors","category":["Ai","Carbon emissions","Standard cells","Chip design"],"dc:creator":"Tekla S. Perry","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-group-of-people-sitting-in-chairs-on-a-stage-talking-to-an-audience.jpg?id=50473038&width=980"}},{"title":"A New Enterprise Linux Alliance","link":"https://spectrum.ieee.org/suse-oracle-ciq-linux","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/image.jpg?id=46469653&width=980\"/><br/><br/><iframe frameborder=\"no\" height=\"180\" scrolling=\"no\" seamless=\"\" src=\"https://share.transistor.fm/e/55ee6462\" width=\"100%\"></iframe><p style=\"\">\n<strong>Stephen Cass: </strong>Hello and welcome to <em>Fixing the Future</em>, an <em>IEEE Spectrum</em> podcast where we look at concrete solutions to some big problems. I’m your host, Stephen Cass, a senior editor at IEEE Spectrum. And before we start, I just want to tell you that you can get the latest coverage from some of Spectrum’s most important beats, including AI, climate change, and robotics, by signing up for one of our free newsletters. Just go to spectrum.ieee.org/newsletters to subscribe.\n</p><p style=\"\">\n\tToday, our guest is <a href=\"https://www.linkedin.com/in/alanhclark/\" rel=\"noopener noreferrer\" target=\"_blank\">Alan Clark</a> from SUSE’s CTO office. <a href=\"https://www.suse.com/\" rel=\"noopener noreferrer\" target=\"_blank\">SUSE</a> is one of the oldest open-source companies in the world. I think I still have some SUSE Linux CD-ROMs from the 1990s lurking in a drawer myself. But it’s now a founding member of one of the newest trade associations, the <a href=\"https://openela.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Open Enterprise Linux Association</a>, or OpenELA, along with <a href=\"https://www.oracle.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Oracle</a> and <a href=\"https://ciq.com/\" rel=\"noopener noreferrer\" target=\"_blank\">CIQ</a>. We’re going to be talking with Alan about the crisis that prompted the creation of the OpenELA and how the new association hopes to address it. Alan, welcome to the show.\n</p><p style=\"\">\n<strong>Alan Clark: </strong>Thanks, Stephen. It’s great to be here. And by the way, I wish I had kept those floppies and CDs from those old releases, just for the museum piece, right?\n</p><p style=\"\">\n<strong>Cass: </strong>Yeah, they’re just deep, deep in a drawer in that. I cannot— can I toss that? No. No, I can’t. But I mentioned a crisis. For people who aren’t familiar with the world of enterprise Linux and the companies involved, can you explain what happened earlier this year that really upset a lot of people?\n</p><p style=\"\">\n<strong>Clark: </strong>Yeah, so there was an action by <a href=\"https://www.redhat.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Red Hat</a> that upset a lot of people. We can talk about why, but it’s actually been a trend for quite a while. And then they made the announcement that they were going to remove public access to the RHEL source code. And that’s really contrary to open source principles and values, right? And so that created a lot of concerns amongst vendors, developers, and users of the technology, right?\n</p><p style=\"\">\n<strong>Cass:</strong> So RHEL is Red Hat Enterprise Linux.\n</p><p style=\"\">\n<strong>Clark:</strong> Yes.\n</p><p style=\"\">\n<strong>Cass: </strong>And why is it so important that it would cause so many people to go, “Bah”?\n</p><p style=\"\">\n<strong>Clark: </strong>Well think about it from open-source perspectives, right? Open source has always had the meaning that I can take that and do things with it, right? I can create innovation and I can use it for the things that fit my need. And then all of a sudden now, they’ve switched the game and people are going, “Wait, will I not be able to use this anymore? Will I not be able to use it how I need it to be used, right? Is this going to kill my innovation?” And so that’s caused great consternation, not just from other vendors that are part of the ecosystem, but from users themselves.\n</p><p style=\"\">\n<strong>Cass: </strong>And this is because Red Hat was also a very early entrant, it’s been around a long time, and so people have kind of coalesced around it in many ways. And so this was a bit of a shock to them.\n</p><p style=\"\">\n<strong>Clark:</strong> It is a bit of a shock, and two aspects of that. One is you’re exactly correct, there’s a lot of people that have been using this technology for a long time and based their business on it. And then the second aspect, when you think about it, I’m sure it’s upwards of 90 percent of businesses are using open source today, right? So they’ve caught on to the benefits that open source brings, and then all of a sudden you’re saying, “Well, this isn’t quite so open,” and they’re going, “Wait, my business is built on those concepts of open source, and now you’re ripping that away. What does this mean to me?”\n</p><p style=\"\">\n<strong>Cass:</strong> So maybe just for readers who might not be familiar, because <a href=\"https://www.linux.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Linux</a> comes in so many different flavors. It’s found everywhere from satellites to mainframes. What is kind of the defining characteristic of enterprise Linux?\n</p><p style=\"\">\n<strong>Clark:</strong> So enterprise Linux, and you’re correct, it does come in all kinds of flavors from very small to very large, right? The enterprise portion of this is that it’s ready to run your critical business processes, right? That’s what we define as being enterprise ready. So I can use it in a hobby situation, right? And there’s a lot of distros that are attuned to specific hobby needs, right? I know people that run HO scale railroad systems using Linux, for example. Well, if it has a fault and crashes, it’s not a big deal. You put the train back on the track and away it goes. If you’re using Linux for air traffic control, right, that has got to be really hardened and tested and secure. And so that’s what the enterprise portion of this means.\n</p><p style=\"\">\n<strong>Cass:</strong> So can you talk a little bit about the genesis of OpenELA? So we have this controversy, people are unhappy with what Red Hat has been doing. How is it that Oracle and CIQ and SUSE kind of like pick up the <a href=\"https://en.wikipedia.org/wiki/Bat_phone\" rel=\"noopener noreferrer\" target=\"_blank\">bat phone</a> and call each other and start this ball rolling?\n</p><p style=\"\">\n<strong>Clark: </strong>Well, so their announcement spurred us to say, “Oh, we should do something and we should react to this.” But on the other hand, part of this has come about just because the power of collaboration, right? And the simplest aspect of that is we’re reducing cost, right, by sharing that cost. And those are the costs of getting a code and assembling it and putting it in a format where we can consume it. It’s not a market differentiator. And so by sharing that cost amongst us, we’ve reduced it for everybody, and it makes it quicker to market, reduces our costs. The other aspect of it is— that I think is key and why we really want others and others want to come join us is we’re preventing the market from fragmenting, right? Like you said, there’s all kinds of distros out there, but we’re looking to continue on with this enterprise Linux standard that Red Hat has set. And if we all go off and do our own little thing, there’s a chance it’ll fragment. And we know what happens when that occurs, right? You look back at the Unix days and you cause that fragmentation and all of a sudden you can’t get applications and services that work on everybody’s distros, right? By pulling together, unifying together, we’re going to keep that market whole.\n</p><p style=\"\">\n<strong>Cass: </strong>And what is now OpenELA actually going to do in concrete terms in terms of stopping that fragmentation from happening and maintaining a standard sort of independent of Red Hat’s current offerings?\n</p><p style=\"\">\n<strong>Clark: </strong>Yeah. So the first thing— one of the big things we’re working on is creating a neutral legal body, right, so that it’s not controlled by any single vendor, right? So we’ve all come together, big, small, whatever, it doesn’t matter. We’re all going to be equal players, right? So that’s key in building good open source practices. So the second thing we’ve done or are working on is building the ability to have the source code that is, we’ll call it pristine. It’s in line and in tune with what Red Hat has been producing, right? And we will keep that compatibility. We want to keep that compatibility. And so we’re setting up the code repository so that we can keep that compatibility. But then we’re also setting them up so that innovation can occur. And so I’ll be able to come in there and say, “I just want to stay in step with the standard that Red Hat is setting. And that’s what I want. I don’t want anything else.” Others will be able to come in and say, “I want to contribute this piece.” And they’ll be able to pick up that as well as the one-to-one compatibility. So those are the big things we’re working on right now.\n</p><p style=\"\">\n<strong>Cass: </strong>When the announcement was made to launch OpenELA, you did say, yes, it’s going to be under control of a nonprofit board of directors and the bylaws will be published shortly. So how are the formation of the board and the creation of the bylaws going?\n</p><p style=\"\">\n<strong>Clark:</strong> They’re coming along quite well, actually. I smile because this is one of those things that always takes longer than you want, right? But they are coming along. Legal things are always slow, slower than you want them to be. But they’re moving along quite well. We’ve actually are pushing ahead with a stronger-- I wouldn’t say stronger. Very concerted effort to get the technical stuff done, because that’s really the proof of it, right, that we can actually get the code out there and make it available to everybody. So we’ve been putting a really large amount of effort into getting that completed as well.\n</p><p style=\"\">\n<strong>Cass:</strong> And how is that development? You talked about organizing source code, and also there’s creation of software tooling that has to go along with that. How is that work going? I mean, is it being evenly distributed across sort of the three founders, or is one group taking a lead at this particular moment, or is it all being done in parallel? How is that work being done?\n</p><p style=\"\">\n<strong>Clark:</strong> It’s working out very well. You recognize that these companies have been doing this for years, right? So we don’t have to reinvent everything, right, or invent everything. It’s already being done. So it’s more a matter of taking the best of everything we’ve got and putting it into a format that we know will be usable by everybody. So we don’t have to start from scratch. We’re able to pick up a lot of the tools and stuff that are already being used and tune them and modify them to fit OpenELA.\n</p><p style=\"\">\n<strong>Cass: </strong>So OpenELA was founded just a couple of months ago, so I appreciate it’s very early days. But what kind of response have you had from the wider community?\n</p><p style=\"\">\n<strong>Clark: </strong>It’s been very positive, really positive. We have a lot of people that are anxious to get started. A lot of people have been pinging us going, “Hey, we want to contribute. We want to join. How do I do that?” And we’re going, “Hang on just a little bit longer, just a little bit longer.” We really got to get that legal entity so that it’s a neutral body, right? We don’t want it to be not neutral. So we got to get those rules down on how people can join and so forth. So they’re coming out really soon, so.\n</p><p style=\"\">\n<strong>Cass: </strong>So looking to the future, we talked about maintaining the sort of enterprise Linux standard, which is closely based on the Red Hat de facto standard. Do you foresee a time in the future where maybe those might diverge? And so you have the OpenELA enterprise Linux standard, and then over here is RHELs. And maybe those two aren’t tightly as coupled before. One is RHELs thing, and the other is this open source community thing.\n</p><p style=\"\">\n<strong>Clark:</strong> I don’t have a crystal ball, so I don’t know what will happen. Right now, our mission is that we will stay one-to-one compatible with them. If they make some decisions that personally, I believe would actually very much hurt them, themselves, right, self-inflicted wounds kind of thing, it’s possible they could do something. But you also have to remember that everything we’re dealing with here is open source, right? And it’s open source that SUSE has been contributing to, like you said, what, 30-something years? Oracle, the same thing, they contributed for years and years and years in CIQ and all these other community members. So it’s all open source. So unless they do something really dramatic and go proprietary, even more proprietary, right, it all feeds back upstream. So it’s all going to be available. So I’m not overly worried about it, given their current decisions, that we’ll be able to stay one-to-one compatible.\n</p><p style=\"\">\n<strong>Cass: </strong>So just I want to step back for a moment while I have you and just look at some big question issues. I talk about Linux in the ‘90s, and the first time I touched a Linux machine was as an undergraduate in the early ‘90s, when it was this very fascinating, if somewhat clunky thing. And we’ve had this evolution with people like <a href=\"https://www.linkedin.com/in/linustorvalds/\" rel=\"noopener noreferrer\" target=\"_blank\">Linus Torvalds</a> has been the guy for 30 years and so on. And we’re kind of— I know I’m not as young as I used to be, and we’re kind of coming to this generation inflection point with Linux, where sort of a new cadre of people are coming up and using it. What are your thoughts about how sort of open source has evolved in 30 years? Is it recognizable from those early days to what is now? And where do you think it’s going to go as we start to see people in the next 10, 15 years start to retire and a new generation take over?\n</p><p style=\"\">\n<strong>Clark:</strong> Well, the beauty of open source is sometimes people say, “Well, it’s like herding cats,” because you’ve got so many people involved, right, and they’re all there to serve their own needs, right? Some will say that’s bad. I say that’s really good. But what it’s proven out over the years— and yeah, it has changed, it’s grown, right? I’ve seen these projects. Some of these projects that I’m involved with have thousands of engineers, right? And a couple of things that I’ve seen happen over the years is they’ve become very diverse geographically and people wise, just the different varying talents and skills and backgrounds has really grown over the years. And the big thing is, is I’ve seen this talent emerge. And because of the collaborative nature, it’s not that a single person has all the knowledge, right? I’ve worked in proprietary software, and you end up depending on this key guy that knows it all, right? And the company sits and worries about what if the train hits this guy tomorrow and he dies? What’s the company going to do, right? The stock will crash or whatever. I’m not as worried about that with open source, because there’s so much. It’s so open and transparent that people with all these different talents are able to come in and become a real critical piece to this. And so I think that with that talent pool, I’m not worried about the future of open source. It’ll just keep rolling on. We’ve got some real good leaders today. I do not want to see them disappear, right? People like Linus, they are a key, they are really key. But open source will continue to grow and move on.\n</p><p style=\"\">\n<strong>Cass: </strong>So I just want to finish up. Is there any question you think I should have asked you, which I haven’t asked you?\n</p><p style=\"\">\n<strong>Clark:</strong> That’s always the catch-all question, isn’t it? No, I think we’ve talked about a lot of good things. I’m just very excited about the future of open source and the potential that it brings, right, the innovation. I see all these new concepts. I remember when I first started, I started in engineering and networking, right? And TCP/IP developed and everybody says, “It’s done.” Right? “TCP/IP, it’s done. Let’s all move on to something else.” Right? And then all of a sudden it was like, oh, wait a minute, we didn’t write TCP/IP with enough addresses to cover the world. We never envisioned that everybody would have 10 devices in their house, let alone 100. And all of a sudden, you got to invent again, right? And so I just think there’s so much new technology to be invented that I’m very excited about the future.\n</p><p style=\"\">\n<strong>Cass:</strong> Wonderful. So today we were talking with Alan Clark of SUSE. Thank you so much for coming on the show.\n</p><p style=\"\">\n<strong>Clark:</strong> Thank you, Stephen.\n</p><p style=\"\">\n<strong>Cass:</strong> And Alan was talking about the new OpenLinux Enterprise Association. And for more information on that, you can visit their website, which is openela.org, I believe.\n</p><p style=\"\">\n<strong>Clark: </strong>Correct.\n</p><p style=\"\">\n<strong>Cass: </strong>And yeah, please come back and check out in two weeks’ time another episode of <em>Fixing the Future</em> here from IEEE Spectrum.\n</p>"},"pubDate":"Wed, 15 Nov 2023 10:00:02 +0000","guid":"https://spectrum.ieee.org/suse-oracle-ciq-linux","category":["Type:podcast","Software","Linux","Red hat","Oracle","Suse","Open source","Fixing the future"],"dc:creator":"Stephen Cass","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://assets.rbl.ms/46469653/origin.jpg"}},{"title":"IEEE Life Members to Hold Their First Conference","link":"https://spectrum.ieee.org/ieee-life-members-first-conference","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/rear-view-of-people-sitting-in-chairs-looking-at-someone-speaking-in-background.jpg?id=50467563&width=1200&height=800&coordinates=0%2C21%2C0%2C188\"/><br/><br/><p><a href=\"https://life.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">The IEEE Life Members Committee</a> plans to hold its first <a href=\"https://lifemembersconference.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">conference</a> from 14 to 16 April in Austin, Texas. </p><p>Open to all interested technology enthusiasts, the event is centered on the theme of Evolution: Technology, Applications, and Contributions. The conference is expected to bring together technology professionals from across the globe to explore emerging technologies and how they impact senior citizens.</p><p>IEEE life members are technology innovators and pioneers, working together to mentor students, participate in educational excursions, and improve their communities. The life member designation is for those who have reached the age of 65 and have been with IEEE for such a period of time that the sum of their age and their years of membership equals or exceeds 100.</p><p>“Because IEEE life members come from all IEEE’s fields of interest and are loaded with many years of experience, we can provide an engaging conference for all ages,” says Life Member <a href=\"https://www.linkedin.com/in/kirpalsinghkhalsa\" rel=\"noopener noreferrer\" target=\"_blank\">Kirpal Singh Khalsa</a>, one of the event’s two communications cochairs.</p><p style=\"\">“We want to empower and equip attendees with the knowledge and insights necessary to navigate the transformative landscape of technological advancements—deepening their understanding of how emerging technologies will shape their lives,” adds Senior Life Member <a href=\"https://life.ieee.org/regional-coordinator-highlight-terry-branch/\" rel=\"noopener noreferrer\" target=\"_blank\">Terry Branch</a>, conference vice chair.</p><p class=\"pull-quote\" style=\"\">“Our hope is to capture the wealth of experiences from IEEE life members and provide them an opportunity to continue to contribute to the profession that has been an integral part of their lives.” <strong>—Maxine Cohen</strong></p><p style=\"\">The event will include engaging talks, interactive workshops, and panel discussions with experts from a wide variety of technology fields, organizers say, adding that speakers will share their insights and experiences, providing valuable lessons and inspiration. Scheduled speakers include Life Fellow <a href=\"https://spectrum.ieee.org/robust-ai-rodney-brooks\" target=\"_self\">Rodney Brooks</a>, Senior Member <a href=\"https://en.wikipedia.org/wiki/Whurley\" rel=\"noopener noreferrer\" target=\"_blank\">Whurley</a>, and Life Fellow <a href=\"https://spectrum.ieee.org/smarts-producting-payoffs-in-power-distribution\" target=\"_self\">John McDonald</a>. </p><p>“Conference attendees will also have the opportunity to interact with company representatives and speakers to contribute to the design of the next generation of products and services that will be offered to senior citizens,” says Senior Life Member <a href=\"https://life.ieee.org/regional-coordinator-highlight-mark-andrews/\" rel=\"noopener noreferrer\" target=\"_blank\">Mike Andrews</a>, the conference chair. “We embrace the fact that learning never stops, that we can continue to make a difference and remain active participants in life and technology.”</p><p>Senior Life Member <a href=\"https://life.ieee.org/life-member-highlight-maxine-cohen/\" rel=\"noopener noreferrer\" target=\"_blank\">Maxine Cohen</a>, the conference’s other communications cochair, adds, “Our hope is to capture the wealth of experiences from IEEE life members and provide them an opportunity to continue to contribute to the profession that has been an integral part of their lives. The conference will provide time to listen, chat, and connect with speakers, peers, and other professionals.” </p><p>Austin is home to cutting-edge technology companies, and tours are planned for conference attendees and their guests. Cohen is designing a companion program for attendees’ guests.</p><p style=\"\">To register, visit the conference <a href=\"http://lifemembersconference.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">website</a>.</p>"},"pubDate":"Tue, 14 Nov 2023 19:00:01 +0000","guid":"https://spectrum.ieee.org/ieee-life-members-first-conference","category":["Conference","Ieee life members","Ieee news","Type:ti"],"dc:creator":"IEEE Life Members Committee","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/rear-view-of-people-sitting-in-chairs-looking-at-someone-speaking-in-background.jpg?id=50467563&width=980"}},{"title":"Speaker Chip Uses Ultrasound to Crack Volume Limits","link":"https://spectrum.ieee.org/mems-speakers-xmems","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/two-squares-float-above-a-black-disk-in-front-of-a-black-background.jpg?id=50461164&width=1200&height=800&coordinates=14%2C0%2C14%2C0\"/><br/><br/><p>Despite having heard the song probably 50 times in the last two years, I discovered there are notes in David Bowie’s “<a href=\"https://en.wikipedia.org/wiki/Starman_(song)\" target=\"_blank\">Starman</a>” that I’d never heard until one morning in early November. That’s when I got to try a prototype noise-canceling earbud from <a href=\"https://xmems.com/\" target=\"_blank\"><sub></sub>xMEMS</a>. </p><p>The five-year-old startup specializes in making speakers from microelectromechanical systems (<a data-linked-post=\"2659889297\" href=\"https://spectrum.ieee.org/mems-speakers\" target=\"_blank\">MEMS</a>) silicon-and-piezoelectric chips. Its existing designs are <a href=\"https://us.creative.com/aurvanatws/\" target=\"_blank\">starting to appear in consumer devices</a>, and they have many advantages over today’s miniature speakers. Those previously hidden notes in “Starman” are just one of them. But their peak volume has never been enough to overcome a technical requirement of noise-cancelling earbuds—20 more decibels in the bass register. A new MEMS tech, called Cypress,  forms audible tones by generating and combining ultrasound and should give chip-scale speakers enough oomph for the job and maybe even lead the tech takeover for other small speakers, like those in cars and computers.</p><p>“Most conventional speakers generate sound by actuating and pushing a diaphragm; you’re pushing air to generate sound,” says <a href=\"https://www.linkedin.com/in/mike-housholder-3a25103/\" target=\"_blank\">Mike Householder</a>, vice president of marketing and business development at xMEMS. With Cypress, he says, “We’re actually going to use ultrasonic modulation and demodulation to create pressure and generate sound...this is fundamentally the first time humans are experiencing sound generated in a different way.”</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A tiny chip on a finger\" class=\"rm-shortcode\" data-rm-shortcode-id=\"8c8a9217e224661146e0cb987c3e4af4\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"3f89e\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-tiny-chip-on-a-finger.jpg?id=50461834&width=980\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-46546\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">The Cypress MEMS speaker chip is about 9 millimeters diagonally.</small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-346529\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">xMEMS</small></p><p>MEMS chips have already conquered the microphone market, <a href=\"https://www.yolegroup.com/product/report/consumer-mems-microphone-comparison-2022/\" target=\"_blank\">making up</a> the majority of microphones sold even five years ago, according to <a href=\"https://www.yolegroup.com/\" target=\"_blank\">the Yole Group</a> market research firm. But speakers demand something different from MEMS, explains Householder. They have to propel a volume of air, rather than be pushed by it. <a href=\"https://spectrum.ieee.org/mems-speakers\" target=\"_blank\">xMEMS speakers</a> going into products <a href=\"https://us.creative.com/aurvanatws/\" target=\"_blank\">now</a> are chips with multiple silicon flaps coated in piezoelectric material that vibrate at audible frequencies.</p><p>XMEMS has already delivered a number of advantages of MEMS technology. MEMS chips that specialize in audible frequencies include very low phase distortion. That’s the variation in the timing of an acoustic signal according to its frequency. In an <a href=\"https://spectrum.ieee.org/mems-speakers\" target=\"_blank\">earlier article,</a> <a href=\"https://magicgardenmastering.com/\" target=\"_blank\">Brian Lucey</a>, a mastering engineer who has worked on 9 Grammy-winning albums, told <em>IEEE Spectrum</em>:</p><blockquote>“Phase inaccuracy is so ubiquitous that we simply accept it.... Driver technology up to now has never been able to be this accurate. It’s really not a question of what does it sound like when it’s inaccurate, because that’s just normal to our ears. It’s more a question of what does it sound like when it’s this near perfectly accurate.... Everything is hitting you at the same time. There’s no time smear in the way the sound comes across.”</blockquote><p>From a manufacturing and engineering standpoint, MEMS is a win, as well, argues Householder. For one thing, it’s a less complex system, made up of just a single packaged chip and an accompanying IC instead of a complex assembly of coil, magnet, diaphragm, and other parts. Coil speakers require labor-intensive manufacturing and testing, partly because of inconsistencies from unit to unit. And MEMS allow for easier earbud design, because they don’t cause electromagnetic interference like coil speakers and they don’t require a particular volume of air at the back of the earbud to improve sound quality.</p><h2>MEMS Noise-Cancellation Problem</h2><p>All that is enough for some applications, but for “true wireless stereo” earbuds there’s a catch. If you have a pair, and you probably do, you’ll notice a tiny air vent. It’s there for three reasons, Householder explains. One is to vent uncomfortable pressure from between the bud and your ear canal. Another is to reduce an odd effect where your own voice gets amplified inside your head. And the third is to facilitate active noise cancellation.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A rendering of an earbud with a chip inside.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"29649971354e92ca02a20ae319c7cfdd\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"cb1b0\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-rendering-of-an-earbud-with-a-chip-inside.jpg?id=50461820&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">The Cypress MEMS speaker chip is loud enough to accommodate active noise canceling without an additional woofer.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">xMEMS</small></p><p>Active noise cancellation relies on algorithms that assume a relatively stable seal between the bud and your ear. But real life doesn’t work that way. The buds shift in ordinary use and the seal is not consistent. The vent is meant to be a much larger leak in the system than any small breaks in the seal, overwhelming the small changes and allowing the noise-cancellation algorithm to do its work, Householder explains.</p><p>“The downside is when you open air to a speaker,” it effects low frequencies, he says. “That’s just the physics of speakers.” In an earbud you’ll typically lose about 20 decibels of low frequency, he says. On their own xMEMS speakers in devices today can hit 120 dB, and, yes, that’s a pretty unhealthy level already. But to cancel out the jackhammers and jet engines of the world, you need 140 dB at low frequency.</p><p>To make up the difference with a MEMS device, designers currently pair it with a coil speaker that’s used as a woofer. But xMEMS new ultrasound tech can do the complete job on its own, says Householder.</p><h2>How xMEMS Ultrasound Tech Works</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Three boxes with arrows between them, and a sine wave signal.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"e142f2642acc135ae8994d30db80758e\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"97c23\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/three-boxes-with-arrows-between-them-and-a-sine-wave-signal.jpg?id=50461813&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Ultrasound is shaped into pulses with an envelope at an audio frequency.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">xMEMS</small></p><p>In the first step, a custom IC modulates an ultrasound carrier signal with the audio signal. The result is an ultrasound signal whose amplitude is the shape of the audio signal. This combined signal drives a pair of cantilevers that turn the signal into ultrasonic pressure waves inside the speaker chamber. A second signal then periodically vents the chamber, producing a series of pressure spikes whose envelope is the audio signal we hear.</p><p>The new chip is effectively 40 times as loud, reaching more than 140 dB even at the lowest end of human hearing, 20 hertz. And that’s good enough to do the job of active noise cancellation. Just as important, it gives the technology a path to consumer products that need even more volume, such as smartphones and laptops.</p><p>Certain early customers are already sampling the prototype Cypress chips, and production samples are set to ship in June 2024, with mass production set for late 2024.</p>"},"pubDate":"Tue, 14 Nov 2023 18:15:35 +0000","guid":"https://spectrum.ieee.org/mems-speakers-xmems","category":["Audio electronics","Earbuds","Mems","Piezoelectric","Speakers"],"dc:creator":"Samuel K. Moore","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/two-squares-float-above-a-black-disk-in-front-of-a-black-background.jpg?id=50461164&width=980"}},{"title":"Thermal Transistors Handle Heat With No Moving Parts","link":"https://spectrum.ieee.org/thermal-transistor","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/close-up-of-a-computer-chip-with-an-orange-wavy-line-coming-out-the-middle.jpg?id=50442936&width=1200&height=800&coordinates=0%2C75%2C0%2C75\"/><br/><br/><p style=\"\">Electronic transistors are central to modern electronics. These devices precisely control the flow of electricity, but in doing so, they generate heat. Now, researchers at the University of California, Los Angeles have developed a solid-state <em>thermal </em>transistor—the first device of its kind that can use an electric field to control the flow of heat through electronics. Their study, which was recently <a href=\"https://www.science.org/doi/10.1126/science.abo4297?adobe_mc=MCMID%3D80093549277727036801369131698673845939%7CMCORGID%3D242B6472541199F70A4C98A6%2540AdobeOrg%7CTS%3D1699466887\" rel=\"noopener noreferrer\" target=\"_blank\">published in <em>Science</em></a>, demonstrates the capabilities of the new technology. </p><p style=\"\">“There has been a strong desire from engineers and scientists to control heat transfer the same way we control electronics, but it has been very challenging,” says study lead author <a href=\"https://samueli.ucla.edu/people/yongjie-hu/\" rel=\"noopener noreferrer\" target=\"_blank\">Yongjie Hu</a>, a professor of mechanical and aerospace engineering at UCLA. </p><p style=\"\">Historically, electronics have been cooled down with heat sinks that passively draw the excess heat away. More active approaches to thermal management have also been proposed, but these often rely on moving parts or fluids and can take a long time—typically minutes to hours—to ramp up or ramp down the material’s thermal conductivity. With thermal transistors, the researchers can actively modulate the flow of heat faster and with more precision. This speed makes them a promising option for managing heat in electronic devices. </p><p class=\"pull-quote\" style=\"\">“I think we are living in a kind of thermal renaissance.” <strong>—Miguel Muñoz Rojo, Materials Science Institute of Madrid</strong></p><p style=\"\">Analogous to an electronic transistor, the UCLA group’s thermal transistor also uses electric fields to modulate the conductance of a channel, in this case thermal conductance rather than electrical. This is done with a thin film of cagelike molecules engineered by the researchers that acts as the channel of the transistor; applying an electric field makes the molecular bonds in the film stronger, which increases its thermal conductance. “Our contribution was literally only one molecule thin,” says <a href=\"https://www.chemistry.ucla.edu/directory/weiss-paul-s/\" rel=\"noopener noreferrer\" target=\"_blank\">Paul Weiss</a>, a professor of chemistry, bioengineering, and materials science at UCLA and the study’s coauthor.</p><p style=\"\">With that single-molecule layer, the researchers were able to reach the maximum change in conductivity at a frequency of more than 1 megahertz, several orders of magnitude faster than other heat-management systems. Molecular motion typically controls heat flow in other types of thermal switches. But molecular motion is quite slow compared with the motion of electrons, explains Weiss. By leveraging electric fields, the researchers are able to speed up the switch from millihertz to megahertz frequencies. </p><p style=\"\">Molecular motion also can’t achieve as large a difference in thermal conductance between the on state and the off state. The UCLA device, by comparison, achieves a 13-fold difference. “It really is an enormous difference, both in terms of magnitude and speed,” Weiss says. </p><p style=\"\">With these improvements, the device could be important for cooling processors. The transistors are especially promising for semiconductors because they use a small amount of power to control the heat flow, compared with other routes of active energy dissipation. Many thermal transistors could also be integrated on the same chip in the same way that electronic transistors are, Hu says. </p><p style=\"\">In particular, thermal transistors could effectively manage heat in new semiconductor designs, such as in <a href=\"https://spectrum.ieee.org/amd-3d-stacking-intel-graphcore\" target=\"_self\">3D-stacked chiplets</a>, where they would reduce hot spots, thereby allowing for more freedom in the design of the chiplets. They may also help cool power electronics made from wide-bandgap semiconductors like <a href=\"https://spectrum.ieee.org/silicon-carbide\" target=\"_self\">gallium nitride and silicon carbide</a>, Hu says. </p><p class=\"pull-quote\" style=\"\">“Our contribution was literally only one molecule thin.” <strong>—Paul Weiss, UCLA</strong></p><p style=\"\">Beyond these applications in electronics, the UCLA researchers’ work on thermal transistors could also provide insights into molecular-level mechanisms of how living cells regulate temperature. Hu thinks there may be a similar effect connecting heat flow and electric potential at work in our cells. In a separate ongoing project, he is studying the mechanisms of ion channels—the proteins that act as gates to control the flow of ions across a cell membrane. When it comes to heat flow in the human body, “the macroscopic picture has been established in physiology; however, the molecular-level mechanism still remains largely unknown,” Hu says. </p><p style=\"\">“I think we are living in a kind of thermal renaissance,” says <a href=\"https://research.utwente.nl/en/persons/miguel-mu%C3%B1oz-rojo\" rel=\"noopener noreferrer\" target=\"_blank\">Miguel Muñoz Rojo</a>, a senior researcher at the Materials Science Institute of Madrid. Muñoz Rojo is excited about the possibility of thermal transistors adding to the stock of heat--management technologies, and is interested in the possibility of using them for a wide array of large-scale applications, like refrigeration, in addition to the nanoscale cooling of electronics. He and his colleague <a href=\"https://www.linkedin.com/in/andrej-kitanovski-42415949/?originalSubdomain=si\" rel=\"noopener noreferrer\" target=\"_blank\">Andrej Kitanovski</a>, a thermal-engineering professor at the University of Ljubljana, in Slovenia, are working together to develop these thermal-management technologies. For Muñoz Rojo, that range of potential uses makes thermal transistors the pinnacle of heat-management technology. </p><p style=\"\">The demonstration of this technology is an exciting advance and will likely motivate more fundamental research, says <a href=\"https://profiles.rice.edu/faculty/geoff-wehmeyer\" rel=\"noopener noreferrer\" target=\"_blank\">Geoff Wehmeyer</a>, an assistant professor of mechanical engineering at Rice University, in Houston. “It will be interesting to see if thermal engineers can find ways to integrate these molecular thermal switches into switchable thermal-management systems for electronics or batteries.”</p>While this proof of concept is promising, the UCLA researchers acknowledge that the technology is still early in its development. Going forward, Hu says they aim to further improve the device’s performance."},"pubDate":"Mon, 13 Nov 2023 15:00:03 +0000","guid":"https://spectrum.ieee.org/thermal-transistor","category":["Semiconductors","Solid-state","Thermal management","Transistors"],"dc:creator":"Gwendolyn Rak","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/close-up-of-a-computer-chip-with-an-orange-wavy-line-coming-out-the-middle.jpg?id=50442936&width=980"}},{"title":"MIT Professor’s IoT Sensors Make Roads Safer","link":"https://spectrum.ieee.org/mit-professor-iot-sensors","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/portrait-of-a-man-wearing-a-blue-button-up-shirt-against-a-light-background.jpg?id=50442683&width=1200&height=800&coordinates=0%2C0%2C0%2C209\"/><br/><br/><p style=\"\">\n\tBack in 2005, before smartphones were generally available, MIT Professor <a href=\"http://nms.csail.mit.edu/~hari/\" rel=\"noopener noreferrer\" target=\"_blank\">Hari Balakrishnan</a> was so fed up with commuting delays in Boston that he built a mobile system to monitor road conditions.\n</p><h3>​Hari Balakrishnan</h3><br/><p>\n<strong>Employer</strong>\n</p><p>\n\t MIT\n</p><p>\n<strong>Title</strong>\n</p><p>\n\t Professor\n</p><p>\n<strong>Member grade\n</strong></p><p>\n\tFellow\n</p><p><strong>Alma maters </strong></p><p>Indian Institute of Technology, Madras, and the University of California, Berkeley</p><p>\n\tHe and his research team at MIT’s <a href=\"https://www.csail.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Computer Science and Artificial Intelligence Laboratory</a> developed CarTel, short for <em>car telematics</em>. Using signal processing and machine learning, their sensing device for vehicles was able to infer the presence of potholes and other impediments from changes in traffic flow, which it measured with GPS and an accelerometer. Their research won several awards, and the system was covered by <a href=\"https://www.bostonglobe.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>The Boston Globe</em></a>.\n</p><p>\n\tIn 2010 Balakrishnan and two cofounders commercialized CarTel by launching <a href=\"https://www.cmtelematics.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Cambridge Mobile Telematics</a>. Today the Massachusetts company is the largest telematics service provider in the world. Insurance companies, car manufacturers, rideshare services, and public agencies use CMT data to assess driver behavior, encourage safer driving, dispatch roadside assistance, and more.\n</p><p>\n\tBalakrishnan, an IEEE Fellow, is this year’s <a href=\"https://marconisociety.org/awards-gala-2023/\" rel=\"noopener noreferrer\" target=\"_blank\">Marconi Prize</a> winner for his “fundamental discoveries in mobile sensing, networking, and distributed systems.” The award, given by the <a href=\"https://marconisociety.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Marconi Society</a>, is considered to be the top honor in communications.\n</p><p style=\"\">\n\t“On paper this award honors me, but it really is a recognition of my 30-plus Ph.D. students, postdocs, collaborators, and the team at CMT who have worked incredibly hard in creative ways to take research ideas and have them really impact the world,” he says. “It honors the field of mobile sensing and networked systems.”\n</p><p class=\"shortcode-media shortcode-media-youtube\" style=\"\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"a3551c5bcc3cebf39549b7a2522a84ff\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Lezw6UAZgls?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Hari Balakrishnan talks to the Marconi Society about his career highlights and his thoughts on receiving the prize.</small>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Marconi Society</small>\n</p><h2 style=\"\">Using data to make driving safer<br/>\n</h2><p>\n\tBalakrishnan came up with the idea for CarTel while talking with fellow MIT Professor <a href=\"https://db.csail.mit.edu/madden/\" rel=\"noopener noreferrer\" target=\"_blank\">Samuel Madden</a>, a director of the university’s <a href=\"https://dsail.csail.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Data Systems and AI Lab</a> and an expert on data management and sensor computing.\n</p><p>\n\t“I told him we should start a research project that takes sensors that we both know a lot about, attach them to cars, measure what’s happening, and then try to understand the data,” Balakrishnan recalls. “This was before <a href=\"https://www.apple.com/iphone/\" rel=\"noopener noreferrer\" target=\"_blank\">iPhones</a>, <a href=\"https://www.android.com/phones/\" rel=\"noopener noreferrer\" target=\"_blank\">Androids</a>, and <a href=\"https://www.google.com/maps\" rel=\"noopener noreferrer\" target=\"_blank\">Google Maps</a>.”\n</p><p>\n\tThey later founded CMT, with Madden serving as its chief scientist.\n</p><p>\n\t“CarTel was one of the first projects in mobile sensing,” Balakrishnan says. “We showed that it could work at scale.\n</p><p>\n\t“I was trying to figure out how to commercialize it using the notion of mobile sensing for social good.”\n</p><p>\n\tHelp came in 2009 from <a href=\"https://www.linkedin.com/in/wvpowers/\" rel=\"noopener noreferrer\" target=\"_blank\">William V. Powers</a>, a seasoned sales executive who became Balakrishnan’s business partner. He is also a CMT cofounder and the company’s CEO.\n</p><p style=\"\">\n\tBalakrishnan says that although the startup had the technology, it didn’t have a business model. After reading articles about how insurance companies were using expensive hardware to measure people’s driving to set premium prices and uncover fraudulent claims, they found their model.\n</p><p class=\"pull-quote\">“Our mission is to make the world’s roads and drivers safer.”</p><p>\n\t“It clicked in my head that we had shown, in principle, how to do that with consumer phones and inexpensive Internet of Things [IoT] devices that could be put into a car without professional installers,” he says.\n</p><p>\n\tThat early system evolved into <a href=\"https://www.cmtelematics.com/safe-driving-technology/how-it-works/\" rel=\"noopener noreferrer\" target=\"_blank\">DriveWell</a>, an AI-driven platform that gathers data from monitors including accelerometers, gyroscopes, and position sensors in smartphones, dashcams, and IoT devices such as the <a href=\"https://www.cmtelematics.com/drivewell-tag/\" rel=\"noopener noreferrer\" target=\"_blank\">DriveWell Tag</a>.\n</p><p>\n\tThe platform combines the information with contextual data to create a picture of how drivers are operating their vehicles, measuring factors such as hard braking, excessive speeding, and phone distraction, Balakrishnan says.\n</p><p>\n\t“Our mission is to make the world’s roads and drivers safer,” he says.\n</p><p>\n\tDriveWell has provided services to more than 30 million vehicles to date. Insurance companies including <a href=\"https://www.admiral.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Admiral</a>, <a href=\"https://www.discovery.co.za/portal/\" rel=\"noopener noreferrer\" target=\"_blank\">Discovery</a>, <a href=\"https://www.huk.de/\" rel=\"noopener noreferrer\" target=\"_blank\">HUK-Coburg</a>, <a href=\"https://www.ms-ad-hd.com/en/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">MS&AD</a>, and <a href=\"https://www.usaa.com/?akredirect=true\" rel=\"noopener noreferrer\" target=\"_blank\">USAA</a> use CMT’s programs to offer discounts to better drivers. CMT recently partnered with <a href=\"https://www.hyundaiusa.com/us/en\" rel=\"noopener noreferrer\" target=\"_blank\">Hyundai</a> to offer its customers real-time roadside assistance and repair services. There are also <a href=\"https://www.cmtelematics.com/safe-driving-technology/how-it-works/\" rel=\"noopener noreferrer\" target=\"_blank\">DriveWell</a>, <a href=\"https://www.getfuelstar.com/\" rel=\"noopener noreferrer\" target=\"_blank\">FuelStar</a>, and <a href=\"https://www.getopenroad.app/\" rel=\"noopener noreferrer\" target=\"_blank\">Openroad</a> mobile apps for motorists who want feedback about their driving.\n</p><h2>The first indoor location system</h2><p>\n\tBalakrishnan has created other systems that use sensors for practical purposes. Between 1999 and 2004, he oversaw the development of the <a href=\"http://cricket.csail.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Cricket</a> indoor location system. It combined radio frequency and ultrasound technologies. Beacons mounted on walls and ceilings publish information on an RF channel, which sends out a chirping signal. The beacon then sounds out a corresponding ultrasonic pulse. Receivers attached to mobile devices listen for the RF signals and the ultrasonic pulse. Cricket uses the different speeds of sound and of RF to calculate the distance between the receiver and the beacon.\n</p><p>\n\tThe system provided space identifiers, position coordinates, and orientation. Cricket provided distance ranging and positioning precision of between 3 and 5 centimeters. It was used in areas where GPS didn’t work well, such as hospitals, office buildings, and research centers.\n</p><p>\n\t“GPS only works outdoors,” Balakrishnan says. “Even today, you can’t get GPS signals inside. When your apps show you the location inside, it’s using other technologies.”\n</p><p>\n\tThe research team open-sourced the hardware and software, and more than 1 million units were built and deployed.\n</p><p style=\"\">\n\t“This approach didn’t scale to every device in the world,” Balakrishnan says, “because adding ultrasonic hardware to every device is not practical. However, with modern smartphones capable of sending and receiving ultrasonic signals on their speakers and microphones, the approach developed in Cricket might become useful in the future. Indeed, some recent proposals for contact tracing for COVID-19 have used this approach.”\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\" style=\"\">\n<img alt=\"portrait of two men in tuxedos against a green backdrop with white text  Info for editor if needed: \" class=\"rm-shortcode\" data-rm-shortcode-id=\"8ceb25b88c3913adf3c8bab49a871bf5\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"05e70\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-two-men-in-tuxedos-against-a-green-backdrop-with-white-text-info-for-editor-if-needed.jpg?id=50442723&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">This year’s IEEE Medal of Honor recipient Vint Cerf congratulates Marconi Prize winner Hari Balakrishnan at the Marconi Awards Gala, held on 27 October in Washington, D.C.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Marconi Society</small></p><h2>A love of research and academia</h2><p>\n\tBalakrishnan earned a bachelor’s degree in computer science in 1993 from the <a href=\"https://www.iitm.ac.in/\" rel=\"noopener noreferrer\" target=\"_blank\">Indian Institute of Technology, Madras</a>. He picked the field, he says, because he thought it would let him make practical use of mathematics.\n</p><p>\n\t“I knew nothing about computer science,” he says. “I had never programmed a computer before. But I knew I was interested in things that were mathematical in nature, and I enjoyed both math and physics greatly. After about a year and a half, I felt like I understood what the field was about. By the time I finished my undergraduate degree, I absolutely loved it.”\n</p><p>\n\tWhile pursuing a Ph.D. in computer science at the <a href=\"https://www.berkeley.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of California, Berkeley</a>, he became passionate about conducting research, he says. He enjoyed it so much, he says, that he wanted to make a career of it.\n</p><p>\n\tHe’s also known for his early <a href=\"https://ieeexplore.ieee.org/search/searchresult.jsp?newsearch=true&queryText=Hari%20Balakrishnan\" rel=\"noopener noreferrer\" target=\"_blank\">research</a> on how to improve wireless networks—which can be found in the <a href=\"https://ieeexplore.ieee.org/Xplore/home.jsp\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Xplore Digital Library</a> and which won the 1998 Association for Computing Machinery’s <a href=\"https://awards.acm.org/doctoral-dissertation/\" rel=\"noopener noreferrer\" target=\"_blank\">Doctoral Dissertation Award</a>.\n</p><p>\n\tIn the final year of his Ph.D., in 1998, he decided to pursue an academic career. He interviewed for a faculty position at MIT and knew immediately it was where he wanted to work, he says. The university hired him that year, and he has worked there ever since.\n</p><p>\n\t“I felt like this was the place where people were on the same wavelength as me,” he says. “It’s always good to go to a place where people appreciate what you do.”\n</p><p>\n\tDespite his entrepreneurial success, Balakrishnan continues to teach.\n</p><p>\n\t“I just really enjoy working with students and just love research,” he says. “I enjoy teaching students and, frankly, they teach me as much as I teach them.”\n</p><h2>The IEEE community</h2><p>\n\tBalakrishnan says he intially joined IEEE as a student to get the discounted rate for membership and conference registrations. But after he began working, he realized that it’s important to be part of a “professional community that has like-minded people who care about the fields that I care about,” he says. “IEEE has benefited my career because I’ve been at conferences and events where I’ve made professional connections that will last a lifetime.”\n</p><p>\n\tHe is also a member of the U.S. <a href=\"http://www.nae.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">National Academy of Engineering</a> and the <a href=\"https://www.amacad.org/\" rel=\"noopener noreferrer\" target=\"_blank\">American Academy of Arts and Sciences</a>.\n</p><p>IEEE recognized him in 2021 with its <a href=\"https://corporate-awards.ieee.org/corporate-awards/#field-awards\" rel=\"noopener noreferrer\" target=\"_blank\">Koji Kobayashi Computers and Communications Award</a> for “broad contributions to computer networking and mobile and wireless systems.”</p>"},"pubDate":"Sun, 12 Nov 2023 19:00:03 +0000","guid":"https://spectrum.ieee.org/mit-professor-iot-sensors","category":["Internet of things","Ieee member news","Sensors","Transportation","Type:ti"],"dc:creator":"Kathy Pretz","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/portrait-of-a-man-wearing-a-blue-button-up-shirt-against-a-light-background.jpg?id=50442683&width=980"}},{"title":"Google, Intel, Nvidia Battle in Generative AI Training","link":"https://spectrum.ieee.org/generative-ai-training","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/rows-of-black-rectangular-structures-with-yellow-lines-on-them-receding-into-the-shadows.jpg?id=50438311&width=1200&height=800&coordinates=130%2C0%2C130%2C0\"/><br/><br/><p style=\"\">The leading public apples-to-apples test for computer systems’ ability to train machine-learning neural networks has fully entered the <a href=\"https://spectrum.ieee.org/tag/generative-ai\" target=\"_blank\">generative AI</a> era. Earlier this year, MLPerf <a href=\"https://spectrum.ieee.org/large-language-models-training-benchmark\" target=\"_blank\">added a test for training large language models</a> (LLM), GPT-3 in particular. This month it adds Stable Diffusion, a <a href=\"https://spectrum.ieee.org/openai-dall-e-2\" target=\"_blank\">text-to-image generator</a>. Computers powered by Intel and Nvidia took on the new benchmark. And the rivals continued their earlier battle in training GPT-3, where they were joined this go-around by Google. </p><p style=\"\">All three devoted  huge systems to the task—Nvidia’s 10,000-GPU supercomputer was the largest ever tested—and that size is necessary in generative AI. Even Nvidia’s largest system would have taken eight days of work to fully complete its LLM job.</p><p style=\"\">Overall, 19 companies and institutions submitted more than 200  results, which showed a 2.8-fold performance boost over the past five months, and a 49-fold boost since MLPerf began five years ago.</p><div class=\"rm-embed embed-media\" style=\"\"><div class=\"flourish-embed flourish-scatter\" data-src=\"visualisation/15042930?1509099\"><script src=\"https://public.flourish.studio/resources/embed.js\"></script></div></div><h2 style=\"\">Nvidia, Microsoft test 10,752-GPU monsters</h2><p style=\"\">Nvidia continued to dominate the MLPerf benchmarks with systems made from its H100 GPUs. But the results from <a href=\"https://nvidianews.nvidia.com/news/nvidia-announces-dgx-h100-systems-worlds-most-advanced-enterprise-ai-infrastructure\" target=\"_blank\">Eos</a>, the company’s new 10,752-GPU AI supercomputer, were the cherry on top. Bending all those GPUs<strong> </strong>to the task of the GPT-3 training benchmark, Eos had the job done in just under 4 minutes. Microsoft’s cloud computing arm, Azure, tested a system of the exact same size and were behind Eos by mere seconds. (Azure powers GitHub’s coding assistant <a href=\"https://spectrum.ieee.org/ai-software\" target=\"_blank\">CoPilot</a> and OpenAI’s <a href=\"https://spectrum.ieee.org/tag/chatgpt\" target=\"_blank\">ChatGPT</a>.)</p><p>Eos’s GPUs are capable of an aggregate 42.6 billion billion floating-point operations per second (exaflops). And they are bound together with interconnects—Nvidia’s Quantum-2 Infiniband—that sling 1.1 million billion bytes per second. “Some of these speeds and feeds are mind-blowing,” says Dave Salvatore, Nvidia’s director of AI benchmarking and cloud computing. “This is an incredibly capable machine.”</p><p style=\"\">Eos triples the number of H100 GPUs that have been bound into a single machine. That threefold increase achieved a 2.8-fold performance improvement, or 93 percent scaling efficiency. Efficient scaling is key to continued improvement of generative AI, which has been <a href=\"https://blogs.nvidia.com/blog/2023/09/29/huangs-law-dally-hot-chips/\" target=\"_blank\">growing tenfold every year</a>. </p><p style=\"\">The GPT-3 benchmark Eos tackled is not a complete training of GPT-3, because MLPerf wanted it to be within reach of many companies. Instead, it involves training the system to a certain checkpoint that proves the training would have reached the needed accuracy given enough time. And these trainings do take time. Extrapolating from Eos’s 4 minutes means it would take eight days to complete the training, and that’s on what might be the most powerful AI supercomputer yet built. A computer of more reasonable size—512 H100s—would take four months.</p><h2>Intel continues to close in</h2><p>Intel submitted results for systems using the <a href=\"https://habana.ai/wp-content/uploads/2023/10/Intel-Gaudi2-AI-Accelerators-whitepaper.pdf\" target=\"_blank\">Gaudi 2</a> accelerator chip and for those that had no accelerator at all, relying on only its fourth-generation Xeon CPU. The big change from the last set of training benchmarks was that the company had enabled Gaudi 2’s 8-bit floating-point (FP8) capabilities. The use of lower precision numbers, such as FP8, has been responsible for <a href=\"https://spectrum.ieee.org/nvidia-gpu\" target=\"_blank\">most of the improvement in GPU performance in last 10 years</a>. The use of FP8 in parts of GPT-3 and other transformer neural networks where their low precision won’t affect accuracy has already showed its value in Nvidia’s H100 results. Now Gaudi 2 is seeing the boost.</p><p>“We projected a 90 percent gain” from switching on FP8, says <a href=\"https://www.linkedin.com/in/eitan-medina-7147964/?originalSubdomain=il\" target=\"_blank\">Eitan Medina</a>, chief operating officer at Intel’s Habana Labs. “We delivered more than what was promised—a 103 percent reduction in time-to-train for a 384-accelerator cluster.”</p><p style=\"\">That new result puts the Gaudi 2 system at a little less than one-third the speed of an Nvidia system on a per-chip basis and three times as fast as Google’s TPUv5e. On the new image-generation benchmark, Gaudi 2 was also about half the H100’s speed. GPT-3 was the only benchmark FP8 enabled for this round, but Medina says his team is working on switching it on for others now.<span></span></p><p>Medina continued to make the case that Gaudi 2 has a significantly lower price to the H100, and so it has an advantage on a combined metric of price and performance. Medina expects the advantage will grow with the next generation of Intel accelerator chip, Gaudi 3. That chip will be in volume production in 2024 and will be built using the same semiconductor manufacturing process as the Nvidia H100.</p><p>Separately, Intel submitted results for systems based only on CPUs, again showing training times between minutes and hours for several benchmarks. Beyond the MLPerf benchmarks, Intel also shared some data showing that a 4-node Xeon system, whose chips include the AMX matrix engine, can fine-tune the Stable Diffusion image generator in less than 5 minutes. Fine-tuning takes an already trained neural network and specializes it toward a certain task. For example, <a href=\"https://spectrum.ieee.org/ai-for-engineering\" target=\"_blank\">Nvidia’s chip design AI</a> is a fine-tuning of an existing large language model called NeMo.</p><p style=\"\">You can see all the results <a href=\"https://mlcommons.org/benchmarks/inference-datacenter/\" target=\"_blank\">here</a>.</p>"},"pubDate":"Sun, 12 Nov 2023 15:00:02 +0000","guid":"https://spectrum.ieee.org/generative-ai-training","category":["Intel","Mlperf","Supercomputing","Nvidia","Generative ai"],"dc:creator":"Samuel K. Moore","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/rows-of-black-rectangular-structures-with-yellow-lines-on-them-receding-into-the-shadows.jpg?id=50438311&width=980"}},{"title":"Video Friday: Beyond the Limit","link":"https://spectrum.ieee.org/video-friday-beyond-the-limit","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-picture-of-a-silver-robot-dog-climbing-a-set-of-concrete-outdoor-stairs-with-logs-rolling-down-them.png?id=50439766&width=1200&height=800&coordinates=150%2C0%2C150%2C0\"/><br/><br/><p>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at <em>IEEE Spectrum</em> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please <a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a> for inclusion.<br/></p><h5><a href=\"https://ssrr2023.org/\">IEEE SSRR 2023</a>: 13–15 November 2023, FUKUSHIMA, JAPAN</h5><h5><a href=\"https://2023.ieee-humanoids.org/\">Humanoids 2023</a>: 12–14 December 2023, AUSTIN, TEXAS</h5><h5><a href=\"https://cybathlon.ethz.ch/en/events/challenges/Challenges-2024\">Cybathlon Challenges</a>: 2 February 2024, ZURICH</h5><h5><a href=\"https://www.eurobot.org/\">Eurobot Open 2024</a>: 8–11 May 2024, LA ROCHE-SUR-YON, FRANCE</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><blockquote><em>Unitree B2: beyond the limit. Maximum speed of 6m/s, sustained load of 40kg and sustained walking endurance of 5h. The comprehensive performance is two to three times that of existing quadruped robots worldwide! Adaptable to all terrains, large load, long-lasting endurance, and super athletic performance! Evolve, evolve, and evolve again!</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5910320152f1e0e4ec91904187b1dda5\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/-0n_MFLKD3M?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.unitree.com/en/b2/\">Unitree</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>This shape-changing robot just got a lot smaller. In a new study, engineers at the University of Colorado Boulder debuted mCLARI, a 2-centimeter-long modular robot that can passively change its shape to squeeze through narrow gaps in multiple directions. It weighs less than a gram but can support over three times its body weight as an additional payload.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"c38abaac0a26fdb43ce3ddbdad03eb4b\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/KbMi6ezXf-Y?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.colorado.edu/lab/jayaram/research/mclari\">CU Boulder</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Researchers at CMU used fossil evidence to engineer a soft robotic replica of pleurocystitids, a marine organism that existed nearly 450 million years ago and is believed to be one of the first echinoderms capable of movement using a muscular stem.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5f55acaaf5499d28c94df3d8d2eae4b7\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/KMz26Q6Vh-g?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://engineering.cmu.edu/news-events/news/2023/11/06-paleobionics.html\">CMU</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Stretch has moved over a million customer boxes in under a year, improving predictability and preventing injuries. But how did we get there? Discover how we put our expertise in robotics research to use designing, testing, and deploying a warehouse robot. Starting from the technological building blocks of Atlas, Stretch has the mobility, power, and intelligence to automate the industry’s toughest challenges.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"250e2f4e7d15ef17c15faa50a242a603\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/8WZoVJIV9V0?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://bostondynamics.com/products/stretch/\">Boston Dynamics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>What do the robots do on Halloween after everyone leaves? Join the Ingenuity Labs robots on their trick or treating adventure. Happy Halloween!</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"6d3a10374f9377312d8addc4be18013d\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/8NdBNtQmzZg?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://offroad.engineering.queensu.ca/\">Queens University</a>, Canada ]</p><p>Thanks Josh!</p><div class=\"horizontal-rule\"></div><blockquote><em>FreeLander is a versatile, modular legged-robot hardware platform with adaptive bio-inspired neural control. The robot platform can be used to construct different bio-inspired legged robots. Each module of the platform consists of two legs designed to function as a two-legged robot, which is able to walk on a metal pipe using electromagnetic feet. Multiple modules can be combined to obtain six-legged and eight-legged robots to walk on difficult terrains, such as rough terrain, slopes, random stepfield, gravel, grass, and even in-pipe.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5e416fdf3643ab494da5dbe819459528\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/qr5hahtGYdc?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://manoonpong.com/\">VISTEC</a> ]</p><p>Thanks Poramate!</p><div class=\"horizontal-rule\"></div><p>Energy Robotics hopes you had a Happy Halloween!</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"ace83c6b2839636f127daed0dfd97894\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/XMnJ2u1TfyA?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.energy-robotics.com/\">Energy Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>This work presents a camera model for refractive media such as water and its application in underwater visual-inertial odometry. The model is self-calibrating in real time and is free of known correspondences or calibration targets.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"0a8ba98aec4860b657f90ab89f10847d\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/OtLE6sEH4IU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.autonomousrobotslab.com/\">ARL</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Humans naturally exploit haptic feedback during contact-rich tasks like loading a dishwasher or stocking a bookshelf. Current robotic systems focus on avoiding unexpected contact, often relying on strategically placed environment sensors. In this paper we train a contact-exploiting manipulation policy in simulation for the contact-rich household task of loading plates into a slotted holder, which transfers without any fine-tuning to the real robot.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"bd80fc8dae16bba97dcc18e8197ad6c8\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/CS7uP_pW77U?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://sites.google.com/view/compliant-object-insertion\">Paper</a> ]</p><p>Thanks Samarth!</p><div class=\"horizontal-rule\"></div><blockquote><em>Presented herewith is another PAPRAS (Plug-And-Play Robotic Arm System) add-on system engineered to augment the functionalities of the quadrupedal robot, Boston Dynamics Spot. The system adeptly integrates two PAPRAS units onto the Spot, drawing inspiration from the mythological creature Orthrus—a two-headed dog in Greek mythology.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"236726e6921a52b5f3d83ba5681e8432\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Yn3IxwAzN6o?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://publish.illinois.edu/kimlab2020/\">KIMLAB</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Marwa Eldiwiny is a Ph.D. student and early stages researcher (ESR) at the Vrije Universiteit Brussel whose current research focus is on modelling and simulating self-healing soft materials for industrial applications. Her master’s thesis was “UAV anti-stealth technology for safe operation.” She worked as a research engineer at Inria Lille Nord Europe, research scholar at Tartu Institute of Technology, and a lecturer with the Mechatronics and Industrial Robotics Programme at Minia University, Egypt. Eldiwiny hosts the IEEE RAS Soft Robotics Podcast where researchers from both academia and industry discuss recent developments in the soft robotics research field.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"ab655bcf7f9effa8d68de88bdc32d514\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/BXl__8K2gyw?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"http://www.smartitn.eu/smart-project-esrs/\">SMART ITN</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>3 labs. Different robotic solutions of the future. Meet CSAIL’s machine friends.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"df9eacac45b21c2d1a07c205a6b7fe91\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/l5o_edsg_nU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.csail.mit.edu/\">MIT CSAIL</a> ]</p><div class=\"horizontal-rule\"></div><p>This University of Pennsylvania GRASP SFI Seminar is by E Farrell Helbling at Cornell, on autonomy for insect-scale robots.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"a8da7aa6065c2787190ddf1281841f6c\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/XbFaPdXiUHI?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><blockquote><em>Countless science fiction works have set our expectations for small, mobile, autonomous robots for use in a broad range of applications. The ability to move through highly dynamic and complex environments can expand capabilities in search-and-rescue operations and safety-inspection tasks. These robots can also form a diverse collective to provide more flexibility than a multifunctional robot. I will present my work on the analysis of control and power requirements for this vehicle, as well as results on the integration of onboard sensors. I also will discuss recent results that culminate nearly two decades of effort to create a power autonomous insect-scale vehicle. Lastly, I will outline how this design strategy can be readily applied to other micro and bioinspired autonomous robots.</em></blockquote><p>[ <a href=\"https://www.grasp.upenn.edu/events/fall-2023-grasp-sfi-margaret-coad/\">UPenn</a> ]</p><div class=\"horizontal-rule\"></div>"},"pubDate":"Fri, 10 Nov 2023 22:03:41 +0000","guid":"https://spectrum.ieee.org/video-friday-beyond-the-limit","category":["Video friday","Quadruped robots","Unitree","Stretch","Robotics"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/a-picture-of-a-silver-robot-dog-climbing-a-set-of-concrete-outdoor-stairs-with-logs-rolling-down-them.png?id=50439766&width=980"}},{"title":"Notice to Membership","link":"https://spectrum.ieee.org/notice-to-membership-nov-2023","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-overlapping-blue-word-bubbles-with-ieee-on-one.jpg?id=50443560&width=1200&height=800&coordinates=0%2C100%2C0%2C100\"/><br/><br/><p style=\"\">The <a href=\"https://www.ieee.org/about/ethics/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Ethics and Member Conduct Committee</a> (EMCC) received a complaint against Dr. Peng Zhang, a member in the grade of Senior Member of the IEEE. A hearing board appointed by the IEEE Board of Directors found Cause that Dr. Zhang violated Section II, Subsection 8 of the <a href=\"https://www.ieee.org/about/corporate/governance/p7-8.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Code of Ethics</a>. The IEEE Board of Directors sustained these findings and imposed the sanction of a five-year suspension from IEEE membership on Dr. Zhang, in accordance with <a href=\"https://www.ieee.org/content/dam/ieee-org/ieee/web/org/about/corporate/ieee-constitution-and-bylaws.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Bylaw</a> I-110.5. The IEEE Board of Directors also determined that this notification to the IEEE membership should be made. For identification purposes only, Dr. Zhang has past affiliations with a university in the state of Connecticut and, as of the date of this notice, current affiliation with a university in the state of New York.</p>"},"pubDate":"Fri, 10 Nov 2023 21:00:03 +0000","guid":"https://spectrum.ieee.org/notice-to-membership-nov-2023","category":["Ethics","Ieee board of directors","Ieee bylaws","Ieee member news","Ieee news","Type:ti"],"dc:creator":"IEEE","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/an-illustration-of-overlapping-blue-word-bubbles-with-ieee-on-one.jpg?id=50443560&width=980"}},{"title":"USC Professor’s Simulation Software Teaches Systems Engineering Topics","link":"https://spectrum.ieee.org/usc-professor-azad-madni","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/portrait-of-an-older-man-smiling-at-the-camera-against-a-white-background.jpg?id=50433414&width=1200&height=800&coordinates=0%2C0%2C0%2C158\"/><br/><br/><p style=\"\"><a href=\"https://www.azadmadni.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Azad M. Madni</a> spent some 40 years working on artificial intelligence and simulation technologies that allowed U.S. soldiers to safely train for combat operations in virtual worlds. Now Madni—a professor of astronautics, aerospace, and mechanical engineering at the <a href=\"https://www.usc.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Southern California</a>—is working to transform engineering education. But he hasn’t abandoned the world of simulation. </p><h3>Azad Madni</h3><br/><p>\n<strong></strong><strong>Employer </strong>\n</p><p>\n<strong></strong>University of Southern California, in Los Angeles\n</p><p>\n<strong>Title</strong>\n</p><p>\n\tProfessor of astronautics, aerospace, and mechanical engineering\n</p><p>\n<strong>Member grade</strong>\n</p><p>\n\tIEEE Life Fellow\n</p><p><strong>Alma Mater</strong></p><p>University of California, Los Angeles</p><p>In 2013 the IEEE Life Fellow created the Transdisciplinary Systems Engineering Education (<a href=\"https://sae.usc.edu/trasee/\" rel=\"noopener noreferrer\" target=\"_blank\">TRASEE</a>) paradigm, in which professors use simulation software to teach topics through storytelling and role-playing techniques, allowing students to apply their engineering lessons to real-world situations.</p><p> For that and other “pioneering contributions to model-based systems engineering, education, and industrial impact using interdisciplinary approaches,” Madni received this year’s <a href=\"https://corporate-awards.ieee.org/award/ieee-simon-ramo-medal/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Simon Ramo Medal</a>.</p><p><a href=\"https://ethw.org/Simon_Ramo\" rel=\"noopener noreferrer\" target=\"_blank\">Ramo</a> was a leader in microwave research who headed the development of <a href=\"https://ethw.org/General_Electric_(GE)\" rel=\"noopener noreferrer\" target=\"_blank\">General Electric</a>’s electron microscope. Ramo served as a presidential chair and professor of electrical engineering at USC’s <a href=\"https://viterbischool.usc.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Viterbi School of Engineering</a> from 2008 until he died in 2016. </p><p>Madni says the award is “the crowning achievement” of his career as a systems engineer. It’s particularly special to him, he says, because he and Ramo were colleagues at USC.</p><h2>From NASA to teaching at USC</h2><p style=\"\">Madni, who grew up in Mumbai, became captivated by the U.S. space program after listening to the 1962 “<a href=\"https://www.youtube.com/watch?v=iQV9CAJWlVY\" rel=\"noopener noreferrer\" target=\"_blank\">We choose to go to the moon</a>” speech delivered by <a href=\"https://www.whitehouse.gov/about-the-white-house/presidents/john-f-kennedy/\" rel=\"noopener noreferrer\" target=\"_blank\">John F. Kennedy</a> at <a href=\"https://www.rice.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Rice University</a>, in Houston. The president’s speech was designed to bolster public support for his proposal to land a man on the moon before 1970.</p><p>Madni, who knew he wanted to become an engineer, decided he wanted to be part of the “space adventure,” he says.</p><p>He moved to the United States to pursue a bachelor’s degree in engineering at the <a href=\"https://www.ucla.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of California, Los Angeles</a>. Finding himself drawn to systems engineering after taking a UCLA class in the field, he decided to merge his new interest with his passion for space.</p><p>After graduating in 1968, Madni joined <a href=\"https://www.parsons.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Parsons Corp.</a> in Los Angeles as a full-time systems engineer and analyst working on defense programs. At night, he took graduate courses at UCLA, and in 1971 he earned his master’s degree in engineering.</p><p style=\"\">He went on to pursue a Ph.D. while also working full-time at <a href=\"https://en.wikipedia.org/wiki/Rockwell_International\" rel=\"noopener noreferrer\" target=\"_blank\">Rockwell International</a>’s space division in Downey, Calif., as a simulation systems engineer.</p><p>At the time, the company was the prime contractor for <a href=\"https://www.nasa.gov/\" rel=\"noopener noreferrer\" target=\"_blank\">NASA</a>’s <a href=\"https://www.spaceline.org/united-states-manned-space-flight/space-shuttle-program-history/\" rel=\"noopener noreferrer\" target=\"_blank\">space shuttle program</a>. Working on the program was a dream come true, he says.</p><p>He developed a model-based analysis program to virtually test the performance of the shuttle’s navigation system. He also led the creation of a simulation program that analyzed the navigation system’s performance under different high-stress conditions. Madni’s model-based approach reduced the need for extensive hardware-in-the-loop testing and consequently reduced costs, he says.</p><p style=\"\">After receiving his Ph.D. in 1978 in engineering systems with a concentration in computer methodology and AI, he joined Perceptronics in Woodland Hills, Calif., as director of artificial intelligence and software research, eventually rising to executive vice president and chief technology officer.</p><p class=\"pull-quote\" style=\"\">“IEEE is the premier engineering society.”</p><p>In 1980 he began working on a distributed simulation technology for the U.S. <a href=\"https://www.goarmy.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Army</a>. He led a team that was designing a program to train soldiers and allow them to complete practice missions in safe, virtual environments. The <a href=\"https://www.darpa.mil/\" rel=\"noopener noreferrer\" target=\"_blank\">Defense Advanced Research Projects Agency</a> (DARPA) and the Army sponsored the work.</p><p>At the time, the training simulators used were expensive to build, underutilized, and inflexible.</p><p> Madni says he had two goals for the new simulation system: to lower costs, increase utilization, and allow military personnel to modify the scenarios as needed. The technology he and his team developed did just that.</p><p>He later returned to the simulation effort, this time focused on enhancing it with immersive story-telling techniques. The project was funded by the U.S. <a href=\"https://www.airforce.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Air Force</a>, Army, <a href=\"https://www.navy.mil/\" rel=\"noopener noreferrer\" target=\"_blank\">Navy</a>, DARPA, and the <a href=\"https://www.energy.gov/\" rel=\"noopener noreferrer\" target=\"_blank\">U.S. Department of Energy</a> as well as several aerospace and automotive companies.</p><p>Madni modeled the simulations after video games and movies, engaging multiple senses to create more immersive experiences for users.</p><p>Today the Army uses the two systems, called the “game-based training simulations for part-task training” and the “VR-enabled distributed simulation system for collective training.”</p><p>Madni left Perceptronics in 1994 to help found Intelligent Systems Technology, an R&D company in Los Angeles that specializes in modeling and simulation technology. He served as the startup’s CEO and CTO until 2009, when he joined the USC faculty as head of the interdisciplinary systems architecting and engineering master’s degree program. Madni is the founding director of USC’s Distributed Autonomy and Intelligent Systems Laboratory, which conducts research in augmented intelligence, autonomous systems, cyber-physical-human-systems, and transdisciplinary systems engineering.</p><p style=\"\">“My father had a passion for education and instilled that same passion in me from a very young age,” he says. “His dream for me was to someday be a faculty member at a prestigious U.S. university. By joining USC, I have fulfilled his dream and have contributed to transforming engineering education for 21st century engineering challenges.”</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\" style=\"\">\n<img alt=\"three men standing in suits for a portrait against a white background with black writing\" class=\"rm-shortcode\" data-rm-shortcode-id=\"74f62fe0d6c9b5b930c26a4c01a9f19b\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"cec30\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/three-men-standing-in-suits-for-a-portrait-against-a-white-background-with-black-writing.jpg?id=50433494&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Life Fellow Azad Madni [middle] proudly displays his IEEE Simon Ramo Medal at the IEEE Honors Ceremony. He is accompanied by IEEE President-Elect Thomas Coughlin [left] and IEEE President Saifur Rahman.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Robb Cohen Photography</small></p><h2>Teaching systems engineering through storytelling</h2><p>It was at USC that Madni developed TRASEE.</p><p>Instead of a typical lecture format, students start with a short scenario and a technical problem to solve. Each member of a group is assigned a role. The teams use a digital twin—a virtual model—of a machine relevant to the story to assess how well their efforts are succeeding.</p><p>Madni says the approach helps students pick up information faster, gain leadership skills, and learn to work with others outside their discipline and from other cultures.</p><p>“By taking abstract engineering concepts and embedding them in stories, I’m able to communicate the ideas to students much more clearly,” he says.</p><p><a href=\"https://www.emerald.com/insight/content/doi/10.1108/JRIT-06-2018-0013/full/html\" rel=\"noopener noreferrer\" target=\"_blank\">According to a 2018 study</a>, students who learn through role-playing exercises score 45 percent higher on tests than those taught through traditional lectures.</p><p>Madni has been recognized by several organizations for creating TRASEE. This year he received the <a href=\"http://www.nae.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">National Academy of Engineering</a>’s <a href=\"https://www.nae.edu/20685/GordonPrize\" rel=\"noopener noreferrer\" target=\"_blank\">Gordon Prize for Innovation in Engineering and Technology Education</a>. The prize includes a US $500,000 award; Madni donated half of the money to the NAE and half to USC.</p><h2>Networking with engineers from different disciplines</h2><p style=\"\">Madni has been an IEEE member for 46 years. Since 1980 he has held several leadership positions and has presented papers at IEEE conferences worldwide. </p><p style=\"\">In 2013, he cofounded the<a href=\"https://www.ieeesmc.org/technical-activities/systems-science-and-engineering/model-based-systems-engineering/\" rel=\"noopener noreferrer\" target=\"_blank\"> IEEE Systems, Man, and Cybernetics Society’s technical committee on model-based systems engineering</a> and serves as its chair. The committee creates educational resources, and members are involved in standardization efforts. Members also hosted panel sessions at the 2023 <a href=\"https://cser.info/cser2023/\" rel=\"noopener noreferrer\" target=\"_blank\">International Conference on Systems Engineering Research</a> and presented research papers. As chair, Madni has led several collaborative efforts with professional engineering societies including <a href=\"https://www.incose.org/\" rel=\"noopener noreferrer\" target=\"_blank\">International Council on Systems Engineering</a> and the <a href=\"https://www.iise.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Institute of Industrial and Systems Engineers</a>. </p><p>Madni is also an active volunteer with the <a href=\"https://ieee-aess.org/home\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Aerospace and Electronic Systems Society</a>, the <a href=\"https://www.computer.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Computer Society</a>, <a href=\"https://ieeeusa.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE-USA</a>, and the <a href=\"https://ieeesystemscouncil.org/ieee-systems-council-welcome\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Systems Council</a>.</p><p>“IEEE is the premier engineering society,” he says. “It goes well beyond electronics and electrical engineering. It encompasses many disciplines including biomedical engineering, control systems engineering, cybernetics, systems engineering, and engineering management.</p><p>“IEEE being multidisciplinary makes it an ideal forum for networking with engineers from different disciplines.”</p> Madni says he enjoys mentoring aspiring engineering students and young professionals working in both academia and industry. He says this is his way of giving back and he enjoys helping them to “realize and live their dream as I did.”"},"pubDate":"Thu, 09 Nov 2023 19:00:02 +0000","guid":"https://spectrum.ieee.org/usc-professor-azad-madni","category":["Ieee award","Education","Ieee member news","Simulation","Systems engineering","Type:ti"],"dc:creator":"Joanna Goodrich","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/portrait-of-an-older-man-smiling-at-the-camera-against-a-white-background.jpg?id=50433414&width=980"}},{"title":"Watch This Giant Chopstick Robot Handle Boxes With Ease","link":"https://spectrum.ieee.org/warehouse-robots","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/two-men-stand-next-to-a-black-mechanical-robotic-frame-taller-than-they-are-which-big-chopstick-grippers-connected-to-movable-t.jpg?id=50393306&width=1200&height=800&coordinates=0%2C0%2C0%2C497\"/><br/><br/><p style=\"\">Although robots are already in warehouses, shuffling small items between bins for shipping or storage, they have yet to take over the job of lugging big, heavy things. And that’s just where they could be of the most use, because lugging is hard for people to do.</p><p style=\"\">Several companies are working on the problem, and there’s likely to be plenty of room for all of them, because the opportunity is enormous. There are a lot of trailers out there that need to be unloaded. Arguably the <em>most</em> interesting approach comes from <a href=\"https://www.dextrousrobotics.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Dextrous Robotics</a>, which has a robot that moves boxes around with a giant pair of chopsticks.</p><hr/><p style=\"\">We first wrote about Dextrous Robotics <a href=\"https://spectrum.ieee.org/dexterous-robotics-develops-chopstick-manipulation-for-boxes\" target=\"_self\">in 2021</a>, when they were working on a proof of concept using Franka Panda robotic arms. Since then, the concept has been proved successfully, and Dextrous has scaled up to a much larger robot that can handle hundreds of heavy boxes per hour with its chopstick manipulators.</p><p class=\"shortcode-media shortcode-media-youtube\" style=\"\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"2bec340386a21c649da07c98ca0959c1\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/ZtXuustzyqo?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p style=\"\">“The chopstick type of approach is very robust,” Dextrous CEO <a href=\"https://edrumwri.github.io/\" target=\"_blank\">Evan Drumwright</a> tells us. “We can carry heavy payloads and small items with very precise manipulation. Independently posable chopsticks permit grasping a nearly limitless variety of objects with a straightforward mechanical design. It’s a real simplification of the grasping problem.”</p><p style=\"\">The video above shows the robot moving about 150 boxes per hour in a scenario that simulates unloading a packed trailer, but the system is capable of operating much faster. The demonstration was done without any path optimization. In an uncluttered environment, Dextrous has been able to operate the system at 900 boxes per hour, about twice as fast as the 300 to 500 boxes per hour that a person can handle.</p><p style=\"\">Of course, the heavier the box, the harder it is for a person to maintain that pace. And once a box gets heavier than about 20 kilograms, it takes two people to move it. At that point, labor becomes far less efficient. On paper, the hardware of Dextrous’s robot is capable of handling 40 kg boxes at an acceleration of up to 3 <em>g</em>s, and up to 65 kg at a lower acceleration. That would equate to 2,000 boxes per hour. True, this is just a theoretical maximum, but it’s what Dextrous is working toward.</p><p style=\"\">If the only problem was to move heavy boxes quickly, robots would have solved it long ago. However, before you can move the box you first have to pick it up, and that complicates matters. Other robotics companies use suction to pick things up. Dextrous alone favors giant chopsticks. </p><p style=\"\">Suction does have the advantage of being somewhat easier to handle on the perception and planning side: Find a flat surface, stick to it, and there you go. That approach assumes you can find a flat surface, but the well-ordered stacks of boxes seen in most demo videos aren’t necessarily what you’ll get in a warehouse. Suction has other problems: It typically has a payload limit of 20 kg or so, it doesn’t work very well with odd-size boxes, and it has trouble operating in temperatures below 10 °C. Suction systems also pull in a lot of dirt, which can cause mechanical problems.</p><p style=\"\">A suction system typically attaches to just one surface, and that limits how fast it can move without losing its grip or tearing open a box. The Dextrous chopsticks can support a box on two sides. But making full use of this capability adds difficulty to the perception and planning side.</p><p style=\"\">“Just getting to this point has been hardcore,” Drumwright says. “We’ve had to get to a level of precision in the perception system and the manipulation to be able to understand what we’re picking with high confidence. Our initial engineering hurdle has been very, very high.”</p><p style=\"\">Manipulating rigid objects with rigid manipulators like chopsticks has taken Dextrous several years to perfect. “Figuring out how to get a robot to perceive and understand its environment, figure out the best item to pick, and then manipulating that item and doing all that in a reasonable length of time—that is really, really hard,” Drumwright tells us. “I’m not going to say we’ve solved that 100 percent, but it’s working very well. We still have plenty of stuff left to do, but the proof of concept of actually getting a robot that does contact-based manipulation to pick variably sized objects out of an unconstrained environment in a reasonable time period? We’ve solved that.”</p><p style=\"\">Here’s another video showing a sustained box-handling sequence; if you watch carefully, you’ll notice all kinds of precise little motions as the robot uses its manipulators to slightly reposition boxes to give it the best grasp:</p><p class=\"shortcode-media shortcode-media-youtube\" style=\"\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"1d4b4de7d35670283318c90b8e69a9c9\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/mi7kO0QTTRs?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p style=\"\">All of those motions makes the robot look almost like it’s being teleoperated, but Drumwright assures me that it’s completely autonomous. It turns out that teleoperation doesn’t work very well in this context. “We looked at doing teleop, and we actually could not do it. We found that our controllers are so precise that we could not actually make the system behave better through teleop than it did autonomously.” As to <em>how</em> the robot decides what to do what it does, “I can’t tell you exactly where these behaviors came from,” Drumwright says, “Let’s just call it AI. But these are all autonomous manipulation behaviors, and the robot is able to utilize this diverse set of skills to figure out how to pick every single box.”</p><p style=\"\">You may have noticed that the boxes in the videos are pretty beat up. That’s because the robot has been practicing with those boxes for months, but Dextrous is mindful of the fact that care is necessary, says Drumwright. “One of the things that we were worried about from the very beginning was, how do we do this in a gentle way? But our newest version of the robot has the sensitivity to be very gentle with the boxes.”</p><p style=\"\">I asked Drumwright what would be the most difficult object for his robot to pick up. I suggested a bowling ball (heavy, slippery, spherical). “Challenging, but by no means impossible,” was his response, citing research from <a href=\"https://goodrobot.ai/\" target=\"_blank\">Siddhartha Srinivasa</a> at the University of Washington showing that <a href=\"https://goodcherrybot.github.io/\" rel=\"noopener noreferrer\" target=\"_blank\">a robot with chopsticks can learn to do dynamic fine manipulation of spherical objects</a>. Dextrous isn’t above cheating slightly, though, by adding a thin coating of hard rubber to the chopsticks’ end effectors to add just a tiny bit of compliance—not enough to mess with planning or control, but enough to make grasping some tricky objects a little easier.</p><p class=\"shortcode-media shortcode-media-youtube\" style=\"\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"a98597c2119567981f99b1fe609dc2fc\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/pXgjySxI1qQ?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p style=\"\">By a year ago, Dextrous had shown that it could move boxes at high speeds under limited scenarios. For the past year, it has been making sure that the system can handle the full range of scenarios that it’s likely to encounter in warehouses. Up next is combining those two things—cranking the speed back up while still working reliably and autonomously.</p><p style=\"\">“On the manipulation side, the system is fully autonomous,” Drumwright says. “We currently have humans involved in driving the robot into the container and then joysticking it forward once it’s picked all that it can reach, but we’re making that fully autonomous, too.” And the robot has so far been quite reliable, requiring little more than lubrication.<br/></p><p style=\"\">According to Drumwright, the biggest challenge on the business side at this point is simply manufacturing enough robots, since the company builds the hardware in-house. The remaining question is how long it will take to make the transition from experiment to product. The company is starting a few commercial pilots, and Drumwright says the thing that’s slowing them down the most is building enough robots to keep up with demand.</p><p style=\"\">“We’ve solved all of the hardest technical problems,” he says. “And now, it’s the business part.”</p>"},"pubDate":"Tue, 07 Nov 2023 18:00:03 +0000","guid":"https://spectrum.ieee.org/warehouse-robots","category":["Manipulation","Warehouse robots","Robotics","Industrial robots"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/two-men-stand-next-to-a-black-mechanical-robotic-frame-taller-than-they-are-which-big-chopstick-grippers-connected-to-movable-t.jpg?id=50393306&width=980"}},{"title":"Get to Know the IEEE Board of Directors","link":"https://spectrum.ieee.org/ieee-bod-november-2023","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/photo-of-2-women-and-a-man.png?id=50348367&width=1200&height=800&coordinates=1572%2C0%2C0%2C0\"/><br/><br/><p>\n\tThe IEEE Board of Directors shapes the future direction of IEEE and is committed to ensuring IEEE remains a strong and vibrant organization—serving the needs of its members and the engineering and technology community worldwide—while fulfilling the IEEE mission of advancing technology for the benefit of humanity.\n</p><p>\n\tThis article features IEEE Board of Directors members Leila De Floriani, Kathy Herring Hayashi, and Vincenzo Piuri.\n</p><h2 style=\"\">IEEE Fellow Leila De Floriani</h2><p style=\"\">\n<strong>  Director, Division VIII</strong>\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Portrait of a smiling red haired woman in a black shirt and beaded necklace.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"0aa5ea4b8f250cb91b0ecc2b257d4b88\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"65983\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-a-smiling-red-haired-woman-in-a-black-shirt-and-beaded-necklace.png?id=50348157&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\"><a href=\"https://www.rossellamurgia.it/\" rel=\"noopener noreferrer\" target=\"_blank\">Rosella Murgia</a></small>\n</p><p style=\"\">\n\tDe Floriani is a mathematician, computer scientist, and educator with academic experience in Europe and the United States. She is a pioneer in data visualization and geometric modeling. Her work on multi-resolution terrain modeling and visualization has been extensively used in geographic information systems, video games, flight simulators, and web-based terrain navigation tools. Her recent work on topology-based analysis resulted in software tools for tree segmentation and reconstruction from big forestry data acquired through lidar. These tools have been used to track forest characteristics in connection with carbon emission evaluation and forecasting forest evolution.\n</p><p style=\"\">\n\tAs the 2020 president of the \n\t<a href=\"https://www.computer.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Computer Society</a>, De Floriani established a permanent committee on Diversity and Inclusion. Additionally, she strengthened the society’s leadership in open access and open science—focusing on research reproducibility, which led to a roadmap for professional societies. She is also a member of the IEEE Conferences Committee.\n</p><p style=\"\">\n\tHaving authored more than 300 peer-reviewed scientific publications, De Floriani served as editor in chief of the \n\t<a href=\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=2945\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Transactions on Visualization and Computer Graphics</em></a> from 2015 to 2018. She introduced research reproducibility projects by publishing papers enhanced with reproducible code and data.\n</p><p style=\"\">\n\tDe Floriani is a Fellow of the \n\t<a href=\"https://iapr.org/\" rel=\"noopener noreferrer\" target=\"_blank\">International Association for Pattern Recognition</a> and <a href=\"https://www.eg.org/wp/\" rel=\"noopener noreferrer\" target=\"_blank\">Eurographics Association</a>. She was named a pioneer by the <a href=\"http://solidmodeling.org/awards/sma-pioneers/\" rel=\"noopener noreferrer\" target=\"_blank\">Solid Modeling Association</a> designation that honors early contributors and those who have expanded the field. She also received the IEEE Computer Society<a href=\"https://www.computer.org/volunteering/awards/golden-core\" rel=\"noopener noreferrer\" target=\"_blank\"> Golden Core</a> recognition for her long-standing service to the society.\n</p><p style=\"\">\n\tShe is also an inducted member of the \n\t<a href=\"https://tc.computer.org/vgtc/awards/visualization-academy/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Visualization and Graphics Technical Community Visualization Academy</a> and the <a href=\"https://hkn.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE-Eta Kappa Nu</a> honor society.\n</p><h2 style=\"\">IEEE Senior Member Kathy Herring Hayashi</h2><p style=\"\">\n<strong>Director, Region 6: Western U.S.</strong>\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Portrait of a smiling woman with gray hair and glasses\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"7623708a92f76ea3f8bd21ad31d71d4d\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"cb9eb\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-a-smiling-woman-with-gray-hair-and-glasses.png?id=50348148&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">SemiCon Headshot Central</small>\n</p><p>\n\tKathy Herring Hayashi has been involved in the semiconductor industry her entire career. She has developed, deployed, and analyzed advanced software tools to create computer and mobile phone chips. She designed advanced in-house CAD software tools for the semiconductor industry, transitioned to commercial electronic design automation tools, and then brought her professional leadership to focus on semiconductor-yield solutions. Herring Hayashi currently works with semiconductor workflows in large-scale computer environments.\n</p><p style=\"\">\n\tHerring Hayashi has served in a wide variety of leadership roles, interfacing within many levels of IEEE. She has a track record of projects that embrace innovation and community leadership. As the IEEE Region 6 director, Herring Hayashi has led region-wide initiatives related to semiconductors, engaging young professionals and supporting sustainable and global humanitarian related technologies. In this role, she also establishes Board-level policies and interfaces with IEEE volunteer leadership. She serves as Vice Chair of the \n\t<a href=\"https://semiconductors.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Global Semiconductors </a>ad hoc and is a member of the <a href=\"https://www.ieee.org/communities/geographic-activities.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Member and Geographic Activities </a>(MGA) and <a href=\"https://ieeeusa.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE-USA</a> Board of Directors.\n</p><p>\n\tShe says that by working together with IEEE members, the IEEE community can help others reach career goals by showing them the full benefits of the organization.\n</p><p>\n\tHerring Hayashi has received many honors. She was named one of the \n\t<a href=\"https://www.sdbj.com/women_of_influence/\" rel=\"noopener noreferrer\" target=\"_blank\">Women of Influence in Engineering</a> from the <a href=\"https://www.sdbj.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>San Diego Business Journal</em></a><em>, </em>and she received a <a href=\"https://www.athenastemwomen.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Pinnacle Award</a> from Athena, which recognized her as one of San Diego’s outstanding technology leaders. She also received the IEEE <a href=\"https://mga.ieee.org/awards/mga-awards-and-recognition-program/mga-innovation-award\" rel=\"noopener noreferrer\" target=\"_blank\">MGA Innovation Award</a> for initiating the industry IEEE Evening of Innovation collaboration for members at the IEEE Honors Ceremony. Herring Hayashi is a member of <a href=\"https://hkn.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE-Eta Kappa Nu</a>.\n</p><h2 style=\"\">IEEE Fellow Vincenzo Piuri</h2><p style=\"\">\n<strong>Director, Region 8: Africa, Europe, Middle East</strong>\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Portrait of a smiling man in a suit and tief\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"7ac64e3ee177601236751fd8c2065ff1\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"26076\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-a-smiling-man-in-a-suit-and-tief.png?id=50348080&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Vincenzo Piuri</small>\n</p><p>\n\tPiuri is a scientist, educator, and community leader. His theoretical research deepened interdisciplinary aspects of artificial intelligence to allow for adaptivity to evolving environmental situations and operational needs. His scientific achievements have enhanced applications in industry, the environment, biometrics, and ambient intelligence. Piuri’s original research results have been published in more than 400 international journals, conference proceedings, and books.\n</p><p>\n\tA member of the \n\t<a href=\"https://www.computer.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Computer</a>, <a href=\"https://cis.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Computational Intelligence</a>, and <a href=\"https://ieee-ims.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Instrumentation and Measurement</a> societies, Piuri has served scientific and professional communities and IEEE for almost 40 years. He has spent the last 15 years in worldwide leadership roles.\n</p><p>\n\tIn his IEEE volunteer activities, Piuri focuses on serving with a human-centered personalized approach, empowering everyone in the community to be leaders in technology and innovation, and embracing emerging technologies. By nurturing local communities, supporting underserved groups and geographical areas, and promoting cooperation, he has been a champion of proactively ensuring equal opportunities and promoting diversity and inclusion.\n</p><p style=\"\">\n\tPiuri was the past editor in chief of the \n\t<em>IEEE Systems Journal</em> and former associate editor of the <a href=\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6245519\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Transactions on Cloud Computing</em></a>; he has also served as associate editor for <a href=\"https://www.computer.org/csdl/journal/tc\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Transactions on Computers</em></a>, the <a href=\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Transactions on Neural Networks</em></a>, the <a href=\"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Transactions on Instrumentation and Measurement</em></a>, and <a href=\"https://ieeeaccess.ieee.org/about-ieee-access/learn-more-about-ieee-access/?gclid=CjwKCAjwvfmoBhAwEiwAG2tqzDnaHkTFgTmQNltp9NHwNgQlMy6o7zrFY0lN3iGoI9DZvkAYTCRR4BoCvpYQAvD_BwE\" rel=\"noopener noreferrer\" target=\"_blank\"><em>IEEE Access</em></a>.\n</p><p>\n\tIn addition to being an honorary professor at several universities around the world, he is a distinguished scientist of the \n\t<a href=\"https://www.acm.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Association for Computing Machinery</a>.\n</p><p>\n\tPiuri received the <a href=\"https://ieee-ims.org/awards/technical-award\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Instrumentation and Measurement Society Technical Award</a> in 2020 and in 2019, he was inducted into the <a href=\"https://www.ieee.org/about/tab-hall-of-honor.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Technical Activities Board Hall of Honor</a>.\n</p>"},"pubDate":"Mon, 06 Nov 2023 19:00:06 +0000","guid":"https://spectrum.ieee.org/ieee-bod-november-2023","category":["Ieee member news","Ieee board of directors","Careers","Type:ti"],"dc:creator":"IEEE","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/photo-of-2-women-and-a-man.png?id=50348367&width=980"}},{"title":"Redwood Materials Will Recycle Hawaiian Grid Batteries","link":"https://spectrum.ieee.org/redwood-materials-recycles-hawaiian-grid-batteries","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/multiple-solar-panel-arrays-next-to-an-electrical-substation-in-a-lush-green-environment.jpg?id=50405571&width=1200&height=800&coordinates=39%2C0%2C39%2C0\"/><br/><br/><p style=\"\">Lithium-ion battery recycling took a big step forward this week, as a Hawaiian utility announced it is undertaking one of the biggest examples of grid-storage recycling in North America to date.<br/></p><p style=\"\">The Kaua’i Island Utility Cooperative is working with <a href=\"https://www.redwoodmaterials.com/\" target=\"_blank\">Redwood Materials</a> to decommission the Anahola Solar Project substation and recycle its lithium-ion batteries in order to make new batteries.</p><p style=\"\">The Anahola recycling project is one of the earliest examples of stationary storage recycling. As such, it sets the stage for an expected rise in stationary battery storage recycling in the future. A Redwood Materials spokesman said that “successful decommissioning of these initial projects serves as an industry model for future gigawatt-scale projects.”</p><p style=\"\">By electric grid standards, Anahola’s 4-megawatt-hour storage facility is not big. However, its compliment of lithium-ion batteries is one of the largest to be recycled thus far. “The thing to keep in mind is that the large-scale lithium-battery sector is relatively young,” noted Sam Abuelsamid, the principal analyst for transportation and mobility at the market intelligence firm <a href=\"https://guidehouseinsights.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Guidehouse Insights</a>. “The vast majority of batteries are nowhere near end of life yet. They’re not ready for recycling.”</p><p style=\"\">Built in 2015, the Anahola station is old enough that its batteries have reached their end of life. The station had been using the batteries to store power from 53 acres of photovoltaic panels, which was then used to power homes, businesses, and streetlights on Hawaii’s Kaua’i Island. The facility’s substation included eight stationary power containers made up of 2,320 lithium-ion battery modules in total. All of the lithium-ion cells employed nickel cobalt aluminum oxide chemistry (NCA). Redwood Materials would not name the original supplier of the NCA batteries, but did say it was not <a href=\"https://www.tesla.com/energy\" target=\"_blank\">Tesla</a> (Redwood Materials was launched by Tesla cofounder JB Straubel).</p><p style=\"\">Following substation decommissioning, the Anahola solar facility will continue to operate, but it will be a direct-to-grid solar facility, a Redwood Materials spokesman said.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\" style=\"\">\n<img alt=\"Two people in hardhats stand next to a large container divided into three sections, each with an open door.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"063b27967930b8d83f11d8c2f00257de\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"dae22\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/two-people-in-hardhats-stand-next-to-a-large-container-divided-into-three-sections-each-with-an-open-door.jpg?id=50405635&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Redwood Materials’ founder JB Straubel [left, in vest] worked with Anahola in the decommissioning and recycling of the substation batteries.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Redwood Materials</small></p><p style=\"\">Anahola is the biggest stationary storage recycling project for Redwood Materials to date, but it is still only a small part of Redwood’s business. Since its launch in 2017, the company has set out to create a “circular supply chain” of lithium-ion batteries for electric vehicles and clean-energy products. Last year, it recycled approximately 10 gigawatt-hours of lithium-ion batteries, which would be enough for 100,000 electric vehicles, the company said. Much of the recycled material came from consumer electronics batteries and manufacturing scrap.</p><p style=\"\">Plans are for a rapid rise in those numbers over the next few years. Last December, Redwood Materials announced plans for a US $3.5 billion “<a href=\"https://www.redwoodmaterials.com/news/announcing-redwood-south-carolina/\" target=\"_blank\">Battery Materials Campus</a>” just outside Charleston, S.C., where it eventually expects to recycle 100 GWh of battery anode and cathode materials per year. The 600-acre campus will be one of the biggest economic-development projects in the history of South Carolina.</p><p style=\"\">Such plans are important for the future of the domestic battery industry, experts say, because they would enable EV and battery manufacturers to source materials from inside the United States. Currently, materials such as nickel, manganese, lithium, and cobalt are sourced from Indonesia, South Africa, Australia, South America, the Democratic Republic of the Congo, and elsewhere.</p><p>“Instead of mining it in the ground, it just makes sense that it would be cheaper to recover the materials from recycled, end-of-life items,” said Jeffrey Spangenberger, group leader for materials recycling at Argonne National Laboratory.</p><p style=\"\">Battery manufacturers hope that recycled materials will enable them to dramatically cut product cost. The U.S. Department of Energy’s <a href=\"https://www.energy.gov/energy-storage-grand-challenge/articles/energy-storage-grand-challenge-roadmap\" rel=\"noopener noreferrer\" target=\"_blank\">Energy Storage Grand Challenge Roadmap</a> has called for battery-pack costs to be reduced from about $140 per kilowatt-hour today to $80/kWh by 2030, and most experts believe that recycling would aid in that reduction because it would diminish the need to obtain materials from abroad.</p><p style=\"\">“We have to get the materials from somewhere,” Spangenberger said. “So the idea is, buy it once and keep it here.”</p><p style=\"\">Grid-storage batteries would play an important role in that future plan because those applications are often very large, containing millions of lithium-ion cells. Many large grid-storage sites already exist in North America. In California, big grid-storage projects include the Moss Landing facility in Monterey, which offers 400 megawatts of battery storage, and the McCoy Solar Energy project in Riverside County, which has 230 MW of storage. The Manatee Energy Storage Center, in Florida, also has 409 MW of battery storage, and the Kaua’I Island Utility Cooperative has a <a href=\"https://spectrum.ieee.org/tesla-teams-with-tiny-hawaiian-utility-to-store-solar#:~:text=Tesla%20Motors%20Inc.%2C%20in%20association,of%2013%20megawatts%20(MW).\" target=\"_self\">52-MW battery-storage facility</a> that went on line in 2017. Last year alone, the United States deployed 4.8 GW of stationary storage, according to <a href=\"https://www.publicpower.org/periodical/article/us-energy-storage-market-installed-record-48-gw-2022\" rel=\"noopener noreferrer\" target=\"_blank\">statistics</a> from the American Public Power Association.</p><p>“It’s going to continue to grow,” Spangenberger said. “That’s why it’s going to be important to be able to recycle at large scale.”</p>"},"pubDate":"Mon, 06 Nov 2023 17:48:04 +0000","guid":"https://spectrum.ieee.org/redwood-materials-recycles-hawaiian-grid-batteries","category":["Battery recycling","Batteries","Climate change","Climate tech","Grid storage"],"dc:creator":"Charles J. Murray","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/multiple-solar-panel-arrays-next-to-an-electrical-substation-in-a-lush-green-environment.jpg?id=50405571&width=980"}},{"title":"Remembering IEEE Director Emeritus Theodore W. Hissey","link":"https://spectrum.ieee.org/remembering-theodore-w-hissey","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/elderly-man-smiling-for-a-portrait-in-front-of-a-white-background-with-black-text-on-it.jpg?id=50383142&width=1200&height=800&coordinates=0%2C33%2C0%2C74\"/><br/><br/><p>IEEE Life Fellow Theodore W. “Ted” Hissey died on 14 October at the age of 97. </p><p>An active volunteer whose involvement with IEEE spanned more than six decades, Hissey served as IEEE director emeritus from 1994 to 1996. In 1997 he was vice president of the <a href=\"https://www.ieeefoundation.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Foundation</a>. </p><p>More recently, he focused on facilitating partnerships and establishing joint awards with other technical societies in IEEE Regions 8, 9, and 10. But in a 2014 interview with <a href=\"https://spectrum.ieee.org/ted-hissey-a-tireless-volunteer\" target=\"_self\"><em>The Institute</em></a>, Hissey said his real passion was organizing outreach events for students and mentoring new volunteers through <a href=\"https://yp.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Young Professionals</a>.</p><p>“I seek out and mentor ambitious young professionals and encourage them to seek higher-level positions within IEEE to bring their fresh and innovative ideas into the organization,” he said. </p><p>To honor his mentoring activities within IEEE YP, in 2017 the <a href=\"https://corporate-awards.ieee.org/award/2021-ieee-theodore-w-hissey-outstanding-young-professional-award/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Theodore W. Hissey Outstanding Young Professional Award</a> was established. It recognizes young engineers for contributions to the technical community and IEEE’s fields of interest.</p><p>“Theodore Hissey was the kindest and most empowering soul,” <a href=\"https://spectrum.ieee.org/legacy-of-eddie-custovic\" target=\"_self\">Eddie Custovic says</a>. The IEEE senior member received the 2022 IEEE Theodore W. Hissey Outstanding Young Professional Award. </p><p>“His encouragement and support is something that helped me tremendously in my early career,” Custovic adds. “Receiving the 2022 IEEE award that bears his name is the greatest highlight of my professional career. His legacy and what it means to be a selfless leader, will continue to serve our global IEEE community as exemplary. He will never be forgotten. Rest in peace Uncle Ted.”</p><h2>A jet-setting career</h2><p>After receiving his bachelor’s degree in power engineering in 1948 from <a href=\"https://www.psu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Pennsylvania State University</a> in University Park, Hissey joined <a href=\"http://www.leedsandnorthrup.co.uk/\" rel=\"noopener noreferrer\" target=\"_blank\">Leeds and Northrup</a> (L&N) in Philadelphia as an applications engineer. The company made electrical measurement instruments and control and power systems. He worked there for 43 years, serving in a variety of engineering and management positions. </p><p>While at L&N, Hissey joined a number of technical and standards committees and helped establish IEEE conferences. His work took him to more than 50 countries, and he befriended many engineers around the globe.</p><p>Those contacts helped Hissey and L&N take on several international projects such as setting up telemetry systems for <a href=\"https://www.aramco.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Aramco</a>, a national oil and natural gas company in Saudi Arabia. He spent time in Brazil helping engineers there expand and stabilize the power grid.</p><p>Later he was a principal engineer at Macro Corp., an engineering consultancy firm based in Horsham, Pa. </p><p>In the 2014 interview, Hissey credited some of his career achievements to his involvement with the American Institute of Electrical Engineers—one of IEEE’s predecessor societies—and later IEEE. </p><p>“Organizing and attending global conferences, networking with engineers, and having access to the latest technical research really helped me keep up as hardware and software evolved,” he said. “IEEE paved a road for me throughout my working life.”</p><h2>Giving back and guiding others</h2><p>Hissey’s involvement with IEEE can be traced to the late 1940s, when he chaired Penn State’s student AIEE chapter.</p><p>He became a member of the <a href=\"https://www.ieee-pes.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Power & Energy Society</a> governing board in 1973, and he served as society’s 1985–1986 president.</p><p>Toward the end of his career, he was on the IEEE Board of Directors, and he was director of IEEE Division VII (Energy and Power Engineering). He also served on several committees as well as the Regional Activities (now Member and Geographic Activities), Standards, and Technical Activities boards.</p><p>He served as IEEE treasurer in the early 1990s. In 1994 he was appointed acting IEEE executive director.</p><p>In 1996, Hissey began serving on the IEEE Foundation Board of Directors and in 2005, became its director emeritus. </p><p>Hissey enjoyed sharing his wisdom with the next generation. “I tell young people they’re in a different world today than when I started out in the late 1940s,” he told <em>The Institute</em> in 2014. “In those days, companies were more supportive of their employees; their professional development was a priority. Now young professionals often have to learn these skills on their own.”</p><p>Through his mentorship, “Uncle Ted” helped many volunteers feel as though they did not have to go it alone.</p><p>“Ted’s support of [students and young professionals] was outstanding,” says Francisco Martinez, 2021 director of the IEEE Foundation. “He motivated them not only to improve their professional skills but also to continue their involvement with IEEE.”</p><p>To help honor his legacy, Hissey’s family and the IEEE Foundation have launched <a href=\"https://secure.ieeefoundation.org/site/Donation2?df_id=2340&mfc_pref=T&2340.donation=form1\" target=\"_blank\">a donation page in his name</a>. Donations will be directed to the IEEE Theodore Hissey Young Professional Award Fund, which supports the annual presentation of this distinguished honor.</p>"},"pubDate":"Sun, 05 Nov 2023 19:00:02 +0000","guid":"https://spectrum.ieee.org/remembering-theodore-w-hissey","category":["Ieee member news","In memoriam","Obituary","Ted hissey","Type:ti"],"dc:creator":"Amanda Davis","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/elderly-man-smiling-for-a-portrait-in-front-of-a-white-background-with-black-text-on-it.jpg?id=50383142&width=980"}},{"title":"A Bold New Plan for Preserving Online Privacy and Security","link":"https://spectrum.ieee.org/data-privacy","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-a-person-and-a-person-shaped-icon-on-a-jar.png?id=50406100&width=1200&height=800&coordinates=135%2C0%2C135%2C0\"/><br/><br/><p style=\"\">\n<strong>Whether we like it</strong> or not, we all use the cloud to communicate and to store and process our data. We use dozens of cloud services, sometimes indirectly and unwittingly. We do so because the cloud brings real benefits to individuals and organizations alike. We can access our data across multiple devices, communicate with anyone from anywhere, and command a remote data center’s worth of power from a handheld device.\n</p><p style=\"\">\n\tBut using the cloud means our security and privacy now depend on cloud providers. Remember: The cloud is just another way of saying “someone else’s computer.” Cloud providers are single points of failure and prime targets for hackers to scoop up everything from proprietary corporate communications to our personal photo albums and financial documents.\n</p><p>\n\tThe risks we face from the cloud today are not an accident. For Google to show you your work emails, it has to store many copies across many servers. Even if they’re stored in encrypted form, Google must decrypt them to display your inbox on a webpage. When Zoom coordinates a call, its servers receive and then retransmit the video and audio of all the participants, learning who’s talking and what’s said. For Apple to analyze and share your photo album, it must be able to access your photos.\n</p><p>\n\tHacks of cloud services happen so often that it’s hard to keep up. Breaches can be so large as to affect nearly every person in the country, as in the \n\t<a href=\"https://www.washingtonpost.com/news/the-switch/wp/2018/03/01/equifax-keeps-finding-millions-more-people-who-were-affected-by-its-massive-data-breach/\" target=\"_blank\">Equifax breach of 2017</a>, or a large fraction of the Fortune 500 and the U.S. government, as in the <a href=\"https://www.wired.com/story/the-untold-story-of-solarwinds-the-boldest-supply-chain-hack-ever/\" target=\"_blank\">SolarWinds breach of 2019–20</a>.\n</p><p>\n\tIt’s not just attackers we have to worry about. Some companies use their access—benefiting from weak laws, complex software, and lax oversight—to mine and sell our data. Other companies sell us fancy but ineffective security technologies. Every company needs an attentive chief information security officer and has to pay through the nose for cybersecurity insurance. Individuals have to keep track of data breaches and privacy policy changes from their cloud providers.\n</p><p>\n\tYet this vigilance does little to protect us. Just this year, \n\t<a href=\"https://www.reuters.com/technology/microsoft-under-fire-after-hacks-us-state-commerce-departments-2023-07-13/\" target=\"_blank\">Microsoft faced a firestorm</a> for major, long-running hacks of its cloud services, and <a href=\"https://gizmodo.com/zoom-ai-privacy-policy-train-on-your-data-1850712655\" target=\"_blank\">Zoom faced a backlash</a> about its quiet policy changes regarding the use of private user data for AI. No major remedies seem likely.\n</p><p>\n\tWe’re all hoping that companies will keep us safe, but it’s increasingly clear that they don’t, can’t, and won’t. We should stop expecting them to.\n</p><p>\n\tOur message is simple: It is possible to get the best of both worlds. We can and should get the benefits of the cloud while taking security back into our own hands. Here we outline a strategy for doing that.\n</p><h2 style=\"\">What is decoupling?</h2><p>\n\tIn the last few years, a slew of ideas old and new have converged to reveal a path out of this morass, but they haven’t been widely recognized, combined, or used. These ideas, which we’ll refer to in the aggregate as “decoupling,” allow us to rethink both security and privacy.\n</p><p>\n\tHere’s the gist. The less someone knows, the less they can put you and your data at risk. In security this is called Least Privilege. The \n\t<a href=\"https://conferences.sigcomm.org/hotnets/2022/papers/hotnets22_schmitt.pdf\" target=\"_blank\">decoupling principle</a> applies that idea to cloud services by making sure systems know as little as possible while doing their jobs. It states that we gain security and privacy by separating private data that today is unnecessarily concentrated.\n</p><p>\n\tTo unpack that a bit, consider the three primary modes for working with our data as we use cloud services: data in motion, data at rest, and data in use. We should decouple them all.\n</p><p style=\"\">\n\tOur data is in motion as we exchange traffic with cloud services such as videoconferencing servers, remote file-storage systems, and other content-delivery networks. Our data at rest, while sometimes on individual devices, is usually stored or backed up in the cloud, governed by cloud provider services and policies. And many services use the cloud to do extensive processing on our data, sometimes without our consent or knowledge. Most services involve more than one of these modes.\n</p><p class=\"pull-quote\" style=\"\">\n\t“We’re all hoping that companies will keep us safe, but it’s increasingly clear that they don’t, can’t, and won’t. We should stop expecting them to.”\n</p><p>\n\tTo ensure that cloud services do not learn more than they should, and that a breach of one does not pose a fundamental threat to our data, we need two types of decoupling. The first is organizational decoupling: dividing private information among organizations such that none knows the totality of what is going on. The second is functional decoupling: splitting information among layers of software. Identifiers used to authenticate users, for example, should be kept separate from identifiers used to connect their devices to the network.\n</p><p>\n\tIn designing decoupled systems, cloud providers should be considered potential threats, whether due to malice, negligence, or greed. To verify that decoupling has been done right, we can learn from how we think about encryption: You’ve encrypted properly if you’re comfortable sending your message with your adversary’s communications system. Similarly, you’ve decoupled properly if you’re comfortable using cloud services that have been split across a noncolluding group of adversaries.\n</p><p>\n\tCryptographer David Chaum first applied the decoupling approach in security protocols for anonymity and digital cash in the 1980s, long before the advent of online banking or cryptocurrencies. Chaum asked: How can a bank or a network service provider provide a service to its users without spying on them while doing so?\n</p><p style=\"\">\n\tChaum’s ideas included sending Internet traffic through multiple servers run by different organizations and divvying up the data so that a breach of any one node reveals minimal information about users or usage. Although these ideas have been influential, they have found only niche uses, such as in the popular Tor browser.\n</p><h3>Trust, but Don’t Identify</h3><br/><p style=\"\">The decoupling principle can protect the privacy of data in motion, such as financial transactions and Web browsing patterns that currently are wide open to vendors, banks, websites, and Internet Service Providers (ISPs).<br/></p><h3></h3><br><img alt=\"Illustration of a process.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"4ce1896019ae4e83f237774e766eaa43\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"f7554\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/illustration-of-a-process.png?id=50406122&width=980\"/><p>\n<span style=\"color:red\">1. Barath orders Bruce’s audiobook from Audible. 2. His bank does not know what he is buying, but it guarantees the payment. 3. A third party decrypts the order details but does not know who placed the order. 4. Audible delivers the audiobook and receives the payment.</span>\n</p><p>\n<strong>DECOUPLED E-COMMERCE:</strong> By inserting an independent verifier between the bank and the seller and by blinding the buyer’s identity from the verifier, the seller and the verifier cannot identify the buyer, and the bank cannot identify the product purchased. But all parties can trust that the signed payment is valid.<br/>\n</p><h3></h3><br><img alt=\"Illustration of a process\" class=\"rm-shortcode\" data-rm-shortcode-id=\"2b9db53100858f03aae8779ccabb183f\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"94f4e\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/illustration-of-a-process.png?id=50406128&width=980\"/><p style=\"color:red\">\n\t1. Bruce’s browser sends a doubly encrypted request for the IP address of sigcomm.org. 2. A third-party proxy server decrypts one layer and passes on the request, replacing Bruce’s identity with an anonymous ID. 3. An Oblivious DNS server decrypts the request, looks up the IP address, and sends it back in an encrypted reply. 4. The proxy server forwards the encrypted reply to Bruce’s browser. 5. Bruce’s browser decrypts the response to obtain the IP address of sigcomm.org.\n</p><p>\n<strong>DECOUPLED WEB BROWSING: </strong>Currently Internet service or virtual private network providers can track which websites their users visit because requests to the Domain Name System <span style=\"background-color: initial;\">(DNS)</span><span style=\"background-color: initial;\">,</span> which <span style=\"background-color: initial;\">convert</span><span style=\"background-color: initial;\">s</span> domain names to IP addresses, are unencrypted. A new protocol called <a href=\"https://schmittpaul.github.io/EE693F_Fall2022/papers/odns.pdf\" target=\"_blank\">Oblivious DNS</a> can protect users’ browsing requests from third parties. Each name-resolution request is encrypted twice and then sent to an intermediary (a “proxy”) that strips out the user’s IP address and decrypts the outer layer before passing the request to a domain name server, which then decrypts the actual request. Neither the ISP nor any other computer along the way can see what name is being queried. The Oblivious resolver has the key needed to decrypt the request but no information about who placed it. The resolver encrypts its reply so that only the user can read it.\n</p><p style=\"\">\n\tSimilar methods have been extended beyond DNS to multiparty-relay protocols that protect the privacy of all Web browsing through free services such as Tor and subscription services such as INVISV Relay and Apple’s iCloud Private Relay.\n</p><h3></h3><br/><h2>How decoupling can protect data in motion</h2><p>Three classes of new technology developed in the last few years now make decoupling practical in many more applications.</p><p>Imagine you’re on a Zoom call. Your device and those of your colleagues are sending video to Zoom’s servers. By default, this is encrypted when sent to Zoom, but Zoom can decrypt it. That means Zoom’s servers see the video and hear the audio, and then forward it to others on the call. Zoom also knows who’s talking to whom, and when.</p><p>Meetings that were once held in a private conference room are now happening in the cloud, and third parties like Zoom see it all: who, what, when, where. There’s no reason a videoconferencing company has to learn such sensitive information about every organization it provides services to. But that’s the way it works today, and we’ve all become used to it.</p><p>There are multiple threats to the security of that Zoom call. A Zoom employee could go rogue and <a href=\"https://www.washingtonpost.com/technology/2020/12/18/zoom-helped-china-surveillance/\" rel=\"noopener noreferrer\" target=\"_blank\">snoop on calls</a>. Zoom could spy on calls of other companies or <a href=\"https://arstechnica.com/tech-policy/2021/08/zoom-to-pay-85m-for-lying-about-encryption-and-sending-data-to-facebook-and-google/\" rel=\"noopener noreferrer\" target=\"_blank\">harvest and sell</a> user data to data brokers. It could use your personal data to train its AI models. And even if Zoom and all its employees are completely trustworthy, the risk of Zoom getting breached is omnipresent. Whatever Zoom can do with your data in motion, a hacker can do to that same data in a breach. Decoupling data in motion could address those threats.</p><p>Videoconferencing doesn’t need access to unencrypted video to push bits between your device and others. A properly decoupled video service could secure the who, what, where, and when of your data in motion, beginning with the “what”—the raw content of the call. True end-to-end encryption of video and audio would keep that content private to authorized participants in a call and nobody else. (Zoom does currently offer this option, but using it disables many other features.)</p><p>To protect the “who,” functional decoupling within the service could authenticate users using cryptographic schemes that mask their identity, such as blind signatures, which Chaum invented decades ago for anonymizing purchases.</p><p>Organizational decoupling can protect the “where” and “when,” preventing the service from learning the network addresses of the participants and thus their locations and identities through different means. Newer multihop relay systems, more efficient than Tor, route data through third-party infrastructure so that when it reaches the video service, the true source is unknown.</p><p>Taken together, these decoupling measures would protect users from both Zoom’s deliberate actions and its security failures.</p><h2>How decoupling can protect data storage</h2><p>Data at rest, unencrypted on a laptop or phone, poses obvious risks from thieves and malware. Cloud storage is convenient, fast, and reliable, but those benefits come with new risks. A breach that affects any customer could affect all of them, making it all the more lucrative for a hacker to try to break in.</p><p>Most storage and database providers started encrypting data on disk years ago, but that’s not enough to ensure security. In most cases, the data is decrypted every time it is read from disk. A hacker or malicious insider silently snooping at the cloud provider could thus intercept your data despite it having been encrypted.</p><p>Cloud-storage companies have at various times harvested user data for AI training or to sell targeted ads. Some <a href=\"https://techcrunch.com/2014/02/12/slack-exits-beta/\" rel=\"noopener noreferrer\" target=\"_blank\">hoard it and offer paid access back to us</a> or just sell it wholesale to data brokers. Even the best corporate stewards of our data are getting into the <a href=\"https://www.bloomberg.com/news/newsletters/2022-08-14/apple-aapl-set-to-expand-advertising-bringing-ads-to-maps-tv-and-books-apps-l6tdqqmg\" rel=\"noopener noreferrer\" target=\"_blank\">advertising game</a>, and the decade-old <a href=\"https://www.wired.com/2012/11/feudal-security/\" rel=\"noopener noreferrer\" target=\"_blank\">feudal model of security</a>—where a single company provides users with hardware, software, and a variety of local and cloud services—is breaking down.</p><p>Decoupling can help us retain the benefits of cloud storage while keeping our data secure. As with data in motion, the risks begin with access the provider has to raw data (or that hackers gain in a breach). End-to-end encryption, with the end user holding the keys, ensures that the cloud provider can’t independently decrypt data from disk. But the uses of data at rest are different, so the decoupling remedies must also be different.</p><p>Functional decoupling once again becomes just as important as organizational decoupling. We need decoupled infrastructure for authentication so that users can prove who they are, for authorization so that users can be given or denied access to data, for repositories that store raw data, and for applications that operate only on data the user permits them to access. Ideally, these functions would be decoupled across multiple providers, using standard protocols and programming interfaces to weave together seamless services for users.</p><p>We also must consider use cases. We store data in the cloud not only to retrieve it ourselves, but to share it with others. Many cloud systems that hold our data—whether Amazon’s Simple Storage Service (S3), Google Drive, or Microsoft 365, or analytics platforms, such as Intuit or Salesforce—provide the illusion of control, by giving customers tools for sharing. In reality, the cloud-storage provider still has complete access to and control over your data.</p><p>Here we need to decouple data control from data hosting. The storage provider’s job is to host the data: to make it available from anywhere, instantly. The hosting company doesn’t need to control access to the data or even the software stack that runs on its machines. The cloud software that grants access should put control entirely in the end user’s hands.</p><p>Modern protocols for decoupled data storage, like Tim Berners-Lee’s <a href=\"https://solidproject.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Solid</a>, provide this sort of security. Solid is a protocol for distributed personal data stores, called pods. By giving users control over both where their pod is located and who has access to the data within it—at a fine-grained level—Solid ensures that data is under user control even if the hosting provider or app developer goes rogue or has a breach. In this model, users and organizations can manage their own risk as they see fit, sharing only the data necessary for each particular use.</p><h3>By Invitation Only: How to keep private meetings private</h3><br/><p>Online services such as Zoom, Google Meet, and Microsoft Teams know who is meeting with whom, when and where they’re meeting, and what they’re saying because users’ devices are sending all video and audio data to the cloud, which can decrypt video streams internally and see participants’ IP addresses and identities. By using multiparty relays, end-to-end encryption, and oblivious authentication, a decoupled meeting service such as <a href=\"https://invisv.com/articles/booth\" rel=\"noopener noreferrer\" target=\"_blank\">Booth</a> prevents tech giants and hackers from snooping on private discussions.</p><h3></h3><br/><img alt=\"Illustration of a process\" class=\"rm-shortcode\" data-rm-shortcode-id=\"478666f402b6f87387979ebbd0353a0d\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"76108\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/illustration-of-a-process.png?id=50390760&width=980\"/><p style=\"color:red\">\n\tEach meeting is assigned a randomly generated link. The host sends these to each meeting participant so that they—and only they—can join the meeting. The cloud service does not know who they are.\n</p><p style=\"color:red\">\n\tThe meeting data stream, encrypted end-to-end between users, applies decoupling and is routed through third-party proxies. The multiparty relay scheme can authenticate each user without revealing their identities to the meeting service.</p><h3></h3><br/><h2 style=\"\">How decoupling can make computation more secure</h2><p>Almost all cloud services have to perform some computation on our data. Even the simplest storage provider has code to copy bytes from an internal storage system and deliver them to the user. End-to-end encryption is sufficient in such a narrow context. But often we want our cloud providers to be able to perform computation on our raw data: search, analysis, AI model training or fine-tuning, and more. Without expensive, esoteric techniques, such as secure multiparty computation protocols or homomorphic encryption techniques that can perform calculations on encrypted data, cloud servers require access to the unencrypted data to do anything useful.</p><p>Fortunately, the last few years have seen the advent of general-purpose, hardware-enabled secure computation. This is powered by special functionality on processors known as trusted execution environments (TEEs) or secure enclaves. TEEs decouple who runs the chip (a cloud provider, such as Microsoft Azure) from who secures the chip (a processor vendor, such as Intel) and from who controls the data being used in the computation (the customer or user). A TEE can keep the cloud provider from seeing what is being computed. The results of a computation are sent via a secure tunnel out of the enclave or encrypted and stored. A TEE can also generate a signed attestation that it actually ran the code that the customer wanted to run.</p><p>With TEEs in the cloud, the final piece of the decoupling puzzle drops into place. An organization can keep and share its data securely at rest, move it securely in motion, and decrypt and analyze it in a TEE such that the cloud provider doesn’t have access. Once the computation is done, the results can be reencrypted and shipped off to storage. CPU-based TEEs are now widely available among cloud providers, and soon GPU-based TEEs—useful for AI applications—will be common as well.</p><h2>How decoupling protects both privacy and security</h2><p>One of the key benefits of decoupling is that it ensures there will be no single point of failure. If a cloud provider of a decoupled videoconferencing service is breached, all that’s visible is the flow of encrypted bytes to and from other nameless cloud servers. Same with storage: A breach reveals only a bunch of encrypted disks and encrypted flows of data. Same with compute: The hardware enclave shields the data in use from the attacker’s prying eyes.</p><p>The remaining risks are largely within each mode. The fact that decoupled storage feeds into decoupled compute doesn’t magnify the risk—but it’s worth thinking through in more detail.</p><p>Suppose Microsoft Azure is used to host a Solid pod, but it’s encrypted at rest and only decrypted within one of Azure’s secure enclaves. What can Microsoft or a hacker learn? The fact that Azure hosts both services does not give it much additional information, especially if data in motion is also encrypted to ensure that Microsoft doesn’t even know who is accessing that data. With all three modes decoupled, Azure sees an unknown user accessing an unknown blob of encrypted data to run unknown code within a secure enclave on Intel processors. This is exactly what an enterprise should want and expect from its cloud service providers: that they are no longer a breach risk even as they deliver the same useful cloud services as before.</p><h3></h3><br/><p>“Self-regulation is a time-honored stall tactic. We need government policy that mandates decoupling-based best practices, a tech sector that implements this architecture, and public awareness of the benefits of this better way forward.”</p><h3></h3><br/><p>Decoupling also allows us to look at security more holistically. For example, we can dispense with the distinction between security and privacy. Historically, privacy meant freedom from observation, usually for an individual person. Security, on the other hand, was about keeping an organization’s data safe and preventing an adversary from doing bad things to its resources or infrastructure.</p><p>There are still rare instances where security and privacy differ, but organizations and individuals are now using the same cloud services and facing similar threats. Security and privacy have converged, and we can usefully think about them together as we apply decoupling.</p><p>Decoupling also creates new opportunities: for companies to offer new services in a decoupled cloud ecosystem, for researchers to develop new technologies that can improve security and privacy, and for policymakers to ensure better security for everyone.</p><p>Decoupling isn’t a panacea. There will always be new, clever side-channel attacks. And most decoupling solutions assume a degree of noncollusion between independent companies or organizations. But that noncollusion is already an implicit assumption today: We trust that Google and Advanced Micro Devices will not conspire to break the security of the TEEs they deploy, for example, because the reputational harm from being found out would hurt their businesses. The primary risk, real but also often overstated, is if a government secretly compels companies to introduce backdoors into their systems. In an age of international cloud services, this would be hard to conceal and would cause irreparable harm.</p><h3>How a Credit-Reporting Agency Should Work: Decoupling could thwart a privacy disaster</h3><br/><p>Some of the most pernicious risks we face today are from organizations that we have no choice in interacting with, such as credit-reporting agencies. Equifax, for example, had famously lax security, which allowed hackers to steal personal data on some <span style=\"background-color: initial;\">163 million</span> people in 2017. Yet the company still holds some of the most sensitive personal financial data that exists.\n</p><p style=\"\">\n\tApplying the decoupling principle to those credit records could ensure a far better outcome if the company were breached again. Attackers would not be able to identify any individuals nor read any credit facts because the compromised data would be encrypted and scattered across myriad, far-flung personal data stores.\n</p><h3></h3><br/><img alt=\"Illustration of a process\" class=\"rm-shortcode\" data-rm-shortcode-id=\"71bb5bcc34baa1a47d124c4b35ed9b7b\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"9a943\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/illustration-of-a-process.png?id=50390893&width=980\"/><p style=\"color:red\">\n<span style=\"color:#5a5860\"><strong>DATA AT REST:</strong></span> Individuals and organizations could hold their credit data themselves, along with all their other personal data, in cloud repositories that they control and encrypt. New storage protocols such as Solid decouple the hosting provider from data access control and from applications. Individual credit facts (such as bank account numbers, reports from lenders, and so forth) could be cryptographically signed by those parties and supplied to the individual for storage in the repository. When applying for a loan, the user could then grant time-limited access to a specific organization for a specific application.</p><h3></h3><br/><img alt=\"Illustration of a process.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"d7f0d6847c096d7e292c789e9c5bcd1d\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"a1408\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/illustration-of-a-process.png?id=50406135&width=980\"/><p>\n<strong>DATA IN MOTION:</strong><span style=\"color: red\"> Communications to and from the reporting agency’s servers should be decoupled by multiparty-relay protocols that build in blinding and encryption to conceal who is doing the communicating as well as the identity of the individual whose data is being analyzed.</span>\n</p><p>\n<strong>DATA IN USE: </strong><span style=\"color: red\"> A credit-analysis algorithm should run only in a secure enclave on the server—known as a trusted execution environment—so that the credit agency cannot see the data as it is processed. The user can check an attestation, perhaps via an external auditor, that only a permitted algorithm was used, but cannot see the proprietary code that was executed.</span>\n</p></br></br><h2 style=\"\">Rethinking Equifax</h2><p>\n\tDecoupling doesn’t just benefit individual organizations or users: It also has positive ripple effects when properly applied. All of the decoupling we’ve talked about could lead to a better and very different outcome if Equifax were breached again, for example.\n</p><p>\n\tImagine that individuals and organizations held their credit data in cloud-hosted repositories that enable fine-grained encryption and access control. Applying for a loan could then take advantage of all three modes of decoupling. First, the user could employ Solid or a similar technology to grant access to Equifax and a bank only for the specific loan application. Second, the communications to and from secure enclaves in the cloud could be decoupled and secured to conceal who is requesting the credit analysis and the identity of the loan applicant. Third, computations by a credit-analysis algorithm could run in a TEE. The user could use an external auditor to confirm that only that specific algorithm was run. The credit-scoring algorithm might be proprietary, and that’s fine: In this approach, Equifax doesn’t need to reveal it to the user, just as the user doesn’t need to give Equifax access to unencrypted data outside of a TEE.\n</p><p>\n\tBuilding this is easier said than done, of course. But it’s practical today, using widely available technologies. The barriers are more economic than technical.\n</p><h2 style=\"\">Rethinking AI</h2><p>\n\tAs more organizations apply AI, decoupling becomes ever more important. Most cloud AI offerings—whether large language models like ChatGPT, automated transcription services from video and voice companies, or big-data analytics—require the revelation of troves of private data to the cloud provider. Sometimes organizations seek to build a custom AI model, trained on their private data, that they will then use internally. Sometimes organizations use pretrained AI models on their private data. Either way, when an AI model is used, the cloud service learns all sorts of things: the content of the prompts or data input, access patterns of the organization’s users, and sometimes even business use cases and contexts. AI models typically require substantial data, and that means substantial risk.\n</p><p>\n\tOnce again, the three modes of decoupling can enable secure, cloud-hosted AI. Data, of organizations or ordinary people, can be held in a decoupled data store with fine-grained user control and mechanisms that decouple identity from usage. When the data needs to be processed, access can be explicitly granted for that purpose to allow the secure movement of the data from the store to a TEE. The actual AI training or operation on the user’s data can leverage GPU-based secure enclaves. Basically, a GPU TEE is like a CPU TEE, so nothing is leaked about the raw data.\n</p><h2 style=\"\">How decoupling could lead to better policy</h2><p>\n\tWhy hasn’t this design philosophy been adopted widely? It’s hard to say for sure, but we think it’s because the enabling technologies—\n\t<a href=\"https://datatracker.ietf.org/wg/masque/documents/\" target=\"_blank\">multiparty relay protocols</a>, secure <a href=\"https://solidproject.org/\" target=\"_blank\">fine-grained data stores</a>, and hardware-based <a href=\"http://tees/\" target=\"_blank\">TEEs</a>—have matured only in the last few years. Also, security rarely drives business decisions, so even after the tech is available, adoption can lag.\n</p><p>\n\tRegulation, especially in the United States, is also lagging. What few data protections exist do not cover—or even clearly distinguish among—the three modes of decoupling. At the same time, it’s unreasonable to expect policymakers to make the first move. They can’t mandate something they don’t know is even possible. Technologists need to educate policymakers that potential solutions are in hand.\n</p><p>\n\tOne of the challenges of trying to regulate tech is that industry incumbents push for tech-only approaches that simply whitewash bad practices. For example, when Facebook rolls out \n\t<a href=\"https://www.facebook.com/business/news/our-progress-on-developing-and-incorporating-privacy-enhancing-technologies\" target=\"_blank\">“privacy-enhancing” advertising</a>, but still collects every move you make, has control of all the data you put on its platform, and is embedded in nearly every website you visit, that privacy technology does little to protect you. We need to think beyond minor, superficial fixes.\n</p><p>\n\tDecoupling might seem strange at first, but it’s built on familiar ideas. Computing’s main tricks are abstraction and indirection. Abstraction involves hiding the messy details of something inside a nice clean package: When you use Gmail, you don’t have to think about the hundreds of thousands of Google servers that have stored or processed your data. Indirection involves creating a new intermediary between two existing things, such as when Uber wedged its app between passengers and drivers.\n</p><p>\n\tThe cloud as we know it today is born of three decades of increasing abstraction and indirection. Communications, storage, and compute infrastructure for a typical company were once run on a server in a closet. Next, companies no longer had to maintain a server closet, but could rent a spot in a dedicated colocation facility. After that, colocation facilities decided to rent out their own servers to companies. Then, with virtualization software, companies could get the illusion of having a server while actually just running a virtual machine on a server they rented somewhere. Finally, with serverless computing and most types of software as a service, we no longer know or care where or how software runs in the cloud, just that it does what we need it to do.\n</p><p>\n\tWith each additional abstraction and layer of indirection, we’ve become further separated from true control of the underlying compute infrastructure. Meanwhile, we’ve gained operational benefits. And these operational benefits are key, even in the context of security: After all, denial of service is an attack on availability, making it a security issue even if there is no loss in confidentiality or integrity of data.\n</p><p>\n\tWe’re now at a turning point where we can add further abstraction and indirection to improve security, turning the tables on the cloud providers and taking back control as organizations and individuals while still benefiting from what they do.\n</p><p>\n\tThe needed protocols and infrastructure exist, and there are services that can do all of this already, without sacrificing the performance, quality, and usability of conventional cloud services.\n</p><p style=\"\">\n\tBut we cannot just rely on industry to take care of this. Self-regulation is a time-honored stall tactic: A piecemeal or superficial tech-only approach would likely undermine the will of the public and regulators to take action. We need a belt-and-suspenders strategy, with government policy that mandates decoupling-based best practices, a tech sector that implements this architecture, and public awareness of both the need for and the benefits of this better way forward. \n\t<span class=\"ieee-end-mark\"></span>\n</p>"},"pubDate":"Sun, 05 Nov 2023 16:00:03 +0000","guid":"https://spectrum.ieee.org/data-privacy","category":["Computer security","Data privacy","Hacking","Cloud computing"],"dc:creator":"Bruce Schneier","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/an-illustration-of-a-person-and-a-person-shaped-icon-on-a-jar.png?id=50406100&width=980"}},{"title":"Robots and the Humans Who Make Them","link":"https://spectrum.ieee.org/chatbot-podcast-2666060927","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-smiling-man-kneels-with-his-arm-around-a-squat-robot-which-has-two-flipper-legs-a-boxy-body-and-glowing-eyes-on-a-flat-head.jpg?id=50300836&width=1200&height=800&coordinates=0%2C0%2C0%2C352\"/><br/><br/><p>When<em> IEEE Spectrum</em> editors are putting together an issue of the magazine, a story on the website, or an episode of a podcast, we try to facilitate dialogue about technologies, their development, and their implications for society and the planet. We feature expert voices to articulate technical challenges and describe the engineering solutions they’ve devised to meet them. </p><p>So when Senior Editor Evan Ackerman cooked up a concept for a robotics podcast, he leaned hard into that idea. Ackerman, the world’s premier robotics journalist, talks with roboticists every day, and recording those conversations to turn those interviews into a podcast is usually a relatively straightforward process. But Ackerman wanted to try something a little bit different: bringing two roboticists together and just getting out of the way.</p><p style=\"\">“The way the Chatbot podcast works is that we invite a couple of robotics experts to talk with each other about a topic they have in common,” Ackerman explains. “They come up with the questions, not us, which results in the kinds of robotics conversations you won’t hear anywhere else—uniquely informative but also surprising and fun.”</p><p>Each episode focuses on a general topic the roboticists have in common, but once they get to chatting, the guests are free to ask each other about whatever interests them. Ackerman is there to make sure they don’t wander too far into the weeds, because we want everyone to be able to enjoy these conversations. “But otherwise, I’ll mostly just be listening,” Ackerman says, “because I’ll be as excited as you are to see how each episode unfolds.”</p><p style=\"\">We think this unique format gives the listener the inside scoop on aspects of robotics that only the roboticists themselves could get each other to reveal. Our first few episodes are already live. They include <a href=\"https://spectrum.ieee.org/autonomous-drones\" target=\"_self\">Skydio CEO Adam Bry and the University of Zurich professor Davide Scaramuzza</a> talking about autonomous drones, <a href=\"https://spectrum.ieee.org/domestic-robots\" target=\"_self\">Labrador Systems CEO Mike Dooley and iRobot chief technology officer Chris Jones</a> on the challenges domestic robots face in unpredictable dwellings, and <a href=\"https://spectrum.ieee.org/boston-dynamics-dancing-robots\" target=\"_self\">choreographer Monica Thomas and Amy LaViers of the Robotics, Automation, and Dance (RAD) Lab</a> discussing how to make Boston Dynamics’ robot dance. </p><p style=\"\">We have plenty more Chatbot episodes in the works, so please subscribe on whatever podcast service you like, <a href=\"https://spectrum.ieee.org/podcasts/\" target=\"_self\">listen and read the transcript on our website</a>, or watch the video versions on the <a href=\"https://www.youtube.com/playlist?list=PL8Ug41r-ywn-R8rHLer9X5hxLRaXnuOyz\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Spectrum</em> YouTube channel</a>. While you’re at it, subscribe to our other biweekly podcast, <a href=\"https://spectrum.ieee.org/podcasts/fixing-the-future/\" target=\"_blank\">Fixing the Future</a>, where we talk with experts and <em>Spectrum</em> editors about sustainable solutions to climate change and other topics of interest. And we’d love to hear what you think about our podcasts: what you like, what you don’t like, and especially who you’d like to hear on future episodes.</p>"},"pubDate":"Sat, 04 Nov 2023 15:00:02 +0000","guid":"https://spectrum.ieee.org/chatbot-podcast-2666060927","category":["Podcasts","Robotics"],"dc:creator":"Harry Goldstein","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-smiling-man-kneels-with-his-arm-around-a-squat-robot-which-has-two-flipper-legs-a-boxy-body-and-glowing-eyes-on-a-flat-head.jpg?id=50300836&width=980"}},{"title":"Augmented-Reality Platform Lets Consumers Customize Products","link":"https://spectrum.ieee.org/augmented-reality-consumers-customize-products","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-hand-holding-a-smart-phone-with-a-photo-of-a-suitcase-on-the-screen.jpg?id=50379344&width=1200&height=800&coordinates=0%2C60%2C0%2C60\"/><br/><br/><p>\n\tInteractive 3D and augmented reality online are making it easier for car manufacturers, fashion brands, and other businesses to design and produce their products. The platform developed by startup <a href=\"https://emersya.com/en/home\" rel=\"noopener noreferrer\" target=\"_blank\">Emersya</a> of Montpellier, France, pioneered the approach for product development, allowing teams to collaborate in 3D on design from ideation to market.\n</p><p style=\"\">\n\tCompanies purchase a subscription to access Emersya’s platform. From there, company designers upload a 3D model of their product and then start building their collections, selecting colors, materials, and graphics before determining which to sell.\n</p><h3>Emersya</h3><br/><p><strong></strong><strong>Founded </strong></p><p>2008</p>\n<p><strong>Headquarters </strong></p><p>Montpellier, France</p>\n<p><strong>Employees </strong></p><p>30</p><p>\n\tEmersya can create a configurable 3D model of an item that can be displayed on the manufacturer’s website so that customers can view the product while deciding whether to purchase it. The virtual product can be rotated 360 degrees, and in some cases can be customized by the customer. When customers are purchasing a car, for example, they can choose the vehicle’s exterior and interior colors as well as add-ons such as a sunroof.\n</p><p>\n\tEmersya’s interactive viewers are embedded on the websites of more than 1,000 retailers.\n</p><p>\n\tFor its innovation, Emersya was named the winner of the 2022 <a href=\"https://standards.ieee.org/events/3dbp/dt-grand-challenge-2022/\" rel=\"noopener noreferrer\" target=\"_blank\">3D Retail Coalition Digital Transformation Grand Challenge</a>. The award, from the <a href=\"https://standards.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Standards Association</a>, recognizes a solution that transforms the way companies create, make, and sell new products by harnessing the power of scaling and automation of 3D digital product creation.\n</p><p>\n\t“We’re happy to get this prize because it highlights what we’ve worked on for years and shows that we are offering what the industry needs right now,” says cofounder <a href=\"https://www.linkedin.com/in/aurelienvaysset/?originalSubdomain=fr\" rel=\"noopener noreferrer\" target=\"_blank\">Aurélien Vaysset</a>, the startup’s CEO. “No other platform is doing what we do. Our customers can create whatever they dream of on our platform, rather than being confined to select features, and in only a few minutes.”\n</p><h2>Speeding up product development </h2><p>\n\tDesign teams don’t have to have a technical background to use Emersya’s platform, Vaysset says, because it is built to be simple and intuitive.\n</p><p>\n\tDesigners start by uploading a 3D model of the product they want to produce. There are free tools available to create a 3D model if the team using Emersya does not have a design background. Emersya’s customer support team can assist as well.\n</p><p style=\"\">\n\tWhen the 3D asset has been created, it can be used to create an interactive and AR product experience for retail. It can be animated to enable customers to simulate product features, visualize interior components, and enlarge the view to get a better look.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\" style=\"\">\n<img alt=\"white running shoes with an arrow pointing to 3 different colored running shoes with an arrow pointing to a laptop screen with a deconstructed running shoe\" class=\"rm-shortcode\" data-rm-shortcode-id=\"6e155d55e4cc39ecebed691d0a0520a2\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"32406\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/white-running-shoes-with-an-arrow-pointing-to-3-different-colored-running-shoes-with-an-arrow-pointing-to-a-laptop-screen-with-a.jpg?id=50381814&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Using Emersya’s augmented-reality platform, a company’s designer, like this sneaker manufacturer, can build a 3D model of its product. The 3D asset can then be displayed on the manufacturer’s website so that customers can view the product to decide whether to purchase it.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Emersya</small></p><p>\n\tThe designers can share the virtual product with other team members for feedback, which they can provide directly on the platform by leaving notes. Collaborators can rate the designs on a scale of 1 to 5 so that teams can vote to determine their favorite.\n</p><p>\n\tOnce the final design or designs are selected, and the company is ready to sell the product, an HTML link is automatically generated to embed the 3D visualization on the retailer’s website.\n</p><p>\n\tCustomers can go online to examine the 3D representation and learn more about the item’s features. If, for example, customers are deciding whether to purchase a baseball cap, they can click on the image to read about the hat’s features, and they can rotate it to see different angles.\n</p><p>\n\tEmersya also can provide product information in different languages.\n</p><h2>Customization: The future of retail </h2><p>\n\tEmersya’s platform can help customers create their own custom products. Appliance manufacturer <a href=\"https://emersya.com/en/useCase/X03UONWA20\" rel=\"noopener noreferrer\" target=\"_blank\">KitchenAid</a>, headquartered in Benton Harbor, Mich., integrates Emersya’s 3D configurator on its website to let customers choose the color of the doors and handles. Surf clothing brand <a href=\"https://www.billabong.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Billabong</a>, headquartered in Gold Coast, Australia, allows customers to select a range of colors and prints for their wetsuit and to add text if they like.\n</p><p style=\"\">\n\tEmersya also offers an augmented-reality tool for retailers to incorporate on their websites and embed on their mobile apps. The tool enables customers to visualize their selected product for scale in their physical surroundings. <br/>\n\t Luggage retailer <a href=\"https://emersya.com/en/useCase/B66V1VC25H\" rel=\"noopener noreferrer\" target=\"_blank\">Samsonite USA</a>, headquartered in Mansfield, Mass., incorporates the AR technology on its website so customers can select a suitcase and then take a photo of themselves to gauge the relative size of the luggage. The AR feature gives customers a more comprehensive view of the product—which helps them make a more informed decision, Vaysset says.\n</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"e313a1b66a606f2e37f1b1b643a71692\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/bolxrR65ar8?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Samsonite’s interactive Web AR experience powered by Emersya</small>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">\n<a href=\"https://www.youtube.com/watch?v=bolxrR65ar8\" target=\"_blank\">www.youtube.com</a>\n</small>\n</p><p style=\"\">\n\tA monthly subscription starts at a little more than US $300 (€290) for a small project and goes up from there depending on the company’s size, the number of collaborators, and the number of products and configurations designed.\n</p><h2>Ready to ship while reducing waste </h2><p>\n\tMany of the businesses that use Emersya’s platform manufacture on demand instead of in mass quantities. “It saves companies from making more than they can sell,” Vaysset notes.\n</p><p>\n\tThat is especially true of fashion-industry companies, which typically offer collections split into four seasons: spring/summer, autumn/winter, resort, and pre-fall.\n</p><p>\n\t“Overproduced products have a big impact on the environment, and our goal is to help companies be environmentally friendly,” Vaysset says. “Not to mention, being wasteful is expensive for companies.”\n</p><p>\n\tHe adds that providing more product information and—in some cases—customization options to customers reduces returns.\n</p><p>\n\tEvery year, companies in the United States spend almost $50 billion on product returns. The returned goods are responsible for massive landfill waste and produce more than 24 million tonnes of carbon dioxide emissions annually, according to an <a href=\"https://www.fastcompany.com/90756025/product-returns-are-wasteful-for-companies-and-the-planet-heres-how-to-change-that\" rel=\"noopener noreferrer\" target=\"_blank\">article</a> in <em>Fast Company</em>.\n</p><p>Vaysset became interested in interactive 3D for the Web in 2008 while pursuing his master’s degree in computer science and computer graphics at <a href=\"https://www.dimension-ingenieur.com/ecole-superieure-d-ingenieurs-de-luminy-marseille/320\" rel=\"noopener noreferrer\" target=\"_blank\">École Supérieure d’Ingénieurs de Luminy</a>, in Marseille, France. The 3D technology was emerging, and that’s when he saw an enormous opportunity to apply the technology for visualizing and customizing products online.</p>"},"pubDate":"Fri, 03 Nov 2023 18:00:04 +0000","guid":"https://spectrum.ieee.org/augmented-reality-consumers-customize-products","category":["Ieee member news","Consumer products","Augmented reality","Startups","Type:ti"],"dc:creator":"Monica Rozenfeld","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-hand-holding-a-smart-phone-with-a-photo-of-a-suitcase-on-the-screen.jpg?id=50379344&width=980"}},{"title":"Video Friday: Robots for Humanity","link":"https://spectrum.ieee.org/video-friday-robots-for-humanity","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-photograph-of-a-young-child-in-a-colorful-dress-and-an-older-woman-sitting-on-the-floor-next-to-a-mobile-robot-with-a-screen-o.png?id=50376290&width=1121&height=718&coordinates=121%2C0%2C38%2C2\"/><br/><br/><p style=\"\">Video Friday is your weekly selection of awesome robotics videos, collected by your friends at <em>IEEE Spectrum</em> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please <a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a> for inclusion.<br/></p><h5><a href=\"https://ssrr2023.org/\">IEEE SSRR 2023</a>: 13–15 November 2023, FUKUSHIMA, JAPAN</h5><h5 style=\"\"><a href=\"https://2023.ieee-humanoids.org/\">Humanoids 2023</a>: 12–14 December 2023, AUSTIN, TEXAS</h5><h5 style=\"\"><a href=\"https://cybathlon.ethz.ch/en/events/challenges/Challenges-2024\">Cybathlon Challenges</a>: 2 February 2024, ZURICH</h5><h5><a href=\"https://www.eurobot.org/\">Eurobot Open 2024</a>: 8–11 May 2024, LA ROCHE-SUR-YON, FRANCE</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><blockquote><em>An overview of ongoing work by Hello Robot, the University of Illinois Urbana-Champaign, the University of Washington, and Robots for Humanity to empower Henry Evans’s independence through the use of the mobile manipulator Stretch.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"fcdd65bc5bdd105974abd316b54cb266\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/GsdRvu-2nZ4?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p style=\"\">And of course, you can read more about this project in <a href=\"https://spectrum.ieee.org/stretch-assistive-robot\" target=\"_blank\">this month’s issue of <em>IEEE Spectrum</em> magazine</a>.</p><p style=\"\">[ <a href=\"https://hello-robot.com/\">Hello Robot</a> ]</p><div class=\"horizontal-rule\" style=\"\"></div><blockquote><em>At KIMLAB, we have a unique way of carving Halloween pumpkins! Our MOMO (Mobile Object Manipulation Operator) is equipped with PAPRAS arms featuring prosthetic hands, allowing it to use human tools.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"d53e0d4b77ee1cf7ab583073e53e22a2\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/A4W6SqH5_Ew?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://publish.illinois.edu/kimlab2020/\">KIMLAB</a> ]</p><div class=\"horizontal-rule\"></div><p style=\"\">This new haptic system from Carnegie Mellon University seems actually amazing, although watching the haptic arrays pulse is wigging me out a little bit for some reason.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"df7089628ec802c70e4877b099748e94\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/UJXLBqG9E_s?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.figlab.com/research/2023/FluidReality\">Fluid Reality Group</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>We are excited to introduce you to the Dingo 1.5,  the next generation of our popular Dingo platform!  With enhanced hardware and software updates, the Dingo 1.5 is ready to tackle even more challenging tasks with ease.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"6a29e38237128a65322e2f2b306d75d3\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/MKMav31GWv8?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://clearpathrobotics.com/dingo-indoor-mobile-robot/\">Clearpath</a> ]</p><div class=\"horizontal-rule\"></div><p>A little bit of a jump scare here from ANYbotics.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"afcbe782cbac3cc19d0f947c19715f24\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/0pyfUQG4Yts?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.anybotics.com/\">ANYbotics</a> ]</p><div class=\"horizontal-rule\"></div><p>Happy haunting from Boston Dynamics!</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"d7dd644a3e299024685d62e3bd3ac811\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/KfkDg8KE_JY?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://bostondynamics.com/products/spot/\">Boston Dynamics</a> ]</p><div class=\"horizontal-rule\"></div><p style=\"\">I’m guessing this is some sort of testing setup, but it’s low-key terrifying.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"eb4b10a2e1f6e4008c5f4f765acf73a9\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/pzewNZk-B04?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.flexiv.com/en/\">Flexiv</a> ]</p><div class=\"horizontal-rule\" style=\"\"></div><blockquote><em>KUKA has teamed up with Augsburger Puppenkiste to build a mobile show cell in which two robots do the work of the puppeteers.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"aec7d3712305b46925b1be244a2982af\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/KeAUdbaDEvE?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.kuka.com/HomeOfRobotik\">KUKA</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>In this video, we showcase the Advanced Grasping premium software package’s capabilities. We demonstrate how TIAGo collects objects and places them, how the gripper adapts to different shapes, and the TIAGo robot’s perception and manipulation capabilities.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"869171dfff55d84b63d2e06bbe746a2b\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/n_dbm0gttP8?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://pal-robotics.com/robots/tiago/\">PAL Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>HEBI Robotics produces a platform for robot development.  Our long-term vision is to make it easy and practical for any worker, technician, farmer, et cetera, to create robots as needed.   Today the platform is used by researchers around the world, and HEBI is using it to solve challenging automation tasks related to inspections and maintenance.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"25c6bf6e6322dc57f52882ef17bfa32e\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/4Y6Pw6sUaBY?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.hebirobotics.com/\">HEBI Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Folded robots are a rapidly growing field that is revolutionizing how we think about robotics.  Taking inspiration from the ancient art of origami results in thinner, lighter, more flexible autonomous robots.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5c06f4339e5314d50c9bcc0e5198fb2b\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/_94RMdIqW9g?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p style=\"\">[ <a href=\"https://www.youtube.com/@NSFScience\">NSF</a> ]</p><div class=\"horizontal-rule\"></div><blockquote>Can I Have a Pet T. rex? <em>is a short interdisciplinary portrait documentary featuring the paleontologist and Kod*lab postdoc Aja Mia Carter and the Kod*lab robotics researchers postdoc Wei-Hsi Chen and Ph.D. student J. Diego Caporale. Chen applies the art of origami to make a hopping robot, while Caporale adds a degree of freedom to the spine of a quadruped robot to interrogate ideas about twisting and locomotion. An expert in the evolution of tetrapod spines from 380 million years ago, Carter is still motivated by her childhood dream of a pet T. rex. But how can these robotics researchers get her closer to her vision?</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\" style=\"\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"f82bc82877ff3e281c9ef13077e747fe\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/VkKuxDJ0Xtg?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://kodlab.seas.upenn.edu/\">Kodlab</a> ]</p><div class=\"horizontal-rule\"></div>"},"pubDate":"Fri, 03 Nov 2023 15:16:31 +0000","guid":"https://spectrum.ieee.org/video-friday-robots-for-humanity","category":["Anybotics","Boston dynamics","Hello robot","Video friday","Robotics"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/a-photograph-of-a-young-child-in-a-colorful-dress-and-an-older-woman-sitting-on-the-floor-next-to-a-mobile-robot-with-a-screen-o.png?id=50376290&width=980"}},{"title":"The Future of Fully Homomorphic Encryption","link":"https://spectrum.ieee.org/fully-homomorphic-encryption","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/image.png?id=50349974&width=980\"/><br/><br/><p style=\"\"><em>This sponsored article is brought to you by <a href=\"https://engineering.nyu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">NYU Tandon School of Engineering</a>.</em></p><p style=\"\">In our digital age, where information flows seamlessly through the vast network of the internet, the importance of encrypted data cannot be overstated. As we share, communicate, and store an increasing amount of sensitive information online, the need to safeguard it from prying eyes and malicious actors becomes paramount. Encryption serves as the digital guardian, placing our data in a lockbox of algorithms that only those with the proper key can unlock.</p><h3></h3><br/><p>Whether it’s personal messages, health data, financial transactions, or confidential business communications, encryption plays a pivotal role in maintaining privacy and ensuring the integrity of our digital interactions. Typically, data encryption protects data in transit: it’s locked in an encrypted “container” for transit over potentially unsecured networks, then unlocked at the other end, by the other party for analysis. But outsourcing to a third-party is inherently insecure.</p><h3></h3><br/><img alt=\"A man with short light brown hair and beard, wearing glasses, smiles at the camera.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"2becf662f40f1fa3262c49e6df2fe8e3\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1d7c9\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-man-with-short-light-brown-hair-and-beard-wearing-glasses-smiles-at-the-camera.png?id=50349673&width=980\"/><h3></h3><br/><p>But what if encryption didn’t just exist in transit and sit unprotected on either end of the transmission? What if it was possible to do all of your computer work — from basic apps to complicated algorithms — fully encrypted, from beginning to end.</p><p>That is the task being taken up by <a href=\"https://engineering.nyu.edu/faculty/brandon-reagen\" rel=\"noopener noreferrer\" target=\"_blank\">Brandon Reagen</a>, Assistant Professor of Computer Science and Engineering and Electrical and Computer Engineering at the <a href=\"https://engineering.nyu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">NYU Tandon School of Engineering</a>. Reagen, who is also a member of the <a href=\"https://cyber.nyu.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">NYU Center for Cybersecurity</a>, focuses his research on designing specialized hardware accelerators for applications including privacy preserving computation. And now, he is proving that the future of computing can be privacy-forward while making huge advances in information processing and hardware design.</p><h2>All-encompassing Encryption</h2><p>In a world where cyber threats are ever-evolving and data breaches are a constant concern, encrypted data acts as a shield against unauthorized access, identity theft, and other cybercrimes. It provides individuals, businesses, and organizations with a secure foundation upon which they can build trust and confidence in the digital realm.</p><p>The goal of cybersecurity researchers is the protection of your data from all sorts of bad actors — cybercriminals, data-hungry companies, and authoritarian governments. And Reagen believes encrypted computing could hold an answer. “This sort of encryption can give you three major things: improved security, complete confidentiality and sometimes control over how your data is used,” says Reagen. “It’s a totally new level of privacy.”</p><p class=\"pull-quote\">“My aim is to develop ways to run expensive applications, for example, massive neural networks, cost-effectively and efficiently, anywhere, from massive servers to smartphones” <strong>—Brandon Reagen, NYU Tandon</strong></p><p>Fully homomorphic encryption (FHE), one type of privacy preserving computation, offers a solution to this challenge. FHE enables computation on encrypted data, or ciphertext, to keep data protected at all times. The benefits of FHE are significant, from enabling the use of untrusted networks to enhancing data privacy. FHE is an advanced cryptographic technique, widely considered the “holy grail of encryption,” that enables users to process encrypted data while the data or models remain encrypted, preserving data privacy throughout the data computation process, not just during transit.</p><p>While a number of FHE solutions have been developed, running FHE in software on standard processing hardware remains untenable for practical data security applications due to the massive processing overhead. Reagen and his colleagues have recently been working on a DARPA-funded project called The Data Protection in Virtual Environments (DPRIVE) program, that seeks to speed up FHE computation to more usable levels.</p><h3></h3><br/><img alt=\"Diagram showing four different parts, including interconnected logic, memory, and other elements, of a cybersecurity chip.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"d0701ef99567ef40f0c40aba10bd14ed\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"f2646\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/diagram-showing-four-different-parts-including-interconnected-logic-memory-and-other-elements-of-a-cybersecurity-chip.png?id=50349678&width=980\"/><h3></h3><br/><p>Specifically, the program seeks to develop novel approaches to data movement and management, parallel processing, custom functional units, compiler technology, and formal verification methods that ensure the design of the FHE implementation is effective and accurate, while also dramatically decreasing the performance penalty incurred by FHE computations. The target accelerator should reduce the computational run time overhead by many orders of magnitude compared to current software-based FHE computations on conventional CPUs, and accelerate FHE calculations to within one order of magnitude of current performance on unencrypted data.</p><h2>The Hardware Promising Privacy</h2><p>While FHE has been shown to be possible, the hardware required for it to be practical is still rapidly being developed by researchers. Reagen and his team are designing it from the ground up, including new chips, datapaths, memory hierarchies, and software stacks to make it all work together.</p><p>The team was the first to show that the extreme levels of speedup needed to make HE feasible was possible. And by early next year, they’ll begin manufacturing of their prototypes to further their field testing.</p><p>Reagen — who earned a doctoral degree in computer science from Harvard in 2018 and undergraduate degrees in computer systems engineering and applied mathematics from the University of Massachusetts, Amherst, in 2012 — focused on creating specialized hardware accelerators for applications like deep learning. These accelerators enhance specialized hardware that can be made orders of magnitude more efficient than general-purpose platforms like CPUs. Enabling accelerators requires changes to the entire compute stack, and to bring about this change, he has made several contributions to lowering the barrier of using accelerators as general architectural constructs, including benchmarking, simulation infrastructure, and System on a Chip (SoC) design.</p><h3></h3><br/><img alt=\"Diagram showing different parts of the Cheetah accelerator architecture, including IO buffers, engines, and memory.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"7c4633cd0b11bc2aa6df95d3b2fef966\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"200bb\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/diagram-showing-different-parts-of-the-cheetah-accelerator-architecture-including-io-buffers-engines-and-memory.png?id=50349685&width=980\"/><h3></h3><br/><p>“My aim is to develop ways to run expensive applications, for example, massive neural networks, cost-effectively and efficiently, anywhere, from massive servers to smartphones,” he says.</p><p>Before coming to NYU Tandon, Reagen was a former research scientist on Facebook’s AI Infrastructure Research team, where he became deeply involved in studying privacy. This combination of a deep cutting-edge computer hardware background and a commitment to digital security made him a perfect fit for NYU Tandon and the NYU Center for Cybersecurity, which has been at the forefront of cybersecurity research since its inception.</p><p class=\"pull-quote\">“A lot of the big problems that we have in the world right now revolve around data. Consider global health coming off of COVID: if we had better ways of computing global health data analytics and sharing information without exposing private data, we might have been able to respond to the crisis more effectively and sooner” <strong>—Brandon Reagen, NYU Tandon</strong></p><p>For Reagen, this is an exciting moment in the history of privacy preserving computation, a field that will have huge implications for the future of data and computing.</p><p>“I’m an optimist — I think this could have as big an impact as the Internet itself,” says Reagen. “And the reason is that, if you think about a lot of the big problems that we have in the world right now, a lot of them revolve around data. Consider global health. We’re just coming off of COVID, and if we had better ways of computing global health data analytics and sharing information without exposing private data, we might have been able to respond to the crisis more effectively and sooner. If we had better ways of sharing data about climate change data from all over the world, without exposing what each individual country or state or city was actually emitting, you could imagine better ways of managing and fighting global climate change. These problems are, in large part, problems of data, and this kind of software can help us solve them.”</p>"},"pubDate":"Wed, 01 Nov 2023 20:35:30 +0000","guid":"https://spectrum.ieee.org/fully-homomorphic-encryption","category":["Encryption","Security","Nyu tandon","Privacy","Cybersecurity"],"dc:creator":"NYU Tandon School of Engineering","media:content":{"@medium":"image","@type":"image/png","@url":"https://assets.rbl.ms/50349974/origin.png"}},{"title":"This Durable Strand of Jelly Can Block Pain","link":"https://spectrum.ieee.org/optogenetics-hydrogel-fiber-chronic-pain","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/black-background-with-illuminated-blue-fiber-held-by-a-hand-and-illuminating-a-blue-object.jpg?id=50348129&width=1200&height=800&coordinates=0%2C0%2C0%2C0\"/><br/><br/><p style=\"\">\n\tIs there a better way for scientists to shine a light on nerve cells throughout the body? When researchers Xinyue Liu and Siyuan Rao first began their collaboration at MIT, they treated this question literally.\n</p><p style=\"\">\n<a href=\"https://en.wikipedia.org/wiki/Optogenetics#:~:text=Optogenetics%20is%20a%20biological%20technique,specifically%20in%20the%20target%20cells.\" target=\"_blank\">Optogenetics</a> is an interdisciplinary branch of science in which cells are genetically altered to be light-sensitive, making it possible to inhibit or excite cells and to study their function by applying colored light. Typically, the light-transmitting wires that reach target cells are made of materials that work well when stationary in the brain. However, if they’re implanted elsewhere in a test animal’s body, they could break, damage tissue, or affect behavior, making it difficult to study the peripheral nervous system and pain in particular.\n</p><p class=\"pull-quote\" style=\"\">\n\t“This flexible fiber expands the toolbox of approaches we have.” <strong>—Rob Bonin, University of Toronto</strong>\n</p><p style=\"\">\n\tNow, Liu, Rao, and colleagues have developed a soft, flexible, durable optical fiber capable of delivering an optogenetic light signal away from the brain or spine using a new material: \n\t<a data-linked-post=\"2659321240\" href=\"https://spectrum.ieee.org/hydrogel\" target=\"_blank\">hydrogel</a>. The filament consists of an inner core and an outer cladding of two versions of the hydrogel with different refractive properties, yet the fiber is only about one millimeter in diameter.\n</p><p style=\"\">\n\tResearchers described the optical fiber and a variety of ways it was put through its paces in model mice in a paper in \n\t<a href=\"https://www.nature.com/articles/s41592-023-02020-9\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Nature Methods</em></a>, published 19 October. The work adds another technique—and a bit of flexibility—to the repertoire of optogenetics, the study of the peripheral nervous system, and possibly future translational medicine, including the treatment of pain, chronic pain, and nerve disorders.\n</p><p style=\"\">\n\t“This flexible fiber expands the toolbox of approaches we have for peripheral optogenetic work,” said Rob Bonin, a pain researcher at the \n\t<a href=\"https://www.pharmacy.utoronto.ca/faculty/rob-bonin-assistant-professor\" rel=\"noopener noreferrer\" target=\"_blank\">University of Toronto</a> who was not involved in the research, citing flexibility and durability as two major advantages of the new approach.\n</p><p>\n\tBroadly, hydrogels are soft networks of polymers and water, such as tofu or jelly. “Our body is also made of hydrogels. Except for bones and teeth, our muscles and other organs are all actually hydrogels,” said Liu, a materials scientist now at \n\t<a href=\"https://www.egr.msu.edu/people/profile/xyliu\" rel=\"noopener noreferrer\" target=\"_blank\">Michigan State University</a>. The fiber uses a polyvinyl alcohol hydrogel, selected for its combination of optical properties and durability under repeated mechanical stress.\n</p><p>\n\tThe investigation of soft materials was initiated with optogenetic pain research in the peripheral nervous system specifically in mind. “If your implant itself is causing pain, how are you going to use this technology to study pain?” said Rao, a neuroscientist now at the \n\t<a href=\"http://www.syraolab.com/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Massachusetts Amherst</a>.\n</p><p style=\"\">\n\tAnd although at the moment the hydrogel fiber primarily figures as a research tool in mice, the same qualities that set this new technology apart for basic science—it’s durable and apparently comfortable in a freely moving body with no compromises in optical performance—are also positives for potential therapeutic purposes. “We are working towards that direction,” said Rao.\n</p><p class=\"pull-quote\" style=\"\">\n\tThe technology promises a wide range of potential applications beyond just the brain and spine.\n</p><p style=\"\">\n\tResearchers anchored one end of their fiber to the mice’s skulls, threaded it underneath the skin, and wrapped a cuff at the other end around the sciatic nerve in the leg. From a practical standpoint, this made the implant compatible with existing external light sources, and kept mice from scratching at any element of the device. But it also worked as a demonstration that enabled a full range of motion of the subject. At a mouse scale, the fiber needed to be only 6 centimeters long, but the authors said it could be extended for other uses.\n</p><p style=\"\">\n\tA series of tests showed that the fiber transmitted light and also how it performed in the mice, blocking pain caused by a hot plate on the foot and inducing movement in the leg. Critically, the fiber performed well after several weeks of voluntary exercise-wheel use, which researchers estimated added up to thousands of bends and twists.\n</p><p>\n\tOther optogenetic studies of the peripheral nervous system in mice have attempted various methods of light delivery that don’t use an optical fiber at all, instead shining light through the skin or implanting miniaturized remote devices. In comparison, the new hydrogel fiber should be able to more precisely target specific cells, said Rao.\n</p><p>\n\tFor Bonin, the external light source has its pros and cons, including higher intensity light and the possibility that a tether could affect behavior, respectively.\n</p><p style=\"\">\n\tFederico Iseppon, a pain researcher at \n\t<a href=\"https://www.ucl.ac.uk/molecular-nociception-group/group-members\" rel=\"noopener noreferrer\" target=\"_blank\">University College London</a> who was not involved in the study, said that although the fiber may be relatively easy to use, it will still require specialized knowledge to fabricate and surgically implant. It promises a wide range of potential applications beyond just the brain and spine. “Its plasticity lies in the multiple different tissues that could be targeted with this technology,” he said.\n</p><p style=\"\">\n\tLiu is currently working on an interface, such as a patch, between the hydrogel and organs that would enable connections that the current cuff design doesn’t allow. Ideally, the fiber will eventually also let scientists record activity as well as send signals to cells.\n</p>"},"pubDate":"Wed, 01 Nov 2023 15:25:05 +0000","guid":"https://spectrum.ieee.org/optogenetics-hydrogel-fiber-chronic-pain","category":["Chronic pain","Hydrogels","Optical fiber","Optogenetics"],"dc:creator":"Greg Uyeno","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/black-background-with-illuminated-blue-fiber-held-by-a-hand-and-illuminating-a-blue-object.jpg?id=50348129&width=980"}},{"title":"Energy Harvesting for Wearable Technology Steps Up","link":"https://spectrum.ieee.org/energy-harvesting-wearable-tech","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-piece-of-material-with-a-black-circuitry-pattern-is-pealing-off-a-second-piece-with-an-intricate-electronics-pattern-which-s.jpg?id=50292357&width=1200&height=800&coordinates=0%2C103%2C0%2C103\"/><br/><br/><p style=\"\">Wearable devices, like nearly every other piece of tech, need energy. Fortunately, though, at wearables’ modest power budgets, energy is effectively everywhere. It’s in<a href=\"https://spectrum.ieee.org/stretchy-waterproof-solar-cells-to-power-wearables\" target=\"_self\"> the sun’s rays</a> and radio waves, the skin’s sweat and body heat, a person’s motion and their footfalls. And today, technology is maturing to the point that meaningful amounts of these energy giveaways can be harvested to liberate wearables from ever needing a battery. Which seems plenty attractive to a range of companies and researchers.</p><p style=\"\">“Energy is something we take for granted, because we just plug things into the wall, and it feels as inevitable as air. But we do actually need that energy to be generated,” says Alper Bozkurt, who with Veena Misra codirects the Center for Advanced Self-Powered Systems of Integrated Sensors and Technologies (ASSIST) at North Carolina State University. </p><p style=\"\">The best-known wearable energy-harvesting tech today is, of course, solar, which pulls down electrons from sunlight or ambient light. But solar is just the opening gambit. There are, researchers have discovered, a wide range of options to harvest enough microwatts to replace wearables’ batteries. Among them are piezoelectric and triboelectric generators, which leverage mechanical strain and materials’ electrostatic properties to generate electricity. Meanwhile, the well-known phenomenon of electromagnetic induction harvests bumps, jumps, and strides to create tiny but still useful trickles of current.</p><p>While wearable devices don’t generally require much power, wearables must be, well, easy to wear. A backpack with a giant solar panel might work technically, but not in reality. A light human health sensor would be no use to biologists trying to keep a tracker on a bison for the rest of its life. </p><p style=\"\">The variety of needs—and energy sources—is apparent in a<a href=\"https://www.sciencedirect.com/science/article/pii/S2211467X23000743\" rel=\"noopener noreferrer\" target=\"_blank\"> flurry of recent energy-harvesting research</a>, including some hybrid work that integrates multiple modalities.</p><h3 style=\"\">The power of breaking a sweat</h3><p class=\"shortcode-media shortcode-media-rebelmouse-image\" style=\"\">\n<img alt=\"Black 3D printed circuitry sits on a piece of material attached to a person's forearm.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"3e639a64e3168ad2783a1caed912c04f\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"bface\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/black-3d-printed-circuitry-sits-on-a-piece-of-material-attached-to-a-person-s-forearm.jpg?id=50292378&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Caltech’s team has experimented with different forms of energy to harvest for powering its e-skin, including human sweat and friction of materials during movement.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Wei Gao/Caltech</small></p><p style=\"\"><br/></p><p style=\"\">California Institute of Technology’s Wei Gao developed a self-powering “electronic skin.” E-skin, he says, is a sensor-embedded device applied directly to skin to read and transmit health indicators like heart rate, body temperature, blood sugar, and metabolic byproducts. </p><p>“Personalized health care could revolutionize traditional medical practice,” Gao says. “But to incorporate many different types of sensors, we need different material designs and tools. Not least of those considerations is energy storage [and generation].” </p><p>Gao’s first e-skin, produced in <a href=\"https://www.science.org/doi/10.1126/scirobotics.aaz7946\" rel=\"noopener noreferrer\" target=\"_blank\">April 2020</a>, was made of soft, flexible rubber, and it harnessed the<a href=\"https://spectrum.ieee.org/new-wearable-sensor-detects-stress-hormone-in-sweat\" target=\"_self\"> patient’s sweat</a> to power the device. Using built-in fuel cells, the device absorbed the lactate in the sweat and combined it with atmospheric oxygen to generate water and pyruvate. Through this process the biofuels generated enough electricity to power both the e-skin’s sensors and data transmission, continuously charging a capacitor from 1.5 to 3.8 volts for about 60 hours. (For capacitors,<a href=\"http://www1.lasalle.edu/~blum/p106wks/pl106_RC.htm#:~:text=The%20voltage%20drop%20across%20a,dropped%20across%20the%20capacitor%20now.\" rel=\"noopener noreferrer\" target=\"_blank\"> voltage translates to electrons stored</a>—the voltage drop across a capacitor is proportional to its total charge.) </p><p style=\"\">Months later Gao and his team<a href=\"https://authors.library.caltech.edu/records/nx4hn-e6r27\" rel=\"noopener noreferrer\" target=\"_blank\"> developed an e-skin model that used kinetic energy</a> from movement to generate<a href=\"https://spectrum.ieee.org/walk-around-in-the-sun-to-power-your-phone-with-this-cloth\" target=\"_self\"> triboelectricity, the liberation of current from the relative motion of materials of differing electrostatic properties.</a> This second-generation e-skin sandwiched thin sheets of Teflon, copper, and polyimide that slide as the person moves, generating maximum power of 0.94 milliwatts. </p><p>The team next turned to 3D printing. In a study reported in<a href=\"https://www.science.org/doi/10.1126/sciadv.adi6492\" rel=\"noopener noreferrer\" target=\"_blank\"> <em>Science Advances </em>in September</a>, they 3D-printed the essential components—physical sensors, chemical sensors, microfluidics, and supercapacitors—for a multimodal health-tracking system called e3-skin (epifluidic elastic electronic skin). </p><p style=\"\">The platform uses an array of sensors, hydrogel-coated electrodes, and more, along with a microsize supercapacitor that in this case was powered by a solar cell. The precision of 3D printing allows researchers to create customized components for early warning and diagnosis of health conditions, Gao says.</p><h3 style=\"\">Leveraging watch tech for…bisons?</h3><p style=\"\">Much talk of wearable technology focuses on health or other human needs. But biologists are also looking at energy harvesting for the tracking of animals, as current technology is insufficient. Batteries die before animals do. Solar won’t work for nocturnal animals or creatures in low-light environments. A little device that harvests energy from a runner’s evening jog clearly is not designed for a massive bison, which can weigh up to a tonne. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A furry brown animal with horns stands in a field. A Red and black collar is around their neck.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"e85b08cbc03888eff8bd2d9bee5a6a83\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"b7c81\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-furry-brown-animal-with-horns-stands-in-a-field-a-red-and-black-collar-is-around-their-neck.jpg?id=50292388&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-367037\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\" style=\"max-width: 100%;\">A team of biologists built a custom Kinefox GPS tracker that wildlife—including this European bison test subject—can recharge simply by moving around as usual.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">Rasmus W. Havmøller</small></p><p style=\"\">Those challenges inspired teams of researchers at the<a href=\"https://www.ku.dk/\" target=\"_blank\"> University of Copenhagen</a>,<a href=\"https://www.dtu.dk/english/\" target=\"_blank\"> the Technical University of Denmark</a>, and Germany’s <a href=\"https://www.ab.mpg.de/ding\" target=\"_blank\">Max Planck Institute of Animal Behavior</a> to build a better wearable-size generator for their purposes: tracking wild animals for, ideally, their whole lives. That goal is currently out of reach—using battery- and solar-powered devices—for most mammalian species.<br/></p><p style=\"\">In work published in<a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0285930#sec010\" target=\"_blank\"> <em>PLoS One</em></a> in May, they detailed the Kinefox, a GPS tracker that wildlife can recharge simply by moving. The team tested their devices with three species: four domestic dogs, an Exmoor pony, and a European bison. </p><p style=\"\">The team was inspired by<a href=\"https://en.wikipedia.org/wiki/Automatic_watch\" rel=\"noopener noreferrer\" target=\"_blank\"> self-winding watches</a>, which have existed since the late 18th century and transform wrist movement into energy. So the researchers bought a commercial microgenerator designed for wearable and IoT devices called the Kinetron MSG32. They combined it with a lithium-ion capacitor and a custom GPS-enabled tracker that transmits data via the<a href=\"https://en.wikipedia.org/wiki/Sigfox\" rel=\"noopener noreferrer\" target=\"_blank\"> Sigfox low-power wireless network</a>. </p><p style=\"\">“We wanted to take the stuff already created and use it off the shelf for animal tracking, even though it isn’t designed for that,” says Troels Gregersen, guest scientist at the Max Planck Institute of Animal Behavior. </p><p>The researchers’ first version fitted the Kinefox to the animals’ existing collars and harnesses to observe and learn.  </p><p style=\"\">However, Gregersen says, “the first collar we put on the bison got destroyed <em>immediately</em>. They’re 900-kilo animals that run up against trees. It’s not a use case in human wearables.” </p><p>Taking results from the first version, the team ultimately created a custom tracker and collar. They glued the microgenerator’s pendulum-based automatic-watch movement to a ferromagnetic ring, placing the combination around a coil of copper wire. As the pendulum swings back and forth with the animal’s movement, the ring creates an alternating current in the coil—and a voltage-doubling circuit transforms it into direct current. </p><p>“There’s a lot of value in being able to place a tracker once, when the animal is born, or only having to tranquilize it once,” Gregersen says. “If something can transmit new types of data, or it can last longer than anything else, it has an application and it has value.” </p><p style=\"\">Kinefox is open source, with<a href=\"https://github.com/TroelsG/Kinefox\" rel=\"noopener noreferrer\" target=\"_blank\"> files published on GitHub</a>. And where a traditional wildlife tracker costs €3,500 to €4,000, the Kinefox costs about €270 in materials, according to researchers at <a href=\"https://www.ab.mpg.de/539037/animal-powered-tracking\" rel=\"noopener noreferrer\" target=\"_blank\">Max Planck</a>. </p><p style=\"\">In the future, DIY may not even be necessary. The team is in talks with the Tilburg, Netherlands–based company<a href=\"https://www.kinetron.eu/about-us\" rel=\"noopener noreferrer\" target=\"_blank\"> Kinetron</a> to make a microgenerator designed specifically for animals, rather than self-winding wristwatches, Gregersen says.</p><h3 style=\"\">Challenges: Sustainability and industry collaboration</h3><p class=\"shortcode-media shortcode-media-rebelmouse-image\" style=\"\">\n<img alt=\"An illustration of a device with multiple layers of materials.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"76eb91d5733db3f9e0f55d92cc648395\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"bf944\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/an-illustration-of-a-device-with-multiple-layers-of-materials.jpg?id=50292417&width=980\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-462604\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">This efficient energy harvester combines piezoelectric composites with carbon fiber–reinforced polymer and epoxy resin, a unique combination that was able to store electricity even after 100,000 uses.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Tohoku University</small></p><p style=\"\">Looking to the future more broadly, some researchers are focused on combining unique materials and creating energy-harvesting systems from more sustainable materials. A team including researchers from Japan’s Tohoku University<a href=\"https://www.sciencedirect.com/science/article/pii/S1359835X2300163X?via%3Dihub\" target=\"_blank\"> recently developed</a> a durable, efficient energy harvester that combines piezoelectric composites with carbon-fiber-reinforced polymer (CFRP).<br/></p><p style=\"\">The group fabricated their device using CFRP, sodium potassium niobate (KNN) nanoparticles, and epoxy resin. And even after 100,000 uses, says Yaonan Yu, a graduate student at Tohoku and co-author of the study, the device could still store the electricity it generated. </p><p>This combination of strength and energy generation could be used in several types of wearables and Internet of Things applications, including infrastructure systems to reinforce bridges and highways that sense when a crack, pothole, or other damage appears, Yu says. </p><p>The sweet spot, says Bozkurt of the ASSIST center, will be in data analysis—and matching the energy-harvesting capabilities to collect and transmit the data that users truly need. </p><p style=\"\">“If I measure your heartbeat in picoseconds, that would be a waste because your heart doesn’t beat that quickly,” he says. For one project, “we asked medical doctors, ‘How much data do you need?’ They said, ‘We don’t know. We see our patients every month, so if we get more than one monthly reading it’ll be an improvement.’ That was some perspective.”</p>"},"pubDate":"Wed, 01 Nov 2023 13:00:03 +0000","guid":"https://spectrum.ieee.org/energy-harvesting-wearable-tech","category":["Energy harvesting","Solar power","Triboelectric generators","Triboelectricity","Wearable devices"],"dc:creator":"Julianne Pepitone","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-piece-of-material-with-a-black-circuitry-pattern-is-pealing-off-a-second-piece-with-an-intricate-electronics-pattern-which-s.jpg?id=50292357&width=980"}},{"title":"Andrew Ng: Unbiggen AI","link":"https://spectrum.ieee.org/andrew-ng-data-centric-ai","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednes.jpg?id=29206806&width=1200&height=800&coordinates=0%2C0%2C0%2C210\"/><br/><br/><p><strong><a href=\"https://en.wikipedia.org/wiki/Andrew_Ng\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">Andrew Ng</a> has serious street cred</strong> in artificial intelligence. He pioneered the use of graphics processing units (GPUs) to train deep learning models in the late 2000s with his students at <a href=\"https://stanfordmlgroup.github.io/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">Stanford University</a>, cofounded <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">Google Brain</a> in 2011, and then served for three years as chief scientist for <a href=\"https://ir.baidu.com/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">Baidu</a>, where he helped build the Chinese tech giant’s AI group. So when he says he has identified the next big shift in artificial intelligence, people listen. And that’s what he told <em>IEEE Spectrum</em> in an exclusive Q&A.</p><hr/><p>\n\tNg’s current efforts are focused on his company \n\t<a href=\"https://landing.ai/about/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">Landing AI</a>, which built a platform called LandingLens to help manufacturers improve visual inspection with computer vision. <a name=\"top\"></a>He has also become something of an evangelist for what he calls the <a href=\"https://www.youtube.com/watch?v=06-AZXmwHjo\" target=\"_blank\">data-centric AI movement</a>, which he says can yield “small data” solutions to big issues in AI, including model efficiency, accuracy, and bias.\n</p><p>\n\tAndrew Ng on...\n</p><ul>\n<li><a href=\"#big\">What’s next for really big models</a></li>\n<li><a href=\"#career\">The career advice he didn’t listen to</a></li>\n<li><a href=\"#defining\">Defining the data-centric AI movement</a></li>\n<li><a href=\"#synthetic\">Synthetic data</a></li>\n<li><a href=\"#work\">Why Landing AI asks its customers to do the work</a></li>\n</ul><p>\n<a name=\"big\"></a><strong>The great advances in deep learning over the past decade or so have been powered by ever-bigger models crunching ever-bigger amounts of data. Some people argue that that’s an <a href=\"https://spectrum.ieee.org/deep-learning-computational-cost\" target=\"_self\">unsustainable trajectory</a>. Do you agree that it can’t go on that way?</strong>\n</p><p>\n<strong>Andrew Ng: </strong>This is a big question. We’ve seen foundation models in NLP [natural language processing]. I’m excited about NLP models getting even bigger, and also about the potential of building foundation models in computer vision. I think there’s lots of signal to still be exploited in video: We have not been able to build foundation models yet for video because of compute bandwidth and the cost of processing video, as opposed to tokenized text. So I think that this engine of scaling up deep learning algorithms, which has been running for something like 15 years now, still has steam in it. Having said that, it only applies to certain problems, and there’s a set of other problems that need small data solutions.\n</p><p>\n<strong>When you say you want a foundation model for computer vision, what do you mean by that?</strong>\n</p><p>\n<strong>Ng:</strong> This is a term coined by <a href=\"https://cs.stanford.edu/~pliang/\" rel=\"noopener noreferrer\" target=\"_blank\">Percy Liang</a> and <a href=\"https://crfm.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">some of my friends at Stanford</a> to refer to very large models, trained on very large data sets, that can be tuned for specific applications. For example, <a href=\"https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business\" target=\"_self\">GPT-3</a> is an example of a foundation model [for NLP]. Foundation models offer a lot of promise as a new paradigm in developing machine learning applications, but also challenges in terms of making sure that they’re reasonably fair and free from bias, especially if many of us will be building on top of them.\n</p><p>\n<strong>What needs to happen for someone to build a foundation model for video?</strong>\n</p><p>\n<strong>Ng:</strong> I think there is a scalability problem. The compute power needed to process the large volume of images for video is significant, and I think that’s why foundation models have arisen first in NLP. Many researchers are working on this, and I think we’re seeing early signs of such models being developed in computer vision. But I’m confident that if a semiconductor maker gave us 10 times more processor power, we could easily find 10 times more video to build such models for vision.\n</p><p>\n\tHaving said that, a lot of what’s happened over the past decade is that deep learning has happened in consumer-facing companies that have large user bases, sometimes billions of users, and therefore very large data sets. While that paradigm of machine learning has driven a lot of economic value in consumer software, I find that that recipe of scale doesn’t work for other industries.\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"career\"></a>\n</p><p>\n<strong>It’s funny to hear you say that, because your early work was at a consumer-facing company with millions of users.</strong>\n</p><p>\n<strong>Ng: </strong>Over a decade ago, when I proposed starting the <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer\" target=\"_blank\">Google Brain</a> project to use Google’s compute infrastructure to build very large neural networks, it was a controversial step. One very senior person pulled me aside and warned me that starting Google Brain would be bad for my career. I think he felt that the action couldn’t just be in scaling up, and that I should instead focus on architecture innovation.\n</p><p class=\"pull-quote\">\n\t“In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.”<br/>\n\t—Andrew Ng, CEO & Founder, Landing AI\n</p><p>\n\tI remember when my students and I published the first \n\t<a href=\"https://nips.cc/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">NeurIPS</a> workshop paper advocating using <a href=\"https://developer.nvidia.com/cuda-zone\" rel=\"noopener noreferrer\" target=\"_blank\">CUDA</a>, a platform for processing on GPUs, for deep learning—a different senior person in AI sat me down and said, “CUDA is really complicated to program. As a programming paradigm, this seems like too much work.” I did manage to convince him; the other person I did not convince.\n</p><p>\n<strong>I expect they’re both convinced now.</strong>\n</p><p>\n<strong>Ng:</strong> I think so, yes.\n</p><p>\n\tOver the past year as I’ve been speaking to people about the data-centric AI movement, I’ve been getting flashbacks to when I was speaking to people about deep learning and scalability 10 or 15 years ago. In the past year, I’ve been getting the same mix of “there’s nothing new here” and “this seems like the wrong direction.”\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"defining\"></a>\n</p><p>\n<strong>How do you define data-centric AI, and why do you consider it a movement?</strong>\n</p><p>\n<strong>Ng:</strong> Data-centric AI is the discipline of systematically engineering the data needed to successfully build an AI system. For an AI system, you have to implement some algorithm, say a neural network, in code and then train it on your data set. The dominant paradigm over the last decade was to download the data set while you focus on improving the code. Thanks to that paradigm, over the last decade deep learning networks have improved significantly, to the point where for a lot of applications the code—the neural network architecture—is basically a solved problem. So for many practical applications, it’s now more productive to hold the neural network architecture fixed, and instead find ways to improve the data.\n</p><p>\n\tWhen I started speaking about this, there were many practitioners who, completely appropriately, raised their hands and said, “Yes, we’ve been doing this for 20 years.” This is the time to take the things that some individuals have been doing intuitively and make it a systematic engineering discipline.\n</p><p>\n\tThe data-centric AI movement is much bigger than one company or group of researchers. My collaborators and I organized a \n\t<a href=\"https://neurips.cc/virtual/2021/workshop/21860\" rel=\"noopener noreferrer\" target=\"_blank\">data-centric AI workshop at NeurIPS</a>, and I was really delighted at the number of authors and presenters that showed up.\n</p><p>\n<strong>You often talk about companies or institutions that have only a small amount of data to work with. How can data-centric AI help them?</strong>\n</p><p>\n<strong>Ng: </strong>You hear a lot about vision systems built with millions of images—I once built a face recognition system using 350 million images. Architectures built for hundreds of millions of images don’t work with only 50 images. But it turns out, if you have 50 really good examples, you can build something valuable, like a defect-inspection system. In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.\n</p><p>\n<strong>When you talk about training a model with just 50 images, does that really mean you’re taking an existing model that was trained on a very large data set and fine-tuning it? Or do you mean a brand new model that’s designed to learn only from that small data set?</strong>\n</p><p>\n<strong>Ng: </strong>Let me describe what Landing AI does. When doing visual inspection for manufacturers, we often use our own flavor of <a href=\"https://developers.arcgis.com/python/guide/how-retinanet-works/\" rel=\"noopener noreferrer\" target=\"_blank\">RetinaNet</a>. It is a pretrained model. Having said that, the pretraining is a small piece of the puzzle. What’s a bigger piece of the puzzle is providing tools that enable the manufacturer to pick the right set of images [to use for fine-tuning] and label them in a consistent way. There’s a very practical problem we’ve seen spanning vision, NLP, and speech, where even human annotators don’t agree on the appropriate label. For big data applications, the common response has been: If the data is noisy, let’s just get a lot of data and the algorithm will average over it. But if you can develop tools that flag where the data’s inconsistent and give you a very targeted way to improve the consistency of the data, that turns out to be a more efficient way to get a high-performing system.\n</p><p class=\"pull-quote\">\n\t“Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.”<br/>\n\t—Andrew Ng\n</p><p>\n\tFor example, if you have 10,000 images where 30 images are of one class, and those 30 images are labeled inconsistently, one of the things we do is build tools to draw your attention to the subset of data that’s inconsistent. So you can very quickly relabel those images to be more consistent, and this leads to improvement in performance.\n</p><p>\n<strong>Could this focus on high-quality data help with bias in data sets? If you’re able to curate the data more before training?</strong>\n</p><p>\n<strong>Ng:</strong> Very much so. Many researchers have pointed out that biased data is one factor among many leading to biased systems. There have been many thoughtful efforts to engineer the data. At the NeurIPS workshop, <a href=\"https://www.cs.princeton.edu/~olgarus/\" rel=\"noopener noreferrer\" target=\"_blank\">Olga Russakovsky</a> gave a really nice talk on this. At the main NeurIPS conference, I also really enjoyed <a href=\"https://neurips.cc/virtual/2021/invited-talk/22281\" rel=\"noopener noreferrer\" target=\"_blank\">Mary Gray’s presentation,</a> which touched on how data-centric AI is one piece of the solution, but not the entire solution. New tools like <a href=\"https://www.microsoft.com/en-us/research/project/datasheets-for-datasets/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">Datasheets for Datasets</a> also seem like an important piece of the puzzle.\n</p><p>\n\tOne of the powerful tools that data-centric AI gives us is the ability to engineer a subset of the data. Imagine training a machine-learning system and finding that its performance is okay for most of the data set, but its performance is biased for just a subset of the data. If you try to change the whole neural network architecture to improve the performance on just that subset, it’s quite difficult. But if you can engineer a subset of the data you can address the problem in a much more targeted way.\n</p><p>\n<strong>When you talk about engineering the data, what do you mean exactly?</strong>\n</p><p>\n<strong>Ng: </strong>In AI, data cleaning is important, but the way the data has been cleaned has often been in very manual ways. In computer vision, someone may visualize images through a <a href=\"https://jupyter.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Jupyter notebook</a> and maybe spot the problem, and maybe fix it. But I’m excited about tools that allow you to have a very large data set, tools that draw your attention quickly and efficiently to the subset of data where, say, the labels are noisy. Or to quickly bring your attention to the one class among 100 classes where it would benefit you to collect more data. Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.\n</p><p>\n\tFor example, I once figured out that a speech-recognition system was performing poorly when there was car noise in the background. Knowing that allowed me to collect more data with car noise in the background, rather than trying to collect more data for everything, which would have been expensive and slow.\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"synthetic\"></a>\n</p><p>\n<strong>What about using synthetic data, is that often a good solution?</strong>\n</p><p>\n<strong>Ng: </strong>I think synthetic data is an important tool in the tool chest of data-centric AI. At the NeurIPS workshop, <a href=\"https://tensorlab.cms.caltech.edu/users/anima/\" rel=\"noopener noreferrer\" target=\"_blank\">Anima Anandkumar</a> gave a great talk that touched on synthetic data. I think there are important uses of synthetic data that go beyond just being a preprocessing step for increasing the data set for a learning algorithm. I’d love to see more tools to let developers use synthetic data generation as part of the closed loop of iterative machine learning development.\n</p><p>\n<strong>Do you mean that synthetic data would allow you to try the model on more data sets?</strong>\n</p><p>\n<strong>Ng: </strong>Not really. Here’s an example. Let’s say you’re trying to detect defects in a smartphone casing. There are many different types of defects on smartphones. It could be a scratch, a dent, pit marks, discoloration of the material, other types of blemishes. If you train the model and then find through error analysis that it’s doing well overall but it’s performing poorly on pit marks, then synthetic data generation allows you to address the problem in a more targeted way. You could generate more data just for the pit-mark category.\n</p><p class=\"pull-quote\">\n\t“In the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models.”<br/>\n\t—Andrew Ng\n</p><p>\n\tSynthetic data generation is a very powerful tool, but there are many simpler tools that I will often try first. Such as data augmentation, improving labeling consistency, or just asking a factory to collect more data.\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"work\"></a>\n</p><p>\n<strong>To make these issues more concrete, can you walk me through an example? When a company approaches <a href=\"https://landing.ai/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">Landing AI</a> and says it has a problem with visual inspection, how do you onboard them and work toward deployment?</strong>\n</p><p>\n<strong>Ng: </strong>When a customer approaches us we usually have a conversation about their inspection problem and look at a few images to verify that the problem is feasible with computer vision. Assuming it is, we ask them to upload the data to the <a href=\"https://landing.ai/platform/\" rel=\"noopener noreferrer nofollow\" target=\"_blank\">LandingLens</a> platform. We often advise them on the methodology of data-centric AI and help them label the data.\n</p><p>\n\tOne of the foci of Landing AI is to empower manufacturing companies to do the machine learning work themselves. A lot of our work is making sure the software is fast and easy to use. Through the iterative process of machine learning development, we advise customers on things like how to train models on the platform, when and how to improve the labeling of data so the performance of the model improves. Our training and software supports them all the way through deploying the trained model to an edge device in the factory.\n</p><p>\n<strong>How do you deal with changing needs? If products change or lighting conditions change in the factory, can the model keep up?</strong>\n</p><p>\n<strong>Ng:</strong> It varies by manufacturer. There is data drift in many contexts. But there are some manufacturers that have been running the same manufacturing line for 20 years now with few changes, so they don’t expect changes in the next five years. Those stable environments make things easier. For other manufacturers, we provide tools to flag when there’s a significant data-drift issue. I find it really important to empower manufacturing customers to correct data, retrain, and update the model. Because if something changes and it’s 3 a.m. in the United States, I want them to be able to adapt their learning algorithm right away to maintain operations.\n</p><p>\n\tIn the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models. The challenge is, how do you do that without Landing AI having to hire 10,000 machine learning specialists?\n</p><p>\n<strong>So you’re saying that to make it scale, you have to empower customers to do a lot of the training and other work.</strong>\n</p><p>\n<strong>Ng: </strong>Yes, exactly! This is an industry-wide problem in AI, not just in manufacturing. Look at health care. Every hospital has its own slightly different format for electronic health records. How can every hospital train its own custom AI model? Expecting every hospital’s IT personnel to invent new neural-network architectures is unrealistic. The only way out of this dilemma is to build tools that empower the customers to build their own models by giving them tools to engineer the data and express their domain knowledge. That’s what Landing AI is executing in computer vision, and the field of AI needs other teams to execute this in other domains.\n</p><p>\n<strong>Is there anything else you think it’s important for people to understand about the work you’re doing or the data-centric AI movement?</strong>\n</p><p>\n<strong>Ng: </strong>In the last decade, the biggest shift in AI was a shift to deep learning. I think it’s quite possible that in this decade the biggest shift will be to data-centric AI. With the maturity of today’s neural network architectures, I think for a lot of the practical applications the bottleneck will be whether we can efficiently get the data we need to develop systems that work well. The data-centric AI movement has tremendous energy and momentum across the whole community. I hope more researchers and developers will jump in and work on it.\n</p><p>\n<a href=\"#top\">Back to top</a>\n</p><p><em>This article appears in the April 2022 print issue as “Andrew Ng, AI Minimalist</em><em>.”</em></p>"},"pubDate":"Wed, 09 Feb 2022 15:31:12 +0000","guid":"https://spectrum.ieee.org/andrew-ng-data-centric-ai","category":["Andrew ng","Artificial intelligence","Deep learning","Type:cover"],"dc:creator":"Eliza Strickland","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednes.jpg?id=29206806&width=980"}},{"title":"How AI Will Change Chip Design","link":"https://spectrum.ieee.org/ai-chip-design-matlab","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&width=1200&height=800&coordinates=0%2C0%2C0%2C0\"/><br/><br/><p>The end of <a href=\"https://spectrum.ieee.org/on-beyond-moores-law-4-new-laws-of-computing\" target=\"_self\">Moore’s Law</a> is looming. Engineers and designers can do only so much to <a href=\"https://spectrum.ieee.org/ibm-introduces-the-worlds-first-2nm-node-chip\" target=\"_self\">miniaturize transistors</a> and <a href=\"https://spectrum.ieee.org/cerebras-giant-ai-chip-now-has-a-trillions-more-transistors\" target=\"_self\">pack as many of them as possible into chips</a>. So they’re turning to other approaches to chip design, incorporating technologies like AI into the process.</p><p>Samsung, for instance, is <a href=\"https://spectrum.ieee.org/processing-in-dram-accelerates-ai\" target=\"_self\">adding AI to its memory chips</a> to enable processing in memory, thereby saving energy and speeding up machine learning. Speaking of speed, Google’s TPU V4 AI chip has <a href=\"https://spectrum.ieee.org/heres-how-googles-tpu-v4-ai-chip-stacked-up-in-training-tests\" target=\"_self\">doubled its processing power</a> compared with that of  its previous version.</p><p>But AI holds still more promise and potential for the semiconductor industry. To better understand how AI is set to revolutionize chip design, we spoke with <a href=\"https://www.linkedin.com/in/heather-gorr-phd\" rel=\"noopener noreferrer\" target=\"_blank\">Heather Gorr</a>, senior product manager for <a href=\"https://www.mathworks.com/\" rel=\"noopener noreferrer\" target=\"_blank\">MathWorks</a>’ MATLAB platform.</p><p><strong>How is AI currently being used to design the next generation of chips?</strong></p><p><strong>Heather Gorr:</strong> AI is such an important technology because it’s involved in most parts of the cycle, including the design and manufacturing process. There’s a lot of important applications here, even in the general process engineering where we want to optimize things. I think defect detection is a big one at all phases of the process, especially in manufacturing. But even thinking ahead in the design process, [AI now plays a significant role] when you’re designing the light and the sensors and all the different components. There’s a lot of anomaly detection and fault mitigation that you really want to consider.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Portrait of a woman with blonde-red hair smiling at the camera\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"1f18a02ccaf51f5c766af2ebc4af18e1\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"2dc00\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-a-woman-with-blonde-red-hair-smiling-at-the-camera.jpg?id=29288554&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\" style=\"max-width: 100%;\">Heather Gorr</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">MathWorks</small></p><p>Then, thinking about the logistical modeling that you see in any industry, there is always planned downtime that you want to mitigate; but you also end up having unplanned downtime. So, looking back at that historical data of when you’ve had those moments where maybe it took a bit longer than expected to manufacture something, you can take a look at all of that data and use AI to try to identify the proximate cause or to see  something that might jump out even in the processing and design phases. We think of AI oftentimes as a predictive tool, or as a robot doing something, but a lot of times you get a lot of insight from the data through AI.</p><p><strong>What are the benefits of using AI for chip design?</strong></p><p><strong>Gorr:</strong> Historically, we’ve seen a lot of physics-based modeling, which is a very intensive process. We want to do a <a href=\"https://en.wikipedia.org/wiki/Model_order_reduction\" rel=\"noopener noreferrer\" target=\"_blank\">reduced order model</a>, where instead of solving such a computationally expensive and extensive model, we can do something a little cheaper. You could create a surrogate model, so to speak, of that physics-based model, use the data, and then do your <a href=\"https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html\" rel=\"noopener noreferrer\" target=\"_blank\">parameter sweeps</a>, your optimizations, your <a href=\"https://www.ibm.com/cloud/learn/monte-carlo-simulation\" rel=\"noopener noreferrer\" target=\"_blank\">Monte Carlo simulations</a> using the surrogate model. That takes a lot less time computationally than solving the physics-based equations directly. So, we’re seeing that benefit in many ways, including the efficiency and economy that are the results of iterating quickly on the experiments and the simulations that will really help in the design.</p><p><strong>So it’s like having a digital twin in a sense?</strong></p><p><strong>Gorr:</strong> Exactly. That’s pretty much what people are doing, where you have the physical system model and the experimental data. Then, in conjunction, you have this other model that you could tweak and tune and try different parameters and experiments that let sweep through all of those different situations and come up with a better design in the end.</p><p><strong>So, it’s going to be more efficient and, as you said, cheaper?</strong></p><p><strong>Gorr:</strong> Yeah, definitely. Especially in the experimentation and design phases, where you’re trying different things. That’s obviously going to yield dramatic cost savings if you’re actually manufacturing and producing [the chips]. You want to simulate, test, experiment as much as possible without making something using the actual process engineering.</p><p><strong>We’ve talked about the benefits. How about the drawbacks?</strong></p><p><strong>Gorr: </strong>The [AI-based experimental models] tend to not be as accurate as physics-based models. Of course, that’s why you do many simulations and parameter sweeps. But that’s also the benefit of having that digital twin, where you can keep that in mind—it’s not going to be as accurate as that precise model that we’ve developed over the years.</p><p>Both chip design and manufacturing are system intensive; you have to consider every little part. And that can be really challenging. It’s a case where you might have models to predict something and different parts of it, but you still need to bring it all together.</p><p>One of the other things to think about too is that you need the data to build the models. You have to incorporate data from all sorts of different sensors and different sorts of teams, and so that heightens the challenge.</p><p><strong>How can engineers use AI to better prepare and extract insights from hardware or sensor data?</strong></p><p><strong>Gorr: </strong>We always think about using AI to predict something or do some robot task, but you can use AI to come up with patterns and pick out things you might not have noticed before on your own. People will use AI when they have high-frequency data coming from many different sensors, and a lot of times it’s useful to explore the frequency domain and things like data synchronization or resampling. Those can be really challenging if you’re not sure where to start.</p><p>One of the things I would say is, use the tools that are available. There’s a vast community of people working on these things, and you can find lots of examples [of applications and techniques] on <a href=\"https://github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub</a> or <a href=\"https://www.mathworks.com/matlabcentral/\" rel=\"noopener noreferrer\" target=\"_blank\">MATLAB Central</a>, where people have shared nice examples, even little apps they’ve created. I think many of us are buried in data and just not sure what to do with it, so definitely take advantage of what’s already out there in the community. You can explore and see what makes sense to you, and bring in that balance of domain knowledge and the insight you get from the tools and AI.</p><p><strong>What should engineers and designers consider wh</strong><strong>en using AI for chip design?</strong></p><p><strong>Gorr:</strong> Think through what problems you’re trying to solve or what insights you might hope to find, and try to be clear about that. Consider all of the different components, and document and test each of those different parts. Consider all of the people involved, and explain and hand off in a way that is sensible for the whole team.</p><p><strong>How do you think AI will affect chip designers’ jobs?</strong></p><p><strong>Gorr:</strong> It’s going to free up a lot of human capital for more advanced tasks. We can use AI to reduce waste, to optimize the materials, to optimize the design, but then you still have that human involved whenever it comes to decision-making. I think it’s a great example of people and technology working hand in hand. It’s also an industry where all people involved—even on the manufacturing floor—need to have some level of understanding of what’s happening, so this is a great industry for advancing AI because of how we test things and how we think about them before we put them on the chip.</p><p><strong>How do you envision the future of AI and chip design?</strong></p><p><strong>Gorr</strong><strong>:</strong> It’s very much dependent on that human element—involving people in the process and having that interpretable model. We can do many things with the mathematical minutiae of modeling, but it comes down to how people are using it, how everybody in the process is understanding and applying it. Communication and involvement of people of all skill levels in the process are going to be really important. We’re going to see less of those superprecise predictions and more transparency of information, sharing, and that digital twin—not only using AI but also using our human knowledge and all of the work that many people have done over the years.</p>"},"pubDate":"Tue, 08 Feb 2022 14:00:01 +0000","guid":"https://spectrum.ieee.org/ai-chip-design-matlab","category":["Chip fabrication","Moore’s law","Chip design","Ai","Matlab","Digital twins"],"dc:creator":"Rina Diane Caballar","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&width=980"}},{"title":"Atomically Thin Materials Significantly Shrink Qubits","link":"https://spectrum.ieee.org/2d-hbn-qubit","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&width=1200&height=800&coordinates=0%2C0%2C0%2C0\"/><br/><br/><p>Quantum computing is a devilishly complex technology, with many technical hurdles impacting its development. Of these challenges two critical issues stand out: miniaturization and qubit quality.</p><p>IBM has adopted the superconducting qubit road map of <a href=\"https://spectrum.ieee.org/ibms-envisons-the-road-to-quantum-computing-like-an-apollo-mission\" target=\"_self\">reaching a 1,121-qubit processor by 2023</a>, leading to the expectation that 1,000 qubits with today’s qubit form factor is feasible. However, current approaches will require very large chips (50 millimeters on a side, or larger) at the scale of small wafers, or the use of chiplets on multichip modules. While this approach will work, the aim is to attain a better path toward scalability.</p><p>Now researchers at <a href=\"https://www.nature.com/articles/s41563-021-01187-w\" rel=\"noopener noreferrer\" target=\"_blank\">MIT have been able to both reduce the size of the qubits</a> and done so in a way that reduces the interference that occurs between neighboring qubits. The MIT researchers have increased the number of superconducting qubits that can be added onto a device by a factor of 100.</p><p>“We are addressing both qubit miniaturization and quality,” said <a href=\"https://equs.mit.edu/william-d-oliver/\" rel=\"noopener noreferrer\" target=\"_blank\">William Oliver</a>, the director for the <a href=\"https://cqe.mit.edu/\" target=\"_blank\">Center for Quantum Engineering</a> at MIT. “Unlike conventional transistor scaling, where only the number really matters, for qubits, large numbers are not sufficient, they must also be high-performance. Sacrificing performance for qubit number is not a useful trade in quantum computing. They must go hand in hand.”</p><p>The key to this big increase in qubit density and reduction of interference comes down to the use of two-dimensional materials, in particular the 2D insulator hexagonal boron nitride (hBN). The MIT researchers demonstrated that a few atomic monolayers of hBN can be stacked to form the insulator in the capacitors of a superconducting qubit.</p><p>Just like other capacitors, the capacitors in these superconducting circuits take the form of a sandwich in which an insulator material is sandwiched between two metal plates. The big difference for these capacitors is that the superconducting circuits can operate only at extremely low temperatures—less than 0.02 degrees above absolute zero (-273.15 °C).</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Golden dilution refrigerator hanging vertically\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"694399af8a1c345e51a695ff73909eda\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"6c615\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/golden-dilution-refrigerator-hanging-vertically.jpg?id=29281593&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\" style=\"max-width: 100%;\">Superconducting qubits are measured at temperatures as low as 20 millikelvin in a dilution refrigerator.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">Nathan Fiske/MIT</small></p><p>In that environment, insulating materials that are available for the job, such as PE-CVD silicon oxide or silicon nitride, have quite a few defects that are too lossy for quantum computing applications. To get around these material shortcomings, most superconducting circuits use what are called coplanar capacitors. In these capacitors, the plates are positioned laterally to one another, rather than on top of one another.</p><p>As a result, the intrinsic silicon substrate below the plates and to a smaller degree the vacuum above the plates serve as the capacitor dielectric. Intrinsic silicon is chemically pure and therefore has few defects, and the large size dilutes the electric field at the plate interfaces, all of which leads to a low-loss capacitor. The lateral size of each plate in this open-face design ends up being quite large (typically 100 by 100 micrometers) in order to achieve the required capacitance.</p><p>In an effort to move away from the large lateral configuration, the MIT researchers embarked on a search for an insulator that has very few defects and is compatible with superconducting capacitor plates.</p><p>“We chose to study hBN because it is the most widely used insulator in 2D material research due to its cleanliness and chemical inertness,” said colead author <a href=\"https://equs.mit.edu/joel-wang/\" rel=\"noopener noreferrer\" target=\"_blank\">Joel Wang</a>, a research scientist in the Engineering Quantum Systems group of the MIT Research Laboratory for Electronics. </p><p>On either side of the hBN, the MIT researchers used the 2D superconducting material, niobium diselenide. One of the trickiest aspects of fabricating the capacitors was working with the niobium diselenide, which oxidizes in seconds when exposed to air, according to Wang. This necessitates that the assembly of the capacitor occur in a glove box filled with argon gas.</p><p>While this would seemingly complicate the scaling up of the production of these capacitors, Wang doesn’t regard this as a limiting factor.</p><p>“What determines the quality factor of the capacitor are the two interfaces between the two materials,” said Wang. “Once the sandwich is made, the two interfaces are “sealed” and we don’t see any noticeable degradation over time when exposed to the atmosphere.”</p><p>This lack of degradation is because around 90 percent of the electric field is contained within the sandwich structure, so the oxidation of the outer surface of the niobium diselenide does not play a significant role anymore. This ultimately makes the capacitor footprint much smaller, and it accounts for the reduction in cross talk between the neighboring qubits.</p><p>“The main challenge for scaling up the fabrication will be the wafer-scale growth of hBN and 2D superconductors like [niobium diselenide], and how one can do wafer-scale stacking of these films,” added Wang.</p><p>Wang believes that this research has shown 2D hBN to be a good insulator candidate for superconducting qubits. He says that the groundwork the MIT team has done will serve as a road map for using other hybrid 2D materials to build superconducting circuits.</p>"},"pubDate":"Mon, 07 Feb 2022 16:12:05 +0000","guid":"https://spectrum.ieee.org/2d-hbn-qubit","category":["Qubits","Mit","Ibm","Superconducting qubits","Hexagonal boron nitride","2d materials","Quantum computing"],"dc:creator":"Dexter Johnson","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&width=980"}}]}}}