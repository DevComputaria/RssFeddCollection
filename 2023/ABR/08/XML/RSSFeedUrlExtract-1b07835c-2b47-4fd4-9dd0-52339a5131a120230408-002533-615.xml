<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:slash="http://purl.org/rss/1.0/modules/slash/">
  <channel>
    <title>Biz &amp; IT – Ars Technica</title>
    <atom:link href="https://arstechnica.com/information-technology/feed/" rel="self" type="application/rss+xml" />
    <link>https://arstechnica.com</link>
    <description>Serving the Technologist for more than a decade. IT news, reviews, and analysis.</description>
    <lastBuildDate>Fri, 07 Apr 2023 22:49:34 +0000</lastBuildDate>
    <language>en-US</language>
    <sy:updatePeriod>
	hourly	</sy:updatePeriod>
    <sy:updateFrequency>
	1	</sy:updateFrequency>
    <generator>https://wordpress.org/?v=6.0.3</generator>
    <image>
      <url>https://cdn.arstechnica.net/wp-content/uploads/2016/10/cropped-ars-logo-512_480-32x32.png</url>
      <title>Biz &amp; IT – Ars Technica</title>
      <link>https://arstechnica.com</link>
      <width>32</width>
      <height>32</height>
    </image>
    <item>
      <title>Artists astound with AI-generated film stills from a parallel universe</title>
      <link>https://arstechnica.com/?p=1904461</link>
      <comments>https://arstechnica.com/gadgets/2023/04/artists-astound-with-ai-generated-film-stills-from-a-parallel-universe/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Fri, 07 Apr 2023 22:49:34 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Gaming & Culture]]></category>
      <category><![CDATA[Tech]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[AI art]]></category>
      <category><![CDATA[dall-e]]></category>
      <category><![CDATA[image synthesis]]></category>
      <category><![CDATA[John Meta]]></category>
      <category><![CDATA[Jon Finger]]></category>
      <category><![CDATA[julie wieland]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[MidJourney]]></category>
      <category><![CDATA[Stable Diffusion]]></category>
      <category><![CDATA[synthography]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1904461</guid>
      <description><![CDATA[A Q&#038;A with "synthographer" Julie Wieland on the #aicinema movement.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/wieland_hero_2-800x450.jpg" alt="An AI-generated image from an #aicinema still series called " vinyl vengeance by julie wieland created using midjourney.>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/wieland_hero_2.jpg" class="enlarge-link" data-height="675" data-width="1200">Enlarge</a> <span class="sep">/</span> An AI-generated image from an #aicinema still series called "Vinyl Vengeance" by Julie Wieland, created using Midjourney. (credit: <a rel="nofollow" class="caption-link" href="https://twitter.com/juliewdesign_/status/1618365397316800513?s=20">Julie Wieland / Midjourney</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Since last year, a group of artists have been using an AI image generator called <a href="https://arstechnica.com/information-technology/2023/03/ai-imager-midjourney-v5-stuns-with-photorealistic-images-and-5-fingered-hands/">Midjourney</a> to create still photos of films that don't exist. They call the trend "AI cinema." We spoke to one of its practitioners, Julie Wieland, and asked her about her technique, which she calls "synthography," for synthetic photography.</p>
<h2>The origins of “AI cinema” as a still image art form</h2>
<p>Last year, image synthesis models like <a href="https://arstechnica.com/information-technology/2022/09/openai-image-generator-dall-e-now-available-without-waitlist/">DALL-E 2</a>, <a href="https://arstechnica.com/information-technology/2022/09/with-stable-diffusion-you-may-never-believe-what-you-see-online-again/">Stable Diffusion</a>, and Midjourney began allowing anyone with a text description (called a "prompt") to generate a still image in many different styles. The technique has been <a href="https://arstechnica.com/information-technology/2022/12/artstation-artists-stage-mass-protest-against-ai-generated-artwork/">controversial</a> among some artists, but other artists have embraced the new tools and run with them.</p>

<p>While anyone with a prompt can make an AI-generated image, it soon became clear that some people possessed a special talent for finessing these new AI tools to produce better content. As with painting or photography, the human creative spark is still necessary to produce notable results consistently.</p></div><p><a href="https://arstechnica.com/?p=1904461#p3">Read 22 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1904461&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/gadgets/2023/04/artists-astound-with-ai-generated-film-stills-from-a-parallel-universe/feed/</wfw:commentRss>
      <slash:comments>24</slash:comments>
    </item>
    <item>
      <title>There’s a new form of keyless car theft that works in under 2 minutes</title>
      <link>https://arstechnica.com/?p=1930147</link>
      <comments>https://arstechnica.com/information-technology/2023/04/crooks-are-stealing-cars-using-previously-unknown-keyless-can-injection-attacks/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Fri, 07 Apr 2023 21:24:48 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[can]]></category>
      <category><![CDATA[controller area network]]></category>
      <category><![CDATA[injection attack]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1930147</guid>
      <description><![CDATA[As car owners grow hip to one form a theft, crooks are turning to new ones.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/vehicle-theft-800x600.jpg" alt="Infrared image of a person jimmying open a vehicle.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/vehicle-theft.jpg" class="enlarge-link" data-height="750" data-width="1000">Enlarge</a> <span class="sep">/</span> Infrared image of a person jimmying open a vehicle. (credit: Getty Images)</p>  </figure>






<div><a name="page-1"></a></div>
<p>When a London man discovered the front left-side bumper of his Toyota RAV4 torn off and the headlight partially dismantled not once but twice in three months last year, he suspected the acts were senseless vandalism. When the vehicle went missing a few days after the second incident, and a neighbor found their Toyota Land Cruiser gone shortly afterward, he discovered they were part of a new and sophisticated technique for performing keyless thefts.</p>
<p>It just so happened that the owner, Ian Tabor, is a cybersecurity researcher specializing in automobiles. While investigating how his RAV4 was taken, he stumbled on a new technique called CAN injection attacks.</p>
<h2>The case of the malfunctioning CAN</h2>
<p>Tabor began by poring over the “MyT” telematics system that Toyota uses to track vehicle anomalies known as DTCs (Diagnostic Trouble Codes). It turned out his vehicle had recorded many DTCs around the time of the theft.</p></div><p><a href="https://arstechnica.com/?p=1930147#p3">Read 11 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1930147&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/04/crooks-are-stealing-cars-using-previously-unknown-keyless-can-injection-attacks/feed/</wfw:commentRss>
      <slash:comments>50</slash:comments>
    </item>
    <item>
      <title>Why ChatGPT and Bing Chat are so good at making things up</title>
      <link>https://arstechnica.com/?p=1902025</link>
      <comments>https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Thu, 06 Apr 2023 15:58:54 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Features]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[AI ethics]]></category>
      <category><![CDATA[ChatGPT]]></category>
      <category><![CDATA[confabulation]]></category>
      <category><![CDATA[GPT-3]]></category>
      <category><![CDATA[large language model]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[openai]]></category>
      <category><![CDATA[text synthesis]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1902025</guid>
      <description><![CDATA[A look inside the hallucinating artificial minds of the famous text prediction bots.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/AI-the-ultimate-BSer-800x450.jpg" alt="Why ChatGPT and Bing Chat are so good at making things up">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/AI-the-ultimate-BSer.jpg" class="enlarge-link" data-height="1080" data-width="1920">Enlarge</a> (credit: Aurich Lawson | Getty Images)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Over the past few months, AI chatbots like <a href="https://arstechnica.com/information-technology/2022/12/openai-invites-everyone-to-test-new-ai-powered-chatbot-with-amusing-results/">ChatGPT</a> have captured the world's attention due to their ability to converse in a human-like way on just about any subject. But they come with a serious drawback: They can present convincing false information easily, making them unreliable sources of factual information and potential sources of <a href="https://arstechnica.com/tech-policy/2023/04/openai-may-be-sued-after-chatgpt-falsely-says-aussie-mayor-is-an-ex-con/">defamation</a>.</p>
<p>Why do AI chatbots make things up, and will we ever be able to fully trust their output? We asked several experts and dug into how these AI models work to find the answers.</p>
<h2>“Hallucinations”—a loaded term in AI</h2>
<p>AI chatbots such as OpenAI's ChatGPT rely on a type of AI called a "large language model" (LLM) to generate their responses. An LLM is a computer program trained on millions of text sources that can read and generate "natural language" text—language as humans would naturally write or talk. Unfortunately, they can also make mistakes.</p></div><p><a href="https://arstechnica.com/?p=1902025#p3">Read 41 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1902025&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/feed/</wfw:commentRss>
      <slash:comments>174</slash:comments>
    </item>
    <item>
      <title>Operation Cookie Monster: Feds seize “notorious hacker marketplace”</title>
      <link>https://arstechnica.com/?p=1929514</link>
      <comments>https://arstechnica.com/tech-policy/2023/04/operation-cookie-monster-feds-seize-notorious-hacker-marketplace/#comments</comments>
      <dc:creator><![CDATA[Jon Brodkin]]></dc:creator>
      <pubDate>Wed, 05 Apr 2023 20:44:14 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Policy]]></category>
      <category><![CDATA[genesis market]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1929514</guid>
      <description><![CDATA[Genesis Market sold user data and a tool that mimics each victim's web browser.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/genesis-market-800x450.jpg" alt="A screenshot from the Genesis Market domain that says, " this website has been seized.>
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/genesis-market.jpg" class="enlarge-link" data-height="1440" data-width="2560">Enlarge</a> <span class="sep">/</span> Domain seizure message at genesis.market. </p>  </figure>






<div><a name="page-1"></a></div>
<p>An international law enforcement operation shut down a "notorious hacker marketplace" that sold access to infected devices and stolen account credentials, the US Department of Justice and Europol announced today. The operation targeting Genesis Market involved 17 countries, seized the platform's infrastructure, and resulted in "119 arrests, 208 property searches, and 97 knock-and-talk measures," <a href="https://www.europol.europa.eu/media-press/newsroom/news/takedown-of-notorious-hacker-marketplace-selling-your-identity-to-criminals">Europol said</a>.</p>
<p>The now-shuttered Genesis Market "advertised and sold packages of account access credentials—such as usernames and passwords for email, bank accounts, and social media—that had been stolen from malware-infected computers around the world," the <a href="https://www.justice.gov/opa/pr/criminal-marketplace-disrupted-international-cyber-operation">Justice Department said</a>. The so-called "Operation Cookie Monster" seized 11 domain names pursuant to a warrant authorized by the US District Court for the Eastern District of Wisconsin.</p>
<p>While Genesis Market's <a href="https://www.genesis.market/">public website</a> was taken down, its .onion domain was still accessible on the dark web using Tor today. Law enforcement is apparently still looking for at least some of the people behind the platform, as the domain seizure message seeks tips from anyone who has been in contact with Genesis Market administrators. The US Treasury Department <a href="https://home.treasury.gov/news/press-releases/jy1388">said</a> Genesis Market "is believed to be located in Russia."</p></div><p><a href="https://arstechnica.com/?p=1929514#p3">Read 11 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1929514&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/tech-policy/2023/04/operation-cookie-monster-feds-seize-notorious-hacker-marketplace/feed/</wfw:commentRss>
      <slash:comments>34</slash:comments>
    </item>
    <item>
      <title>New AI model can “cut out” any object within an image—and Meta is sharing the code</title>
      <link>https://arstechnica.com/?p=1929377</link>
      <comments>https://arstechnica.com/information-technology/2023/04/meta-introduces-ai-model-that-can-isolate-and-mask-objects-within-images/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Wed, 05 Apr 2023 19:55:15 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[computer vision]]></category>
      <category><![CDATA[corgi]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[meta]]></category>
      <category><![CDATA[Meta AI]]></category>
      <category><![CDATA[SAM]]></category>
      <category><![CDATA[segmentation]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1929377</guid>
      <description><![CDATA[Meta's "Segment Anything" uses AI to isolate objects on command.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/corgi_segmentation_hero_1-800x450.jpg" alt="An example of SAM selecting the outline of a Corgi in a photo.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/corgi_segmentation_hero_1.jpg" class="enlarge-link" data-height="675" data-width="1200">Enlarge</a> <span class="sep">/</span> An example of SAM selecting the outline of a corgi in a photo. (credit: Meta)</p>  </figure>






<div><a name="page-1"></a></div>
<p>On Wednesday, Meta announced an AI model called the <a href="https://ai.facebook.com/research/publications/segment-anything/">Segment Anything Model</a> (SAM) that can identify individual objects in images and videos, even those not encountered during training, <a href="https://www.reuters.com/technology/meta-releases-ai-model-that-can-identify-items-within-images-2023-04-05/">reports</a> Reuters.</p>
<p>According to <a href="https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/">a blog post</a> from Meta, SAM is an image segmentation model that can respond to text prompts or user clicks to isolate specific objects within an image. Image segmentation is a process in computer vision that involves dividing an image into multiple segments or regions, each representing a specific object or area of interest.</p>

<p>The purpose of image segmentation is to make an image easier to analyze or process. Meta also sees the technology as being useful for understanding webpage content, augmented reality applications, image editing, and aiding scientific study by automatically localizing animals or objects to track on video.</p></div><p><a href="https://arstechnica.com/?p=1929377#p3">Read 6 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1929377&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/04/meta-introduces-ai-model-that-can-isolate-and-mask-objects-within-images/feed/</wfw:commentRss>
      <slash:comments>60</slash:comments>
    </item>
    <item>
      <title>President Biden delivers remarks on “risks of artificial intelligence”</title>
      <link>https://arstechnica.com/?p=1929227</link>
      <comments>https://arstechnica.com/information-technology/2023/04/amid-calls-for-ai-regulation-president-biden-addresses-potential-risks/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Wed, 05 Apr 2023 15:48:33 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Policy]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[AI ethics]]></category>
      <category><![CDATA[AI risks]]></category>
      <category><![CDATA[Joe Biden]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[President Biden]]></category>
      <category><![CDATA[White House]]></category>
      <category><![CDATA[x-risk]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1929227</guid>
      <description><![CDATA[Biden addresses fears about AI's impact on society.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/biden_april4_hero-800x450.jpg" alt="WASHINGTON, DC - APRIL 04: U.S. President Joe Biden holds a meeting with his science and technology advisors at the White House on April 04, 2023 in Washington, DC. Biden met with the group to discuss the advancement of American science, technology, and innovation, including artificial intelligence.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/biden_april4_hero-scaled.jpg" class="enlarge-link" data-height="1440" data-width="2560">Enlarge</a> </p>  </figure>






<div><a name="page-1"></a></div>
<p>On Tuesday, President Joe Biden <a href="https://www.whitehouse.gov/briefing-room/speeches-remarks/2023/04/04/remarks-by-president-biden-in-meeting-with-the-presidents-council-of-advisors-on-science-and-technology/">delivered brief remarks</a> on artificial intelligence risks at the opening of a meeting with the <a href="https://www.whitehouse.gov/pcast/">President’s Council of Advisors on Science and Technology</a> at the White House. The remarks come in the context of <a href="https://arstechnica.com/information-technology/2023/03/openai-checked-to-see-whether-gpt-4-could-take-over-the-world/">increasing worry</a> about generative AI and its potential threats to society and <a href="https://arstechnica.com/information-technology/2023/03/fearing-loss-of-control-ai-critics-call-for-6-month-pause-in-ai-development/">controversial calls</a> for regulatory oversight of the fast-growing industry.</p>

<p>"AI can help deal with some very difficult challenges like disease and climate change," Biden said, according to a <a href="https://www.whitehouse.gov/briefing-room/speeches-remarks/2023/04/04/remarks-by-president-biden-in-meeting-with-the-presidents-council-of-advisors-on-science-and-technology/">transcript</a> provided by the White House. "But we also have to address the potential risks to our society, to our economy, to our national security."</p>
<p>Last week, a group of AI researchers, pundits, and critics <a href="https://arstechnica.com/information-technology/2023/03/fearing-loss-of-control-ai-critics-call-for-6-month-pause-in-ai-development/">called for a six-month pause</a> in the development of AI systems "more powerful" than OpenAI's <a href="https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/">GPT-4</a>. GPT-4 is a multimodal AI model that can analyze text and images and generate human-like responses. That letter, which has <a href="https://www.wired.com/story/the-call-to-halt-dangerous-ai-research-ignores-a-simple-truth/">proven controversial</a> among AI experts, called for potential government action if necessary and "new and capable regulatory authorities dedicated to AI."</p></div><p><a href="https://arstechnica.com/?p=1929227#p3">Read 6 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1929227&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/04/amid-calls-for-ai-regulation-president-biden-addresses-potential-risks/feed/</wfw:commentRss>
      <slash:comments>106</slash:comments>
    </item>
    <item>
      <title>Amazon Web Services and Microsoft Azure face antitrust probe</title>
      <link>https://arstechnica.com/?p=1929214</link>
      <comments>https://arstechnica.com/tech-policy/2023/04/microsoft-and-amazon-face-uk-probe-on-cloud-computing/#comments</comments>
      <dc:creator><![CDATA[Financial Times]]></dc:creator>
      <pubDate>Wed, 05 Apr 2023 13:44:22 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Policy]]></category>
      <category><![CDATA[Amazon]]></category>
      <category><![CDATA[antitrust]]></category>
      <category><![CDATA[AWS]]></category>
      <category><![CDATA[azure]]></category>
      <category><![CDATA[cloud computing]]></category>
      <category><![CDATA[microsoft]]></category>
      <category><![CDATA[syndication]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1929214</guid>
      <description><![CDATA[Ofcom "particularly concerned" over practices of tech giants that dominate cloud market
]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/ofcom-800x533.jpg" alt="Ofcom sign">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/ofcom-scaled.jpg" class="enlarge-link" data-height="1707" data-width="2560">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="https://www.gettyimages.com/detail/news-photo/the-ofcom-logo-is-attached-to-the-front-of-their-news-photo/73032942">Bruno Vincent / Getty Images</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>The UK’s communications watchdog has called for a probe into Microsoft and Amazon’s dominance of the country’s cloud computing market in the latest challenge to the tech giants from global regulators.</p>
<p>Ofcom said on Wednesday it was “particularly concerned” by the practices of Amazon Web Services and Microsoft, which together control between 60 and 70 percent of the UK cloud market. It has proposed referring the sector to the Competition and Markets Authority for further investigation.</p>
<p>Cloud computing is dominated by Amazon and Microsoft, and has become a crucial driver of revenue at the tech giants.</p></div><p><a href="https://arstechnica.com/?p=1929214#p3">Read 12 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1929214&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/tech-policy/2023/04/microsoft-and-amazon-face-uk-probe-on-cloud-computing/feed/</wfw:commentRss>
      <slash:comments>52</slash:comments>
    </item>
    <item>
      <title>ChatGPT vs Google Bard: Which is better? We put them to the test.</title>
      <link>https://arstechnica.com/?p=1928609</link>
      <comments>https://arstechnica.com/information-technology/2023/04/clash-of-the-ai-titans-chatgpt-vs-bard-in-a-showdown-of-wits-and-wisdom/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Wed, 05 Apr 2023 13:30:18 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Features]]></category>
      <category><![CDATA[Tech]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[Bard]]></category>
      <category><![CDATA[ChatGPT]]></category>
      <category><![CDATA[google]]></category>
      <category><![CDATA[Google Bard]]></category>
      <category><![CDATA[GPT-3]]></category>
      <category><![CDATA[GPT-4]]></category>
      <category><![CDATA[large language models]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[openai]]></category>
      <category><![CDATA[text synthesis]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1928609</guid>
      <description><![CDATA[We compare two top AI language models in seven categories to pick a winner.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/robot_battle_hero-800x450.jpg" alt="An AI-generated image of two robots fighting in an arena.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/robot_battle_hero.jpg" class="enlarge-link" data-height="731" data-width="1301">Enlarge</a> <span class="sep">/</span> An AI-generated image of two robots fighting in an arena. (credit: Benj Edwards / Midjourney)</p>  </figure>






<div><a name="page-1"></a></div>
<p>In today's world of generative AI chatbots, we've witnessed the sudden rise of OpenAI's <a href="https://arstechnica.com/information-technology/2022/12/openai-invites-everyone-to-test-new-ai-powered-chatbot-with-amusing-results/">ChatGPT</a>, introduced in November, followed by <a href="https://arstechnica.com/information-technology/2023/02/microsoft-announces-ai-powered-bing-search-and-edge-browser/">Bing Chat</a> in February and Google's <a href="https://arstechnica.com/gadgets/2023/03/google-says-its-bard-generative-chat-ai-is-out-launches-waitlist/">Bard</a> in March. We decided to put these chatbots through their paces with an assortment of tasks to determine which one reigns supreme in the AI chatbot arena. Since Bing Chat uses similar <a href="https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/">GPT-4</a> technology as the latest ChatGPT model, we opted to focus on two titans of AI chatbot technology: OpenAI and Google.</p>

<p>We tested ChatGPT and Bard in seven critical categories: dad jokes, argument dialog, mathematical word problems, summarization, factual retrieval, creative writing, and coding. For each test, we fed the exact same instruction (called a "prompt") into ChatGPT (with GPT-4) and Google Bard. We used the first result, with no cherry-picking.</p>
<p>It's worth noting that a version of ChatGPT based on the earlier <a href="https://arstechnica.com/information-technology/2022/11/openai-conquers-rhyming-poetry-with-new-gpt-3-update/">GPT-3.5</a> model is also available, but we did not use that in the test. Since we used GPT-4 only, we will refer to ChatGPT as "ChatGPT-4" in this article to reduce confusion.</p></div><p><a href="https://arstechnica.com/?p=1928609#p3">Read 45 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1928609&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/04/clash-of-the-ai-titans-chatgpt-vs-bard-in-a-showdown-of-wits-and-wisdom/feed/</wfw:commentRss>
      <slash:comments>216</slash:comments>
    </item>
    <item>
      <title>Open garage doors anywhere in the world by exploiting this “smart” device</title>
      <link>https://arstechnica.com/?p=1929120</link>
      <comments>https://arstechnica.com/information-technology/2023/04/open-garage-doors-anywhere-in-the-world-by-exploiting-this-smart-device/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Tue, 04 Apr 2023 22:30:15 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[garage door]]></category>
      <category><![CDATA[Internet of things]]></category>
      <category><![CDATA[iot]]></category>
      <category><![CDATA[nexx]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1929120</guid>
      <description><![CDATA[A universal password. Unencrypted user data and commands. What could go wrong?]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/04/garage-door-opener-800x534.jpg" alt="woman inside the car using mobile phone to open garage. woman entering pin into smartphone while unlocking garage.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/04/garage-door-opener.jpg" class="enlarge-link" data-height="667" data-width="1000">Enlarge</a> (credit: Getty Images)</p>  </figure>






<div><a name="page-1"></a></div>
<p>A market-leading garage door controller is so riddled with severe security and privacy vulnerabilities that the researcher who discovered them, Sam Sabetan, is advising anyone using one to immediately disconnect it until they are fixed.</p>
<p>Each $80 device, used to open and close garage doors and control home security alarms and smart power plugs, employs the same easy-to-find universal password to communicate with Nexx servers. The controllers also broadcast the unencrypted email address, device ID, first name, and last initial corresponding to each one, along with the message required to open or shut a door or turn on or off a smart plug or schedule such a command for a later time.</p>
<h2>Immediately unplug all Nexx devices</h2>
<p>The result: Anyone with a moderate technical background can search Nexx servers for a given email address, device ID, or name and then issue commands to the associated controller. (Nexx controllers for home security alarms are susceptible to a similar class of vulnerabilities.) Commands allow a door to be opened, a device connected to a smart plug to be turned off, or an alarm to be disarmed. Worse still, over the past three months, personnel for Texas-based Nexx haven’t responded to multiple private messages warning of the vulnerabilities.</p></div><p><a href="https://arstechnica.com/?p=1929120#p3">Read 14 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1929120&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/04/open-garage-doors-anywhere-in-the-world-by-exploiting-this-smart-device/feed/</wfw:commentRss>
      <slash:comments>227</slash:comments>
    </item>
    <item>
      <title>Users fume after My Cloud network breach locks them out of their data</title>
      <link>https://arstechnica.com/?p=1928711</link>
      <comments>https://arstechnica.com/information-technology/2023/04/users-fume-after-my-cloud-network-breach-locks-them-out-of-their-data/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Mon, 03 Apr 2023 19:07:14 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[data theft]]></category>
      <category><![CDATA[my cloud]]></category>
      <category><![CDATA[network breach]]></category>
      <category><![CDATA[outage]]></category>
      <category><![CDATA[Western Digital]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1928711</guid>
      <description><![CDATA[The compromise allowed hackers to steal data, raising the specter of ransomware.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/01/my-cloud-800x436.jpg" alt="Users fume after My Cloud network breach locks them out of their data">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2022/01/my-cloud.jpg" class="enlarge-link" data-height="558" data-width="1024">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="http://www.westerndigital.com/">Western Digital</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Users of the Western Digital My Cloud service are fuming after a network breach has locked them out of their data for more than 24 hours and has put company-handled information into the hands of currently unknown hackers.</p>
<p>The inability to access data stored in My Cloud was reported on social media by multiple users, including <a href="https://twitter.com/iricigor/status/1642647923707060225">this one</a>, who indicated the outage started sometime on Saturday. Since then, the number of users (and their anxiety levels) have only ratcheted up.</p>
<h2>Sounds like ransomware</h2>
<p>By early morning California time on Monday, Western Digital issued a <a href="https://www.businesswire.com/news/home/20230402005076/en/Western-Digital-Provides-Information-on-Network-Security-Incident">release</a> saying that a week ago Sunday the company learned that an “unauthorized third party gained access to a number of the Company’s systems.” The release added: “​​Based on the investigation to date, the Company believes the unauthorized party obtained certain data from its systems and is working to understand the nature and scope of that data.”</p></div><p><a href="https://arstechnica.com/?p=1928711#p3">Read 6 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1928711&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/04/users-fume-after-my-cloud-network-breach-locks-them-out-of-their-data/feed/</wfw:commentRss>
      <slash:comments>103</slash:comments>
    </item>
    <item>
      <title>Hackers exploit WordPress plugin flaw that gives full control of millions of sites</title>
      <link>https://arstechnica.com/?p=1928488</link>
      <comments>https://arstechnica.com/information-technology/2023/03/hackers-exploit-wordpress-plugin-flaw-that-gives-full-control-of-millions-of-sites/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Fri, 31 Mar 2023 22:40:19 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[content management system]]></category>
      <category><![CDATA[exploits]]></category>
      <category><![CDATA[plugin]]></category>
      <category><![CDATA[vulnerabilities]]></category>
      <category><![CDATA[wordpress]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1928488</guid>
      <description><![CDATA[Elementor Pro fixed the vulnerability, but not everyone has installed the patch.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/05/caution-tape-800x600.jpeg" alt="Hackers exploit WordPress plugin flaw that gives full control of millions of sites">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2022/05/caution-tape.jpeg" class="enlarge-link" data-height="750" data-width="1000">Enlarge</a> (credit: Getty Images)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Hackers are actively exploiting a critical vulnerability in a widely used WordPress plugin that gives them the ability to take complete control of millions of sites, researchers said.</p>
<p>The vulnerability, which carries a severity rating of 8.8 out of a possible 10, is present in Elementor Pro, a <a href="https://elementor.com/pricing/">premium plugin</a> running on more than 12 million sites powered by the WordPress content management system. Elementor Pro allows users to create high-quality websites using a wide range of tools, one of which is WooCommerce, a separate WordPress plugin. When those conditions are met, anyone with an account on the site—say a subscriber or customer—can create new accounts that have full administrator privileges.</p>
<p>The vulnerability was discovered by Jerome Bruandet, a researcher with security firm NinTechNet. Last week, Elementor, the developer of the Elementor Pro plugin, <a href="https://elementor.com/pro/changelog/">released</a> version 3.11.7, which patched the flaw. In a <a href="https://blog.nintechnet.com/high-severity-vulnerability-fixed-in-wordpress-elementor-pro-plugin/">post</a> published on Tuesday, Bruandet wrote:</p></div><p><a href="https://arstechnica.com/?p=1928488#p3">Read 7 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1928488&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/hackers-exploit-wordpress-plugin-flaw-that-gives-full-control-of-millions-of-sites/feed/</wfw:commentRss>
      <slash:comments>67</slash:comments>
    </item>
    <item>
      <title>These angry Dutch farmers really hate Microsoft</title>
      <link>https://arstechnica.com/?p=1928218</link>
      <comments>https://arstechnica.com/tech-policy/2023/03/these-angry-dutch-farmers-really-hate-microsoft/#comments</comments>
      <dc:creator><![CDATA[WIRED]]></dc:creator>
      <pubDate>Fri, 31 Mar 2023 13:46:55 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Policy]]></category>
      <category><![CDATA[climate change]]></category>
      <category><![CDATA[data centers]]></category>
      <category><![CDATA[europe]]></category>
      <category><![CDATA[microsoft]]></category>
      <category><![CDATA[Netherlands]]></category>
      <category><![CDATA[syndication]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1928218</guid>
      <description><![CDATA[Tech giants want to build massive, “hyperscale” data centers in the Netherlands.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/microsoft-sign-800x471.jpg" alt="Microsoft sign">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/microsoft-sign.jpg" class="enlarge-link" data-height="603" data-width="1024">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="https://www.gettyimages.com/detail/news-photo/microsoft-sign-seen-on-july-08-2020-in-berlin-germany-news-photo/1255138671">Jeremy Moeller/Getty Images</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>As soon as Lars Ruiter steps out of his car, he is confronted by a Microsoft security guard, who is already seething with anger. Ruiter, a local councillor, has parked in the rain outside a half-finished Microsoft data center that rises out of the flat North Holland farmland. He wants to see the construction site. The guard, who recognizes Ruiter from a previous visit when he brought a TV crew here, says that’s not allowed. Within minutes, the argument has escalated, and the guard has his hand around Ruiter’s throat.</p>
<p>The security guard lets go of Ruiter within a few seconds, and the councillor escapes with a red mark across his neck. Back in his car, Ruiter insists he’s fine. But his hands shake when he tries to change gears. He says the altercation—which he will later report to the police—shows the fog of secrecy that surrounds the Netherlands’ expanding <a href="https://www.wired.com/story/facebook-dutch-data-center/">data center</a> business.</p>
<p></p></div><p><a href="https://arstechnica.com/?p=1928218#p3">Read 18 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1928218&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/tech-policy/2023/03/these-angry-dutch-farmers-really-hate-microsoft/feed/</wfw:commentRss>
      <slash:comments>316</slash:comments>
    </item>
    <item>
      <title>3CX knew its app was flagged as malicious but took no action for 7 days</title>
      <link>https://arstechnica.com/?p=1928121</link>
      <comments>https://arstechnica.com/information-technology/2023/03/3cx-knew-its-app-was-flagged-as-malicious-but-took-no-action-for-7-days/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Thu, 30 Mar 2023 21:46:12 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[3cx]]></category>
      <category><![CDATA[exploit]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1928121</guid>
      <description><![CDATA["It's not exactly our place to comment on it," 3CX rep says of malicious detection.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/error-800x516.jpg" alt="3CX knew its app was flagged as malicious but took no action for 7 days">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/error.jpg" class="enlarge-link" data-height="645" data-width="1000">Enlarge</a> </p>  </figure>






<div><a name="page-1"></a></div>
<p>The support team for 3CX, the VoIP/PBX software provider with more than 600,000 customers and 12 million daily users, was aware its desktop app was being flagged as malware but decided to take no action for a week when it learned it was on the receiving end of a <a href="https://arstechnica.com/information-technology/2023/03/massive-supply-chain-attack-with-ties-to-north-korea-hits-users-of-3cx-voice-app/">massive supply chain attack</a>, a <a href="https://www.3cx.com/community/threads/threat-alerts-from-sentinelone-for-desktop-update-initiated-from-desktop-client.119806/">thread</a> on the company’s community forum shows.</p>
<p>“Is anyone else seeing this issue with other A/V vendors?” one company customer asked on March 22, in a post titled “Threat alerts from SentinelOne for desktop update initiated from desktop client.” The customer was referring to an endpoint malware detection product from security firm SentinelOne. Included in the post were some of SentinelOne’s suspicions: the detection of shellcode, code injection to other process memory space, and other trademarks of software exploitation.</p>
<blockquote><p>Is anyone else seeing this issue with other A/V vendors?</p>
<p>Post Exploitation<br>
Penetration framework or shellcode was detected<br>
Evasion<br>
Indirect command was executed<br>
Code injection to other process memory space during the target process' initialization<br>
\Device\HarddiskVolume4\Users\**USERNAME**\AppData\Local\Programs\3CXDesktopApp\3CXDesktopApp.exe<br>
SHA1 e272715737b51c01dc2bed0f0aee2bf6feef25f1</p>
<p>I'm also getting the same trigger when attempting to redownload the app from the web client ( 3CXDesktopApp-18.12.416.msi ).</p></blockquote>
<h2>Defaulting to trust</h2>
<p>Other users quickly jumped in to report receiving the same warnings from their SentinelOne software. They all reported receiving the warning while running 18.0 Update 7 (Build 312) of the 3CXDesktopApp for Windows. Users soon decided the detection was a false positive triggered by a glitch in the SentinelOne product. They created an exception to allow the suspicious app to run without interference. On Friday, a day later, and again on the following Monday and Tuesday, more users reported receiving the SentinelOne warning.</p></div><p><a href="https://arstechnica.com/?p=1928121#p3">Read 6 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1928121&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/3cx-knew-its-app-was-flagged-as-malicious-but-took-no-action-for-7-days/feed/</wfw:commentRss>
      <slash:comments>80</slash:comments>
    </item>
    <item>
      <title>AI-generated video of Will Smith eating spaghetti astounds with terrible beauty</title>
      <link>https://arstechnica.com/?p=1927886</link>
      <comments>https://arstechnica.com/information-technology/2023/03/yes-virginia-there-is-ai-joy-in-seeing-fake-will-smith-ravenously-eat-spaghetti/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Thu, 30 Mar 2023 21:02:00 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[deepfakes]]></category>
      <category><![CDATA[google]]></category>
      <category><![CDATA[image synthesis]]></category>
      <category><![CDATA[Joe Biden]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[meta]]></category>
      <category><![CDATA[Runway]]></category>
      <category><![CDATA[scarlett johansson]]></category>
      <category><![CDATA[Stable Diffusion]]></category>
      <category><![CDATA[video synthesis]]></category>
      <category><![CDATA[will smith]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1927886</guid>
      <description><![CDATA[Open source "text2video" ModelScope AI made the viral sensation possible.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/will_smith_spaghetti_hero-800x450.jpg" alt="Stills from an AI-generated video of Will Smith eating spaghetti.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/will_smith_spaghetti_hero.jpg" class="enlarge-link" data-height="675" data-width="1200">Enlarge</a> <span class="sep">/</span> Stills from an AI-generated video of Will Smith eating spaghetti that has been heating up the Internet. (credit: <a rel="nofollow" class="caption-link" href="https://www.reddit.com/r/StableDiffusion/comments/1244h2c/will_smith_eating_spaghetti/">chaindrop / Reddit</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Amid this past week's controversies in AI over <a href="https://arstechnica.com/tech-policy/2023/03/ftc-should-investigate-openai-and-halt-gpt-4-releases-ai-research-group-says/">regulation</a>, fears of <a href="https://arstechnica.com/information-technology/2023/03/fearing-loss-of-control-ai-critics-call-for-6-month-pause-in-ai-development/">world-ending doom</a>, and <a href="https://arstechnica.com/information-technology/2023/03/generative-ai-set-to-affect-300-million-jobs-across-major-economies/">job disruption</a>, the clouds have briefly parted. For a brief and shining moment, we can enjoy an absolutely ridiculous AI-generated video of Will Smith eating spaghetti that is now lighting up our lives with its terrible glory.</p>

<p>On Monday, a Reddit user named "chaindrop" <a href="https://www.reddit.com/r/StableDiffusion/comments/1244h2c/will_smith_eating_spaghetti/">shared the AI-generated video</a> on the r/StableDiffusion subreddit. It <a href="https://twitter.com/MagusWazir/status/1640555696750993415?s=20">quickly spread</a> to other forms of social media and inspired mixed ruminations in the press. For example, <a href="https://www.vice.com/en/article/xgw8ek/ai-will-smith-eating-spaghetti-hill-haunt-you-for-the-rest-of-your-life">Vice</a> said the video will "haunt you for the rest of your life," while the AV Club <a href="https://www.avclub.com/will-smith-scarlett-johansson-joe-biden-ai-spaghetti-1850283199">called it</a> the "natural end point for AI development."</p>
<p>We're somewhere in between. The 20-second silent video consists of 10 independently generated two-second segments stitched together. Each one shows different angles of a simulated Will Smith (at one point, even two Will Smiths) ravenously gobbling up spaghetti. It's entirely computer-generated, thanks to AI.</p></div><p><a href="https://arstechnica.com/?p=1927886#p3">Read 8 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1927886&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/yes-virginia-there-is-ai-joy-in-seeing-fake-will-smith-ravenously-eat-spaghetti/feed/</wfw:commentRss>
      <slash:comments>147</slash:comments>
    </item>
    <item>
      <title>Trojanized Windows and Mac apps rain down on 3CX users in massive supply chain attack</title>
      <link>https://arstechnica.com/?p=1927920</link>
      <comments>https://arstechnica.com/information-technology/2023/03/massive-supply-chain-attack-with-ties-to-north-korea-hits-users-of-3cx-voice-app/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Thu, 30 Mar 2023 17:13:36 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[3cx]]></category>
      <category><![CDATA[supply chain attack]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1927920</guid>
      <description><![CDATA[Remember SolarWinds? A similar attack is playing out now against a new software supplier.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/03/north-korea-hacking-800x534.jpeg" alt="Trojanized Windows and Mac apps rain down on 3CX users in massive supply chain attack">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2022/03/north-korea-hacking.jpeg" class="enlarge-link" data-height="667" data-width="1000">Enlarge</a> (credit: Getty Images)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Hackers working on behalf of the North Korean government have pulled off a massive supply chain attack on Windows and macOS users of 3CX, a widely used voice and video calling desktop client, researchers from multiple security firms said.</p>
<p>Through means that aren't yet clear, the attack managed to distribute Windows and macOS versions of the app, which provides both VoIP and PBX services to “<a href="https://www.3cx.com/company/customers/">600,000+ customers</a>,” including American Express, Mercedes-Benz, and Price Waterhouse Cooper. The attackers somehow gained the ability to hide malware inside 3CX apps that were digitally signed using the company’s official signing key. The macOS version, <a href="https://objective-see.org/blog/blog_0x73.html">according to</a> macOS security expert Patrick Wardle, was also notarized by Apple, indicating that the company analyzed the app and detected no malicious functionality.</p>
<h2>In the making since 2022</h2>
<p>“This is a classic supply chain attack, designed to exploit trust relationships between an organization and external parties,” Lotem Finkelstein, Director of Threat Intelligence &amp; Research at Check Point Software, said in an email. “This includes partnerships with vendors or the use of a third-party software which most businesses are reliant on in some way. This incident is a reminder of just how critical it is that we do our due diligence in terms of scrutinizing who we conduct business with.”</p></div><p><a href="https://arstechnica.com/?p=1927920#p3">Read 11 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1927920&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/massive-supply-chain-attack-with-ties-to-north-korea-hits-users-of-3cx-voice-app/feed/</wfw:commentRss>
      <slash:comments>28</slash:comments>
    </item>
    <item>
      <title>Pro-Russian hackers target elected US officials supporting Ukraine</title>
      <link>https://arstechnica.com/?p=1927817</link>
      <comments>https://arstechnica.com/information-technology/2023/03/pro-russian-hackers-target-elected-us-officials-supporting-ukraine/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Thu, 30 Mar 2023 12:19:17 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[espionage]]></category>
      <category><![CDATA[hacking]]></category>
      <category><![CDATA[russia]]></category>
      <category><![CDATA[Ukraine]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1927817</guid>
      <description><![CDATA[Group tracked since 2021 exploits unpatched Zimbra servers to hack email accounts.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/03/russiaflag-800x556.jpeg" alt="Locked out.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2022/03/russiaflag.jpeg" class="enlarge-link" data-height="695" data-width="1000">Enlarge</a> <span class="sep">/</span> Locked out. (credit: <a rel="nofollow" class="caption-link" href="https://www.gettyimages.com/search/photographer?assettype=image&amp;family=creative&amp;license=rf&amp;photographer=SEAN%20GLADWELL&amp;sort=best#license">Sean Gladwell / Getty Images</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Threat actors aligned with Russia and Belarus are targeting elected US officials supporting Ukraine, using attacks that attempt to compromise their email accounts, researchers from security firm Proofpoint said.</p>
<p>The campaign, which also targets officials of European nations, uses malicious JavaScript that’s customized for individual webmail portals belonging to various NATO-aligned organizations, a <a href="https://www.proofpoint.com/us/blog/threat-insight/exploitation-dish-best-served-cold-winter-vivern-uses-known-zimbra-vulnerability">report</a> Proofpoint published Thursday said. The threat actor—which Proofpoint has tracked since 2021 under the name TA473—employs sustained reconnaissance and painstaking research to ensure the scripts steal targets’ usernames, passwords, and other sensitive login credentials as intended on each publicly exposed webmail portal being targeted.</p>
<h2>Tenacious targeting</h2>
<p>“This actor has been tenacious in its targeting of American and European officials as well as military and diplomatic personnel in Europe,” Proofpoint threat researcher Michael Raggi wrote in an email. “Since late 2022, TA473 has invested an ample amount of time studying the webmail portals of European government entities and scanning publicly facing infrastructure for vulnerabilities all in an effort to ultimately gain access to emails of those closely involved in government affairs and the Russia-Ukraine war.”</p></div><p><a href="https://arstechnica.com/?p=1927817#p3">Read 10 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1927817&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/pro-russian-hackers-target-elected-us-officials-supporting-ukraine/feed/</wfw:commentRss>
      <slash:comments>35</slash:comments>
    </item>
    <item>
      <title>Fearing “loss of control,” AI critics call for 6-month pause in AI development</title>
      <link>https://arstechnica.com/?p=1927560</link>
      <comments>https://arstechnica.com/information-technology/2023/03/fearing-loss-of-control-ai-critics-call-for-6-month-pause-in-ai-development/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Wed, 29 Mar 2023 20:05:01 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[Elon Musk]]></category>
      <category><![CDATA[Emily Bender]]></category>
      <category><![CDATA[Futue of Life Institute]]></category>
      <category><![CDATA[GPT-4]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[openai]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1927560</guid>
      <description><![CDATA["This pause should be public and verifiable, and include all key actors."]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/AI_pause_hero_1-800x450.jpg" alt="An AI-generated image of a globe that has stopped spinning.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/AI_pause_hero_1.jpg" class="enlarge-link" data-height="675" data-width="1200">Enlarge</a> <span class="sep">/</span> An AI-generated image of a globe that has stopped spinning. (credit: Stable Diffusion)</p>  </figure>






<div><a name="page-1"></a></div>
<p>On Wednesday, the Future of Life Institute published an <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter</a> on its website calling on AI labs to "immediately pause for at least 6 months the training of AI systems more powerful than <a href="https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/">GPT-4</a>." Signed by Elon Musk and several prominent AI researchers, the letter quickly began to <a href="https://www.reuters.com/technology/musk-experts-urge-pause-training-ai-systems-that-can-outperform-gpt-4-2023-03-29/">draw attention</a> in the press—and some <a href="https://twitter.com/timnitGebru/status/1640924853493714944?s=20">criticism</a> on social media.</p>

<p>Earlier this month, OpenAI released <a href="https://arstechnica.com/information-technology/2023/03/openai-announces-gpt-4-its-next-generation-ai-language-model/">GPT-4</a>, an AI model that can perform compositional tasks and allegedly pass standardized tests at a human level, although those claims are still being evaluated by research. Regardless, GPT-4 and <a href="https://arstechnica.com/information-technology/2023/02/ai-powered-bing-chat-loses-its-mind-when-fed-ars-technica-article/">Bing Chat's</a> advancement in capabilities over previous AI models <a href="https://arstechnica.com/information-technology/2023/03/openai-checked-to-see-whether-gpt-4-could-take-over-the-world/">spooked some experts</a> who believe we are heading toward super-intelligent AI systems faster than previously expected.</p>
<p>Along these lines, the Future of Life Institute argues that recent advancements in AI have led to an "out-of-control race" to develop and deploy AI models that are difficult to predict or control. They believe that the lack of planning and management of these AI systems is concerning and that powerful AI systems should only be developed once their effects are well-understood and manageable. As they write in the letter:</p></div><p><a href="https://arstechnica.com/?p=1927560#p3">Read 15 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1927560&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/fearing-loss-of-control-ai-critics-call-for-6-month-pause-in-ai-development/feed/</wfw:commentRss>
      <slash:comments>297</slash:comments>
    </item>
    <item>
      <title>Ransomware crooks are exploiting IBM file-exchange bug with a 9.8 severity</title>
      <link>https://arstechnica.com/?p=1927511</link>
      <comments>https://arstechnica.com/information-technology/2023/03/ransomware-crooks-are-exploiting-ibm-file-exchange-bug-with-a-9-8-severity/#comments</comments>
      <dc:creator><![CDATA[Dan Goodin]]></dc:creator>
      <pubDate>Wed, 29 Mar 2023 00:24:24 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[exploits]]></category>
      <category><![CDATA[ibm]]></category>
      <category><![CDATA[ransomware]]></category>
      <category><![CDATA[vulnerabilities]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1927511</guid>
      <description><![CDATA[If you haven't patched your Aspera Faspex server, now would be an excellent time.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2021/02/evil-packet-800x480.jpg" alt="Ransomware crooks are exploiting IBM file-exchange bug with a 9.8 severity">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2021/02/evil-packet.jpg" class="enlarge-link" data-height="600" data-width="1000">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="https://www.gettyimages.com/">Getty Images</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Threat actors are exploiting a critical vulnerability in an IBM file-exchange application in hacks that install ransomware on servers, security researchers have warned.</p>
<p>The IBM Aspera Faspex is a centralized file-exchange application that large organizations use to transfer large files or large volumes of files at very high speeds. Rather than relying on TCP-based technologies such as FTP to move files, Aspera uses IBM’s proprietary FASP—short for Fast, Adaptive, and Secure Protocol—to better utilize available network bandwidth. The product also provides fine-grained management that makes it easy for users to send files to a list of recipients in distribution lists or shared inboxes or workgroups, giving transfers a workflow that’s similar to email.</p>
<p>In late January, IBM <a href="https://www.ibm.com/support/pages/node/6952319">warned</a> of a critical vulnerability in Aspera versions 4.4.2 Patch Level 1 and earlier and urged users to install an update to patch the flaw. Tracked as CVE-2022-47986, the vulnerability makes it possible for unauthenticated threat actors to remotely execute malicious code by sending specially crafted calls to an outdated programming interface. The ease of exploiting the vulnerability and the damage that could result earned CVE-2022-47986 a severity rating of 9.8 out of a possible 10.</p></div><p><a href="https://arstechnica.com/?p=1927511#p3">Read 4 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1927511&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/ransomware-crooks-are-exploiting-ibm-file-exchange-bug-with-a-9-8-severity/feed/</wfw:commentRss>
      <slash:comments>26</slash:comments>
    </item>
    <item>
      <title>Generative AI set to affect 300 million jobs across major economies</title>
      <link>https://arstechnica.com/?p=1927270</link>
      <comments>https://arstechnica.com/information-technology/2023/03/generative-ai-set-to-affect-300-million-jobs-across-major-economies/#comments</comments>
      <dc:creator><![CDATA[Financial Times]]></dc:creator>
      <pubDate>Tue, 28 Mar 2023 13:30:49 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[Policy]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[automation]]></category>
      <category><![CDATA[employment]]></category>
      <category><![CDATA[syndication]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1927270</guid>
      <description><![CDATA[Technology could boost global GDP by 7% but also risks creating "significant disruption."]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/empty-office-800x563.jpg" alt="Empty cubicles in office">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/empty-office-scaled.jpg" class="enlarge-link" data-height="1803" data-width="2560">Enlarge</a> (credit: <a rel="nofollow" class="caption-link" href="https://www.gettyimages.com/detail/photo/businesswoman-standing-alone-in-empty-office-royalty-free-image/102871188">Thomas Barwick via Getty</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>The latest breakthroughs in artificial intelligence could lead to the automation of a quarter of the work done in the US and eurozone, according to research by Goldman Sachs.</p>
<p>The investment bank said on Monday that “generative” AI systems such as ChatGPT, which can create content that is indistinguishable from human output, could spark a productivity boom that would eventually raise annual global gross domestic product by 7 percent over a 10-year period.</p>
<p>But if the technology lived up to its promise, it would also bring “significant disruption” to the labor market, exposing the equivalent of 300 million full-time workers across big economies to automation, according to Joseph Briggs and Devesh Kodnani, the paper’s authors. Lawyers and administrative staff would be among those at greatest risk of becoming redundant.</p></div><p><a href="https://arstechnica.com/?p=1927270#p3">Read 13 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1927270&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/generative-ai-set-to-affect-300-million-jobs-across-major-economies/feed/</wfw:commentRss>
      <slash:comments>327</slash:comments>
    </item>
    <item>
      <title>Immaculate AI images of Pope Francis trick the masses</title>
      <link>https://arstechnica.com/?p=1927164</link>
      <comments>https://arstechnica.com/information-technology/2023/03/the-power-of-ai-compels-you-to-believe-this-fake-image-of-pope-in-a-puffy-coat/#comments</comments>
      <dc:creator><![CDATA[Benj Edwards]]></dc:creator>
      <pubDate>Mon, 27 Mar 2023 21:41:44 +0000</pubDate>
      <category><![CDATA[Biz & IT]]></category>
      <category><![CDATA[AI]]></category>
      <category><![CDATA[deepfakes]]></category>
      <category><![CDATA[image synthesis]]></category>
      <category><![CDATA[machine learning]]></category>
      <category><![CDATA[MidJourney]]></category>
      <category><![CDATA[pope francis]]></category>
      <category><![CDATA[The Catholic Church]]></category>
      <guid isPermaLink="false">https://arstechnica.com/?p=1927164</guid>
      <description><![CDATA[Faux “puffy pontiff” AI image fools many in viral social media post.]]></description>
      <content:encoded><![CDATA[<div id="rss-wrap">
<figure class="intro-image intro-left">
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/FsEy5bVWcAAs4xN-800x980.jpg" alt="An AI-generated photo of Pope Francis wearing a puffy white coat that went viral on social media.">
      <p class="caption" style="font-size:0.8em"><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/03/FsEy5bVWcAAs4xN.jpg" class="enlarge-link" data-height="1323" data-width="1080">Enlarge</a> <span class="sep">/</span> An AI-generated photo of Pope Francis wearing a puffy white coat that went viral on social media. (credit: <a rel="nofollow" class="caption-link" href="https://twitter.com/skyferrori/status/1639647708154675200">@skyferrori on Twitter</a>)</p>  </figure>






<div><a name="page-1"></a></div>
<p>Over the weekend, an AI-generated image of Pope Francis wearing a puffy white coat <a href="https://twitter.com/skyferrori/status/1639703180199047168?s=20">went viral</a> on Twitter, and apparently <a href="https://www.garbageday.email/p/pope-in-a-coat">many people</a> believed it was a real image. Since then, the puffy pontiff has <a href="https://www.theguardian.com/commentisfree/2023/mar/27/pope-coat-ai-image-baby-boomers?CMP=fb_a-technology_b-gdntech">inspired commentary</a> on the deceptive nature of AI-generated images, which are now nearly photorealistic.</p>

<p>The pope image, created using <a href="https://arstechnica.com/information-technology/2023/03/ai-imager-midjourney-v5-stuns-with-photorealistic-images-and-5-fingered-hands/">Midjourney v5</a> (an AI image synthesis model), <a href="https://twitter.com/skyferrori/status/1639647708154675200">first appeared in a tweet</a> by a user named Leon (<span class="css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0">@skyferrori</span>) on Saturday and quickly began circulating as part of other meme tweets featuring similar images as well, including one that <a href="https://twitter.com/donmoyn/status/1639682534597443587">humorously speculates</a> about a pope "lifestyle brand."</p>
<div class="twitter-tweet"><blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">OKAAYYY <a href="https://t.co/MliHsksX7L">pic.twitter.com/MliHsksX7L</a></p>— leonardo (@skyferrori) <a href="https://twitter.com/skyferrori/status/1639647708154675200?ref_src=twsrc%5Etfw">March 25, 2023</a></blockquote></div>
<p>Not long after, Twitter attached a reader-added context warning to the tweet that reads, "<span class="css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0">This is an AI-generated image of Pope Francis. It is not a genuine photo.</span>"</p></div><p><a href="https://arstechnica.com/?p=1927164#p3">Read 6 remaining paragraphs</a> | <a href="https://arstechnica.com/?p=1927164&comments=1">Comments</a></p>]]></content:encoded>
      <wfw:commentRss>https://arstechnica.com/information-technology/2023/03/the-power-of-ai-compels-you-to-believe-this-fake-image-of-pope-in-a-puffy-coat/feed/</wfw:commentRss>
      <slash:comments>196</slash:comments>
    </item>
  </channel>
</rss>