<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/rss2full.xsl"?>
<?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>IEEE Spectrum</title>
    <link>https://spectrum.ieee.org/</link>
    <description>IEEE Spectrum</description>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 May 2022 21:23:38 -0000</lastBuildDate>
    <image>
      <url>https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNjg4NDUyMC9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTY5OTk5OTQzOX0.301VTCew4TbjvOr--sy6SCzN7qjjXsjyR9O35w43oZo/image.png?width=210</url>
      <link>https://spectrum.ieee.org/</link>
      <title>IEEE Spectrum</title>
    </image>
    <atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/rss+xml" href="http://feeds.feedburner.com/IeeeSpectrumFullText" />
    <feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="ieeespectrumfulltext" />
    <atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" />
    <item>
      <title>Meta’s Challenge to OpenAI—Give Away a Massive Language Model</title>
      <link>https://spectrum.ieee.org/large-language-models-meta-openai</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/meta-s-logo-in-the-middle-of-a-speech-bubble.jpg?id=29750523&width=1200&coordinates=0%2C125%2C0%2C125&height=800"/><br/><br/><p>Meta is giving away some of the family jewels: That’s the gist of an announcement from the company formerly known as Facebook this week. In a <a href="https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/" rel="noopener noreferrer" target="_blank">blog post</a> on the <a href="https://ai.facebook.com/" rel="noopener noreferrer" target="_blank">Meta AI</a> site, the company’s researchers announced that they’ve created a massive and powerful language AI system and are making it freely available to all researchers in the artificial intelligence community. Meta describes the move as an effort to democratize access to a powerful kind of AI—but some argue that not very many researchers will actually benefit from this largesse. And even as these models become more accessible to researchers, many questions remain about the path to commercial use. </p><p>Large language models are one of the hottest things in AI right now. Models like <a href="https://openai.com/api/" rel="noopener noreferrer" target="_blank">OpenAI’s GPT-3</a> can generate remarkably fluid and coherent text in just about any format or style: They can write convincing news articles, legal summaries, poems, and advertising copy, or hold up their end of conversation as customer service chatbots or video game characters. GPT-3, which broke the mold with its 175 billion parameters, is available to academic and commercial entities only via OpenAI’s application and vetting process.</p><p>Meta’s Open Pretrained Transformer (known as OPT-175B) matches GPT-3 with 175 billion parameters of its own. Meta is offering the research community not only the model itself, but also its codebase and extensive notes and logbooks about the training process. The model was trained on 800 gigabytes of data from five publicly available data sets, which are described in the <a href="https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/data_card.md" rel="noopener noreferrer" target="_blank">“data card”</a> that accompanies a <a href="https://arxiv.org/abs/2205.01068" rel="noopener noreferrer" target="_blank">technical paper</a> posted by the Meta researchers to the <a href="http://arxiv.org" target="_blank">ArXiv</a> online preprint server.</p><p><a href="https://www.linkedin.com/in/joelle-pineau-371574141/" rel="noopener noreferrer nofollow" target="_blank">Joelle Pineau</a>, director of Meta AI Research Labs, tells <em>IEEE Spectrum</em> that she expects researchers to make use of this treasure trove in several ways. “The first thing I expect [researchers] to do is to use it to build other types of language-based systems, whether it's machine translation, a chat bot, something that complete text—all of these require this kind of state-of-the-art language model,” she says. Rather than training their own language models from scratch, Pineau says, they can build applications and run them “on a relatively modest compute budget.”</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="A smiling woman with short dark hair" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="921e9207cbaf352978f54a3d1a1e2e6e" data-rm-shortcode-name="rebelmouse-image" id="364d5" loading="lazy" src="https://spectrum.ieee.org/media-library/a-smiling-woman-with-short-dark-hair.jpg?id=29756458&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">Joelle Pineau</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit..." style="max-width: 100%;">Meta</small></p><p>The second thing she expects researchers to do, Pineau says, is “pull it apart” to examine its flaws and limitations. Large language models like GPT-3 are famously capable of <a href="https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business" target="_self">generating toxic language</a> full of stereotypes and harmful bias; that troubling tendency is a result of training data that includes hateful language found in Reddit forums and the like. In their technical paper, Meta’s researchers describe how they evaluated the model on benchmarks related to hate speech, stereotypes, and toxic content generation, but Pineau says “there’s so much more to be done.” She adds that the scrutiny should be done “by community researchers, not inside closed research labs.” </p><p>The paper states that “we still believe this technology is premature for commercial deployment,” and says that by releasing the model with a non-commercial license, Meta hopes to facilitate the development of guidelines for responsible use of large language models “before broader commercial deployment occurs.”</p><p>Within Meta, Pineau acknowledges that there’s a lot of interest in using OPT-175B commercially. “We have a lot of groups that deal with text,” she notes, which might want to build a specialized application on top of the language model. It’s easy to imagine product teams salivating over the technology: It could power content moderation tools or text translation, could help suggest relevant content, or could generate text for the creatures of the metaverse, should it <a href="https://spectrum.ieee.org/is-the-metaverse-even-feasible" rel="noopener noreferrer nofollow" target="_blank">truly come to pass</a>. </p><p>There have been other efforts to make an open-source language model, most notably from <a href="https://www.eleuther.ai/" target="_blank">EleutherAI</a>, an association that has released <a href="https://spectrum.ieee.org/eleutherai-openai-not-open-enough" target="_blank">a 20-billion parameter model</a> in February. Connor Leahy, one of the founders of EleutherAI and founder of an AI startup called <a href="https://www.conjecture.dev/" target="_blank">Conjecture</a>, calls Meta’s move a good step for open science. “Especially the release of their logbook is unprecedented (to my knowledge) and very welcome,” he tells <em>IEEE Spectrum</em> in an email. But he notes that Meta's conditional release, making the model available only on request and with a non-commercial license, “falls short of truly open.” EleutherAI doesn't comment on its plans, but Leahy says the group will continue working on its own language AI, and adds that OPT-175B will be helpful for some of its research. “Open research is synergistic in that way,” he says.<span></span></p><p class="pull-quote">“Security through obscurity is not security, as the saying in the computer security world goes. And studying these models and finding ways to integrate their existence into our world is the only feasible path forward.”<br/>—Connor Leahy, EleutherAI</p><p>EleutherAI is a something of an outlier in AI research in that it’s a self-organizing group of volunteers. Much of today’s cutting-edge AI work is done within the R&D departments of big players like Meta, Google, OpenAI, Microsoft, Nvidia, and other deep-pocketed companies. That's because it takes enormous amount of energy and compute infrastructure to train big AI systems. <br/></p><p>Meta claims that its training of OPT-175 required 1/7th the carbon footprint as that required for training GPT-3, yet as Meta's paper notes, that's still a significant energy expenditure. The paper says that OPT-175B was trained on 992 80-gigabyte <a href="https://www.nvidia.com/en-us/data-center/a100/" target="_blank">A100 GPUs</a> from Nvidia, with a carbon emissions footprint of 75 tons, as compared to an estimated carbon budget of 500 tons for GPT-3 (that figure has not been confirmed by OpenAI). </p><p> Meta’s hope is that by offering up this “<a href="https://crfm.stanford.edu/" target="_blank">foundation model</a>” for other entities to build on top of, it will at least reduce the need to build huge models from scratch. Deploying the model, Meta says in its blog post, requires only 16 Nvidia V100 GPUs. The company is also releasing smaller scale versions of OPT-175B that can be used by researchers who don't need the full-scale model or by those who are investigating the behavior of language models at different scales. </p><p><span></span><a href="https://homes.cs.washington.edu/~msap/" target="_blank">Maarten Sap</a>, a researcher at the <a href="https://allenai.org/" target="_blank">Allen Institute for Artificial Intelligence</a> (AI2) and in incoming assistant professor at Carnegie Mellon University’s <a href="https://www.lti.cs.cmu.edu/" target="_blank">Language Technologies Institute</a>, studies large language models and has worked on methods to <a href="https://arxiv.org/abs/2009.11462" target="_blank">detoxify</a> them. In other words, he’s exactly the kind of researcher that Meta is hoping to attract. Sap says that he’d “love to use OPT-175B,” but “the biggest issue is that few research labs actually have the infrastructure to run this model.” If it were easier to run, he says, he’d use it to study toxic language risks and social intelligence within language models. </p><p>While Sap applauds Meta for opening up the model to the community, he thinks they could go a step further. “Ideally, having a demo of the system and an API with much more control/access than [OpenAI’s API for GPT-3] would be great for actual accessibility,” he says. However, he notes that Meta’s release of smaller versions is a good “second best option.”</p><p>Whether models like OPT-175B will ever become as safe and accessible as other kinds of enterprise software is still an open question, and there are different ideas about the path forward. EleutherAI’s Leahy says that preventing broad commercial use of these models won’t solve the problems with them. “Security through obscurity is not security, as the saying in the computer security world goes,” says Leahy, “and studying these models and finding ways to integrate their existence into our world is the only feasible path forward.”</p><p>Meanwhile, Sap argues that AI regulation is needed to<strong> </strong>“prevent researchers, people, or companies from using AI to impersonate people, generate propaganda or fake news, or other harms.” But he notes that “it’s pretty clear that <a href="https://www.cnn.com/2021/10/24/politics/facebook-blumenthal-government-regulation-cnntv/index.html" target="_blank">Meta is against regulation</a> in many ways.”</p><p><a href="http://sameersingh.org/" rel="noopener noreferrer nofollow" target="_blank">Sameer Singh</a>, an associate professor at University of California, Irvine and a research fellow at AI2 who works on language models, praises Meta for releasing the training notes and logbooks, saying that process information may end up being more useful to researchers than the model itself. SIngh says he hopes that such openness will become the norm. He also says he supports providing commercial access to at least smaller models, since such access can be useful for understanding models’ practical limitations.</p><p>"Disallowing commercial access completely or putting it behind a paywall may be the only way to justify, from a business perspective, why these companies should build and release LLMs in the first place,” Singh says. “I suspect these restrictions have less to do with potential damage than claimed.”</p>]]></description>
      <pubDate>Thu, 05 May 2022 21:23:38 +0000</pubDate>
      <guid>https://spectrum.ieee.org/large-language-models-meta-openai</guid>
      <category>Natural language processing</category>
      <category>Meta</category>
      <category>Facebook</category>
      <category>Openai</category>
      <category>Gpt-3</category>
      <category>Metaverse</category>
      <dc:creator>Eliza Strickland</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/meta-s-logo-in-the-middle-of-a-speech-bubble.jpg?id=29750523&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>IEEE’s Plan To Help Combat Climate Change</title>
      <link>https://spectrum.ieee.org/ieee-plan-combat-climate-change</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/two-workers-inspect-solar-panels-behind-them-are-3-wind-turbines.jpg?id=29753856&width=1200&coordinates=0%2C0%2C0%2C0&height=800"/><br/><br/><p>The IEEE Board of Directors formed an ad hoc committee on climate change in February to coordinate its response to the global threat. <em>The Institute</em> asked the committee’s chair, 2022 IEEE President-Elect <a href="https://spectrum.ieee.org/saifur-rahman-2022-president-elect" target="_self">Saifur Rahman</a>, about the issues it will be addressing, what role IEEE members can play, and other topics.</p>
<p>Rahman is a professor of electrical and computer engineering at <a href="https://vt.edu/" rel="noopener noreferrer" target="_blank">Virginia Tech</a>. The IEEE Life Fellow is also founder and chairman of <a href="https://www.bemcontrols.com/" rel="noopener noreferrer" target="_blank">BEM Controls</a>, a software company in McLean, Va., that provides buildings with energy-efficiency solutions.</p><p>His answers have been edited for clarity.</p>
<p><strong>Why was the ad hoc committee established?</strong></p><p><strong>Rahman:</strong> Its charter is to develop a cross-IEEE strategy to synchronize and guide the organization’s response to changes in the global climate. The committee will be the face of IEEE on the global platform dealing with these issues. </p>
<p>IEEE has significant relevant expertise and ongoing efforts that can be brought to bear on this issue. The committee includes experts from all six IEEE organizational units and all 10 IEEE regions. I did this on purpose so that people will have some ownership over this problem. Efforts include the work done by societies such as the<a href="https://www.ieee-pes.org/" rel="noopener noreferrer" target="_blank"> IEEE Power & Energy Society</a>, to which I belong; conferences such as the<a href="https://attend.ieee.org/ispec-2022/" rel="noopener noreferrer" target="_blank"> IEEE Sustainable Power and Energy Conference</a>; publications including<a href="https://www.ieee-pes.org/publications/electrification-magazine" rel="noopener noreferrer" target="_blank"> <em>IEEE Electrification</em></a>; and technical standards, like<a href="https://standards.ieee.org/ieee/1547/5915/" rel="noopener noreferrer" target="_blank"> IEEE 1547</a> for connecting distributed energy resources to the grid. This ad hoc committee will serve to better connect and coordinate these efforts. </p><p><strong>Why should IEEE be involved in combating climate change?</strong></p><p><strong>Rahman: </strong>IEEE has a global footprint, with members in 160 countries. With this very broad footprint, we can help to bring together organizations working on various aspects of climate change and possible solutions. IEEE is here to listen to them. </p><p>For example, organizations such as the<a href="https://www.sierraclub.org/" rel="noopener noreferrer" target="_blank"> Sierra Club</a> and the<a href="https://www.worldwildlife.org/" rel="noopener noreferrer" target="_blank"> World Wildlife Fund</a> aspire to make the world carbon-neutral in 30 to 40 years. There’s nothing wrong with their aspirations. We, as technologists, have a responsibility to point out to them the steps that need to be taken to get there and what the challenges are.</p><p>We are not a power company, a government, or a business that has a target to achieve, but a neutral platform. IEEE is highly respected because we don’t have an agenda.</p><p>As the world’s largest organization of technical professionals, IEEE has both the opportunity and the responsibility to assist in organizing engineers, scientists, and technical professionals to address the causes, mitigate the impact, and adapt to climate change.</p><p><strong>What is the committee working on?</strong></p><p><strong>Rahman: </strong>We are reaching out to the French <a href="https://www.academie-technologies.fr/en/" rel="noopener noreferrer" target="_blank">Academy of Technologies</a>, <a href="https://www.rotary.org/en/about-rotary" rel="noopener noreferrer" target="_blank">Rotary International</a>,<a href="https://www.unesco.org/en" rel="noopener noreferrer" target="_blank"> UNESCO</a>, U.S.<a href="https://www.nae.edu/" rel="noopener noreferrer" target="_blank"> National Academy of Engineering</a>,<a href="http://www.wfeo.org/" rel="noopener noreferrer" target="_blank"> World Federation of Engineering Organizations</a>, and several environmental organizations to collaborate with them. We are sharing each other’s approaches to tackling the climate change problem, and IEEE is offering the services of its volunteer base to address some of these issues.</p><p><strong>Why should members care about climate change? From a practical standpoint, what can they do?</strong></p><p><strong>Rahman: </strong>Climate change is an existential threat to humanity. It has the potential to change the way we live and threatens the livelihood of hundreds of millions of people including members. The concern about climate change is across all age groups.</p><p>IEEE has a responsibility to bring this threat to the attention of our members so that they can in turn educate business leaders, political leaders, and society about its impact and possible solutions.</p><p>For example, engineers and technologists can develop technologies and offer best practices for decarbonization. IEEE can also provide resources to its members so they can give talks to local schools about topics such as coal-burning power plants or solar energy. We want to show that members can talk about climate-change topics with people who are not engineers.</p><p><strong>What are technologies that you think can affect climate change?</strong></p><p><strong>Rahman: </strong>When the ad hoc committee met for the first time in January, I identified what I call a six-point plan approach to show that IEEE is thinking about climate change seriously. The technologies are:</p><ol><li>Energy efficiency. These include low-cost solutions such as using more efficient light bulbs and lowering the temperature of your air conditioner. If you use less electricity, you will burn less coal. It’s as simple as that.</li><li>Battery energy storage. You cannot make wind and solar energy useful throughout the day unless you can store it.</li><li>Renewables such as solar, wind, and hydroelectricity. These have some challenges that need to be solved, such as integration into the grid.</li><li>Nuclear power. While large-scale nuclear power is still very unpopular, there are new technologies, such as advanced nuclear reactors and small reactors, that could be more acceptable and are not as risky as 1,000-megawatt big nuclear power plants, according to “<a href="https://ieeexplore.ieee.org/document/9374057" rel="noopener noreferrer" target="_blank">Small Modular and Advanced Nuclear Reactors: A Reality Check</a>,” published in <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6287639" rel="noopener noreferrer" target="_blank"><em>IEEE Access</em></a>. </li><li>Cross-border power transfer. If countries want to be energy self-sufficient, they may end up putting together a lot of resources that are not very efficient. For example, it’s cheaper for New York state to buy electricity from Canada than to build more power plants. </li><li>Carbon sequestration. Coal plants will be running for the next 30 to 40 years, so we must accept that. Our job as engineers is decarbonization, so we need to extract the CO2 released from power plants and hold it somewhere else. Coal-powered plants could also be more acceptable if we could extract soot from them.</li></ol><p>Climate change and global warming are universal. You can talk about the topic at any level with anybody, from high school kids to life members. My mission for this ad hoc committee is to create a platform to give members the tools to do that. </p>]]></description>
      <pubDate>Thu, 05 May 2022 18:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/ieee-plan-combat-climate-change</guid>
      <category>Ieee news</category>
      <category>Climate change</category>
      <category>Saifur rahman</category>
      <category>Energy</category>
      <dc:creator>Kathy Pretz</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/two-workers-inspect-solar-panels-behind-them-are-3-wind-turbines.jpg?id=29753856&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Bridge the Gaps in Your ADAS Test Strategy</title>
      <link>https://connectlp.keysight.com/ADE_RSE_WP?elqCampaignId=21125&amp;cmpid=ASC-2104561&amp;utm_source=ADSC&amp;utm_medium=ASC&amp;utm_campaign=302</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/image.png?id=27151193&width=980"/><br/><br/><p>Achieving the next level in vehicle autonomy demands robust algorithms trained to interpret radar reflections from automotive radar sensors. Overcome the gaps between software simulation and roadway testing to train the ADAS / AV algorithms with real-world conditions. Sharpen your ADAS' radar vision with full-scene emulation that allows you to lab test complex real-world scenario, while emulating up to 512 objects at distances as close as 1.5 meters.</p><p><a href="https://connectlp.keysight.com/ADE_RSE_WP?elqCampaignId=21125&cmpid=ASC-2104561&utm_source=ADSC&utm_medium=ASC&utm_campaign=302" rel="noopener noreferrer nofollow" target="_blank">Get this free whitepaper now!</a></p>]]></description>
      <pubDate>Thu, 05 May 2022 13:00:01 +0000</pubDate>
      <guid>https://connectlp.keysight.com/ADE_RSE_WP?elqCampaignId=21125&amp;cmpid=ASC-2104561&amp;utm_source=ADSC&amp;utm_medium=ASC&amp;utm_campaign=302</guid>
      <category>Autonomous vehicles</category>
      <category>Keysight</category>
      <category>Radar</category>
      <category>Type:whitepaper</category>
      <dc:creator>Keysight</dc:creator>
      <media:content url="https://assets.rbl.ms/27151193/origin.png" medium="image" type="image/png" />
    </item>
    <item>
      <title>Automating Road Maintenance With LiDAR Technology</title>
      <link>https://spectrum.ieee.org/sick-tim10k-challenge</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-sick-lidar-attached-to-the-back-of-a-car.jpg?id=29742819&width=1200&coordinates=93%2C0%2C94%2C0&height=800"/><br/><br/><p><em>This is a sponsored article brought to you by <a href="https://www.sick.com/us/en/tim10k/w/tim10k/" rel="noopener noreferrer" target="_blank">SICK Inc.</a>.</em></p><p>From advanced manufacturing to automated vehicles, engineers are using LiDAR to change the world as we know it. For the second year, students from across the country submitted projects to <a href="https://www.sick.com/us/en/tim10k/w/tim10k/" rel="noopener noreferrer" target="_blank">SICK's annual TiM$10K Challenge</a>. </p><h3></h3><br/><p>The first place team during the 2020 TiM$10K Challenge hails from <a href="https://www.wpi.edu/" rel="noopener noreferrer" target="_blank">Worcester Polytechnic Institute (WPI)</a> in Worcester, Mass. The team comprised of undergraduate seniors, Daniel Pelaez and Noah Budris, and undergraduate junior, Noah Parker. </p><p>With the help of their academic advisor, <a href="https://www.wpi.edu/people/faculty/alexw" rel="noopener noreferrer" target="_blank">Dr. Alexander Wyglinski</a>, Professor of Electrical Engineering and Robotics Engineering at WPI, the team took first place in the 2020 TiM$10K Challenge with their project titled ROADGNAR, a mobile and autonomous pavement quality data collection system.</p><h2>So what is the TiM$10K Challenge? </h2><p>In this challenge, SICK reached out to universities across the nation that were looking to support innovation and student achievement in automation and technology. Participating teams were supplied with a SICK 270° LiDAR, a TiM, and accessories. They were challenged to solve a problem, create a solution, and bring a new application that utilizes the SICK scanner in any industry. </p><p>Around the United States, many of the nation's roadways are in poor condition, most often from potholes and cracks in the pavement, which can make driving difficult. Many local governments agree that infrastructure is in need of repair, but with a lack of high-quality data, inconsistencies in damage reporting, and an overall lack of adequate prioritization, this is a difficult problem to solve. </p><h3></h3><br/><span class="rm-shortcode" data-rm-shortcode-id="caa8b8e0f7e13a7afa83c6a3fec80384" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/oCbMVgrQ6N4?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span><h3></h3><br/><p>Pelaez, Parker, and Budris first came up with the idea of ROADGNAR before they had even learned of the TiM$10K Challenge. They noticed that the roads in their New England area were in poor condition, and wanted to see if there was a way to help solve the way road maintenance is performed.</p><p>In their research, they learned that many local governments use outdated and manual processes. Many send out workers to check for poor road conditions, who then log the information in notebooks.</p><p>The team began working on a solution to help solve this problem. It was at a career fair that Pelaez met a SICK representative, who encouraged him to apply to the TiM$10K Challenge.</p><h3>Win $10K and a Trip to Germany!</h3><br/><img alt="SICK logo" class="rm-shortcode" data-rm-shortcode-id="b0a2a25afac0e0667a8da6eb0c4a0722" data-rm-shortcode-name="rebelmouse-image" id="26068" loading="lazy" src="https://spectrum.ieee.org/media-library/sick-logo.png?id=29742762&width=980"/><p>SICK is excited to announce the <a href="https://www.sick.com/us/en/tim10k/w/tim10k/" rel="noopener noreferrer" target="_blank">2022-2023 edition of the SICK TiM$10K Challenge</a>. Twenty teams will be selected to participate in the challenge, and the chosen teams will be supplied with a 270º SICK LiDAR sensor (TiM) and accessories. The teams will be challenged to solve a problem, create a solution, bring a new application that utilizes the SICK LiDAR in any industry. This can be part of the curriculum of a senior design project or capstone projects for students.</p><p><strong>Awards:</strong></p><p>The 3 winning teams will win a cash award of </p><p>• 1st Place - $10K<br/>• 2nd Place - $5K<br/>• 3rd place - $3K</p><p> In addition to bragging rights and the cash prize, the 1st place winning team, along with the advising professor, will be offered an all-expenses-paid trip to SICK Germany to visit the SICK headquarters and manufacturing facility!</p><p><a href="https://www.sick.com/us/en/tim10k/w/tim10k/" target="_blank">Registration is now open for the academic year 2022-2023!</a></p><h3></h3><br><p>Using SICK's LiDAR technology, the ROADGNAR takes a 3D scan of the road and the data is then used to determine the exact level of repair needed.<br/></p><p>ROADGNAR collects detailed data on the surface of any roadway, while still allowing for easy integration onto any vehicle. With this automated system, road maintenance can become a faster, more reliable, and more efficient process for towns and cities around the country. </p><p>ROADGNAR solves this problem through two avenues: hardware and software. The team designed two mounting brackets to connect the system to a vehicle. The first, located in the back of the vehicle, supports a LiDAR scanner. The second is fixed in line with the vehicle's axle and supports a wheel encoder, which is wired to the fuse box. </p><p>"It definitely took us a while to figure out a way to power ROADGNAR so we wouldn't have to worry about it shutting off while the car was in motion," said Parker. </p><p>Also wired to the fuse box is a GPS module within the vehicle itself. Data transfer wires are attached to these three systems and connected to a central processing unit within the vehicle. </p><h2>Using LiDAR to collect road data</h2><p>When the car is started, all connected devices turn on. The LiDAR scanner collects road surface data, the wheel encoder tracks an accurate measurement of the distance travelled by the vehicle, and the GPS generates geo-tags on a constant basis. All this data is stored in the onboard database, where a monitor presents it all to the user. The data is then stored in a hard drive. </p><p>Much like the roads in their Massachusetts town, the creation process of ROADGNAR was not without its challenges. The biggest problem took the form of the COVID-19 pandemic, which hit the ROADGNAR team in the middle of development. Once WPI closed to encourage its students and faculty to practice social distancing, the team was without a base of operations. </p><p>"When the coronavirus closed our school, we were lucky enough to live pretty close to each other," said Paleaz. "We took precautions, but were able to come together to test and power through to finish our project."</p><h3></h3><br><img alt="Three engineering students hold a lidar sensor while standing on a road that is in maintenance" class="rm-shortcode" data-rm-shortcode-id="310f99fc6183a7a556c816ae3022e75d" data-rm-shortcode-name="rebelmouse-image" id="57409" loading="lazy" src="https://spectrum.ieee.org/media-library/three-engineering-students-hold-a-lidar-sensor-while-standing-on-a-road-that-is-in-maintenance.jpg?id=29742853&width=980"/><h3></h3><br><p>Integrating LiDAR into the car was also a challenge. Occasionally, the LiDAR would shut off when the car began moving. The team had to take several measures to keep the sensor online, often contacting SICK's help center for instruction.</p><p>"One of the major challenges was making sure we were getting enough data on a given road surface," said Budris. "At first we were worried that we wouldn't get enough data from the sensor to make ROADGNAR feasible, but we figured that if we drove at a slow and constant rate, we'd be able to get accurate scans."</p><p>With the challenge complete, Pelaez, Budris, and Parker are looking to turn ROADGNAR into a genuine product. They have already contacted an experienced business partner to help them determine their next steps.</p><h3></h3><br/><img alt="An engineering student observes a pothole on a road." class="rm-shortcode" data-rm-shortcode-id="50ad4fba79b318ff07b2fecb4c87cd1b" data-rm-shortcode-name="rebelmouse-image" id="c50f6" loading="lazy" src="https://spectrum.ieee.org/media-library/an-engineering-student-observes-a-pothole-on-a-road.png?id=29742856&width=980"/><h3></h3><br/><p>They are now interviewing with representatives from various Department of Public Works throughout Massachusetts and Connecticut. Thirteen municipalities have indicated that they would be extremely interested in utilizing ROADGNAR, as it would drastically reduce the time needed to assess all the roads in the area. The trio is excited to see how different LiDAR sensors can help refine ROADGNAR into a viable product.</p><p>"We'd like to keep the connection going," explained Pelaez. "If we can keep the door open for a potential partnership between us and SICK, that'd be great."</p><p>SICK is now accepting entries for the <a href="https://www.sick.com/us/en/tim10k/w/tim10k/" rel="noopener noreferrer" target="_blank">TiM$10K Challenge for the 2022-2023 school year</a>! </p><p>Student teams are encouraged to use their creativity and technical knowledge to incorporate the SICK LiDAR for any industry in any application. Advisors/professors are allowed to guide the student teams as required.</p></br></br></br>]]></description>
      <pubDate>Wed, 04 May 2022 18:24:29 +0000</pubDate>
      <guid>https://spectrum.ieee.org/sick-tim10k-challenge</guid>
      <category>Lidar</category>
      <category>Robotics</category>
      <category>Autonomous vehicles</category>
      <category>Sensors</category>
      <category>Sick</category>
      <dc:creator>SICK Inc.</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-sick-lidar-attached-to-the-back-of-a-car.jpg?id=29742819&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Harnessing the Power of Innovation Intelligence</title>
      <link>https://discover.clarivate.com/power-of-Innovation-Intelligence?campaignname=DataStories_Innov_Insights_LeadGen_Webinar_May19_IPG_Global_2022&amp;campaignid=7014N0000029HwU&amp;utm_campaign=WaveDirIEEE&amp;utm_source=trade_publication&amp;utm_medium=paid</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/image.png?id=27150766&width=980"/><br/><br/><p>Business and R&D leaders have to make consequential strategic decisions every day in a global marketplace that continues to get more interconnected and complex. Luckily, the job can be more manageable and efficient by leveraging IP and scientific data analytics. <a href="https://discover.clarivate.com/power-of-Innovation-Intelligence?campaignname=DataStories_Innov_Insights_LeadGen_Webinar_May19_IPG_Global_2022&campaignid=7014N0000029HwU&utm_campaign=WaveDirIEEE&utm_source=trade_publication&utm_medium=paid" rel="noopener noreferrer nofollow" target="_blank">Register for this free webinar now!</a><u></u><u></u></p><p>Join us for the webinar, Harnessing the power of innovation intelligence, to hear Clarivate experts discuss how analyzing IP data, together with scientific content and industry-specific data, can provide organization-wide situational awareness and reveal valuable business insights.<u></u><u></u></p><p>Through case studies and data visualizations, they will show you how to cut through the noise, link data and generate intelligence to help anticipate and evaluate emerging opportunities and potential threats.</p>]]></description>
      <pubDate>Wed, 04 May 2022 13:00:01 +0000</pubDate>
      <guid>https://discover.clarivate.com/power-of-Innovation-Intelligence?campaignname=DataStories_Innov_Insights_LeadGen_Webinar_May19_IPG_Global_2022&amp;campaignid=7014N0000029HwU&amp;utm_campaign=WaveDirIEEE&amp;utm_source=trade_publication&amp;utm_medium=paid</guid>
      <category>Analytics</category>
      <category>Big data</category>
      <category>Clarivate</category>
      <category>Intellectual property</category>
      <category>Type:webinar</category>
      <category>Visualization</category>
      <dc:creator>Clarivate</dc:creator>
      <media:content url="https://assets.rbl.ms/27150766/origin.png" medium="image" type="image/png" />
    </item>
    <item>
      <title>Clearpath Announces TurtleBot 4</title>
      <link>https://spectrum.ieee.org/turtlebot-4</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/two-roomba-like-robots-with-sensors-on-top-one-of-which-is-slightly-larger.jpg?id=29751997&width=1200&coordinates=0%2C40%2C0%2C40&height=800"/><br/><br/><p>
	Today, Clearpath Robotics is opening pre-orders for the newest, fanciest TurtleBot: the TurtleBot 4. Built on top of iRobot’s Create 3 in close partnership with Open Robotics, the TurtleBot 4 is “the next-generation of the world’s most popular open-source robotics platform for education and research, offering superior computing power, more payload capacity, improved sensors, and a world class user experience at an affordable price.” Couldn’t have said it better myself, <a href="https://spectrum.ieee.org/tag/TurtleBot" target="_blank">no matter how many times I've tried</a>.</p><hr/><p>TurtleBot 4’s big differentiator is that it’s designed to showcase ROS 2, the powerful open source Robotic Operating System that is working hard to successfully transition from robotics research into an all-purpose framework that can safely and reliably power commercial robots as well. This is the first version of the TurtleBot to run ROS 2 from the ground up (including the Create 3 base), and offers an opportunity for anyone from precious middle schooler on up to learn ROS 2 in a safe and well supported way, on real hardware that is affordable(ish).<br/></p><p><br/></p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Photo of two versions of the TurtleBot 4 robot" class="rm-shortcode" data-rm-shortcode-id="ca08aa9685fbcbb8367138dc6d34a007" data-rm-shortcode-name="rebelmouse-image" id="33c02" loading="lazy" src="https://spectrum.ieee.org/media-library/photo-of-two-versions-of-the-turtlebot-4-robot.jpg?id=29742037&width=980"/>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Clearpath Robotics</small></p><p>
	There will be two versions of the TurtleBot 4 available for pre-order from Clearpath, starting today. Both versions use the iRobot Create 3 development platform (<a href="https://spectrum.ieee.org/irobot-create-3" target="_blank">read more about that here</a>) as a mobility base, with the same power and charging system including a base station. Both also include a 2D RPLIDAR-A1 sensor with a 0.15m to 12m range. Compute comes in the form of a Raspberry Pi 4B running Ubuntu 20.04 with ROS 2 already installed.
</p><p>
	From there, the TurtleBot 4 Standard splits off from the TurtleBot 4 Lite. The Lite version misses out on some additional options for user accessible power, as well as useful interfaces including extra LEDs, some physical buttons, and a small OLED display that by default shows the robot’s IP address (or whatever else you want). This is especially neat because it makes it easy to fire the robot up and launch a demo behavior without requiring an external computer. The other big difference is in the sensor: the Lite includes an 
	<a href="https://shop.luxonis.com/products/oak-d-lite-1" rel="noopener noreferrer" target="_blank">OAK-D-Lite</a> camera and stereo depth sensor, while the TurtleBot 4 Standard comes with a more capable <a href="https://shop.luxonis.com/products/oak-d-pro" rel="noopener noreferrer" target="_blank">OAK-D-Pro</a>.
</p><p>The cost of the TurtleBot 4 Lite is USD $1,195, while the TurtleBot 4 Standard is USD $1,850. Pre-orders will be available starting today through Clearpath distributors in North America, Europe, and Asia, and shipping will begin in July. This is certainly a premium over what you'd pay for all of the parts individually, and you can certainly build yourself a TurtleBot 4 mostly from scratch if you want to. But unless you have a specific interest in that process, there's a lot of value in getting a robot that is ready to go right out of the box.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Technical specifications sheet for Turtlebot 4 and Turtlebot 4 Lite" class="rm-shortcode" data-rm-shortcode-id="b5ee86afbccbab0933e08d4206cabfd2" data-rm-shortcode-name="rebelmouse-image" id="dd5ca" loading="lazy" src="https://spectrum.ieee.org/media-library/technical-specifications-sheet-for-turtlebot-4-and-turtlebot-4-lite.jpg?id=29739525&width=980"/>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Clearpath Robotics</small></p><p>
	Using the Create 3 as a base gives the TurtleBot 4 both the ruggedness of a Roomba and a bunch of useful integrated sensors—the same ones that Roombas use to reliably navigate your house and not fall down your stairs. The Create 3’s battery gives the TurtleBot 4 an impressive minimum battery life of 2.5 hours, and all of the parts are easy to fix or replace since you’ve got access to iRobot’s supply chain. Top speed is nearly half a meter per second, or slightly slower if you don’t disable the cliff sensors.
</p><p>
	If any of this doesn’t satisfy your needs, part of the point of the TurtleBot platform is that it’s super easy to expand, as long as you know what you’re doing (or are willing to learn). Power and communications ports are easy to access, and the TurtleBot 4 has lots of easy ways to mount up to 9 kilograms of hardware.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Turtlebot 4 robot on a lab bench next to a laptop computer" class="rm-shortcode" data-rm-shortcode-id="dac63fc543a45c0e4a43da169b8b6a9c" data-rm-shortcode-name="rebelmouse-image" id="9911e" loading="lazy" src="https://spectrum.ieee.org/media-library/turtlebot-4-robot-on-a-lab-bench-next-to-a-laptop-computer.jpg?id=29742042&width=980"/>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Clearpath Robotics</small></p><p>
	Historically, TurtleBots have been very popular in educational contexts due to their affordable versatility and (at least in part) to the community support behind them and behind ROS more broadly. They’re great platforms for getting started with ROS (now ROS 2) on your own, or with other students. No matter what problem you run into, odds are someone has already had the same one and solved it and you can find it on the <a href="https://answers.ros.org/questions/" target="_blank">ROS Answers</a> message board. But hopefully you won’t need to do that from the start: TurtleBot 4 will ship fully assembled, with all necessary software pre-installed and configured, and you’ll have detailed user documentation plus demo code and a bunch of tutorials. There’s also a Ignition Gazebo simulation model to play with, which you can access without even buying a TurtleBot 4 at all, as it's completely free. This should be especially useful for classrooms, where multiple students could work in simulation before trying things out on the real robot.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Close-up of Turtlebot 4 robot" class="rm-shortcode" data-rm-shortcode-id="82708cdc87debc7cbe6c4d1b05416745" data-rm-shortcode-name="rebelmouse-image" id="12168" loading="lazy" src="https://spectrum.ieee.org/media-library/close-up-of-turtlebot-4-robot.jpg?id=29742066&width=980"/>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Clearpath Robotics</small></p><p>
	To get more details on the TurtleBot 4, we talked with:</p><ul>
<li>Bryan Webb, President of Clearpath Robotics</li>
<li>Steve Shamlian, Principal Software Engineer at iRobot</li>
<li>Katherine Scott, Developer Advocate at Open Robotics</li>
<li>Tully Foote, ROS Platform Manager at Open Robotics</li>
</ul><p>
<strong><em>IEEE Spectrum</em>: Why is now the right time for a TurtleBot 4?</strong>
</p><p>
<strong>Katherine Scott, Open Robotics:</strong> I think there was always a rough idea that we wanted to get a new TurtleBot out around <a href="https://docs.ros.org/en/foxy/index.html" target="_blank">Foxy</a>. Foxy is fairly well baked, and we wanted to give people a way to learn ROS 2, and especially for new people coming into the community, they’d have a way to start with ROS 2—that was a big motivator.
</p><p>
<strong>Tully Foote, OSRF:</strong> It was the beginning of 2021, and basically, we went to Clearpath and started talking about our vision for the TurtleBot 4, and how we wanted to bring it back more along the lines of the TurtleBot 2. We’d found that while the TurtleBot 3 has been awesome as a smaller and cheaper platform, the TurtleBot 2 had hit a sweet spot in size where it could carry things and go over things and be more of a ground robot as opposed to a desk robot. We had some knowledge of what was going on at iRobot with the Create 3, which runs ROS 2, so with that we’re building a ROS 2 robot on top of a ROS 2 base.
</p><p class="pull-quote">“Because it’s got the Raspberry Pi on it, it’s extensible. ... Certainly if you’re creative enough, I could picture taking this robot all the way through at least their masters, and then possibly starting a Ph.D with it.”<br/>—Bryan Webb, Clearpath Robotics </p><p>
<strong>Bryan Webb, Clearpath:</strong> We thought that the primary ingredients for TurtleBot had really progressed over the last few years, so we could offer a much better development platform than was currently available, and support the community with the latest tools. So we were chatting about it, and it just seemed like there was a lot more that could be done to offer a higher capability robot in that entry level space.
</p><p>
<strong>As iRobot was thinking about making a Create 3, at what point did you decide that it could or should be part of the TurtleBot 4?</strong>
</p><p>
<strong>Steve Shamlian, iRobot: </strong>We’re all roboticists here at iRobot. We have a lot of love for the TurtleBot. Especially after seeing how the original Create drove the adoption of ROS—when we saw that ROS 2 was in a place where it needed a TurtleBot, we were really excited to try to help. We really want to help make more makers and more hackers, that’s what this is about.
</p><p>
<strong>How customized is the Create 3 for the TurtleBot 4 platform?</strong>
</p><p>
<strong>Steve Shamlian, iRobot: </strong>The Create 3 is an iRobot product that we’re very proud of. We were going to do it whether or not it was going to be a part of the TurtleBot 4. The timing worked out, and I feel very happy that it did. And we definitely talked about things that would be important for TurtleBot, and whether there were design affordances that we could make, but honestly that didn’t change the design very much from what we were going to do versus the things that were requested for the TurtleBot. I think we know the community well enough that we had a good idea of what we thought they would like, so it felt really good to see those things match up so well with what was needed for the TurtleBot 4.
</p><p>
<strong>One thing that I always appreciated about the TurtleBot 2 was that it came with a netbook on it that made programming and debugging really easy. That’s something I could see myself missing on the TurtleBot 4.</strong>
</p><p>
<strong>Bryan Webb, Clearpath: </strong>Not bundling the TurtleBot 4 with a netbook is partially reflective of the maturity of ROS, but that may be secondary to the supply chain constraints that we’re living with these days. Netbooks are not really available in the way they once were, and even back when I was intimately involved with the TurtleBot 2, it was always a struggle to find netbooks of the quantity that we needed. That was a big challenge in maintaining the product. So, taking that into consideration, coupled with the amount that ROS has matured, we thought that a good compromise was to make it really easy to hook up to a desktop.
</p><p>
<strong>Katherine Scott, Open Robotics: </strong>When the TurtleBot 2 was built, most single-board computers were fairly nascent. We put a laptop on there because that’s what was powerful enough to run the robot. One big thing for me was to at least get some minimum viable interface on the TurtleBot 4—a screen and some buttons so that you can at least see the IP right there and SSH into the robot within a minute of turning it on. We’ll be focusing a lot on the user experience here, and making it easy to use.
</p><p class="pull-quote">“We’re really looking to have something that offers a lot to novice, intermediate, and expert users of ROS.”<br/>—Bryan Webb, Clearpath Robotics</p><p>
<strong>How easy will it be to get started with TurtleBot 4, especially for beginners?</strong>
</p><p>
<strong>Bryan Webb, Clearpath:</strong> We’re going to have at least one formal educational course based around the TurtleBot 4. At this point, there’s going to be at least one, and we have eyes towards other opportunities to extend that.
</p><p>
<strong>Katherine Scott, Open Robotics: </strong>We've had a lot of discussions with academics and other people along the way, trying to figure out what's going to work—you know, do we have to do courseware, or do we just provide the content, and what’s it going to look like?
</p><p>
	With TurtleBot 4, we leaned into the simulation side of it a little bit more than we usually would. In a classroom setting, the feedback that we get a lot is that robots are really exciting, but they’re expensive. Classroom robots have always been expensive. So if we can do everything with simulation and then every classroom has two or three robots, I think it’s going to be a better way to do things going forward.
</p><p>
<strong>Tully Foote, OSRF:</strong> And part of this is also we're going to be working hard to put together courseware and materials to be able to teach in the classroom, for a fully integrated experience. We’re hoping to have someone from academia writing real content for this, rather than asking a silicon valley engineer to do it. We want to get someone who knows what they’re talking about. The scope will be an introduction to robotics, so it may be starting not far beyond turning your computer on, but the goal will be to get to a college-ish level. And once we get a body of work there, we’d love to push it down to make it more accessible to middle and high school students, and also add more advanced things for graduate level.</p><p>
<strong>How far can TurtleBot 4 take you in robotics?</strong>
</p><p>
<strong>Bryan Webb, Clearpath: </strong>There’s a lot of potential with the TurtleBot 4. Because it’s got the Raspberry Pi on it, it’s extensible. You can put on new sensors for different kinds of research, and build on top of it both physically and through software development. Certainly if you’re creative enough, I could picture taking this robot all the way through at least their masters, and then possibly starting a Ph.D with it.
</p><p>
<strong>Tully Foote, OSRF:</strong> I’d like to think that the TurtleBot 4, as a platform, is capable enough to take you through grad school if you’re doing straight robotics. If you want to work on multi-robot coordination, it has all the basics. And you should be able to add an arm onto it, and other things like that. But it’s always going to be an entry level robot. If you want to do mobile manipulation, TurtleBot can get you started, but you’re going to want to upgrade to a bigger, stronger platform. It’s really that entry-level robot for before you specialize.
</p><p>
<strong>Katherine Scott, Open Robotics:</strong> It’s also a good platform for when you’re starting a company. It’s a good platform for getting halfway there, before you can get to where you’re going. As an abstract mobile base, you can build proof of concept ideas, and when you’re ready, move up. The thing I’m excited about, if we do things right, a year from now we’ll see people extending the TurtleBot 4 with new hardware and capabilities.</p>]]></description>
      <pubDate>Wed, 04 May 2022 13:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/turtlebot-4</guid>
      <category>Turtlebot</category>
      <category>Turtlebot 4</category>
      <category>Irobot</category>
      <category>Clearpath robotics</category>
      <category>Robotics</category>
      <dc:creator>Evan Ackerman</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/two-roomba-like-robots-with-sensors-on-top-one-of-which-is-slightly-larger.jpg?id=29751997&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Take the Lead on Satellite Design Using Digital Engineering</title>
      <link>https://connectlp.keysight.com/Satellite-Digital-Engineering?elqCampaignId=20968&amp;cmpid=ASC-2104798&amp;utm_source=ADSC&amp;utm_medium=ASC&amp;utm_campaign=301</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/image.png?id=27151193&width=980"/><br/><br/><p>Win the race to design and deploy satellite technologies and systems. Learn how new digital engineering techniques can accelerate development and reduce your risk and costs. <a href="https://connectlp.keysight.com/Satellite-Digital-Engineering?elqCampaignId=20968&cmpid=ASC-2104798&utm_source=ADSC&utm_medium=ASC&utm_campaign=301" target="_blank">Download this free whitepaper now!</a></p><p><span></span>Our white paper covers:</p><ul><li>Software-based digital twin models to reduce costly satellite system re-design</li><li>Ways to improve models throughout the product lifecycle, increase confidence, and reduce risks</li></ul>]]></description>
      <pubDate>Tue, 03 May 2022 18:22:00 +0000</pubDate>
      <guid>https://connectlp.keysight.com/Satellite-Digital-Engineering?elqCampaignId=20968&amp;cmpid=ASC-2104798&amp;utm_source=ADSC&amp;utm_medium=ASC&amp;utm_campaign=301</guid>
      <category>Keysight</category>
      <category>Satellites</category>
      <category>Software</category>
      <category>Type:whitepaper</category>
      <dc:creator>Keysight</dc:creator>
      <media:content url="https://assets.rbl.ms/27151193/origin.png" medium="image" type="image/png" />
    </item>
    <item>
      <title>Celebrating 25 Years of IEEE Women in Engineering</title>
      <link>https://spectrum.ieee.org/ieee-wie-25-year-anniversary</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-photo-of-a-group-of-woman-standing-on-a-stage.jpg?id=29753687&width=1200&coordinates=0%2C209%2C0%2C0&height=800"/><br/><br/><p><a href="https://wie.ieee.org/" rel="noopener noreferrer" target="_blank">IEEE Women in Engineering</a>, formed 25 years ago, now has more than 35,000 members and 1,000 affinity groups worldwide. WIE facilitates the recruitment and retention of women in technical disciplines around the world. It also works to inspire girls to pursue a career in engineering. Both women and men can join.</p>
<p>To mark its 25th anniversary, the group is planning competitions, panels, seminars, and other events this year. It also has established an award to honor men who actively advocate for diversity and inclusion in science, technology, engineering, and math fields.</p>
<p>The organization’s origins can be traced to the <a href="http://www.ieee-uffc.org/" rel="noopener noreferrer" target="_blank">IEEE Ultrasonics, Ferroelectrics, and Frequency Control Society</a>’s ad hoc committee on women, created in 1994. A year later, UFFC made a motion to the <a href="https://www.ieee.org/about/volunteers/tab.html" rel="noopener noreferrer" target="_blank">IEEE Technical Activities Board</a> to create a committee on women in engineering. TAB approved the motion that June, and a few months later, the IEEE Board of Directors elevated the group to one of its ad hoc committees. It reported directly to the Board and received funding to develop a formal program to increase the number of female members.</p>
<p>In November 1997 IEEE rolled out the Women in Engineering group. A dues-paying membership component was added in 1999.</p>
<p><strong>CELEBRATING STEADY GROWTH</strong></p><p>WIE’s greatest accomplishment is its continuous growth, thanks to enthusiastic members, <a href="https://cinziadavia.org/" rel="noopener noreferrer" target="_blank">Cinzia Da Vià</a> says. The IEEE senior member, who is a physics professor at the <a href="https://www.manchester.ac.uk/" rel="noopener noreferrer" target="_blank">University of Manchester</a>, England, is overseeing the anniversary celebrations. She says the events have been created to highlight the work of WIE members as well as affiliated affinity groups.</p>
<p>WIE kicked off the celebrations in December with a virtual panel that featured past WIE chairs including <a href="https://spectrum.ieee.org/lisa-lazareckasunta-ieees-women-in-engineering-chair-is-just-getting-started" target="_self">Lisa Lasareck-Asunta</a>, <a href="https://www.computer.org/profiles/ramalatha-marimuthu/" rel="noopener noreferrer" target="_blank">Ramalatha Marimuthu</a>, and <a href="https://spectrum.ieee.org/ieees-natural-disaster-relief-program-expanding-to-india-jamaica-and-puerto-rico" target="_self">Mary Ellen Randall</a>. They explained why they joined the group, and they shared their experiences as chair. The event is available <a href="https://bit.ly/31mbLKZ" rel="noopener noreferrer" target="_blank">on demand</a> via IEEE.tv.</p>
<p>On International Women’s Day, 8 March, a 12-hour virtual marathon showcased each IEEE region’s diversity and inclusion efforts.</p>
<p>IEEE WIE “is enormous, so we wanted to give our members the opportunity to meet each other and know what each region is doing,” Da Vià says. The session also is available<a href="https://ieeetv.ieee.org/event/ieee-wie-25th-anniversary-global-marathon" rel="noopener noreferrer" target="_blank"> on demand</a>.</p>
<p>During the yearlong<a href="https://wie.ieee.org/wie25seminarseries/" rel="noopener noreferrer" target="_blank"> Extraordinary Women Extraordinary Science Seminar Series</a>, each month two WIE members present their work. Presentations to date have covered entrepreneurship, technology for the benefit of humanity, and space exploration. The talks are available <a href="https://wie.ieee.org/wie25seminarseries/" rel="noopener noreferrer" target="_blank">on demand</a>. The next event is scheduled for 1 July. IEEE Senior Member <a href="https://www.katinamichael.com/about" rel="noopener noreferrer" target="_blank">Katina Michael</a> and Member <a href="https://au.linkedin.com/in/robaabbas" rel="noopener noreferrer" target="_blank">Roba Abbas</a> plan to make a presentation on the importance of interdisciplinary and transdisciplinary research. Michael and Abbas are professors at <a href="https://www.asu.edu/" rel="noopener noreferrer" target="_blank">Arizona State University</a>’s <a href="https://sfis.asu.edu/" rel="noopener noreferrer" target="_blank">School for the Future of Innovation in Society</a>.</p>
<p>Women’s careers often are interrupted by caretaking responsibilities, and the COVID-19 pandemic has made the situation worse due to shutdowns of day care centers and schools, Da Vià says. There has been an increase in the number of women who died by suicide during the pandemic, she says, as well as more domestic violence and sexual assaults. To help find solutions, WIE launched the <a href="https://wie.ieee.org/w_to_wwie25/" rel="noopener noreferrer" target="_blank">W-to-W Tech Ideas Dedicated to Women</a> competition. The contest sought technologies that could be used to help with child care, and to provide easier access to mental health services as well as protection against abuse.</p>
<p>Finalists receive a plaque and a ticket to attend this year’s<a href="https://spectrum.ieee.org/2022-ieee-wie-conference" target="_self"> IEEE WIE International Leadership Conference</a>, which is scheduled for 6 and 7 June. The winner gets to present his or her idea at the hybrid conference. Its in-person events are to take place at the <a href="https://www.visitsandiego.com/" rel="noopener noreferrer" target="_blank">San Diego Convention Center</a>.</p><p>Women working in STEM fields are often cheered on by extraordinary men, says <a href="https://spectrum.ieee.org/meet-the-first-latina-to-lead-ieee-women-in-engineering" target="_self">Jenifer Castillo</a>, chair of WIE. To recognize such men, the Behind a Successful Woman award has been established. Nominees will be featured on the WIE website and in the December issue of <a href="https://wie.ieee.org/newsletter-magazine/" rel="noopener noreferrer" target="_blank"><em>WIE Magazine</em></a>. Nominations closed in April.</p>
<p>Many WIE affinity groups are having their own celebrations. Learn more about what events are happening near you on the group’s<a href="https://wie.ieee.org/celebratewie25/" rel="noopener noreferrer" target="_blank"> website</a>.</p><p><strong>DIVERSITY AND INCLUSION PROGRAMS </strong></p><p>WIE has been working on several diversity and inclusion initiatives. The group recently <a href="https://spectrum.ieee.org/the-institute/ieee-member-news/ieee-women-in-engineering-leads-a-pledge-to-make-speaker-panels-more-gender-balanced" target="_self">pledged</a> to work toward gender-diversified panels at all IEEE meetings, conferences, and events, including its own.</p>
<p>Castillo says it’s important for conference attendees to feel represented by those on panels.</p><p>The group also is working to increase the number of female <a href="https://wie.ieee.org/senior-member/" rel="noopener noreferrer" target="_blank">IEEE senior members</a>. Senior member is the highest grade for which IEEE members may apply. Members may self-nominate or be nominated by a senior member. One proven way to boost the number of female senior members is by holding <a href="https://www.ieee.org/membership/senior/senior-member-elevation-toolkit.html" rel="noopener noreferrer" target="_blank">elevation drives</a> just for women.</p>
<p><strong>LOOKING AHEAD</strong></p><p>WIE is putting together its strategic plan for the next five years, Castillo says.</p>
<p>“From assessing the current mission, vision, and goals to evaluating the current products and services that represent the benefits we offer, WIE is all in for our members’ experience,” she says. “We want to celebrate this 25th anniversary by building up a great future.”</p>
<p>She says her hope is that 25 years from now, there will be no need for such initiatives.</p>
<p>“Hopefully,” she says, “companies and organizations will be naturally diverse and inclusive.”</p>]]></description>
      <pubDate>Tue, 03 May 2022 18:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/ieee-wie-25-year-anniversary</guid>
      <category>Ieee news</category>
      <category>Ieee wie</category>
      <category>Ieee women in engineering</category>
      <category>Ieee wie leadership conference</category>
      <dc:creator>Joanna Goodrich</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-photo-of-a-group-of-woman-standing-on-a-stage.jpg?id=29753687&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Did J.J. Thomson Discover the Electron?</title>
      <link>https://spectrum.ieee.org/discovery-of-the-electron</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/an-elongated-glass-vacuum-tube-sits-lengthwise-on-a-wooden-stand.jpg?id=29721938&width=1200&coordinates=138%2C0%2C138%2C0&height=800"/><br/><br/><p>
<strong>“We shall call</strong> such particles corpuscles,” announced the physicist J.J. Thomson, during a<a href="https://books.google.com/books?id=vBZbAAAAYAAJ&pg=PA104#v=onepage&q&f=false" rel="noopener noreferrer" target="_blank"> lecture at the Royal Institution</a> in London, on 30 April 1897. “The atoms of the ordinary elements are made up of corpuscles and holes, the holes being predominant,” he continued. Thomson described his experiments with cathode rays to verify the existence of these subatomic corpuscles. This model of the atom became known as the “plum pudding” model, so named for the popular English dessert. In Thomson’s analogy, negatively charged corpuscles were like raisins suspended in a positively charged cake, resulting in a neutral atom. The model also became known as the Thomson model, although its chief proponent was William Thomson (Lord Kelvin), not J.J. Thomson, who merely endorsed the idea.
</p><p>
	Corpuscles and pudding are not how we think about the structure of an atom today. Corpuscles are electrons, and the plum pudding model gave way to Ernest Rutherford’s nuclear model in 1911. Yet J.J. Thomson is often hailed as the discoverer of the electron based on that lecture 125 years ago.
</p><hr/><p>
	Of course, history is always more muddled than that. For this month’s column, I knew that I wanted to write about the 125th anniversary of the electron’s discovery, which for simplicity’s sake I pegged to Thomson’s lecture. The challenge then was to find a museum artifact that captured that discovery. 
	<a href="https://collection.sciencemuseumgroup.org.uk/objects/co31178/karl-ferdinand-brauns-braun-tube-1897-cathode-ray-tube" target="_blank">A Braun vacuum tube</a>, like the one pictured at top, seemed like a good choice, because its inventor, <a href="https://www.lindahall.org/karl-ferdinand-braun/" rel="noopener noreferrer" target="_blank">Karl Ferdinand Braun</a>, created it to study beams of electrons, and Thomson used a similar instrument for his experiments.
</p><p>
	But as I dug into the histories of Thomson and Braun, I learned that theirs were two parallel stories involving many of the same players and similar outcomes (both men won a Nobel Prize in Physics), but having little else in common. Many people, in fact, had a reasonable claim to aspects of the electron’s discovery. The more I researched, the more I contemplated what it meant to discover something.
</p><h2>Cathode rays, vacuum tubes, and the birth of atomic theory</h2><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="In a black-and-white image of the British physicist J.J. Thomson, he has a dark mustache and wire-rimmed glasses." class="rm-shortcode rm-resized-image" data-rm-shortcode-id="ad7f7ac7ce3c7c09a4bcba82a85acb93" data-rm-shortcode-name="rebelmouse-image" id="1bc04" loading="lazy" src="https://spectrum.ieee.org/media-library/in-a-black-and-white-image-of-the-british-physicist-j-j-thomson-he-has-a-dark-mustache-and-wire-rimmed-glasses.jpg?id=29721951&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">Exactly 125 years ago, the British physicist J.J. Thomson gave a lecture detailing his and others’ experiments with the energetic beams inside cathode-ray tubes.</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit..." style="max-width: 100%;">
	Universal Images Group/Getty Images
	</small>
</p><p>
	 As the 19th century was coming to a close, many prominent thinkers believed that all of the great discoveries in science had already been made. Electricity was being tamed, and theories of thermodynamics were coalescing to explain the workings of steam engines. Little did scientists know that atomic theory was about to upend science and change our fundamental understanding of matter. J.J. Thomson was a key player in establishing this new direction in physics.
</p><p>
	 In 1876, Thomson had received a scholarship to study at the University of Cambridge’s Trinity College, and four years later he graduated with a degree in mathematics. In 1884, he was appointed the Cavendish Professor of Experimental Physics and began his lifelong study of electromagnetism. Much of Thomson’s research was devoted to understanding the nature of cathode rays. We now know these rays are streams of electrons emerging from the cathode (or negative electrode) of a vacuum tube. But that knowledge was hard won, after decades of investigations by many players.
</p><p>
	 The purely scientific question—What are cathode rays?—was also wrapped up in national identity. Many German physicists believed that visible cathode rays resulted from an interaction with the ether—a colorless, weightless substance that enveloped all of space. Ether is part of what historians call the Classical Worldview, a 19th-century synthesis of physics that has its roots in Aristotle and Newton. French and British scientists, meanwhile, were beginning to argue that cathode rays were electrified subatomic particles. This did not fit neatly within the Classical Worldview, which held that everything was composed of immutable and indivisible atoms.
</p><p class="pull-quote">
	 In the “plum pudding” model of the atom, negatively charged corpuscles were like raisins suspended in a positively charged cake, resulting in a neutral atom.
</p><p>
	For his experiments, Thomson relied on a specialized vacuum tube known as a Crookes tube (more about Crookes and his tubes in a bit), in which he observed and photographed various phenomena, including the effect of a magnetic force on the electrical discharge at high pressure. He also compared experiments on the charges carried by cathode rays both within and outside of the tube.
</p><p>
	 Thomson’s foray into cathode rays was preceded by more than 200 years of demonstration and experimentation with low-vacuum globes and tubes. Early experimenters such as 
	<a href="https://www.lindahall.org/francis-hauksbee/" rel="noopener noreferrer" target="_blank">Francis Hauksbee</a> were simply trying to figure out what was happening inside the tubes and were mesmerized by the different colored lights they could produce. In the 1850s, things got more serious, when Julius Plücker, a physicist and mathematician at the University of Bonn, and his glassblower colleague Heinrich Geissler observed that the green phosphorescence on the glass of a high-vacuum tube was magnetic. When they placed a magnet near the cathode, the light spread out in a pattern similar to iron filings around a magnet.
</p><p>
	 Plücker’s student Johann Wilhelm Hittorf showed that an object placed in front of the cathode cast a shadow on the opposite wall of the tube. Hittorf’s “glow rays” started a line of inquiry about directionality, which Eugen Goldstein picked up on in the 1870s, in experiments that showed cathode rays could be focused using a concave cathode.
</p><p>
	 It seemed as if each new player made slight modifications to the tubes. Then came 
	<a href="https://www.lindahall.org/william-crookes/" rel="noopener noreferrer" target="_blank">William Crookes</a>. He designed a wide array of vacuum tubes for studying cathode rays and gave beautiful demonstrations with his tubes, popularizing their use in laboratories and making the public aware of the research. When Thomson began the investigations that led to his 30 April lecture, he used a Crookes tube.
</p><h2>How Karl Ferdinand Braun worked out the basics of the oscilloscope</h2><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="In a black-and-white image of the German physicist Karl Ferdinand Braun, he has a full beard and small wire-rimmed glasses." class="rm-shortcode rm-resized-image" data-rm-shortcode-id="d6d3777179ccd662926e87252e83b326" data-rm-shortcode-name="rebelmouse-image" id="1ebb0" loading="lazy" src="https://spectrum.ieee.org/media-library/in-a-black-and-white-image-of-the-german-physicist-karl-ferdinand-braun-he-has-a-full-beard-and-small-wire-rimmed-glasses.jpg?id=29722374&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">The German physicist Karl Ferdinand Braun invented a type of vacuum tube that became the basis of 20th-century CRTs, used in television sets and computer monitors.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit..." style="max-width: 100%;">Alamy</small>
</p><p>
	In the years leading up to Thomson’s lecture, Geissler tubes, Plücker tubes, Hittorf tubes, and Crookes tubes filled laboratories and lecture halls. Mostly they were used to show the colorful effects of the electric discharge of cathode rays on different phosphorescent surfaces, without any clear practical applications.
</p><p>
	Then 
	<a href="https://ethw.org/Wilhelm_Roentgen" rel="noopener noreferrer" target="_blank">Wilhelm Röntgen</a> noticed something unusual. Even though the Crookes tube he was using was encased in black cardboard, a phosphorescent screen across the room started glowing. This led to his 1895 announcement that he had discovered X-rays. The discovery set off a fresh new wave of cathode-ray experiments.
</p><p>
	 One scientist inspired by Röntgen’s work was 
	<a href="https://www.lindahall.org/karl-ferdinand-braun/" rel="noopener noreferrer" target="_blank">Karl Ferdinand Braun</a>. Braun had received his Ph.D. from the University of Berlin in 1872, studying the oscillations of strings and elastic rods, and he spent the next 20 years in various positions at the universities of Marburg, Karlsruhe, and Tübingen. At the time of Röntgen’s discovery, Braun was director of the Physical Institute at Strasbourg. According to historian George Shiers, in his 1974 article “<a href="https://www.jstor.org/stable/24950032?refreqid=excelsior%3Ab8cc6dcfb75ae4d114113907212814cb" rel="noopener noreferrer" target="_blank">Ferdinand Braun and the Cathode Ray Tube</a>,” for <em>Scientific American</em>, Braun differed from many Röntgen enthusiasts in that he was more interested in the source of the X-rays than in the applications of the radiation.</p><p>
	Braun sought a new type of instrument, one that could visually capture the oscillatory and transitory phenomena in electrical circuits. In short, he wanted to map alternating current, in what would turn out to be a precursor of the oscilloscope. He instructed his instrument maker, Franz Müller, to modify a Crookes tube by adding a restrictive diaphragm across the middle of it. The diaphragm focused the thin beam of cathode rays. A phosphor-coated piece of mica served as a viewing screen. A coil outside the tube deflected the cathode-ray beam at right angles to the magnetic field. Because the beam responded almost immediately to changes in voltage or current, it could be used to trace these patterns on the screen. Braun published a description of his tube, including a diagram, in 
	<em>Annalen der Physik </em>in February 1897, 10 weeks before Thomson’s lecture.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A page of scientific text in German with a simple line drawing of an early vacuum tube." class="rm-shortcode" data-rm-shortcode-id="03d8441fd87f2ee31b8747a7297c7622" data-rm-shortcode-name="rebelmouse-image" id="649f2" loading="lazy" src="https://spectrum.ieee.org/media-library/a-page-of-scientific-text-in-german-with-a-simple-line-drawing-of-an-early-vacuum-tube.jpg?id=29722385&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">In Karl Ferdinand Braun’s cathode-ray tube indicator, voltage was applied to the anode (A) and cathode (K), causing a negatively charged beam to be emitted from the cathode. A diaphragm (C) focused the beam, which then struck a phosphor-coated screen (D) at the opposite end.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">The Linda Hall Library of Science, Engineering & Technology</small>
</p><p>If Thomson knew about Braun’s work when he gave his 30 April lecture, he made no mention of it. Nor did Thomson choose to call his subatomic particles by a name that was already in use: the electron. In 1874, the Irish physicist <a href="https://en.wikipedia.org/wiki/George_Johnstone_Stoney" rel="noopener noreferrer" target="_blank">George Johnstone Stoney</a> proposed <em>electrine</em> for the unknown subatomic particle, later changing it to <em>electron</em> in 1891. Stoney also estimated the electron’s charge (which turned out to be very close to the modern value), and he was frustrated that <a href="https://www.biodiversitylibrary.org/item/122066#page/432/mode/2up" rel="noopener noreferrer" target="_blank">Hermann von Helmholtz kept getting credit</a> for that discovery.</p><p>Thomson otherwise did a good job of tracing the history of experiments on cathode rays and naming scientists and instrument makers who had provided the foundation for his work. (The <a href="https://books.google.com/books?id=vBZbAAAAYAAJ&pg=PA104#v=onepage&q&f=false" rel="noopener noreferrer" target="_blank">text of Thomson’s lecture</a> was published in the 21 May 1897 issue of <em>The Electrician</em>.) Only in the final part of his lecture did he posit his corpuscle hypothesis and describe the experiments in which he measured the ratio of the corpuscles’ mass to their charge. But he did not conclude with a definitive statement on the discovery of the electron. Rather, he ended by simply noting that the ratio is of the same order as the value that Dutch physicist <a href="https://www.lindahall.org/pieter-zeeman/" rel="noopener noreferrer" target="_blank">Pieter Zeeman</a> deduced the previous year, in his experiments on the magnetic field of sodium light.</p><p>Zeeman discovered that when an element is burned in the presence of a strong magnetic field, spectral lines are split into regular patterns. Today we understand the “Zeeman effect” to be the result of electron spin, but the electron had not yet been discovered. However, Zeeman's supervisor Hendrik Lorentz had already theorized that atoms might consist of charged particles. Zeeman and Lorentz won a Nobel Prize in 1902 for this work.</p><h2>Different theories of discovery</h2><p>
	Who then discovered the electron? Braun’s invention and Thomson’s discovery both built on decades of work by numerous scientists and instrument makers, so it seems unfair to give credit to one individual. It’s true, though, that Braun never patented his invention, nor did he do much to promote it. By the end of 1897, he’d abandoned his cathode-ray research and moved on to wireless telegraphy, for which he shared a Nobel Prize in Physics with Guglielmo Marconi, in 1909. Braun’s CRTs didn’t see much action during his lifetime, but modified versions dominated television sets and computer monitors during the second half of the 20th century, and Braun is hailed as their original inventor.
</p><p>
	Meanwhile, Thomson doubled down on his corpuscle theory, winning his Nobel Prize in 1906. And, even though the plum pudding model he espoused fizzled after a few years, Thomson is the one recognized as the discoverer of the electron 125 years later.
</p><p>The question of discovery and who should get credit is much debated amongst historians, philosophers, scientists, and textbook writers, who often have different ideas on the matter, especially when there is a long path to the end result with many different players. In her book 
	<a href="http://www.amazon.co.uk/exec/obidos/ASIN/0748407200/qid=1125600918/sr=8-1/ref=sr_8_xs_ap_i1_xgl/202-2540451-5546262" rel="noopener noreferrer" target="_blank"><em>J.J. Thomson and the Discovery of the Electron</em></a>, the historian of mathematics and science <a href="https://uk.linkedin.com/in/isobel-falconer-a394b7a" target="_blank">Isobel Falconer</a> argues (quite persuasively) against the traditional nationalistic debate over the nature of cathode rays. She points out that Thomson didn’t even become interested in them until 1896, and even then, his corpuscles had little in common with what was being called an electron at the time. In his article “<a href="https://www.sciencedirect.com/science/article/abs/pii/S1355219896000196" target="_blank">Rethinking the ‘Discovery’ of the Electron</a>,” historian <a href="http://scholar.uoa.gr/tarabatz/home" target="_blank">Theodore Arabatzis</a> proposes a taxonomy of what it means to discover an unobservable entity. <a href="https://www.informationphilosopher.com/solutions/philosophers/hacking/" target="_blank">Philosopher Ian Hacking</a> suggests in his 1983 book, <a href="https://www.cambridge.org/core/books/representing-and-intervening/F6506B708BB5A8B6A5D884BDCF28E7B7" target="_blank"><em>Representing and Intervening</em></a>, that something has been discovered once a scientist finds a way to manipulate the entity. But maybe discovery should be counted from when something is demonstrated or published or named. Or perhaps the recognition of discovery should occur only retrospectively, once the modern concept of the entity’s various features has been established—in the case of the electron, that would be its mass, charge, spin, and particle-wave nature.<br/></p><p>
	I realize that bringing up these philosophical questions kills the joy of a narrative based on a single aha moment. It’s easier on our brains when histories of discovery have neat edges, with a finite cast of fascinating characters, perhaps some hardship and setbacks to overcome, and a rousing, definitive success at the end. That’s the Hollywood biopic version of discovery. It’s not wrong, necessarily, but the truth is messier, richer, and more tentative.
</p><p>
<em><em>Part of a </em><em><a href="https://spectrum.ieee.org/tag/Past+Forward" rel="noopener noreferrer" target="_self">continuing series</a></em><em> looking at photographs of historical artifacts that embrace the boundless potential of technology.</em></em></p><p><em><em></em><em>An abridged version of this article appears in the May 2022 print issue as “Birth of the Electron."</em></em>
</p>]]></description>
      <pubDate>Sat, 30 Apr 2022 19:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/discovery-of-the-electron</guid>
      <category>Atomic theory</category>
      <category>Cathode-ray tubes</category>
      <category>Discovery of the electron</category>
      <category>J.j. thomson</category>
      <category>Karl ferdinand braun</category>
      <category>Past forward</category>
      <category>Type:departments</category>
      <category>Vacuum tubes</category>
      <category>Electron discovery</category>
      <dc:creator>Allison Marsh</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/an-elongated-glass-vacuum-tube-sits-lengthwise-on-a-wooden-stand.jpg?id=29721938&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>The X-Ray Tech That Reveals Chip Designs</title>
      <link>https://spectrum.ieee.org/chip-x-ray</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/overlapping-circles-on-a-yellow-background-show-a-computer-generated-surface-textured-in-seemingly-random-patterns-of-copper-extends-into-the-distance-at-right.jpg?id=29720947&width=1200&coordinates=352%2C0%2C353%2C0&height=800"/><br/><br/><p>
<strong>When you’re baking</strong> a cake, it’s hard to know when the inside is in the state you want it to be. The same is true—with much higher stakes—for microelectronic chips: How can engineers confirm that what’s inside has truly met the intent of the designers? How can a semiconductor design company tell whether its intellectual property was stolen? Much more worrisome, how can anyone be sure a kill switch or some other hardware trojan hasn’t been secretly inserted?
</p><p>
	Today, that probing is done by grinding away each of the chip’s many layers and inspecting them using an electron microscope. It’s slow going and, of course, destructive, making this approach hardly satisfactory for anybody.
</p><p>
	One of us (Levi) works with semiconductors and the other (Aeppli) with X-rays. So, after pondering this problem, we considered using X-rays to nondestructively image chips. You’d need to go beyond the resolution used in medical X-ray scanners. But it was clear to us that the needed resolution was possible. At that moment, what we’ve been calling the “chip scan” project was born.
</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="A computer-generated 3D image of grey crossing bars of decreasing size." class="rm-shortcode rm-resized-image" data-rm-shortcode-id="0d4e1e6ca2a4e4f9c87e592b5f8ce907" data-rm-shortcode-name="rebelmouse-image" id="567cd" loading="lazy" src="https://spectrum.ieee.org/media-library/a-computer-generated-3d-image-of-grey-crossing-bars-of-decreasing-size.jpg?id=29720974&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Our first technique, ptychographic X-ray computed tomography, was tested first on a portion of a 22-nanometer Intel processor constructing a detailed 3D image of the chip’s interconnects.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">SLS-USC Chip-Scan team</small>
</p><p>
	Several years later, we’ve made it possible to map the entire interconnect structure of even the most advanced and complex processors without destroying them. Right now, that process takes more than a day, but improvements over the next few years should enable the mapping of entire chips within hours.
</p><p>
	This technique—called ptychographic X-ray laminography—requires access to some of the world’s most powerful X-ray light sources. But most of these facilities are, conveniently, located close to where much of the advanced chip design happens. So as access to this technique expands, no flaw, failure, or fiendish trick will be able to hide.
</p><p>
<strong>After deciding to</strong> pursue this approach, our first order of business was to establish what state-of-the-art X-ray techniques could do. That was done at the Paul Scherrer Institute (PSI) in Switzerland, where one of us (Aeppli) works. PSI is home to the Swiss Light Source (SLS) synchrotron, one of the 15 brightest sources of coherent X-rays built so far.
</p><p>
	Coherent X-rays differ from what’s used in a medical or dental office in the same way that the highly collimated beam of light from a laser pointer differs from light emitted in all directions from an incandescent bulb. The SLS and similar facilities generate highly coherent beams of X-ray photons by first accelerating electrons almost to the speed of light. Then, magnetic fields deflect those electrons, inducing the production of the desired X-rays.
</p><p>
	To see what we could do with the SLS, our multidisciplinary team bought an Intel Pentium G3260 processor from a local store for about US $50 and removed the packaging to expose the silicon. (This CPU was manufactured using 22-nanometer CMOS FinFET technology).
</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="c7218d20eb4cd9f53fc9dcb976ce8aa9" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/h_gbDn5Te70?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
<small class="image-media media-caption" placeholder="Add Photo Caption...">A fly-though of the top layers of an Intel 22-nanometer processor reconstructed from X-ray scans.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">SLS-USC Chip-Scan Team</small></p><p>
	Like all such chips, the G3260’s transistors are made of silicon, but it’s the arrangement of metal interconnects that link them up to form circuits. In a modern processor, interconnects are built in more than 15 layers, which from above look like a map of a city’s street grid. The lower layers, closer to the silicon, have incredibly fine features, spaced just nanometers apart in today’s most advanced chips. As you ascend the interconnect layers, the features become sparser and bigger, until you reach the top, where electrical contact pads connect the chip to its package.
</p><p>
	We began our examination by cutting out a 10-micrometer-wide cylinder from the G3260. We had to take this destructive step because it greatly simplified things. Ten micrometers is less than half the penetration depth of the SLS’s photons, so with something this small we’d be able to detect enough photons passing through the pillar to determine what was inside.
</p><p>
	We placed the sample on a mechanical stage to rotate it about its cylindrical axis and then fired a coherent beam of X-rays through the side. As the sample rotated, we illuminated it with a pattern of overlapping 2-µm-wide spots.
</p><p>
	At each illuminated spot, the coherent X-rays diffracted as they passed through the chip’s tortuous tower of copper interconnects, projecting a pattern onto a detector, which was stored for subsequent processing. The recorded projections contained enough information about the material through which the X-rays traveled to determine the structure in three dimensions. This approach is called ptychographic X-ray computed tomography (PXCT). Ptychography is the computational process of producing an image of something from the interference pattern of light through it.
</p><div class="ieee-sidebar-medium">
<h3>Interference Basics</h3>
<p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A chart with blue lines curving downward." class="rm-shortcode" data-rm-shortcode-id="563a1e4a66a791bc25340b16cc7d6af5" data-rm-shortcode-name="rebelmouse-image" id="4cc5b" loading="lazy" src="https://spectrum.ieee.org/media-library/a-chart-with-blue-lines-curving-downward.jpg?id=29721001&width=980"/>
</p>
<p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A chart with red lines going downward and upward." class="rm-shortcode" data-rm-shortcode-id="d2f499b18af4a6376d0a2ef809c5af2a" data-rm-shortcode-name="rebelmouse-image" id="03f72" loading="lazy" src="https://spectrum.ieee.org/media-library/a-chart-with-red-lines-going-downward-and-upward.jpg?id=29721005&width=980"/>
</p>
<p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A chart with light and dark purple lines going downward and upward." class="rm-shortcode" data-rm-shortcode-id="14cbf4c7084aa8fca08849b28014308e" data-rm-shortcode-name="rebelmouse-image" id="14e11" loading="lazy" src="https://spectrum.ieee.org/media-library/a-chart-with-light-and-dark-purple-lines-going-downward-and-upward.jpg?id=29721006&width=980"/>
</p>
<p>
		Some fairly simple X-ray diffraction effects reveal enough information to derive nanoscale structures. Shining X-rays through a small slit [top left] projects the classic Fraunhofer pattern onto a detector [blue, top]. Replace the slit with two pointlike objects [center left], spaced closer together than the slit, and a different pattern is projected [red, center]. Placing the point objects within the slit combines the two interference patterns [dark purple, bottom]. Shifting the objects within the slit [bottom left] alters produce a new combination [light purple]. Several such interference patterns together reveal the position of objects in an X-ray beam’s path.
	</p>
</div><p>
<strong>The underlying principle</strong> behind PXCT is relatively simple, resembling the diffraction of light through slits. You might recall from your introductory physics class that if you shine a coherent beam of light through a slit onto a distant plane, the experiment produces what’s called a Fraunhofer diffraction pattern. This is a pattern of light and dark bands, or fringes, spaced proportionally to the ratio of the light’s wavelength divided by the width of the slit.
</p><p>
	If, instead of shining light through a slit, you shine it on a pair of closely spaced objects, ones so small that they are effectively points, you will get a different pattern. It doesn’t matter where in the beam the objects are. As long as they stay the same distance from each other, you can move them around and you’d get the same pattern.
</p><p>
	By themselves, neither of these phenomena will let you reconstruct the tangle of interconnects in a microchip. But if you combine them, you’ll start to see how it could work. Put the pair of objects within the slit. The resulting interference pattern is derived from the diffraction due to a combination of slit and object, revealing information about the width of the slit, the distance between the objects, and the relative position of the objects and the slit. If you move the two points slightly, the interference pattern shifts. And it’s that shift that allows you to calculate exactly where the objects are within the slit.
</p><p>
	Any real sample can be treated as a set of pointlike objects, which give rise to complex X-ray scattering patterns. Such patterns can be used to infer how those pointlike objects are arranged in two dimensions. And the principle can be used to map things out in three dimensions by rotating the sample within the beam, a process called tomographic reconstruction.
</p><p>
	You need to make sure you’re set up to collect enough data to map the structure at the required resolution. Resolution is determined by the X-ray wavelength, the size of the detector, and a few other parameters. For our initial measurements with the SLS, which used 0.21-nm-wavelength X-rays, the detector had to be placed about 7 meters from the sample to reach our target resolution of 13 nm.
</p><p>
	In March 2017, we demonstrated the use of PXCT for nondestructive imaging of integrated circuits by publishing some very pretty 3D images of copper interconnects in the Intel Pentium G3260 processor. Those images reveal the three-dimensional character and complexity of electrical interconnects in this CMOS integrated circuit. But they also captured interesting details such as the imperfections in the metal connections between the layers and the roughness between the copper and the silica dielectric around it.
</p><p>
	From this proof-of-principle demonstration alone, it was clear that the technique had potential in failure analysis, design validation, and quality control. So we used PXCT to probe similarly sized cylinders cut from chips built with other companies’ technologies. The details in the resulting 3D reconstructions were like fingerprints that were unique to the ICs and also revealed much about the manufacturing processes used to fabricate the chips.
</p><div class="ieee-sidebar-medium">
<h3>Ptychographic Laminography</h3>
<p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Illustration of a yellow projection beam and a orange circuit square along an axis." class="rm-shortcode" data-rm-shortcode-id="bce55f951178d4949cbd1b00ddccdf03" data-rm-shortcode-name="rebelmouse-image" id="d62df" loading="lazy" src="https://spectrum.ieee.org/media-library/illustration-of-a-yellow-projection-beam-and-a-orange-circuit-square-along-an-axis.jpg?id=29721024&width=980"/>
</p>
<p>
		In an edge-on position, this chip [orange] is too thick for X-rays to penetrate. But tilting the chip at an angle [see theta, center] makes the cross section thin enough. The mechanical stage the chip sits on [not shown] then rotates the sample within the X-ray beam around the z axis to project interference patterns onto a detector that can be used to reconstruct the chip’s interconnects.
	</p>
</div><p>
<strong>We were encouraged</strong> by our early success. But we knew we could do better, by building a new type of X-ray microscope and coming up with more effective ways to improve image reconstruction using chip design and manufacturing information. We called the new technique PyXL, shorthand for ptychographic X-ray laminography.
</p><p>
	The first thing to deal with was how to scan a whole 10-millimeter-wide chip when we had an X-ray penetration depth of only around 30 µm. We solved this problem by first tilting the chip at an angle relative to the beam. Next, we rotated the sample about the axis perpendicular to the plane of the chip. At the same time we also moved it sideways, raster fashion. This allowed us to scan all parts of the chip with the beam.
</p><p>
	At each moment in this process, the X-rays passing through the chip are scattered by the materials inside the IC, creating a diffraction pattern. As with PXCT, diffraction patterns from overlapping illumination spots contain redundant information about what the X-rays have passed through. Imaging algorithms then infer a structure that is the most consistent with all measured diffraction patterns. From these we can reconstruct the interior of the whole chip in 3D.
</p><p>
	Needless to say, there is plenty to worry about when developing a new kind of microscope. It must have a stable mechanical design, including precise motion stages and position measurement. And it must record in detail how the beam illuminates each spot on the chip and the ensuing diffraction patterns. Finding practical solutions to these and other issues required the efforts of a team of 14 engineers and physicists. The geometry of PyXL also required developing new algorithms to interpret the data collected. It was hard work, but by late 2018 we had successfully probed 16-nm ICs, publishing the results in October 2019.
</p><p class="pull-quote">Today’s cutting-edge processors can have interconnects as little as 30 nm apart, and our technique can, at least in principle, produce images of structures smaller than 2 nm.</p><p>
	In these experiments, we were able to use PyXL to peel away each layer of interconnects virtually to reveal the circuits they form. As an early test, we inserted a small flaw into the design file for the interconnect layer closest to the silicon. When we compared this version of the layer with the PyXL reconstruction of the chip, the flaw was immediately obvious.
</p><p>
<strong>In principle, a</strong> few days of work is all we’d need to use PyXL to obtain meaningful information about the integrity of an IC manufactured in even the most advanced facilities. Today’s cutting-edge processors can have interconnects just tens of nanometers apart, and our technique can, at least in principle, produce images of structures smaller than 2 nm.
</p><h3></h3><br/><img alt="A computer-generated surface textured in seemingly random patterns of copper extends into the distance at top." class="rm-shortcode" data-rm-shortcode-id="bd7bf4f5e3d066938a56bba44a7e9a62" data-rm-shortcode-name="rebelmouse-image" id="599cb" loading="lazy" src="https://spectrum.ieee.org/media-library/a-computer-generated-surface-textured-in-seemingly-random-patterns-of-copper-extends-into-the-distance-at-top.jpg?id=29731756&width=980"/><h3></h3><br/><img alt="Black-and-white version of a small section of the top image." class="rm-shortcode" data-rm-shortcode-id="a68f6e8f733939b685e7a1559de04081" data-rm-shortcode-name="rebelmouse-image" id="6ccc6" loading="lazy" src="https://spectrum.ieee.org/media-library/black-and-white-version-of-a-small-section-of-the-top-image.png?id=29720980&width=980"/><h3></h3><br/><img alt="Black-and-white version of a small section of the top image with red text reading \u201cERROR\u201d.." class="rm-shortcode" data-rm-shortcode-id="88d262b529da2b86ff724c6d88b6fe3a" data-rm-shortcode-name="rebelmouse-image" id="34d32" loading="lazy" src="https://spectrum.ieee.org/media-library/black-and-white-version-of-a-small-section-of-the-top-image-with-red-text-reading-u201cerror-u201d.png?id=29720981&width=980"/><h3></h3><br/><p class="caption">
	The new version of our X-ray technique, called ptychographic X-ray laminography, can uncover the interconnect structure of entire chips without damaging them, even down to the smallest structures [top]. Using that technique, we could easily discover a (deliberate) discrepancy between the design file and what was manufactured [bottom].
	<style class="photo-credit">
SLS-USC Chip-Scan team
	</style>
</p><p>
	But increased resolution does take longer. Although the hardware we’ve built has the capacity to completely scan an area up to 1.2 by 1.2 centimeters at the highest resolution, doing so would be impractical. Zooming in on an area of interest would be a better use of time. In our initial experiments, a low-resolution (500-nm) scan over a square portion of a chip that was 0.3 mm on a side took 30 hours to acquire. A high-resolution (19-nm) scan of a much smaller portion of the chip, just 40 μm wide, took 60 hours.
</p><p>
	The imaging rate is fundamentally limited by the X-ray flux available to us at SLS. But other facilities boast higher X-ray fluxes, and methods are in the works to boost X-ray source “brilliance”—a combination of the number of photons produced, the beam’s area, and how quickly it spreads. For example, the MAX IV Laboratory in Lund, Sweden, pioneered a way to boost its brilliance by two orders of magnitude. A further one or two orders of magnitude can be obtained by means of new X-ray optics. Combining these improvements should one day increase total flux by a factor of 10,000.
</p><p>
	With this higher flux, we should be able to achieve a resolution of 2 nm in less time than it now takes to obtain 19-nm resolution. Our system could also survey a one-square-centimeter integrated circuit—about the size of an Apple M1 processor—at 250-nm resolution in fewer than 30 hours.
</p><p>
	And there are other ways of boosting imaging speed and resolution, such as better stabilizing the probe beam and improving our algorithms to account for the design rules of ICs and the deformation that can result from too much X-ray exposure.
</p><p>
<strong>Although we can</strong> already tell a lot about an IC from just the layout of its interconnects, with further improvements we should be able to discover everything about it, including the materials it’s made of. For the 16-nm-technology node, that includes copper, aluminum, tungsten, and compounds called silicides. We might even be able to make local measurements of strain in the silicon lattice, which arises from the multilayer manufacturing processes needed to make cutting-edge devices.
</p><p>
	Identifying materials could become particularly important, now that copper-interconnect technology is approaching its limits. In contemporary CMOS circuits, copper interconnects are susceptible to electromigration, where current can kick copper atoms out of alignment and cause voids in the structure. To counter this, the interconnects are sheathed in a barrier material. But these sheaths can be so thick that they leave little room for the copper, making the interconnects too resistive. So alternative materials, such as cobalt and ruthenium, are being explored. Because the interconnects in question are so fine, we’ll need to reach sub-10-nm resolution to distinguish them.
</p><p>
	There’s reason to think we’ll get there. Applying PXCT and PyXL to the “connectome” of both hardware and wetware (brains) is one of the key arguments researchers around the world have made to support the construction of new and upgraded X-ray sources. In the meantime, work continues in our laboratories in California and Switzerland to develop better hardware and software. So someday soon, if you’re suspicious of your new CPU or curious about a competitor’s, you could make a fly-through tour through its inner workings to make sure everything is really in its proper place. 
	<span class="ieee-end-mark"></span>
</p><p><em>The SLS-USC Chip-Scan Team includes Mirko Holler, Michal Odstrcil, Manuel Guizar-Sicairos, Maxime Lebugle, Elisabeth Müller, Simone Finizio, Gemma Tinti, Christian David, Joshua Zusman, Walter Unglaub, Oliver Bunk, Jörg Raabe, A. F. J. Levi, and Gabriel Aeppli.</em></p><p>
<em>This article appears in the May 2022 print issue as “The Naked Chip.”</em>
</p>]]></description>
      <pubDate>Sat, 30 Apr 2022 15:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/chip-x-ray</guid>
      <category>Chip inspection</category>
      <category>Ic design</category>
      <category>Intellectual property</category>
      <category>Reverse engineering</category>
      <category>Security</category>
      <category>Trade secrets</category>
      <category>X-rays</category>
      <category>Semiconductors</category>
      <dc:creator>Anthony F.J. Levi</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/overlapping-circles-on-a-yellow-background-show-a-computer-generated-surface-textured-in-seemingly-random-patterns-of-copper-extends-into-the-distance-at-right.jpg?id=29720947&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Video Friday: Penguins and Huskies</title>
      <link>https://spectrum.ieee.org/video-friday-penguins-and-huskies</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/three-emperor-penguins-stand-in-front-of-a-small-yellow-wheeled-robot-in-a-snowy-landscape.jpg?id=29739614&width=1200&coordinates=148%2C0%2C148%2C0&height=800"/><br/><br/><p><span style="background-color: initial;">Video Friday is your weekly selection of awesome robotics videos, collected by your friends at <em>IEEE Spectrum</em> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please </span><a href="mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday">send us your events</a><span style="background-color: initial;"> for inclusion.</span><br/></p><h5><a href="https://www.icra2022.org/">ICRA 2022</a>: 23–27 May 2022, PHILADELPHIA</h5><h5><a href="https://attend.ieee.org/arso-2022/">IEEE ARSO 2022</a>: 28–30 May 2022, LONG BEACH, CALIF.</h5><h5><a href="https://roboticsconference.org/">RSS 2022</a>: 21–1 June 2022, NEW YORK CITY</h5><h5><a href="https://www.eu-robotics.net/robotics_forum/">ERF 2022</a>: 28–30 June 2022, ROTTERDAM, NETHERLANDS</h5><h5><a href="https://2022.robocup.org/">RoboCup 2022</a>: 11–17 July 2022, BANGKOK</h5><h5><a href="http://www.case2022.org/">IEEE CASE 2022</a>: 20–24 August 2022, MEXICO CITY</h5><h5><a href="https://clawar.org/clawar2022/">CLAWAR 2022</a>: 12–14 September 2022, AZORES, PORTUGAL</h5><p>Enjoy today’s videos!</p><hr/><div style="page-break-after: always"><span style="display:none"> </span></div><p>I’m not sure it’s geographically appropriate for a Husky robot to be this close to penguins in Antarctica, but on the other hand, who cares, because I am all in for robots and penguins.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="020e8751410299330e10e6b3fbcd7763" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/tQXfe7ggfLc?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><blockquote><em>The project consists of a hybrid (autonomous and remote-controlled) Husky UGV-based robot named ECHO that carries a variety of sensors including a camera and a radio-frequency-identification (RFID) antenna to read RFID tags from chipped penguins (the kind of chips that are also used to chip dogs and cats). With the RFID scanner, ECHO will scan penguins to assess their breeding status and survival success. Overall, the robot will be able to track individual penguins throughout their lifetimes, allowing researchers to gather data for behavioral and population dynamics research.</em></blockquote><p>[ <a href="https://clearpathrobotics.com/blog/2022/04/research-team-advances-penguin-conservation-research-with-robotics-in-antarctica/">Clearpath</a> ]</p><div class="horizontal-rule"></div><p>Snap has launched a little camera drone called Pixy. It’s nothing special, but that’s fine: It looks to be small, safe, and quite easy to use. And I really appreciate that this video seems to show actual footage from the drone, which is not fantastic, but totally workable.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="f5a73a3b0af3629fcfae3d82110a3e29" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/cqIsDo-f670?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>Two hundred fifty U.S. dollars seems a bit steep, but perhaps the safe form factor and ease of use could make it worthwhile.</p><p>[ <a href="https://pixy.com/">Pixy</a> ]</p><div class="horizontal-rule"></div><p>This is pretty awesome—it’s a RoboCup standard platform event where the robots are operating fully autonomously. Watch right after kickoff as the robot in the black jersey (closest to the ball) books it off-screen to the left. As it turns out, she (her name is Sarah) went deep into the opponent’s half, where she camped out by the goal, in a perfect position to receive a brilliant pass.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="dee5a68553592399a89f33f7528c82e5" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/xfhiw5o7BKs?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://www.b-human.de/">B-Human</a> ]</p><div class="horizontal-rule"></div><p>GITAI has already demonstrated its robotic arm inside of the International Space Station, and now it looks like the company is getting ready to work outside the station as well.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="9c24bb396d173cdde7f6fbe5fc84fe5c" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/w_ymtpo_EgE?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://gitai.tech/en/">GITAI</a> ]</p><div class="horizontal-rule"></div><p>Things that I want robots to do so that I don’t have to: waste-sorting.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="465f3bc89d7e3e2261fde8b6bcb60817" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/gjCpaUHHdMg?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>Weird to have them call the robot both “she” and “unmanned” in practically the same sentence.</p><p>[ <a href="https://zenrobotics.com/">ZenRobotics</a> ]</p><div class="horizontal-rule"></div><blockquote><em>At Agility, we make robots that are made for work. Our expertise is marrying design, software, and hardware to build robots that are capable of doing limitless tasks as part of a blended human-robot workforce.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="f33fa024331ec8900805724e73a280be" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/ZiDgBl35yMY?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>OK, I really want to know if Digit can use that step stool at the back of the trailer.</p><p>[ <a href="https://agilityrobotics.com/">Agility</a> ]</p><div class="horizontal-rule"></div><blockquote><em>Zimbabwe Flying Labs' Tawanda Chihambakwe shares how Zimbabwe Flying Labs started using drones for STEM programs and how drones impact conservation and agriculture.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="3915acfe2d31d23b0d910ef1c2aeed0f" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/51rd6VZWYNc?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://flyinglabs.org/Zimbabwe/">ZFL</a> ]</p><div class="horizontal-rule"></div><blockquote><em>Robotics has the potential to revolutionize our daily lives, enabling humans to do things never thought possible. SRI is at the forefront of developments that have and will continue to redefine manufacturing, medicine, safety, and so much more.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="03d8cc7772728e08067dba1cb57fd9f5" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/JSndN0ln3Do?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://www.sri.com/robotics-sensors-devices/">SRI</a> ]</p><div class="horizontal-rule"></div><p>A drone show from CollMot, which seems to use much larger drones than anyone else.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="b6220d2384edebba71798635cb850bb9" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/UMtZ2vifxmA?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://collmot.com/">CollMot</a> ]</p><div class="horizontal-rule"></div>]]></description>
      <pubDate>Fri, 29 Apr 2022 18:31:27 +0000</pubDate>
      <guid>https://spectrum.ieee.org/video-friday-penguins-and-huskies</guid>
      <category>Video friday</category>
      <category>Robotics</category>
      <dc:creator>Evan Ackerman</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/three-emperor-penguins-stand-in-front-of-a-small-yellow-wheeled-robot-in-a-snowy-landscape.jpg?id=29739614&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>A Quantum of Sensing—Atomic Scale Bolsters New Sensor Boom</title>
      <link>https://spectrum.ieee.org/quantum-sensors</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/two-men-peer-into-a-cabinet-containing-a-complicated-optics-setup.jpg?id=29741372&width=1200&coordinates=0%2C0%2C0%2C1&height=800"/><br/><br/><p>Imagine sensors that can detect the magnetic fields of thoughts, help lunar rovers detect oxygen in moon rocks, or listen to radio waves from dark matter. Just as quantum computers can theoretically find the answers to problems no classical computer could ever solve, so too can an emerging generation of quantum sensors lead to new levels of sensitivity, new kinds of applications, and new opportunities to advance a range of fields, technologies, and scientific pursuits.</p><p><a href="https://spectrum.ieee.org/europe-will-spend-1-billion-to-turn-quantum-physics-into-quantum-technology" target="_self">Quantum technology</a> relies on quantum effects that can arise because the universe can become a fuzzy place at its very smallest levels. For example, the quantum effect known as <a href="https://spectrum.ieee.org/longlasting-qubits" target="_self">superposition</a> allows atoms and other building blocks of the cosmos to essentially exist in two or more places at the same time, while another quantum effect known as <a href="https://spectrum.ieee.org/ibm-entanglement-forging" target="_self">entanglement</a> can link particles so they can influence each other instantly regardless of how far apart they are.</p><p>These <a href="https://spectrum.ieee.org/fault-tolerant-quantum-computing" target="_self">quantum effects are infamously fragile to outside interference</a>. However, whereas <a href="https://spectrum.ieee.org/topological-photonics-entanglement-protection" target="_self">quantum computers strive to overcome this weakness</a>, quantum sensors capitalize on this vulnerability to achieve extraordinary sensitivity to the slightest disturbances in the environment. Below are just a small sampling of the many kinds and varieties of quantum sensors being developed and deployed today. </p><p><strong>BRAIN SCANS:</strong> Electric currents within the brain generate magnetic fields that sensors can analyze to noninvasively scan brain activity. Now quantum sensors are enabling <a href="https://spectrum.ieee.org/a-new-wearable-brain-scanner" target="_self">a wearable helmet</a> to perform such <a href="https://spectrum.ieee.org/startups-new-type-of-magnetic-sensor-could-make-highperformance-brain-imaging-more-affordable-and-portable" target="_self">magnetoencephalography</a> (MEG) scans with unprecedented performance and cost.</p><p>Currently MEG scans are performed with sensors known as superconducting quantum interference devices (<a href="https://spectrum.ieee.org/how-the-ford-motor-co-invented-the-squid" target="_self">SQUIDs</a>). These require cooling with expensive liquid helium to -269 °C, making the scanners extremely large. In contrast, the new devices from startup <a href="https://www.cercamagnetics.com/" rel="noopener noreferrer" target="_blank">Cerca Magnetics</a> in Nottingham, England, are each about the size of a Lego brick.</p><p>Each device, called an optically pumped magnetometer (OPM), contains a laser that shines a beam through a cloud of rubidium atoms at a light detector. The beam can make the magnetic fields of the rubidium atoms all line up, rendering the cloud essentially transparent. Tiny magnetic fields, such as those from brain activity, can disturb these atoms, making them capable of absorbing light, which the light detector can sense, and the laser resets the cloud so it can continue responding to magnetic disturbances.</p><p>The fact these quantum sensors work at room temperature make them much less bulky than SQUIDs. This means they can get placed much closer to a person’s head, resulting in a signal at least two times better and theoretically up to five times better, for magnetic images with millimeter accuracy and millisecond resolution of surface areas of the brain, says <a href="https://www.nottingham.ac.uk/physics/people/matthew.brookes" rel="noopener noreferrer" target="_blank">Matthew Brookes</a>, chairman of Cerca and a researcher at the University of Nottingham.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A boy wears a blue helmet on his head, fitting with cables and sensors." class="rm-shortcode" data-rm-shortcode-id="37f9c6e5784bf4f4f529d378a725942c" data-rm-shortcode-name="rebelmouse-image" id="00e6b" loading="lazy" src="https://spectrum.ieee.org/media-library/a-boy-wears-a-blue-helmet-on-his-head-fitting-with-cables-and-sensors.jpg?id=29741379&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Cerca Magnetics wearable MEG helmets can safely be worn by even an active child, the company says.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Cerca Magnetics</small></p><p>The small, lightweight nature of the sensors also means they can get mounted in a wearable helmet to let people move freely during scanning, instead of having them remain still for very long periods as is currently the case. In addition, it can adapt to different head shapes and sizes, making it possible to scan not just adults but also children and babies. Moreover, “MEG with OPMs is in principle quite a lot cheaper than with SQUIDs,” Brookes says. “Even now, in early days with OPMs, a full MEG imaging system is still half the price of a SQUID system for similar performance.”</p><p>The Cerca scanner can help probe neurological disorders such as epilepsy, concussions, dementia, and schizophrenia, “helping shed light on many severe and debilitating conditions,” he says.</p><p>Future research can aim to push these sensors closer to their theoretical limits of sensitivity, permit more freedom of movement to perhaps let people walk, and add <a href="https://spectrum.ieee.org/virtual-reality-app-takes-over-your-social-life" target="_self">virtual reality</a> and <a href="https://spectrum.ieee.org/ai-failures" target="_self">machine learning</a> to boost what researchers can do with the scanners on the experimental and analytical fronts, Brookes says.</p><p><strong>GRAVITY MAPPING:</strong> A <a href="https://spectrum.ieee.org/quantum-sensors-gravity-birmingham" target="_self">new quantum sensor that maps the strength of Earth’s gravitational field</a> can help reveal features hidden underground.</p><p>Anything that has mass possesses a gravitational field. The strength of this field’s pull depends on a body’s mass. Since Earth’s mass is not spread out evenly, this means the planet’s gravity is stronger at some places than others.</p><p>For decades, <a href="https://spectrum.ieee.org/satellites-peer-into-indias" target="_self">gravity mapping</a> has uncovered details on large-scale geological activity, but employing such gravity cartography on the scale of meters is challenging, since long measuring times are needed to account for local noise, such as vibrations from nearby traffic.</p><p>The new quantum sensor uses clouds of rubidium atoms cooled to a few millionths of a degree Celsius above absolute zero. Laser pulses drive the atoms into states of superposition, with two versions of the atoms falling down slightly different trajectories, and these atoms are then recombined. Then, due to the <a href="https://theconversation.com/explainer-what-is-wave-particle-duality-7414" target="_blank">wave-particle duality</a>—the quantum phenomenon where particles can act like waves, and vice versa—these atoms quantum mechanically interfere with each other, with their peaks and troughs augmenting or suppressing each other. Analyzing the nature of this interference, a technique known as <a href="https://spectrum.ieee.org/us-energy-secretary-steven-chus-latest-experiment" target="_self">atom interferometry</a>, can reveal the extent of the slightly different gravitational pulls felt along their separate paths.</p><p>The sensor uses an hourglass design, with one cloud in each half of the device separated vertically by 1 meter. As such, the sensor can analyze the strength of Earth’s gravity at two different heights at the same location. By comparing the data from these clouds, the researchers can account for a variety of sources of noise. In experiments, the sensor could detect a 2-by-2-meter utility tunnel buried roughly 0.5 meters under a road surface between two multistory buildings in the city of Birmingham, in England.</p><p>Potential applications for the sensor include seeing hidden underground structures, detecting subterranean natural resources, discovering underground archaeological sites, and monitoring volcanic activity and groundwater flows.</p><p>The initial refrigerator-size sensor was about 300 kilograms and used about 750 watts. The scientists are now working to build a backpack-size sensor weighing about 20 kg that runs on batteries, says <a href="https://www.birmingham.ac.uk/staff/profiles/physics/holynski-michael.aspx" rel="noopener noreferrer" target="_blank">Michael Holynski</a>, an experimental physicist at the University of Birmingham, in England, and director of the startup Delta-G, which is commercializing the sensor. “The current target is to reach a commercial prototype of a next-generation sensor over the next two years,” he says. “The early markets are at around the £100 million mark for the sensors themselves. However, the data they will create is more valuable, and relevant to applications that are a few percent of GDP in the U.K.”</p><p><strong>DETECTING COVID:</strong> Another promising quantum sensor could lead to <a href="https://pubs.acs.org/doi/full/10.1021/acs.nanolett.1c02868" rel="noopener noreferrer" target="_blank">faster, cheaper, and more accurate tests for the SARS-CoV-2 virus</a> behind the global pandemic. It relies on microscopic artificial diamonds with defects within them, in which a carbon atom is replaced with a nitrogen atom and the adjacent carbon atom is missing. This defect in the crystals behaves like a tiny magnet whose alignment is very sensitive to magnetic fields, helping such “<a href="https://spectrum.ieee.org/singleatom-sensor-offers-new-view-of-the-nanoscale" target="_self">nitrogen-vacancy centers</a>” serve as sensors.</p><p>The new technique involves coating <a href="https://spectrum.ieee.org/nitrogen-vacancy-diamond-quantum-computer-accelerator-qubits-server-rack" target="_self">nitrogen-vacancy-center diamonds</a> roughly 25 nanometers wide with magnetic compounds that detach from the gems after they bond with the specific RNA sequence of the SARS-CoV-2 virus. When these diamonds are lit with green light, they will emit a red glow. The magnetic coating dims this glow; exposing the sensors to the virus can increase this glow.</p><p>The <a href="https://spectrum.ieee.org/testing-tests-which-covid19-tests-are-most-accurate" target="_self">current gold-standard test for the SARS-CoV-2</a> virus takes several hours to create enough copies of the virus’s genetic material to detect. Moreover, it cannot quantify the amount of virus present with high accuracy and might have false-negative rates of more than 25 percent. In contrast, computer simulations suggest that the new test can theoretically work in just a second, is sensitive enough to detect just a few hundred strands of the viral RNA, and could have false-negative rates below 1 percent.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Close-up view of a green lit tech on a small workbench" class="rm-shortcode" data-rm-shortcode-id="e10930251a78722e0a0d23d08ace0a3c" data-rm-shortcode-name="rebelmouse-image" id="7e4b4" loading="lazy" src="https://spectrum.ieee.org/media-library/close-up-view-of-a-green-lit-tech-on-a-small-workbench.jpg?id=29741381&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The above quantum sensor for the presence of the SARS-CoV-2 virus uses only low-cost materials. The devices could be scaled up, according to the researchers, to analyze a full batch of samples at once.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">MIT</small></p><p>The nano-diamonds and the other materials used in the test are cheap. In addition, this new method could be adapted to virtually any virus, including any new ones that may emerge, by adjusting the magnetic coating to match the target virus. They are currently synthesizing and testing the sensors to see how well they actually perform. “We hope to get promising results very soon,” says researcher <a href="https://changhaoli.mit.edu/" rel="noopener noreferrer" target="_blank">Changhao Li</a>, a quantum engineer at MIT.</p><p><strong>PROBING CELLS AND MOLECULES:</strong> Quantum diamond sensors can also find use in <a href="https://www.nature.com/articles/nature12373" rel="noopener noreferrer" target="_blank">thermometers inside cells</a>. Nitrogen-vacancy centers in diamonds are very sensitive to small temperature fluctuations. Physicist <a href="https://maurer-lab.com/" rel="noopener noreferrer" target="_blank">Peter Maurer</a> at the University of Chicago and his colleagues have injected nanometer-scale diamonds with such defects into living cells and examined how the crystals responded to laser beams in order to map temperatures within the cells to a few thousandths of a degree Celsius.</p><p>“You can imagine using such atomic-scale thermometers to investigate how temperature influences cell division, gene expression, and how molecules go in and out of cells, all major questions in medicine and biology,” says experimental physicist <a href="https://www.q-next.org/leadership/" rel="noopener noreferrer" target="_blank">David Awschalom</a> at Argonne National Laboratory and director of the Q-NEXT consortium.</p><p>In addition, Maurer and his colleagues are investigating using diamonds with nitrogen-vacancy centers to essentially perform MRI scans on molecules. “With quantum sensors, you can perform MRI to the level of single molecules to understand the relationship between their structure and function, which could radically improve our understanding of medicine,” Awschalom says.</p><p>The scientists developed <a href="https://www.pnas.org/doi/10.1073/pnas.2114186119" rel="noopener noreferrer" target="_blank">a new way</a> to tether single protein and DNA molecules onto the surface of diamonds that host nitrogen-vacancy centers. By analyzing the magnetic fields of these molecules, “you can understand the distances between atoms, the strengths of the interactions between them, where they are, and what keeps them together,” Awschalom says.</p><p><strong>QUANTUM ACCELEROMETER:</strong> The world now relies heavily on global navigation satellite systems such as <a href="https://spectrum.ieee.org/cheap-centimeterprecision-gps-for-cars-and-drones" target="_self">GPS</a>, but the satellite links that help enable such positioning, navigation, and timing do not work <a href="https://spectrum.ieee.org/new-indoor-navigation-technologies-work-where-gps-cant" target="_self">underground</a> or underwater and are vulnerable to <a href="https://spectrum.ieee.org/gps-jamming" target="_self">jamming</a>, <a href="https://spectrum.ieee.org/gps-spoofing" target="_self">spoofing</a>, and weather. Now a quantum sensor from Imperial College London and the Glasgow-based company M Squared can help ships navigate even when <a href="https://spectrum.ieee.org/an-alternative-to-gps" target="_self">GPS is denied</a>.</p><p>The quantum sensor is an atom interferometer like the gravity-mapping device. Analyzing how the phase of its atomic wave-packets shifts can reveal any acceleration or rotation they experienced, which the device can use to calculate the change in its position with time.</p><p>This quantum accelerometer can help serve as the foundation of an inertial navigation system that does not rely on any outside signals. Whereas temperature fluctuations and other factors lead the position estimates of conventional inertial navigation systems to drift within hours without an outside reference signal, M Squared’s device experiences negligible drift even after days, says <a href="https://www.imperial.ac.uk/collegedirectory/index.asp?PeopleID=437376" rel="noopener noreferrer" target="_blank">Joseph Cotter</a>, a research fellow at Imperial College London’s Center for Cold Matter.</p><p>“The early adopters of this emerging quantum technology are likely to be those interested in long-range navigation for underwater and surface vehicles,” Cotter says. “However, as the technology develops and becomes increasingly compact and lower cost, it will have wider benefits across the transportation industry through deployment on ships, trains, and aircraft.”</p><p>The researchers have field tests planned for their latest device this summer. Currently the quantum accelerometer “is about the size of two washing machines,” Cotter notes. “We’re working to get it even more compact.”</p><p><strong>QUANTUM SOFTWARE:</strong> Where most quantum-sensor companies focus on the hardware, Sydney-based startup <a href="https://q-ctrl.com/" rel="noopener noreferrer" target="_blank">Q-CTRL</a> focuses on software to enhance quantum technology. “When you take quantum sensors out of pristine lab environments out into the field, you often see a huge degrading in performance due to noise in the platforms,” says <a href="https://www.sydney.edu.au/science/about/our-people/academic-staff/michael-biercuk.html" rel="noopener noreferrer" target="_blank">Michael Biercuk</a>, CEO and founder of Q-CTRL. “Our focus is recapturing this performance with our quantum control software.”</p><p>For instance, many quantum sensors use lasers to scan cold atoms to detect any changes in the environment, but any movement in the device can lead the atoms to move out of the laser beams. “With our software, we can shape the pulse of light—its frequency, amplitude, phase—to make it more resilient against motion without any changes to the hardware itself,” Biercuk says.</p><p>Q-CTRL is partnering with the Sydney-based inertial navigation company <a href="https://q-ctrl.com/blog/quantum-technology-startup-q-ctrl-announces-global-r-and-d-partnership-with/" rel="noopener noreferrer" target="_blank">Advanced Navigation</a> to develop a rubidium-based atom-interferometer inertial-navigation system that can fit in less than 1 cubic meter and can work in GPS-denied areas. “We aim to have the first delivery of fieldable systems in 2023,” Biercuk says.</p><p>The company also aims to place atom interferometers aboard satellites to perform gravity mapping from space at 100 times less than the current cost, with launches of demonstration payloads into low Earth orbit expected in 2025. In addition, Q-CTRL is a member of Australia’s Seven Sisters space industry consortium designing <a href="https://q-ctrl.com/blog/australian-space-consortium-to-leverage-q-ctrls-quantum-based-technologies/" rel="noopener noreferrer" target="_blank">a new lunar rover</a> in support of NASA’s Artemis program, in which Q-CTRL is working on a rubidium-based quantum atomic magnetometer to magnetically analyze lunar rocks for oxygen.</p><p><strong>DARK MATTER, GIANT TELESCOPES:</strong> Quantum sensors may help probe matters far beyond Earth. For example, one of the greatest mysteries in the universe is the nature and identity of <a href="https://spectrum.ieee.org/deepest-underground-darkmatter-detector-to-start-up-in-china" target="_self">dark matter</a>, the invisible substance thought to make up five-sixths of all matter in the universe. Leading theoretical candidates for dark matter include particles known as <a href="https://spectrum.ieee.org/the-hunt-for-the-invisible-axion" target="_self">axions</a>, which in principle have an exceedingly low mass, at most just a trillionth the mass of the proton, making them difficult to detect.</p><p>Quantum physicist Kent Irwin at Stanford University and his colleagues are developing a “<a href="https://irwinlab.sites.stanford.edu/dark-matter-radio-dmradio" rel="noopener noreferrer" target="_blank">dark matter radio</a>” to detect axions and similar dark-matter candidates. A powerful magnet in the device will convert axions into radio waves, and <a href="https://irwinlab.sites.stanford.edu/rf-quantum-upconverters" rel="noopener noreferrer" target="_blank">quantum sensors</a> will aim to amplify and detect these extremely weak radio signals.</p><p>Since the frequencies the dark-matter radio will probe will include ones used for over-the-air broadcasting, the device will require shielding within a thin layer of superconducting niobium metal cooled in liquid helium. This should screen out artificial signals but will be easily penetrated by dark matter. “We’re planning a version of the dark-matter radio now that’s about a cubic meter in scale that we’d like to build in the next few years,” Irwin says.</p><p>Quantum physics may also help enable giant telescope arrays, Irwin says. Multiple telescopes widely separated in space can theoretically be combined to essentially form <a href="https://spectrum.ieee.org/earthsize-radio-telescope-opens-its-eye" target="_self">a single telescope thousands of kilometers wide</a>.</p><p>Forming such arrays with optical telescopes imaging visible light is difficult because of random fluctuations that inevitably crop up in any fiber optics linking these telescopes. However, entanglement can in principle allow <a href="https://spectrum.ieee.org/researchers-achieve-teleportation-over-134-km-and-entanglement-at-multiple-quantum-levels-with-twisted-photons" target="_self">quantum teleportation</a> of data across great distances.</p><p>Quantum optics researcher <a href="http://research.physics.illinois.edu/QI/Photonics/" rel="noopener noreferrer" target="_blank">Paul Kwiat</a> at the University of Illinois at Urbana–Champaign is currently investigating such “<a href="https://nsf.gov/awardsearch/showAward?AWD_ID=1936321&HistoricalAwards=false" rel="noopener noreferrer" target="_blank">quantum-enhanced telescopy</a>” with tabletop experiments. “It’s still very far off, but also a true holy grail, a moon shot that’s incredibly exciting,” Irwin says. A telescope array roughly the diameter of Earth may in principle image features the size of cities on nearby stars, he says.</p><p><strong>UNTOLD LIMITS:</strong> Recently scientists in Austria developed <a href="https://spectrum.ieee.org/programmable-quantum-sensing" target="_self">the first programmable quantum sensor</a>, a device capable of an unprecedented level of sensitivity operating near the fundamental limits imposed by the laws of quantum mechanics.</p><p>In this work, they programmed a quantum computer to find the best settings for itself with which to measure the states of its components. They found this programmable quantum sensor could optimize itself enough to approach the fundamental sensing limit up to a factor of about 1.45. (The closer a sensor approaches the ultimate sensing limit of 1, the better its performance.) They suggest that programmable quantum sensors could find use in devices such as atomic clocks and global positioning systems, as well as magnetic and inertial sensors.</p><p>All in all, “quantum sensors are emerging with exquisite precision to cover everything from single proteins all the way to questions in astronomy and cosmology,” Awschalom says.</p>]]></description>
      <pubDate>Fri, 29 Apr 2022 18:28:18 +0000</pubDate>
      <guid>https://spectrum.ieee.org/quantum-sensors</guid>
      <category>Sensing</category>
      <category>Magnetometer</category>
      <category>Gravity meter</category>
      <category>Squids</category>
      <category>Nitrogen-vacancy defects diamonds</category>
      <category>Quantum sensor</category>
      <dc:creator>Charles Q. Choi</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/two-men-peer-into-a-cabinet-containing-a-complicated-optics-setup.jpg?id=29741372&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Engineering the Future of Robotics</title>
      <link>https://spectrum.ieee.org/engineering-the-future-of-robotics</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/banner-ad-for-robotics-summit-expo.jpg?id=29742074&width=1200&coordinates=0%2C0%2C258%2C0&height=800"/><br/><br/><p><em>This sponsored article is brought to you by Robotics Summit & Expo.</em></p><p>The Robotics Summit & Expo is returning to Boston on May 10-11 at the Boston Convention and Exhibition Center!</p><h3></h3><br/><p>This international event will bring attendees content that will help them to design, development, manufacture, and deliver commercial-class robots.</p><h3></h3><br/><img class="rm-shortcode" data-rm-shortcode-id="953903257094895f79b0efa4e81433c0" data-rm-shortcode-name="rebelmouse-image" id="78d74" loading="lazy" src="https://spectrum.ieee.org/media-library/image.png?id=29742035&width=980"/><p>Register now and <a href="https://cvent.me/BKkkXW?RefId=IEEE" rel="noopener noreferrer" target="_blank">save 25% on your full conference pass by using code RSE25 at checkout</a>.</p><h3></h3><br/><p>This <a href="https://www.roboticssummit.com/" target="_blank">year's program has an exceptional lineup of speakers</a> covering trending topics in the industry such as interoperability, cloud technology, autonomous mobile robots, human scale automation, collaborative robots, motion control and so much more within the five dedicated tracks of the program.</p><p>Attendees will hear keynote presentations from industry thought leaders including: </p><ul><li>Brian Gerkey, Co-founder/CEO, Open Robotics: "Robotics Needs a Babelfish: The Skinny on Robot Interoperability" </li><li>Rick Faulk, CEO, Locus Robotics Robotics: "Automation in the Warehouse: Optimizing Productivity with Business Intelligence" </li><li>Jon Hirschtick, General Manager of Onshape and Atlas, PTC: "The Future of Product Design in a Connected World" </li><li>Melonee Wise, VP of Robotics Automation, Zebra Technologies: "Why the Cloud is a Force Multiplier for Robotics" </li><li>Greg Smith, President, Industrial Automation Group, Teradyne: "Collaborative Robotics: Resolving the Manufacturing Labor Crisis, Creating New Opportunities" </li><li>Kevin Blankespoor, VP & General Manager of Warehouse Robotics, Boston Dynamics: "The Next Generation of Mobile Robot Applications" </li></ul><h3></h3><br/><p>Not only does our event provide our attendees with educational sessions and access to some of the leading robotics companies around the nation but we also have complimentary events and unlimited networking opportunities for our attendees, including a reception on the expo floor, a career fair after the event, and a chance to walk Boston Dynamic's Spot quadruped.</p><p>Attendees will have access to two additional co-located events: The Healthcare Robotics Engineering Forum and DeviceTalks Boston.</p><p>For an additional bonus, you can <a href="https://cvent.me/BKkkXW?RefId=IEEE" target="_blank">save 25% on your full conference pass right now by using code RSE25 at checkout</a>!</p>]]></description>
      <pubDate>Fri, 29 Apr 2022 18:11:08 +0000</pubDate>
      <guid>https://spectrum.ieee.org/engineering-the-future-of-robotics</guid>
      <category>Robotics summit</category>
      <category>Robotics</category>
      <category>Conferences</category>
      <dc:creator>Robotics Summit &amp; Expo</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/banner-ad-for-robotics-summit-expo.jpg?id=29742074&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Cascading Domino Actuator Transports Objects With a Soliton Wave</title>
      <link>https://spectrum.ieee.org/soliton-dominoes-robotic-actuator</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-short-video-showing-an-array-of-dominos-transporting-a-sugar-cube.gif?id=29736560&width=1200&coordinates=46%2C0%2C47%2C0&height=800"/><br/><br/><p>Biological actuators can be fantastically complex. Networks of nerves can drive tiny muscles to make coordinated motions in ways that are very difficult for engineered systems to match. You can see how far robotics is from nature when you look at our best attempts to mimic things like snakes or millipedes or even intestines, all of which function based on lots of tiny muscles working together. Usually, the closest that robots can get to nature is by connecting a bunch of chonky discrete actuators together, which sometimes results in similar functionality but with far less efficiency and elegance.<br/></p><p>What these biological systems have in common is peristalsis—a series of wavelike coordinated muscle contractions that animals use to move themselves, and that animal insides use to move stuff around. Take just one solitary wave and you’ve got a soliton, which <a href="https://memory-alpha.fandom.com/wiki/Soliton_wave" rel="noopener noreferrer" target="_blank">should probably not be used to propel starships at faster-than-light speeds</a>. Solitons have been mimicked by robotic systems before, although by (again) relying on a complicated and expensive chain of individual actuators. </p><p>A recent paper from the <a href="https://pikul-lab.seas.upenn.edu/james-pikul/" rel="noopener noreferrer" target="_blank">Pikul group</a> at the University of Pennsylvania is exploring a much simpler approach to generating soliton waves: dominoes.</p><hr/><p>Falling dominoes exhibit soliton behavior as they topple in sequence, and you can propagate the wave with a single actuator at the first domino. Using some of those fancy “cheating” dominoes that are hinged at the bottom allows a second actuator to send the soliton right back again, resetting the system. “We wanted to realize a system that would be low power, simple, and could scale to smaller robots,” Penn’s James Pikul tells <em>I</em><em>EEE Spectrum</em>. “Yichao Shi, the first author, was the one who connected the elegant movement of dominoes as a path towards realizing a wavelike motion in a robotic actuator. As we played with the form factors of the dominoes, we were surprised by how complex the wave shape can be programmed, yet how simply the system is actuated.”</p><p>Programming a wave shape with dominoes involves adjusting their physical parameters, like domino height and how close each domino is to its neighbor. Depending on what you want your domino actuator to do, the wave shape is easily adjustable at fabrication time, and the researchers performed a series of practical(ish) experiments to see how effective their actuator could be. First, a sort of conveyor that can push objects in front of the soliton to move them along arbitrary paths:</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="9649eb8e274a51ded6f7720f7af2adf4" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/ipKpm4dDr98?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>In addition to moving objects with soliton waves, they’re also used in nature by animals for motion, so the researchers built themselves a soliton-powered mantis shrimp robot that uses cascading domino “fins” (that actually look kind of similar to the fins on the animal) combined with footlike things to provide anisotropic friction that results in forward propulsion:</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="3e738e11cd88f85afa9a50840a47f70d" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/eb-hzL69KZU?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>For comparison, here’s a picture of a real mantis shrimp; see if you can spot the soliton wave:</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A brightly colored shrimp walks along the seabed with a wave pattern showing in its many legs" class="rm-shortcode" data-rm-shortcode-id="df44a2f1f2ab3dfc76bb594aed05834a" data-rm-shortcode-name="rebelmouse-image" id="0e108" loading="lazy" src="https://spectrum.ieee.org/media-library/a-brightly-colored-shrimp-walks-along-the-seabed-with-a-wave-pattern-showing-in-its-many-legs.jpg?id=29734484&width=980"/>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Evan Ackerman</small></p><p>Cool, right?</p><p>For more details, we interviewed James Pikul and Yichao Shi via email.</p><p><strong>How does the peristaltic motion of the actuator you’ve developed </strong><strong>differ from biological models?</strong></p><p><strong>James H. Pikul & Yichao Shi: </strong>Since our synthetic muscles are less powerful and efficient than animal muscles, we didn’t see coordinated actuation of multiple individual synthetic muscles as an effective way to realize our goals. So, in our system, all the dominoes are linked and constrained by mechanical contact so that they create a soliton with a single signal that is sent to the boundary domino. The advantage of this approach, where only the boundaries have actuators, is that the system is easier to control and build than systems that more precisely mimic biology, and the mechanical constraints make the cascading dominoes easy to apply to different scales. However, the lower degrees of freedom also mean the dominoes have limits in how robust and agile they can be. It is difficult, for example, to push multiple objects through the cascading dominoes at once, or to push liquids. In addition, the dominoes are hard, and although they can be made flexible, the synthetic system is not as compliant as the natural systems.</p><p><strong>Can you elaborate on some of the advantages of a cascading domino actuator relative to other common robotic methods of moving objects, like belt conveyors or roller conveyors?</strong></p><p><strong>Pikul/Shi: </strong>Common automated conveyor systems usually require multiple actuators and separate segments to achieve nonlinear delivery paths. In comparison, our cascading dominoes can realize complex paths with both curvature and elevation changes while being actuated by a single actuator. The cascading dominoes can also be lightweight, flexible, and actuated by a variety of soft actuators (for example, shape memory alloys, inflatable actuators, bending actuators, etc.), whereas conveyor systems are operated by electric motors.</p><p><strong>Are there different tasks that the different wave shapes could be optimized for?</strong></p><p><strong>Pikul/Shi: </strong>In our paper, we show how the force, speed, and aspect ratio (or quality factor) of the wave can be adjusted with small changes in geometry. Having a wave that accelerates at the end of motion, instead of having a uniform wave speed, could be better for launching a projectile or jumping, whereas a uniform wave speed is better for maintaining a constant walking speed. In addition, the aspect ratio of the wave can be tuned for the type of object that is being moved or even for the type of terrain that the robot is moving across. All of these options allow for tunability, which is critical for many robotic designers.</p><p>Wave propagation can be used for a wide variety of applications beyond moving objects. One interesting application could be swimming robots, because many aquatic organisms, from flagella in bacteria to eel and tuna swimming, flex their bodies in a wave to displace water and move forward. Modifying the wave shape could also change the way energy or information is transferred through mechanical systems, which could be useful for mechanical metamaterials.</p><p><strong>What kinds of potential applications do you think this research could eventually be applied toward in a useful and practical way?</strong></p><p><strong>Pikul/Shi: </strong>As we have demonstrated in the paper, the cascading dominoes show effective movement of objects, even with multiple objects or through a complex path, and they can provide a simple tool for locomotion. We think this will be most useful in applications that benefit from low cost or disposable systems, such as swarm robots or single-use robots, or applications that cannot accommodate the complexity of many actuators, such as small-scale robots or mass-produced products, such as toys. In addition to wave propagation, our cascading dominoes provide an alternative to classic linkages or gears for force transmission.</p><p><strong>What are you working on next?</strong></p><p><strong>Pikul/Shi: </strong>Our ambition is to develop an “organ” for robots that allow them to eat objects in the environment and electrochemically convert the chemical energy of those objects into usable electrical power. Realizing these cascading dominoes is a first step in this direction because it allows us to transport food through an internal synthetic digestive system.</p><div class="horizontal-rule"></div><p>We did ask for some extra detail on that last bit, and we’re relieved to be able to report that the “objects” in question are metallic, so it might be a little less questionable to say that the robot is consuming local resources rather than eating in an organic way. This is based on recent research the Pikul group has done on <a href="https://penntoday.upenn.edu/news/even-without-brain-metal-eating-robots-can-search-food" target="_blank">metal-eating robots</a>, and not on <a href="https://spectrum.ieee.org/important-announcement-flesheating-robot-does-not-actually-eat-flesh" target="_self">this scary DARPA project</a>. Phew!</p><p>“<a href="https://ieeexplore.ieee.org/document/9712374" rel="noopener noreferrer" target="_blank">Harnessing Cascading Dominoes for Peristaltic Wave Motion</a>,” by Yichao Shi, Zhimin Jiang, and James H. Pikul from the University of Pennsylvania, is published in <em>IEEE Robotics and Automation Letters</em>.</p>]]></description>
      <pubDate>Thu, 28 Apr 2022 18:42:06 +0000</pubDate>
      <guid>https://spectrum.ieee.org/soliton-dominoes-robotic-actuator</guid>
      <category>Actuators</category>
      <category>Upenn</category>
      <category>Robotics</category>
      <category>Journal watch</category>
      <dc:creator>Evan Ackerman</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-short-video-showing-an-array-of-dominos-transporting-a-sugar-cube.gif?id=29736560&amp;width=980" medium="image" type="image/gif" />
    </item>
    <item>
      <title>New Courses on Technical Standards Used in Aerospace and Defense</title>
      <link>https://spectrum.ieee.org/aerospace-and-defense-standards</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/u-s-f-35-fighter-jet-flying-in-a-blue-sky.jpg?id=29763899&width=1200&coordinates=0%2C178%2C0%2C178&height=800"/><br/><br/><p>As the world tries to recover from the COVID-19 pandemic, the aerospace and defense industries are predicted to grow from US $416 billion to $551 billion by 2030, according to <a href="https://www.mordorintelligence.com/industry-reports/us-aerospace-and-defense-market" rel="noopener noreferrer" target="_blank">Mordor Intelligence</a>. The growth means increased development of aviation, space, and other systems that are crucial to the industries. The use of technical standards can ensure that critical software and systems components that run the systems are reliable and secure.</p><p>To help systems engineers, software engineers, and people working on back-end systems, <a href="https://www.ieee.org/education/index.html" rel="noopener noreferrer" target="_blank">IEEE Educational Activities</a> and the <a href="https://standards.ieee.org/" rel="noopener noreferrer" target="_blank">IEEE Standards Association</a> partnered to create a five-course program: <a href="https://iln.ieee.org/public/contentdetails.aspx?id=C61EB06931DD481E9FE74F2C17FD7D5E&utm_source=institute&utm_medium=articleapril2022&utm_campaign=aerospacedefensecp" rel="noopener noreferrer" target="_blank">IEEE Software and Systems Engineering Standards Used in Aerospace and Defense</a><em>. </em>The program offers an overview of <a href="https://standards.ieee.org/ieee/1012/4021/" rel="noopener noreferrer" target="_blank">IEEE Std. 1012</a> and the <a href="https://standards.ieee.org/ieee/29119-1/10779/" rel="noopener noreferrer" target="_blank">IEEE 29119</a> series of standards developed with the aerospace and defense industries.</p><p>The courses offered in the program are:</p><p><strong>Life Cycle Processes</strong></p><p>From this course, learners can better understand engineering concepts, be able to select and apply systems and software engineering standards, and employ special considerations for critical programs. Complex issues throughout the life cycle are covered. </p><p><strong>Implementing DevOps Best Practices </strong></p><p>This course discusses the required development and operations practices for building reliable and secure systems both in general and in regulated environments. Learners can better understand DevOps, including how the practices can be implemented and what their value is.</p><p><strong>Verification and Validation of Systems, Software, and Hardware </strong></p><p>Learners explore the basic concepts, purposes, and benefits of verification and validation in software and hardware covered in IEEE Std. 1012.</p><p><strong>Software Testing Driven by Standards and Models </strong></p><p>This course provides an overview of the IEEE 29119 series of standards. It teaches how the standards can be applied during the software life cycle, with an emphasis on aerospace and defense purposes.</p><p><strong>Using ISO/IEC/IEEE 29119 for Software Testing</strong></p><p>This series of courses explores the five steps taught in the Software Testing Driven by Standards and Models course. The series provides details on the five supporting parts of the IEEE 29119 series of standards, from proposal to retirement. Included are processes, documentation, testing techniques, and keyword-driven testing.</p><p>Individuals who complete the program can earn up to 0.5 continuing education units or five professional development hour credits, plus a digital badge.</p><p>Institutions interested in the program can contact an <a href="https://forms1.ieee.org/Aerospace-Defense-Course-Program.html?LT=EA_WB_4.2022_LM_aerospacedefense_institutearticle" rel="noopener noreferrer" target="_blank">IEEE account specialist</a> to learn more.</p><p>Visit the <a href="https://iln.ieee.org/public/contentdetails.aspx?id=C61EB06931DD481E9FE74F2C17FD7D5E&utm_source=institute&utm_medium=articleapril2022&utm_campaign=aerospacedefensecp" rel="noopener noreferrer" target="_blank">IEEE Learning Network</a> for member and nonmember pricing.</p>]]></description>
      <pubDate>Thu, 28 Apr 2022 18:00:05 +0000</pubDate>
      <guid>https://spectrum.ieee.org/aerospace-and-defense-standards</guid>
      <category>Ieee products services</category>
      <category>Aerospace</category>
      <category>Defense</category>
      <category>Education</category>
      <category>Standards</category>
      <category>Ieee standards</category>
      <category>Ieee educational activities</category>
      <category>Ieee news</category>
      <category>Type:ti</category>
      <dc:creator>Johanna Perez</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/u-s-f-35-fighter-jet-flying-in-a-blue-sky.jpg?id=29763899&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>COVID: Excess Mortalities Two Years Later</title>
      <link>https://spectrum.ieee.org/mortality-rate-covid-19</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-group-of-people-standing-in-front-a-wall-with-hearts-on-them-and-photos-on-strings-above-it.jpg?id=29710037&width=1200&coordinates=0%2C0%2C0%2C0&height=800"/><br/><br/><p>
	The World Health Organization (WHO) 
	<a href="https://www.who.int/director-general/speeches/detail/who-director-general-s-opening-remarks-at-the-media-briefing-on-covid-19---11-march-2020" target="_blank">declared the outbreak</a> of the COVID-19 pandemic on 11 March 2020. Two years later, it put the cumulative number of cases at about 452 million, more than 5 percent of the world’s population, and the number of new infections was still averaging more than a million a day.
</p><p>
	How many people have died? We can begin to model the problem by using the highest mortality estimates of the two previous major pandemics—138 deaths per 100,000 people in 1957–1958 and 111 per 100,000 in 1968–1969. A similarly virulent two-year event, adjusted for today’s population of 7.9 billion, would then be expected to kill 8.8–10 million people. On 11 March 2022, the WHO’s officially logged COVID death toll was about 6 million. Every epidemiologist knows that this must be a significant underestimate.
</p><hr/><p>
	A better way to assess the death toll is to calculate excess mortality, that is, the difference between the total number of deaths during a crisis and the deaths that would be expected under normal conditions. Obviously, this approach will work only in those countries that collect near-impeccable mortality statistics. The 
	<a href="https://www.who.int/data/stories/the-true-death-toll-of-covid-19-estimating-global-excess-mortality" target="_blank">WHO has assessed</a> the health-information capacity of 133 countries, showing that the share of all deaths that are registered ranges from 100 percent in Japan and 98 percent in the European Union to 80 percent in China and only 10 percent in Africa. Given these realities, calculations of excess mortalities are revealing in France, inaccurate in China, and impossible in Nigeria.
</p><p>
	And even in Japan, interpreting excess mortalities can be complicated. On one hand, COVID excess mortality includes not only the deaths directly attributable to the virus (due to inflammation of tissues or oxygen deprivation) but also the indirect effects caused when COVID aggravates preexisting conditions (heart disease, dementia) or induces the deterioration and disruption of normal health care (forgone diagnoses and treatments). But on the other hand, the spread of COVID appears to have largely preempted seasonal excess mortality caused by winter flu epidemics among the elderly, and lockdowns and economic slowdowns improved the quality of outdoor air.
</p><p class="pull-quote">
	The officially logged COVID death toll is about 6 million; every epidemiologist knows that this must be a significant underestimate.
</p><p>
	By the end of 2020 the official worldwide COVID death toll was 1.91 million, but the WHO’s preliminary evaluation 
	<a href="https://www.who.int/data/stories/the-true-death-toll-of-covid-19-estimating-global-excess-mortality" target="_blank">estimated at least 3 million deaths</a>. According to Seattle’s Institute for Health Metrics and Evaluation (IHME), which counts only cases caused directly by the virus, not by the pandemic’s disruption of health care, excess global mortality reached 15.34 million (that is, between 12.6 and 18.9 million) by 11 March 2022. That’s the second anniversary of the beginning of the pandemic, according to the WHO’s reckoning.
</p><div class="flourish-embed flourish-scatter" data-src="visualisation/9409465?602891">
<script src="https://public.flourish.studio/resources/embed.js"> </script>
</div><p>
	A 
	<a href="https://www.economist.com/graphic-detail/coronavirus-excess-deaths-estimates" target="_blank">model</a> run by <em>The Economist</em> relies on scores of national indicators correlating with data on excess death and thus it has produced a <a href="https://www.economist.com/graphic-detail/coronavirus-excess-deaths-estimates" target="_blank">wide range of estimates</a>. For the pandemic’s 2-year mark, the range is between 14 million (2 times the official tally of 6.86 million) and 23.7 million (3.5 times the official number), with the central value at 20 million (2.9 times the official total). And on 10 March 2022, <em>The Lancet</em>, one of the world’s leading medical journals, <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)02796-3/fulltext" target="_blank">published its excess mortality estimate</a> for 2020 and 2021: 18.2 (17.1 to 19.6) million, nearly 3.1 times the official two-year tally.
</p><p>
	Even using a toll of around 15 million deaths is enough to put COVID-19 far ahead of the two major post-1945 pandemics on a per capita basis. And any number above 20 million would make it in absolute terms (but not in relation to population) an event on the same order of magnitude as the great 1918–1920 influenza pandemic. Will we ever know the real toll to within 10 percent, plus or minus?
</p><div class="flourish-embed flourish-chart" data-src="visualisation/9197507?602891">
<script src="https://public.flourish.studio/resources/embed.js"> </script>
</div>]]></description>
      <pubDate>Thu, 28 Apr 2022 15:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/mortality-rate-covid-19</guid>
      <category>Excess mortality</category>
      <category>Direct cause of death</category>
      <category>Indirect cause of death</category>
      <category>Influenza of 1918-1920</category>
      <category>Deaths from covid-19</category>
      <dc:creator>Vaclav Smil</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-group-of-people-standing-in-front-a-wall-with-hearts-on-them-and-photos-on-strings-above-it.jpg?id=29710037&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>UCSB and Disney Find Out How High a Robot Can Possibly Jump</title>
      <link>https://spectrum.ieee.org/record-breaking-jumping-robot</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/two-squashed-black-loops-overlap-at-ninety-degrees-to-each-other-elastic-ties-criss-cross-the-loops-and-attach-to-a-central-spindle-atop-the-spindle-is-a-blue-cone-shape-and-some-electronics.jpg?id=29728806&width=1200&coordinates=0%2C19%2C0%2C19&height=800"/><br/><br/><p>Over the last decade or so, we’ve seen an enormous variety of jumping robots. With a few exceptions, these robots look to biology to inspire their design and functionality. This makes sense, because the natural world is full of jumping animals that are absolutely incredible, and matching their capabilities with robots seems like a reasonable thing to aspire to—with creatures such as <a href="https://spectrum.ieee.org/swarm-robots-mimic-ant-jaws-to-flip-and-jump" target="_self">ants</a>, <a href="https://spectrum.ieee.org/brilliant-little-jumping-robot-only-needs-one-motor" target="_self">frogs</a>, <a href="https://spectrum.ieee.org/delivery-drones-use-birdinspired-legs-to-jump-into-the-air" target="_self">birds</a>, and <a href="https://spectrum.ieee.org/salto1p-is-the-most-amazing-jumping-robot-weve-ever-seen" target="_self">galagos</a>, robots have tried (and occasionally succeeded in some specific ways) to mimic their motions.</p><p>The few exceptions to this bio-inspired approach have included robots that leverage things like <a href="https://spectrum.ieee.org/boston-dynamics-sand-flea-demonstrates-astonishing-jumping-skills" target="_self">compressed gas</a> and even <a href="https://spectrum.ieee.org/tiny-robot-makes-big-jumps-with-explosive-microrockets" target="_self">explosives</a> to jump in ways that animals cannot. The performance of these robots is very impressive, at least partially because their jumping techniques don’t get all wrapped up in biological models that tend to be influenced by nonjumping things, like versatility.</p><p>For a group of roboticists from the University of California, Santa Barbara, and Disney Research, this led to a simple question: If you were to build a robot that focused <em>exclusively</em> on jumping as high as possible, how high could it jump? And in a paper published today in <em>Nature</em>, they answer that question with a robot that can jump 33 meters high, which reaches right about eyeball level on the Statue of Liberty.</p><hr/><p>These videos are unfortunately not all that great, but here’s a decent one of the jumping robot (which the researchers creatively refer to as “our jumper”) launching itself, landing, self-righting, and then launching again.</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="21d693318dd743683b0415fd6b865c60" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/aT_QFLQnT7Q?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>And here’s a slow-motion close-up of the jump itself.<br/></p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="5f4121450552dbb744d89bc39f8ab8b4" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/9C3cDQMFkUc?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>The jumper is 30 centimeters tall and weighs 30 grams, which is relatively heavy for a robot like this. It’s made almost entirely of carbon fiber bows that act as springs, along with rubber bands that store energy in tension. The center bit of the robot includes a motor, some batteries, and a latching mechanism attached to a string that connects the top of the robot to the bottom. To prepare for a jump, the robot starts spinning its motor, which over the course of 2 minutes winds up the string, squishing the robot down and gradually storing up a kind of ridiculous amount of energy. Once the string is almost completely wound up, one additional tug from the motor trips the latching mechanism, which lets go of the string and releases all of the energy in approximately 9 milliseconds, over which time the robot accelerates from zero to 28 meters per second. All-in, the robot has a specific energy of over 1,000 joules per kilogram, which is enough to propel it about an order of magnitude higher than even the best biological jumpers, and easily triples the height of any other jumping robot in existence.</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-right" data-rm-resized-container="25%" style="float: right;">
<img alt="Photo showing the trajectory of the jumping robot reaching 30m high with a human for scale" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="46af32bc95b6a0b20131194d6fb37861" data-rm-shortcode-name="rebelmouse-image" id="53ae2" loading="lazy" src="https://spectrum.ieee.org/media-library/photo-showing-the-trajectory-of-the-jumping-robot-reaching-30m-high-with-a-human-for-scale.png?id=29728818&width=980" style="max-width: 100%"/>
</p><p>The reason that this robot can jump as high as it does is because it relies on a clever bit of engineering that you won’t find anywhere (well, almost anywhere) in biology: a rotary motor. With a rotary motor and some gears attached to a spring, you can use a relatively low amount of power over a relatively long period of time to store lots and lots of energy as the motor spins. Animals don’t have access to rotary motors, so while they do have access to springs (tendons), the amount that those springs can be charged up for jumping is limited by how much you can do with the single power stroke that you get from a muscle. The upshot here is that the best biological jumpers, <a href="https://spectrum.ieee.org/uc-berkeley-salto-is-the-most-agile-jumping-robot-ever" target="_blank">like the galago</a>, simply have the biggest jumping muscles relative to their body mass. This is fine, but it’s a pretty significant limitation to how high animals can possibly jump.</p><p>While many other robots (stretching back at least a decade) have combined rotary motors and springs for jumping, the key insight that led to this <em>Nature</em> paper is the understanding that the best way to engineer an optimal jumping robot is by completely inverting the biology: Instead of getting bigger jumps through bigger motors, you instead minimize the motor while using as many tricks as possible to go all in on the spring. The researchers were able to model the ratio of muscle to tendon for biological jumpers, and found that the best performance comes from a muscle that’s about 30 times the mass of the tendon. But for an engineered jumper, this paper shows that you actually want to invert that mass ratio, and this jumping robot has a spring that’s 1.2 times the mass of the motor. “We were too tied to the animal model,” coauthor Morgan Pope of Disney Research told <em>IEEE Spectrum</em>. “So we’ve been jumping a few meters high when we should be jumping tens of meters high.”</p><p><br/></p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Five frames show the robot\u2019s loops contracting and becoming vertically elongated, until it leaves the ground." class="rm-shortcode" data-rm-shortcode-id="a70d1d33e2fc03c9f60cadb2bbea8bef" data-rm-shortcode-name="rebelmouse-image" id="df31e" loading="lazy" src="https://spectrum.ieee.org/media-library/five-frames-show-the-robot-u2019s-loops-contracting-and-becoming-vertically-elongated-until-it-leaves-the-ground.jpg?id=29728829&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">A series of high speed images showing the robot releasing the tension in its springs and jumping</small></p><p>“Seeing our robot jump for the first time was magical,” first author Elliot Hawkes from UC Santa Barbara told us. “We started with a design much more like a pogo stick before coming to a bow design, then to the hybrid spring design with the rubber bands and bows together. Countless hours went into troubleshooting all kinds of challenging mechanical problems, from gearbox teeth shearing off to hinges breaking to carbon-fiber springs exploding. Every new iteration was just as exciting—the most recent one that jumps over 30 meters just blows your mind when you see it take off in person. It’s so much energy in such a small device!”<br/></p><p>Getting the robot to jump even higher (since Statue of Liberty eyeball-height obviously just isn’t good enough) will likely involve using a spring that’s even springier to maximize the amount of energy that the robot can store without increasing its mass. “We have pushed the energy storage pretty far with our hybrid tension-compression spring,” Hawkes says. “But I believe there could be spring designs that could push this even further. We’re at around 2,000 joules per kilogram right now.”</p><p>It’s temping to fixate on the bonkers jump height of this robot and wonder why we don’t toss all those other bio-inspired robots out the window, but it’s important to understand that this thing is very much a unitasker in a way that animals (and the robots built with animals in mind) are not. “We have made an incredibly specialized device that does one thing very well,” says Hawkes. “It jumps very high once in a while. Biological jumpers do many other things way better, and are way more robust.”</p><p class="shortcode-media shortcode-media-rebelmouse-image image-crop-custom">
<img alt="A rendering showing the robot launching on the surface of the moon" class="rm-shortcode" data-rm-shortcode-id="890a093270db541484f54df8059009be" data-rm-shortcode-name="rebelmouse-image" id="82f2f" loading="lazy" src="https://spectrum.ieee.org/media-library/a-rendering-showing-the-robot-launching-on-the-surface-of-the-moon.jpg?id=29728823&width=2625&coordinates=0%2C518%2C0%2C-1&height=2858"/>
</p><p>With that in mind, it’s true that even the current version of this jumping robot can self-right, jump repetitively, and carry a small payload, like a camera. The researchers suggest that this combination of mobility and efficiency might make it ideal for exploring space, where jumping can get you a lot farther. On the moon, for example, this robot would be able to cover half a kilometer per jump, thanks to lower gravity and no atmospheric drag. “The application we are currently most excited about is space exploration,” Hawkes tells us. “The moon is a truly ideal location for jumping, which opens up new possibilities for exploration because it could overcome challenging terrain. For instance, the robot could hop onto the side of an inaccessible cliff or leap into the bottom of a crater, take samples, and return to a wheeled rover.” Hawkes says that he and his team are currently working with NASA to develop this system with the goal of launching to the moon within the next five years.</p>“Engineered Jumpers Overcome Biological Limits Via Work Multiplication,” by Elliot W. Hawkes, Charles Xiao, Richard-Alexandre Peloquin, Christopher Keeley, Matthew R. Begley, Morgan T. Pope, and Günter Niemeyer from UC Santa Barbara, Disney Research, and Caltech, <a href="https://www.nature.com/articles/s41586-022-04606-3" rel="noopener noreferrer" target="_blank">appears this week in <em>Nature</em></a>.]]></description>
      <pubDate>Wed, 27 Apr 2022 17:13:32 +0000</pubDate>
      <guid>https://spectrum.ieee.org/record-breaking-jumping-robot</guid>
      <category>Jumping robots</category>
      <category>Disney</category>
      <category>Ucsb</category>
      <category>Robots</category>
      <dc:creator>Evan Ackerman</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/two-squashed-black-loops-overlap-at-ninety-degrees-to-each-other-elastic-ties-criss-cross-the-loops-and-attach-to-a-central-spindle-atop-the-spindle-is-a-blue-cone-shape-and-some-electronics.jpg?id=29728806&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>How Eddie Custovic Is Building His Legacy</title>
      <link>https://spectrum.ieee.org/legacy-of-eddie-custovic</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/eddie-custovic-portrait-in-jacket-and-plaid-shirt.jpg?id=29725322&width=1200&coordinates=0%2C0%2C0%2C96&height=800"/><br/><br/><p><a href="https://www.linkedin.com/in/ecustovic/" rel="noopener noreferrer" target="_blank">Edhem “Eddie” Custovic</a> says he always wanted to leave behind a legacy. He’s now doing so, in a number of ways. </p><p>The IEEE senior member established an innovation lab for budding entrepreneurs at <a href="https://www.latrobe.edu.au/" rel="noopener noreferrer" target="_blank">La Trobe University</a>, in Melbourne, Australia, where he is an engineering professor. He also set up a foundation to provide youngsters in his home country of Bosnia and Herzegovina with educational opportunities, mentorship, and scholarships. And if that isn’t enough, he is working to combat impending food shortages by developing imaging technology to determine how to grow plants in inhabitable environments.</p><hr/><p>For his “leadership in the empowerment and development of technology professionals globally,” Custovic is the recipient of this year’s <a href="https://corporate-awards.ieee.org/award/2021-ieee-theodore-w-hissey-outstanding-young-professional-award/#:~:text=Hissey%20Outstanding%20Young%20Professional%20Award%20is%20presented%20at%20the%20IEEE,and%20IEEE%20fields%20of%20interest." rel="noopener noreferrer" target="_blank">IEEE Theodore W. Hissey Outstanding Young Professional Award. </a>The award is sponsored by <a href="https://yp.ieee.org/" rel="noopener noreferrer" target="_blank">IEEE Young Professionals</a> and the IEEE <a href="https://www.photonicssociety.org/" rel="noopener noreferrer" target="_blank">Photonics</a> and <a href="https://www.ieee-pes.org/" rel="noopener noreferrer" target="_blank">Power & Energy</a> societies.</p><p>Receiving the award is “by far the greatest achievement” in his career, he says. “It encompasses all the work that I’ve put in over the years in empowering young people to achieve more. It’s particularly special to me because it bears the name of Theodore Hissey, someone who I find inspirational and have had the pleasure of working with on numerous occasions at IEEE.”</p><p>Hissey, an IEEE Life Fellow and IEEE director emeritus, has supported the IEEE Young Professionals community over the years.</p><p><strong>BORN ENTREPRENEUR </strong></p><p>Custovic says he has always been entrepreneurial.</p><p>“It goes back to being a refugee in Switzerland, where my brother and I had to learn how to earn money,” Custovic says. He and his family fled Bosnia in 1991 because of ethnic violence there. They later moved to Australia.</p><p>He says those experiences gave him the mentality that “you have to earn and work for [things] yourself.”</p><p>Custovic’s first big entrepreneurial venture began in 2010, while he was a doctoral student at La Trobe. While conducting research for his thesis, he noticed that there was little collaboration between disciplines at the university. It inspired him in 2016 to found the <a href="https://www.lief.tech/" rel="noopener noreferrer" target="_blank">La Trobe Innovation and Entrepreneurship Foundry, </a>which promotes multidisciplinary research among the school’s faculty members and students, plus engineers in industry.</p><p>“We’ve had a lot of success through the lab,” Custovic says. “Not only have participants developed various innovative technologies, but they have also gained interdisciplinary thinking.”</p><p>One project that came out of the foundry is <a href="https://portal.engineersaustralia.org.au/news/la-trobe-researchers-count-kicks-prevent-stillbirths" rel="noopener noreferrer" target="_blank">CountaKick</a>, a tool that detects fetal movements during the third trimester of pregnancy to help determine whether the fetus is healthy. The project brought engineers together with computer scientists and health care professionals. </p><p>The foundry team developed a wearable belt that is embedded with 16 microphones to detect fetal movement. It uses machine learning to differentiate the sounds of fetal movement from background noises and other sounds from the mother’s body. CountaKick was bought by another company, which is now working to commercialize it.</p><p>Another one of Custovic’s entrepreneurial ventures—the <a href="https://www.bhfuturesfoundation.org/" rel="noopener noreferrer" target="_blank">Bosnia and Herzegovina Futures Foundation, in </a>Tuzla, Bosnia—hits closer to home.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Eddie Custovic with students from the La Trobe Innovation & Entrepreneurship Foundry" class="rm-shortcode" data-rm-shortcode-id="105e264914d0eb7349ae8a999471ae66" data-rm-shortcode-name="rebelmouse-image" id="13632" loading="lazy" src="https://spectrum.ieee.org/media-library/eddie-custovic-with-students-from-the-la-trobe-innovation-entrepreneurship-foundry.jpg?id=29725334&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Custovic [bottom right] with students from the La Trobe Innovation & Entrepreneurship Foundry.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Courtesy Eddie Custovic</small></p><p>“As a kid growing up in Australia, I felt a sense of pride for the place where I was born,” he says. “I grew up in a healthy environment and had the opportunity to pursue the career I wanted. But I couldn’t stop thinking about the people who didn’t have that same opportunity.”</p><p>He started the foundation in 2015 with his brother, <a href="http://vertengineering.com/staff4" rel="noopener noreferrer" target="_blank">Resad</a>, who is a civil engineer and also an entrepreneur. They wanted to create an organization that would be their “life legacy” and would help Bosnia and Herzegovina prosper by empowering youth through access to education and mentorship, as well as helping them develop technologies.</p><p>Almost 2 million Bosnians and Herzegovinians were displaced by the 1990s Bosnian War and now live in 30 countries worldwide, Custovic says. Inspired by IEEE’s global membership, the two brothers created a network for them to collaborate on technology projects and mentor youths.</p><p>The foundation provides students with scholarships and mentorship as well as internships in a number of countries. It also holds conferences on emerging technology, interdisciplinary research being done around the world, and how to inspire girls to pursue careers in science, technology, engineering, and math.</p><p>“My mentor <a href="https://www.linkedin.com/in/barry-shoop-ph-d-p-e-25694a4/" rel="noopener noreferrer" target="_blank">Barry Shoop</a>, who was the 2016 IEEE president, said that being a leader is about paving the way for others to succeed,” Custovic says. “I’ve really taken that to heart.”</p><p><strong>ENOUGH TO EAT</strong></p><p>Custovic is working to make sure there’s enough food to feed the growing human population. According to a study conducted by humanitarian organization <a href="https://www.globalcitizen.org/en/content/world-running-out-of-food-by-2023/" rel="noopener noreferrer" target="_blank">Oxfam</a>, Earth will run out of food by 2050.</p><p>Custovic is developing imaging technology that uses artificial intelligence to conduct plant phenotyping—or assessing a plant’s expressed characteristics. By linking the automated assessments to each plant’s genetic data, researchers can study the genetic changes that result in desirable traits such as drought-resistance or high crop yields.</p><p>The research group at La Trobe is composed of engineers, geneticists, and plant biologists. It’s also collaborating with several medicinal agriculture companies such as <a href="https://psi.cz/" rel="noopener noreferrer" target="_blank">Photon Systems Instruments</a> of Drasov, Czech Republic. It’s leading the development of plant phenotyping technology worldwide.</p><p class="pull-quote">“Being an engineer and being a leader is about paving the way for others to succeed.”</p><p><span></span>“We have no more land available for agriculture,” Custovic says, “so we now have to look at how we create efficiencies in growing food.” </p><p>The team is also using the phenotype and genotype data to determine how to grow plants without the use of chemical fertilizers and pesticides. Fertilizers contain phosphorus, which pollutes groundwater and harms aquatic life.</p><p>“Most people are not aware of the impact of phosphorus on the environment,” Custovic says. “We are trying to engineer new plants that will be less dependent on phosphorus and therefore grow effectively without it.”</p><p>The imaging technology will determine how to effectively grow plants—both for human consumption and medicinal use, he says, in environments where they wouldn’t normally grow as well as areas that have been severely impacted by climate change.</p><p>“It’s an honor to work alongside so many talented engineers and scientists in developing technologies,” he says, “and apply their capabilities that have the goal of saving, extending, and improving human lives.”</p><p><strong>A GLOBAL NETWORK</strong></p><p>Custovic joined IEEE as a doctoral student at La Trobe and says the organization has played an enormous role in his life.</p><p>In 2010 he founded the <a href="https://www.facebook.com/IEEELaTrobeESOLU/" target="_blank">student branch</a> at La Trobe. He says his volunteerism in IEEE “really took off from there.” In 2014 he became secretary of the <a href="https://r10.ieee.org/victorian/" target="_blank">IEEE Victorian (Australia) Section</a> and eventually served as its chair. The experience helped him gain leadership skills he wouldn’t have been able to acquire otherwise, he says.</p><p>Custovic was a member of the IEEE Young Professionals committee from 2015 to 2017. </p><p>He also served on the <a href="https://www.ieee.org/documents/opsmanual.pdf" target="_blank">IEEE Publication Services and Products Board</a>’s strategic planning committee—first as the Young Professionals representative and then as a member-at-large—for six years. In addition, he was a member of the product development team, which explored potential offerings for members.</p><p>He was the inaugural chair of the Board of Directors’ <a href="https://www.ieee.org/about/corporate/industry-engagement-committee.html" rel="noopener noreferrer" target="_blank">Industry Engagement Committee</a> and oversaw the creation of the industry advisory board alongside other IEEE volunteers.</p><p>“It's exciting to interact with people who are working on solving different problems around the world,” he says, “and not only learning about emerging technology but also creating a global network.”</p>]]></description>
      <pubDate>Tue, 26 Apr 2022 18:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/legacy-of-eddie-custovic</guid>
      <category>Ieee member news</category>
      <category>Ieee young professionals</category>
      <category>Ieee awards</category>
      <category>Machine learning</category>
      <category>Mentoring</category>
      <category>Entrepreneurship</category>
      <category>Artificial intelligence</category>
      <category>Type:ti</category>
      <dc:creator>Joanna Goodrich</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/eddie-custovic-portrait-in-jacket-and-plaid-shirt.jpg?id=29725322&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Search for Buried Treasure With This DIY Magnetometer</title>
      <link>https://spectrum.ieee.org/magnetometer</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/this-illustration-shows-an-arduino-nano-an-lcd-display-and-a-bulls-eye-level-mounted-on-a-rectangular-base-extending-vertically-upward-is-a-dowel-rod-on-the-top-of-which-a-small-rm3100-sensor-board-is-mounted-the-electronics-are-connected-by-ribbon-cables-the-arduino-is-connected-to-an-external-battery-pack-by-a-short-usb-cable.png?id=29720802&width=1200&coordinates=0%2C179%2C0%2C180&height=800"/><br/><br/><p>
<strong>In the 1968</strong> movie <a href="https://en.wikipedia.org/wiki/2001:_A_Space_Odyssey_(film)" target="_blank"><em>2001: A Space Odyssey</em></a>, an oddness in the moon’s magnetic field leads scientists to an alien monolith buried under Tycho crater. The notion of being led to a hidden object by virtue of the magnetic anomaly it creates must have really intrigued my 9-year-old self, because a decade after seeing that movie I decided to build a circuit to measure the strength of Earth’s magnetic field. So I read some World War II–era journal articles and learned about the magnetometers used to locate submerged German submarines. With that information, I constructed what’s called a <a href="https://www.sensorland.com/HowPage071.html" target="_blank">fluxgate magnetometer</a>. It was crude, but it worked.
</p><p>
	I was reminded of that project by a recent 
	<a href="https://spectrum.ieee.org/the-vacuum-tubes-forgotten-rival" target="_self"><em>IEEE Spectrum</em> feature about magnetic amplifiers</a>, which rely on metal alloys that become highly magnetized in the presence of a magnetic field. These alloys tend to saturate, meaning that they cannot become further magnetized as the field increases. Magnetic amplifiers and fluxgate magnetometers both make use of this phenomenon.
</p><p>
	That jog down memory lane led me to read about a different type of magnetic-field sensor that also relies on such alloys: something called a magneto-inductive magnetometer, which appears to have first been 
	<a href="https://www.pnicorp.com/download/pni-magneto-inductive-technology-overview/" target="_blank">commercialized around 2010</a>. This magnetic-field sensor is surprisingly simple, so I headed to the garage to see whether I could build this type of magnetometer just with stuff I had on hand.
</p><p>
	Amazingly, I managed to locate a tattered envelope containing pieces of the magnetic alloy (<a href="https://en.wikipedia.org/wiki/Mu-metal" target="_blank">Mu-metal</a>) that I had used decades ago to build a fluxgate magnetometer. And that was the only hard-to-obtain item I needed.
</p><p>
	I scrounged a 6-millimeter-diameter plastic tube, which I put into the chuck of an electric drill and wound a few hundred turns of 32-gauge magnet wire around it. I then stuffed five slender pieces of Mu-metal into the tube.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="This illustration shows a top-down view of four small circuit boards\u2014a level-shifter, an RM3100 sensor, an Arduino Nano, and an LCD display\u2014along with a bull\u2019s-eye level." class="rm-shortcode" data-rm-shortcode-id="513d34f99da1e74e990d888cafc7a79c" data-rm-shortcode-name="rebelmouse-image" id="493fb" loading="lazy" src="https://spectrum.ieee.org/media-library/this-illustration-shows-a-top-down-view-of-four-small-circuit-boards-u2014a-level-shifter-an-rm3100-sensor-an-arduino-nano-and-an-lcd-display-u2014along-with-a-bull-u2019s-eye-level.png?id=29720800&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The project involves [clockwise from top left] four small and inexpensive circuit boards—a level shifter, an RM3100 sensor, an Arduino Nano, and an LCD display—along with a bull’s-eye level.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">James Provost</small>
</p><p>
	In addition to this coil, my homebrew magneto-inductive sensor required just three resistors and one LM358 chip, which contains two op amps. One op amp is wired to two resistors to form an inverting 
	<a href="https://www.electronicshub.org/schmitt-trigger-basics/" target="_blank">Schmitt trigger</a>: a comparator with two different voltage thresholds. When the input voltage rises past one threshold, the output switches negative; when the input falls below the second, lower threshold, the output switches positive. The third resistor is attached to the trigger’s input, with the coil providing feedback.
</p><p>
	This arrangement [schematic diagram below] creates a 
	<a href="https://circuitdigest.com/tutorial/relaxation-oscillator-using-op-amp" target="_blank">relaxation oscillator</a>, the output of which looks quite funky on an oscilloscope. But feeding it to a second op amp configured as a simple comparator (one that compares the input with zero volts) squared the signal up nicely, with the output switching between the +12-volt and –12-volt supply rails every 3 milliseconds or so.
</p><p>
	The exact shape of this square wave depends on the changing inductance of the coil, which varies during each oscillation because the magnetic field applied to the coil’s Mu-metal core varies. The Mu-metal is also affected by external magnetic fields. So when the coil is pointed north (<a href="https://en.wikipedia.org/wiki/Dipole_model_of_the_Earth%27s_magnetic_field#/media/File:Mplwp_earth-magnetic-field.svg" target="_blank">and downward, at my northern latitude</a>), the Earth’s magnetic field adds to the magnetic field created by positive currents in the coil windings; when pointed in the opposite direction, the Earth’s field subtracts.
</p><p>
	As a result, the duty cycle of this little square-wave oscillator changes: Point one end of the coil in the direction of Earth’s field and the time spent at +12 volts gets longer while the time spent at –12 volts gets shorter. Rotate the coil by 180 degrees, and the opposite changes occur.
</p><p class="pull-quote">
	In addition to a coil with a Mu-metal core, my homebrew magneto-inductive sensor required just three resistors and one LM358 chip, which contains two op amps.
</p><p>
	After satisfying myself that this homebrew magneto-inductive sensor actually worked, I decided to see what I could do with a commercial unit that contains three sensors of this type. It can be purchased 
	<a href="https://www.amazon.com/High-Accuracy-Magnetometer-Geomagnetism-Military-Grade-High-Revolution/dp/B01N5QL0XC" target="_blank">on Amazon</a> for just US $40.
</p><p>
	I connected this 
	<a href="https://www.pnicorp.com/rm3100/" target="_blank">RM3100 sensor</a> board to an <a href="https://www.amazon.com/ATmega328P-Microcontroller-Board-Cable-Arduino/dp/B00NLAMS9C/ref=sr_1_3?crid=1ZNZ3X1QREIUR&keywords=makerfocus+mini+nano+v3.0+atmega328p&qid=1648571066&sprefix=Makerfocus+mini+n%2Caps%2C306&sr=8-3" target="_blank">Arduino Nano</a> through a Serial Peripheral Interface (SPI), using <a href="https://github.com/hnguy169/RM3100-Arduino" target="_blank">code posted on GitHub</a> late last year by the manufacturer, <a href="https://www.pnicorp.com/" target="_blank">PNI Sensor Corp</a>. The values it produced seemed reasonable for my location—about 40 microteslas—so I added an <a href="https://www.amazon.com/NOYITO-Yellow-Green-Backlight-Interface-MEGA2560/dp/B07SZV1MK8/ref=sr_1_1" target="_blank">LCD display</a> and mounted the sensor board about 30 centimeters from the other components so as to minimize their influence on the field measurements. I also added a <a href="https://www.amazon.com/IRWIN-Tools-Bullseye-Level-1794487/dp/B005XUHKV4/ref=sr_1_1" target="_blank">bull’s-eye level,</a> which I figured would be useful for measuring the vertical component of the magnetic field. Power comes from an <a href="https://www.amazon.com/Voltaic-Systems-Formerly-Battery-Samsung/dp/B07ZS3WYZY/ref=sr_1_3" target="_blank">external USB battery</a>.
</p><p>
	Short-term stability didn’t quite match what’s advertised in the manufacturer’s literature, perhaps because of electrical noise in the environment, but it’s still very good: With the unit motionless, the values shown remain within a few tens of nanoteslas. But the total field calculated from the 
	<em>x</em>, <em>y</em>, <em>z</em> components varies considerably with the orientation of the sensor. That probably reflects the influence of one sensor coil on the others, as <a href="https://www.liverpool.ac.uk/~cmi/mag/magChip.html" target="_blank">another experimenter has concluded</a>. And this would surely prove problematic using this device on the move.
</p><p>
	Hunting for submarines during the Second World War using fluxgate magnetometers involved a similar challenge—how to determine the total magnetic field using vector sensors, which measure 
	<em>x</em>, <em>y</em>, <em>z</em> components. Those sub hunters needed to track the total field because a single component would vary erratically just from physical motions. If the three orthogonal sensors were independent and perfectly calibrated, and if you had digital values and a computer to apply the Pythagorean theorem, no big deal. But all that wasn’t available in the 1940s.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="This schematic diagram shows the circuitry needed to construct a basic magneto-inductive sensor: two op amps, three resistors, and a coil that is wound around a Mu-metal core." class="rm-shortcode" data-rm-shortcode-id="56cc38fe47dd7f03ae3054968cf8a37a" data-rm-shortcode-name="rebelmouse-image" id="2461a" loading="lazy" src="https://spectrum.ieee.org/media-library/this-schematic-diagram-shows-the-circuitry-needed-to-construct-a-basic-magneto-inductive-sensor-two-op-amps-three-resistors-and-a-coil-that-is-wound-around-a-mu-metal-core.png?id=29720801&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">You can construct a very basic magneto-inductive sensor using just two op amps, three resistors, and a coil that is wound around a Mu-metal core. The duty cycle of the square-wave output depends on the magnetic field to which the coil is subjected.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">James Provost</small>
</p><p>
	The solution these sub hunters arrived at was to mount their magnetometers on a gimballed platform, using the output of two of the sensors to drive motors that reoriented the magnetometer so that the third sensor would always be pointed along the magnetic field. The third sensor would thus track the total-field value. I found I could do something similar by hand, orienting my device in a direction that zeroed out the 
	<em>x</em> and <em>y</em> outputs, leaving <em>z</em> to show the total field.
</p><p>
	I’ve not used my DIY magnetometer to search for any submarines or alien monoliths, but I did test it using a steel hammer, which affects the readings in an obvious way when placed within about a meter of the sensor board. In a real search, though, what you can detect will depend on how much the magnetic background varies.
</p><p>
	I suppose a magnetometer like this could be used 
	<a href="https://arxiv.org/abs/1105.3136" target="_blank">to locate shipwrecks</a> or find an old car buried under your garden—<a href="https://www.youtube.com/watch?v=9bapvwJhlcQ&t=1s" target="_blank">it happens</a>! My plan for it is to try to map some interesting geologic structures in my area, where finding a highly magnetizable type of rock sometimes proves valuable to homeowners because it makes for a <a href="https://deq.nc.gov/guide-homeowners-triassic-basins-north-carolina" target="_blank">good place to drill a water well</a>.
</p><p>
<em>This article appears in the May 2022 print issue as “A DIY Magnetometer.”</em>
</p>]]></description>
      <pubDate>Tue, 26 Apr 2022 15:00:00 +0000</pubDate>
      <guid>https://spectrum.ieee.org/magnetometer</guid>
      <category>Magnetic field</category>
      <category>Magnetometer</category>
      <category>Type:departments</category>
      <dc:creator>David Schneider</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/this-illustration-shows-an-arduino-nano-an-lcd-display-and-a-bulls-eye-level-mounted-on-a-rectangular-base-extending-vertically-upward-is-a-dowel-rod-on-the-top-of-which-a-small-rm3100-sensor-board-is-mounted-the-electronics-are-connected-by-ribbon-cables-the-arduino-is-connected-to-an-external-battery-pack-by-a-short-usb-cable.png?id=29720802&amp;width=980" medium="image" type="image/png" />
    </item>
    <item>
      <title>Manganese Could Be the Secret Behind Truly Mass-Market EVs</title>
      <link>https://spectrum.ieee.org/manganese-ev-batteries</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-man-puts-an-electric-charger-into-the-back-of-a-red-car-in-the-background-are-other-electric-vehicles-charging.jpg?id=29722140&width=1200&coordinates=22%2C0%2C0%2C0&height=800"/><br/><br/><p>Most automakers are dying to sell you—and the world—an electric car. But they’re up against the challenge of our global-warming time: dauntingly tight supplies of both batteries and the ethically sourced raw materials required to make them.</p><p>Tesla and Volkswagen are among the automakers who see manganese—element No. 25 on the periodic table, situated between chromium and iron—as the latest, alluringly plentiful metal that may make both batteries and EVs affordable enough for mainstream buyers.</p><p>That’s despite the dispiriting history of the first (and only) EV to use a high-manganese battery, the <a href="https://www.greencarreports.com/news/1117928_2018-nissan-leaf-battery-technology-a-deep-dive" target="_blank">original Nissan Leaf</a>, beginning in 2011. But with the industry needing all the batteries it can get, improved high-manganese batteries could carve out a niche, perhaps as a mid-priced option between lithium-iron phosphate chemistry, and primo nickel-rich batteries in top luxury and performance models.</p><p class="pull-quote">“We need tens, maybe hundreds of millions of tons, ultimately. So the materials used to produce these batteries need to be common materials, or you can’t scale.”<br/>—Elon Musk</p><p>Elon Musk made waves at the opening ceremony of Tesla Gigafactory Berlin, when asked his opinion on graphene in cells: “I think there’s an interesting potential for manganese,” Musk countered. </p><p>Regarding raw minerals, he underlined the ongoing industry flight from cobalt and now nickel: “We need tens, maybe hundreds of millions of tons, ultimately. So the materials used to produce these batteries need to be common materials, or you can’t scale,” Musk said.</p><p>At Volkswagen’s live-streamed <a href="https://spectrum.ieee.org/volkswagen-announces-ev-battery-push" target="_blank">“Power Day” in March</a>—a seeming hat-tip to <a href="https://spectrum.ieee.org/tesla-4680-battery" target="_blank">Tesla’s “Battery Day” spectacle</a>—CEO Herbert Diess set off his own Muskian frenzy by announcing VW would build a half-dozen gigafactories in Europe by 2030, with a total of 240 gigawatt-hours of capacity. VW is already building EV factories in Tennessee and China. VW, despite its EVs outselling Tesla in Europe, is under intense competitive pressure from Tesla, and in the Chinese market where VW underperforms. The global giant is determined to cut its battery costs by half in entry-level models, and by 30 percent in mid-priced cars. </p><p>To get there, VW unveiled a versatile “unified cell” that can use multiple chemistries in a standardized prismatic design. Diess said about 80 percent of VW’s new prismatic batteries would spurn pricey nickel and cobalt in favor of cheaper, more-plentiful cathode materials—including potentially manganese.</p><p>VW’s aggressive strategy to move production of prismatic batteries in-house—the same format built by China’s <a href="https://spectrum.ieee.org/the-top-10-ev-battery-makers" target="_blank">Contemporary Amperex Technology Co., Limited (CATL)</a>, which supplies both VW and Tesla—<a href="https://www.reuters.com/article/us-volkswagen-batteries-southkorea-focus/power-play-volkswagen-abruptly-pulls-plug-on-south-korean-battery-makers-idUSKBN2B90QR" target="_blank">blindsided its current suppliers</a> of pouch-style batteries, South Korea’s LG Energy Solutions and SK Innovation. (VW tried to smooth the waters by saying it would honor existing battery contracts.)</p><p>So why this endless mixing-and-matching of formats and cathodes? And why manganese? It all hinges on what Musk and other experts cite as the looming, limiting factor in accelerating the EV revolution: the lagging rate of both battery production and the mining and processing of their raw materials.</p><p>In Berlin, Musk suggested the world will need <a href="https://www.youtube.com/watch?v=W1vB0sVNFTQ" rel="noopener noreferrer" target="_blank">300 terawatt-hours</a> of annual battery production to realize a full transition from fossil-fueled cars. That’s 100 times what Tesla projects it can produce by 2030, even with its own massive expansion of capacity. Nickel-rich batteries alone won’t get us there, despite currently unmatched energy density and performance. Other materials are required, with an ethical, diverse, uninterrupted pipeline to boot, even if, like manganese or lithium-iron phosphate—the flavor of the moment for EVs—the resulting batteries demand some compromises.</p><p class="pull-quote">“I can see the logic, where if you can get it to a reasonable energy density, manganese becomes this in-between thing.”<br/>—Venkat Srinivisan, Argonne Laboratories</p><p>“The higher number of minerals that go into a battery is a good thing,” said Venkat Srinivisan, director of the <a href="https://www.anl.gov/access" target="_blank">Argonne Collaborative Center for Energy Storage Science</a> (ACCESS). </p><p>As a cathode material, manganese is abundant, safe, and stable. But it has never approached the energy density or life cycle of nickel-rich batteries, Srinivisan cautions. Buyers of early Nissan Leafs might concur: Nissan, with no suppliers willing or able to deliver batteries at scale back in 2011, was forced to build its own lithium manganese oxide batteries with a molecular jungle-gym-like <a href="https://www.marklines.com/en/report_all/rep1786_201811" target="_blank">“spinel” design</a>. Those energy-poor packs brought just 24 kilowatt-hours of storage and a 117-kilometer (73-mile) driving range. Even that piddling storage and range rapidly degraded, especially in the southwestern United States and other searing climates, leaving customers howling. (It didn’t help that Nissan eschewed a thermal-management system for the battery.) A “Lizard” battery in 2014 with a modified manganese chemistry boosted capacity to 40 kWh, but still suffered short life spans.</p><p>Srinivisan said the story of EVs in the United States has been one of insatiable demand for power and driving range, which demanded the highest-energy batteries. That meant cobalt, typically a by-product of nickel and copper mining, and among the priciest battery elements. Cobalt production is also <a href="https://www.nytimes.com/2021/11/20/world/china-congo-cobalt.html" target="_blank">dominated by the Democratic Republic of Congo</a>, which is linked to child labor in mines and other human rights abuses. Low-cobalt batteries have been the response.</p><p>“Everyone is thinking about substitutions for nickel and cobalt and how to recycle these things,” Srinivisan says.</p><p>General Motors and LG Energy Solutions’ <a href="https://www.gm.com/stories/ultium-flexible-battery-cells" rel="noopener noreferrer" target="_blank">pouch-style Ultium cells</a>—which I recently tested for the first time in the GMC Hummer EV—use a nickel cobalt manganese aluminum chemistry that reduces cobalt content by more than 70 percent. With 200 kWh in a double-stacked cell sandwich—twice the size of Tesla’s biggest battery—<a href="https://www.roadandtrack.com/reviews/a39653511/hummer-ev-review/" rel="noopener noreferrer" target="_blank">the reborn Hummer </a>combines a 529-km (329-mile) range with tri-motor propulsion, 1,000 horsepower, and a 3.0-second explosion to 60 miles per hour in its WTF (“Watts to Freedom”) mode. That battery, by far the largest ever shoehorned into an EV, also contributes 1,315 kilograms to the Hummer’s gargantuan 4,082-kg curb weight. (With GM gearing up mass production in Detroit, the Hummer might cause a battery shortage all on its own.)</p><p>As with Tesla’s best cells, GM’s cells use only small amounts of manganese to stabilize structures, not as a main cathode material.</p><p>According to the global materials and recycling company <a href="https://www.umicore.com/" target="_blank">Umicore</a>, more than 90 percent of manganese is mined for iron and stainless-steel production, with less than 1 percent going into batteries.</p><p>The next popular cathode mineral has been nickel, with a more diverse supply than Congolese cobalt, but hardly immune from geopolitical concerns. Global nickel stockpiles were already dwindling before Russia’s invasion of Ukraine in February. Investors and traders got antsy over potential bans or interruptions of metals from Russia, which produces about 17 percent of the world’s high-purity nickel. In March, nickel prices doubled virtually overnight, briefly topping US $100,000 per tonne for the first time, spurring the London Metal Exchange to suspend trading during the wild run-up.</p><p>For all these reasons—commodity prices, politics, ethics, security, shortages, long-term strategy, and hedging of bets—the industry is embarking on a diversification strategy, a smorgasbord of solutions. Or at least until some future Nobel winner comes up with something to replace lithium-ion entirely.</p><p>For the fickle automaker, even nickel is on the outs—at least among those focused on China, or on modest-range, more-affordable EVs. Tesla, VW, Ford, Chinese companies, and others <a href="https://spectrum.ieee.org/the-top-10-ev-battery-makers" target="_self">are rapidly switching</a> to lithium-iron phosphate (LFP) chemistries—invented in the 1990s and until recently viewed as yesterday’s news—for mainstream or commercial models. These batteries require no nickel or cobalt, just abundant iron and phosphate. Musk has confirmed a “long-term switch” to LFP for entry-level cars (including the Model 3) or energy storage.</p><p>High-manganese batteries being eyeballed by Musk and VW would also use less nickel, and zero cobalt. They appear affordable: According to analysts at Roskill cited at Power Day, a lithium nickel manganese oxide chemistry could reduce cathode costs by 47 percent per kilowatt-hour relative to nickel-rich designs. That has VW mulling manganese as a potential fit for mainstream models, with LFP for bottom-rung vehicles or markets, and bespoke high-performance packs for the likes of Porsche, Audi, Bentley, or Lamborghini.</p><p>“I can see the logic, where if you can get it to a reasonable energy density, manganese becomes this in-between thing,” Srinivisan says. Automakers might offset manganese’s lower cathode costs with slightly enlarged batteries, to bring range closer to par with nickel-rich designs.</p><p>Back in 2020, at Tesla’s Battery Day, Musk expressed optimism about the mineral:</p><p>“It is relatively straightforward to do a cathode that’s two-thirds nickel and one-third manganese, which will allow us to make 50 percent more cell volume with the same amount of nickel,” Musk said.</p><p>With Musk still struggling to bring his large-format 4680 cylindrical cell to market—now well behind schedule—experts caution that  the technical challenges aren’t so straightforward. High-manganese batteries have yet to demonstrate commercial viability.</p><p>But the epic scale of the challenge has automakers and battery makers working the labs and scouring the globe for materials as common as dirt, not precious as gold.</p>]]></description>
      <pubDate>Mon, 25 Apr 2022 18:18:40 +0000</pubDate>
      <guid>https://spectrum.ieee.org/manganese-ev-batteries</guid>
      <category>Batteries</category>
      <category>Ev batteries</category>
      <category>Lithium-ion batteries</category>
      <category>Electric vehicles</category>
      <dc:creator>Lawrence Ulrich</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-man-puts-an-electric-charger-into-the-back-of-a-red-car-in-the-background-are-other-electric-vehicles-charging.jpg?id=29722140&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Inside DARPA’s Subterranean Challenge</title>
      <link>https://spectrum.ieee.org/darpa-subterranean-challenge-2657170650</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-photo-of-a-robot-lighting-up-a-stone-tunnel.png?id=29692504&width=1200&coordinates=1%2C0%2C2%2C0&height=800"/><br/><br/><p>
<strong>Deep below the</strong> Louisville, Ky., zoo lies a network of enormous caverns carved out of limestone. The caverns are dark. They’re dusty. They’re humid. And during one week in September 2021, they were full of the most sophisticated robots in the world. The robots (along with their human teammates) were there to tackle a massive underground course designed by DARPA, the Defense Advanced Research Projects Agency, as the culmination of its three-year Subterranean Challenge.
</p><p>
	The SubT was first announced in early 2018. DARPA designed the competition to advance practical robotics in extreme conditions, based around three distinct underground environments: human-made tunnels, the urban underground, and natural caves. To do well, the robots would have to work in teams to traverse and map completely unknown areas spanning kilometers, search out a variety of artifacts, and identify their locations with pinpoint accuracy under strict time constraints. To more closely mimic the scenarios in which first responders might utilize autonomous robots, robots experienced darkness, dust and smoke, and even DARPA-controlled rockfalls that occasionally blocked their progress.
</p><hr/><p>
	With direct funding plus prize money that reached into the millions, DARPA encouraged international collaborations among top academic institutions as well as industry. A series of three preliminary circuit events would give teams experience with each environment.
</p><p>
	During the Tunnel Circuit event, which took place in August 2019 in the National Institute for Occupational Safety and Health’s experimental coal mine, on the outskirts of Pittsburgh, many teams lost communication with their robots after the first bend in the tunnel. Six months later, at the Urban Circuit event, held at an unfinished nuclear power station in Satsop, Wash., teams beefed up their communications with everything from a straightforward tethered Ethernet cable to battery-powered mesh network nodes that robots would drop like breadcrumbs as they went along, ideally just before they passed out of communication range. The Cave Circuit, scheduled for the fall of 2020, was canceled due to COVID-19.
</p><div class="ieee-sidebar-medium">
<p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="A photo of people looking over wheeled robots in a large rocky open area.  " class="rm-shortcode rm-resized-image" data-rm-shortcode-id="072935a4025dbe4d7cc5a5670354781f" data-rm-shortcode-name="rebelmouse-image" id="694c1" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-people-looking-over-wheeled-robots-in-a-large-rocky-open-area.png?id=29692612&width=980" style="max-width: 100%"/>
</p>
<p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="A photo of three yellow four-legged robots lined up with their lights on in a dimmer area " class="rm-shortcode rm-resized-image" data-rm-shortcode-id="24da0b458b0d0caafc538464872c9cad" data-rm-shortcode-name="rebelmouse-image" id="7b70d" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-three-yellow-four-legged-robots-lined-up-with-their-lights-on-in-a-dimmer-area.png?id=29692640&width=980" style="max-width: 100%"/>
</p>
<p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="A photo of two people checking out the back of a robot." class="rm-shortcode rm-resized-image" data-rm-shortcode-id="f28d7607b1a4de8c4786ffca099b16f1" data-rm-shortcode-name="rebelmouse-image" id="2e463" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-two-people-checking-out-the-back-of-a-robot.png?id=29692645&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Team CoSTAR, a collaboration between NASA’s JPL, MIT, Caltech, KAIST,
and LTU, inspects the communications-node deployment system on their
Husky wheeled robots [top]. CoSTAR’s pack of quadrupeds, consisting
of Spot robots from Boston Dynamics modified with customized autonomy
payloads [middle], undergo a hardware check before their final
competition run. The Spots are wearing “socks” made from cut-up
mountain-bike tires, cable ties, and black tape. Despite the ruggedness
of many of the robots, as research platforms, most demanded careful
attention from their human teammates, including Team Cerberus [bottom].
		</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Evan Ackerman</small>
</p>
</div><p>
	By the time teams reached the SubT Final Event in the Louisville Mega Cavern, the focus was on autonomy rather than communications. As in the preliminary events, humans weren’t permitted on the course, and only one person from each team was allowed to interact remotely with the team’s robots, so direct remote control was impractical. It was clear that teams of robots able to make their own decisions about where to go and how to get there would be the only viable way to traverse the course quickly.
</p><p>
	DARPA outdid itself for the final event, constructing an enormous kilometer-long course within the existing caverns. Shipping containers connected end-to-end formed complex networks, and many of them were carefully sculpted and decorated to resemble mining tunnels and natural caves. Offices, storage rooms, and even a subway station, all built from scratch, comprised the urban segment of the course. Teams had one hour to find as many of the 40 artifacts as possible. To score a point, the robot would have to report the artifact’s location back to the base station at the course entrance, which would be a challenge in the far reaches of the course where direct communication was impossible.
</p><p>
	Eight teams competed in the SubT Final, and most brought a carefully curated mix of robots designed to work together. Wheeled vehicles offered the most reliable mobility, but quadrupedal robots proved surprisingly capable, especially over tricky terrain. Drones allowed complete exploration of some of the larger caverns.
</p><p>
	By the end of the final competition, two teams had each found 23 artifacts: Team Cerberus—a collaboration of the University of Nevada, Reno; ETH Zurich; the Norwegian University of Science and Technology; the University of California, Berkeley; the Oxford Robotics Institute; Flyability; and the Sierra Nevada Corp.—and Team CSIRO Data61—consisting of CSIRO’s Data61; Emesent; and Georgia Tech. The equal scores triggered a tie-breaker rule: Which team had been the quickest to its final artifact? That gave first place to Cerberus, which had been just 46 seconds faster than CSIRO.
</p><p>
	Despite coming in second, Team CSIRO’s robots achieved the astonishing feat of creating a map of the course that differed from DARPA’s ground-truth map by less than 1 percent, effectively matching what a team of expert humans spent many days creating. That’s the kind of tangible, fundamental advance SubT was intended to inspire, according to Tim Chung, the DARPA program manager who ran the challenge.
</p><p>
	“There’s so much that happens underground that we don’t often give a lot of thought to, but if you look at the amount of infrastructure that we’ve built underground, it’s just massive,” Chung told 
	<em>IEEE Spectrum</em>. “There’s a lot of opportunity in being able to perceive, understand, and navigate in subterranean environments—there are engineering integration challenges, as well as foundational design challenges and theoretical questions that we have not yet answered. And those are the questions DARPA is most interested in, because that’s what’s going to change the face of robotics in 5 or 10 or 15 years, if not sooner.”
</p><h3></h3><br/><img alt="" class="rm-shortcode" data-rm-shortcode-id="bf9b03a3bb70e7e486e469771fb15d15" data-rm-shortcode-name="rebelmouse-image" id="c0be5" loading="lazy" src="https://spectrum.ieee.org/media-library/image.png?id=29692789&width=980"/><p style="text-align: center;">
This point cloud assembled by Team CSIRO Data61 shows a robotic view of nearly the entire SubT course, with each dot in the cloud representing a point in 3D space measured by a sensor on a robot. Team CSIRO’s point cloud differed from DARPA’s official map by less than 1 percent
</p><p class="caption" style="text-align: center;">
	CSIRO DATA61
</p><p>
<em>IEEE Spectrum</em> was in Louisville to cover the Subterranean Final, and we spoke recently with Chung, as well as CSIRO Data61 team lead Navinda Kottege and Cerberus team lead Kostas Alexis and about their SubT experience and the influence the event is having on the future of robotics.
</p><p>
<strong>DARPA has <a href="https://www.darpa.mil/our-research" rel="noopener noreferrer" target="_blank">hundreds of programs</a>, but most of them don’t involve multiyear international competitions with million-dollar prizes. What was special about the Subterranean Challenge? </strong>
</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="An illustration of Tim Chung" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="26187d9d275227ef6db792a129a2de71" data-rm-shortcode-name="rebelmouse-image" id="dd693" loading="lazy" src="https://spectrum.ieee.org/media-library/an-illustration-of-tim-chung.png?id=29693692&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..."><strong>TIM CHUNG | </strong>DARPA program manager </small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">MCKIBILLO</small>
</p><p>
<strong>Tim Chung: </strong>Every now and then, one of DARPA’s concepts warrants a different model for seeking out innovation. It’s when you know you have an impending breakthrough in a field, but you don’t know exactly how that breakthrough is going to happen, and where the traditional DARPA program model, with a broad announcement followed by proposal selection, might restrict innovation. DARPA saw the SubT Challenge as a way of attracting the robotics community to solving problems that we anticipate being impactful, like resiliency, autonomy, and sensing in austere environments. And one place where you can find those technical challenges coming together is underground.
</p><p>
<strong>The skill that these teams had at autonomously mapping their environments was impressive. Can you talk about that?</strong>
</p><p>
<strong>T.C.: </strong>We brought in a team of experts with professional survey equipment who spent many days making a precisely calibrated ground-truth map of the SubT course. And then during the competition, we saw these robots delivering nearly complete coverage of the course in under an hour—I couldn’t believe how beautiful those point clouds were! I think that’s really an accelerant. When you can trust your map, you have so much more actionable situational awareness. It’s not a solved problem, but when you can attain the level of fidelity that we’ve seen in SubT, that’s a gateway technology with the potential to unlock all sorts of future innovation.
</p><p>
<strong>Autonomy was a necessary part of SubT, but having a human in the loop was critical as well. Do you think that humans will continue to be a necessary part of effective robotic teams, or is full autonomy the future?</strong>
</p><p>
<strong>T.C.: </strong>Early in the competition, we saw a lot of hand-holding, with humans giving robots low-level commands. But teams quickly realized that they needed a more autonomous approach. Full autonomy is hard, though, and I think humans will continue to play a pretty big role, just a role that needs to evolve and change into something that focuses on what humans do best.
</p><p>
	I think that progressing from human operators to human supervisors will enhance the types of missions that human-robot teams will be able to conduct. In the final event, we saw robots on the course exploring and finding artifacts, while the human supervisor was focused on other stuff and not even paying attention to the robots. That was so cool. The robots were doing what they needed to do, leaving the human free to make high-level decisions. That’s a big change: from what was basically remote teleoperation to “you robots go off and do your thing and I’ll do mine.” And it’s incumbent on the robots to become even more capable so that the transition [of the human] from operator to supervisor can occur.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo of a dark area with a quad legged robot lighting up a shaft of stone.  " class="rm-shortcode" data-rm-shortcode-id="2685712125e64ccf07658249142c864c" data-rm-shortcode-name="rebelmouse-image" id="7be81" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-a-dark-area-with-a-quad-legged-robot-lighting-up-a-shaft-of-stone.png?id=29693391&width=980"/>
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo of a quadruped moving through an underground tunnel with wood on the wall.  " class="rm-shortcode" data-rm-shortcode-id="6c47b55e59c97fc0941ae38f9f349b3a" data-rm-shortcode-name="rebelmouse-image" id="c5d92" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-a-quadruped-moving-through-an-underground-tunnel-with-wood-on-the-wall.png?id=29693390&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">An ANYmal quadruped from Team Cerberus enters the course [top]. During
the competition, only robots and DARPA staff were allowed to cross
this threshold. The visual markers surrounding the course entrance
provided a precise origin point from which the robots would base the
maps they created. This allowed DARPA to measure the accuracy of the
artifact locations that teams reported to score points. Cerberus’s
ANYmal exits the urban section of the course, modeled after a subway
station [bottom], and enters the tunnel section of the course, based
on an abandoned mine. 
	</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Evan Ackerman </small>
</p><p>
<strong>What are some remaining challenges for robots in underground environments?</strong>
</p><p>
<strong>T.C.: </strong>Traversability analysis and reasoning about the environment are still a problem. Robots will be able to move through these environments at a faster clip if they can understand a little bit more about where they’re stepping or what they’re flying around. So, despite the fact that they were one to two orders of magnitude faster than humans for mapping purposes, the robots are still relatively slow. Shaving off another order of magnitude would really help change the game. Speed would be the ultimate enabler and have a dramatic impact on first-response scenarios, where every minute counts.
</p><p>
<strong>What difference do you think SubT has made, or will make, to robotics?</strong>
</p><p>
<strong>T.C.:</strong> The fact that many of the technologies being used in the SubT Challenge are now being productized and commercialized means that the time horizon for robots to make it into the hands of first responders has been far shortened, in my opinion. It’s already happened, and was happening, even during the competition itself, and that’s a really great impact.
</p><p>
<strong>What’s difficult and important about operating robots underground?</strong></p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img class="rm-shortcode rm-resized-image" data-rm-shortcode-id="ca67693067b8533e2fc9da68b403b40a" data-rm-shortcode-name="rebelmouse-image" id="8d713" loading="lazy" src="https://spectrum.ieee.org/media-library/navinda-kottege-csiro-data61-team-lead.png?id=29693766&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">NAVINDA KOTTEGE CSIRO | Data61 team lead</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">
            MCKIBILLO
        </small>
</p><p>
<strong>Navinda Kottege: </strong>The fact that we were in a subterranean environment was one aspect of the challenge, and a very important aspect, but if you break it down, what the SubT Challenge meant was that we were in a GPS-denied environment, where you can’t rely on communications, with very difficult mobility challenges. There are many other scenarios where you might encounter these things—the Fukushima nuclear disaster, for example, wasn’t underground, but communication was a massive issue for the robots they tried to send in. The Amazon Rainforest is another example where you’d encounter similar difficulties in communication and mobility. So we saw how each of these component technologies that we would have to develop and mature would have applications in many other domains beyond the subterranean.</p><p><strong>Where is the right place for a human in a human-robot team?</strong>
</p><p>
<strong>N.K.: </strong>There are two extremes. One is that you push a button and the robots go and do their thing. The other is what we call “human in the loop,” where it’s essentially remote control through high-level commands. But if the human is taken out of the loop, the loop breaks and the system stops, and we were experiencing that with brittle communications. The middle ground is a “human on the loop” concept, where you have a human supervisor who sets mission-level goals, but if the human is taken off of the loop, the loop can still run. The human added value because they had a better overview of what was happening across the whole scenario, and that’s the sort of thing that humans are super, super good at.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo of a robot approaching a pair of people and near an underground train station" class="rm-shortcode" data-rm-shortcode-id="9bf2cd73476ac8edf43993c86e08ffef" data-rm-shortcode-name="rebelmouse-image" id="34696" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-a-robot-approaching-a-pair-of-people-and-near-an-underground-train-station.png?id=29693468&width=980"/>
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo of a quadruped robot lighting up a cavern. " class="rm-shortcode" data-rm-shortcode-id="92d024fbafd5ed5c5a98ce747b12a772" data-rm-shortcode-name="rebelmouse-image" id="5907b" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-a-quadruped-robot-lighting-up-a-cavern.png?id=29693464&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The subway station platform [top] incorporated many challenges
for robots. Wheeled and tracked robots had particular difficulty
with the rails. DARPA hid artifacts in the ceiling of the subway
station (accessible only by drone), as well as under a grate in the
platform floor. In addition to building many customized tunnels
and structures inside the Louisville Mega Cavern, DARPA also
incorporated the cavern itself into the course. This massive room
[bottom] rewarded robots that managed to explore it with several
additional artifacts.
	</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Evan Ackerman</small>
</p><p>
<strong>How did SubT advance the field of robotics?</strong>
</p><p>
<strong>N.K.:</strong> For field robots to succeed, you need multiple things to work together. And I think that’s what was forced upon us by the level of complexity of the SubT Challenge. This whole notion of being able to reliably deploy robots in real-world scenarios was, to me, the key thing. Looking back at our team, three years ago we had some cool bits and pieces of technology, but we didn’t have robot systems that could reliably work for an hour or more without a human having to go and fix something. That was one of the biggest advances we had, because now, as we continue this work, we don’t even have to think twice about deploying our robots and whether they’ll destroy themselves if we leave them alone for 10 minutes. It’s that level of maturity that we’ve achieved, thanks to the robustness and reliability that we had to engineer into our systems to be successful at SubT, and now we can start focusing on the next step: What can you do when you have a fleet of autonomous robots that you can rely on?
</p><p>
<strong>Your team of robots created a map of the course that matched DARPA’s official map with an accuracy of better than 1 percent. That’s amazing.</strong>
</p><p>
<strong>N.K.:</strong> I got contacted immediately after the final event by the company that DARPA brought in to do the ground-truth mapping of the SubT course. They’d spent 100 person-hours using very expensive equipment to make their map, and they wanted to know how in the world we got our map in under an hour with a bunch of robots. It’s a good question! But the context is that our one hour of mapping took us 15 years of development to get to that stage.
</p><p>
	There’s a difference in what’s theoretically possible and what actually works in the real world. In its early stages, our software worked, in that it hit all of the theoretical milestones it was supposed to. But then we started taking it out to the real world and testing it in very difficult environments, and that’s where we started finding all the edge cases of where it breaks. Essentially, for the last 10-plus years, we were trying to break our mapping system as much as possible, and that turned it into a really well-engineered solution. Honestly, whenever we see the results of our mapping system, it still surprises us!
</p><p>
<strong>What made you decide to participate in the SubT Challenge?</strong>
</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="An illustration of Kostas Alexis" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="96ac81f862409787b065cee2a69565ea" data-rm-shortcode-name="rebelmouse-image" id="8a465" loading="lazy" src="https://spectrum.ieee.org/media-library/an-illustration-of-kostas-alexis.png?id=29693827&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">KOSTAS ALEXIS | Cerberus team lead</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">
            MCKIBILLO
        </small>
</p><p>
<strong>Kostas Alexis: </strong>What motivated everyone was the understanding that for autonomous robots, this challenge was extremely difficult and relevant. We knew that robotic systems could operate in these environments if humans accompanied them or teleoperated them, but we also knew that we were very far away from enabling autonomy. And we understood the value of being able to send robots instead of humans into danger. It was this combination of societal impact and technical challenge that was appealing to us, especially in the context of a competition where you can’t just do work in the lab, write a paper, and call it a day—you had to develop something that would work all the way through the finals.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo of a quadruped robot moving through a cavern.  " class="rm-shortcode" data-rm-shortcode-id="fa4f4116bccec82c49c0cdf12274b508" data-rm-shortcode-name="rebelmouse-image" id="7406a" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-a-quadruped-robot-moving-through-a-cavern.png?id=29693512&width=980"/>
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo of a quadruped moving through a cavern next to a sign that says \u201cDANGER, Enter at your own risk.\u201d" class="rm-shortcode" data-rm-shortcode-id="2c3ac991e55024feccbcd31f99c5b279" data-rm-shortcode-name="rebelmouse-image" id="bec4d" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-a-quadruped-moving-through-a-cavern-next-to-a-sign-that-says-u201cdanger-enter-at-your-own-risk-u201d.png?id=29693504&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Tight cave sections [top] required careful navigation by ground
robots. Stalactites and stalagmites were especially treacherous for
drones in flight. At the right of the picture, partially hidden by a
column, is a blue coil of rope, one of the artifacts. A Team Cerberus
ANYmal [bottom] walks past a decorative (but not inaccurate) warning
sign, next to a drill artifact.
	</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Evan Ackerman</small>
</p><p>
<strong>What was the most challenging part of SubT for your team?</strong>
</p><p>
<strong>K.A.: </strong>We are at the stage where we can navigate robots in normal officelike environments, but SubT had many challenges. First, relying on communications with our robots was not possible. Second, the terrain was not easy. Typically, even terrain that is hard for robots is easy for humans, but the natural cave terrain has been the only time I’ve felt like the terrain was a challenge for humans too. And third, there’s the scale of kilometer-size environments. The robots had to demonstrate a level of robustness and resourcefulness in their autonomy and functionality that the current state-of-the-art in robotics could not demonstrate. The great thing about the SubT Challenge was that DARPA started it <em>knowing</em> that robotics did not have that capacity, but asked us to deliver a competitive team of robots three years down the road. And I think that approach went well for all the teams. It was a great push that accelerated research.
</p><p>
<strong>As robots get more autonomous, where will humans fit in?</strong>
</p><p>
<strong>K.A.:</strong> It is a fact now that we can have very good maps from robots, and it is a fact that we have object detection, and so on. However, we do not have a way of correlating all the objects in the environment and their possible interactions. So, although we can create awesome, beautiful, accurate maps, we are not equally good at reasoning.
</p><p>
	This is really about time. If we were performing a mission where we wanted to guarantee full exploration and coverage of a place with no time limit, we likely wouldn’t need a human in the loop—we can automate this fully. But when time is a factor and you want to explore as much as you can, then the human ability to reason through data is very valuable. And even if we can make robots that sometimes perform as well as humans, that doesn’t necessarily translate to novel environments.
</p><p>
	The other aspect is societal. We make robots to serve us, and in all of these critical operations, as a roboticist myself, I would like to know that there is a human making the final calls.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo of a flying drone hovering in a dark area.  " class="rm-shortcode" data-rm-shortcode-id="b51759f07d5db2a24103bcd02cffd04d" data-rm-shortcode-name="rebelmouse-image" id="4aaf2" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-a-flying-drone-hovering-in-a-dark-area.png?id=29693539&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">While most of the course was designed to look as much like real
underground environments as possible, DARPA also included sections
that posed very robot-specific challenges. Robots had the potential
to get disoriented in this blank white hallway (part of the urban
section of the course) if they couldn’t identify unique features to
differentiate one part of the hallway from another.
	</small>
<small class="image-media media-photo-credit" placeholder="Add Photo Credit...">Evan Ackerman</small>
</p><p>
<strong>Do you think SubT was able to solve any significant challenges in robotics?</strong><br/>
</p><p>
<strong>K.A.: </strong>One thing, of which I’m very proud for my team, is that SubT established that legged robotic systems can be deployed under the most arbitrary of conditions. [Team Cerberus deployed four ANYmal C quadrupedal robots from Swiss robotics company ANYbotics in the final competition.] We knew before SubT that legged robots were magnificent in the research domain, but now we also know that if you have to deal with complex environments on the ground or underground, you can take legged robots combined with drones and you should be good to go.
</p><p>
<strong>When will we see practical applications of some of the developments made through SubT?</strong>
</p><p>
<strong>K.A.:</strong> I think commercialization will happen much faster through SubT than what we would normally expect from a research activity. My opinion is that the time scale is counted in terms of months—it might be a year or so, but it’s not a matter of multiple years, and typically I’m conservative on that front.
</p><p>
	In terms of disaster response, now we’re talking about responsibility. We’re talking about systems with virtually 100 percent reliability. This is much more involved, because you need to be able to demonstrate, certify, and guarantee that your system works across so many diverse use cases. And the key question: Can you trust it? This will take a lot of time. With SubT, DARPA created a broad vision. I believe we will find our way toward that vision, but before disaster response, we will first see these robots in industry. 
	<span class="ieee-end-mark"></span>
</p><p>
<em>This article appears in the May 2022 print issue as “Robots Conquer the Underground</em><em>.”</em>
</p>]]></description>
      <pubDate>Sun, 24 Apr 2022 15:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/darpa-subterranean-challenge-2657170650</guid>
      <category>Darpa</category>
      <category>Subt</category>
      <category>Robotics</category>
      <category>Type:cover</category>
      <dc:creator>Evan Ackerman</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-photo-of-a-robot-lighting-up-a-stone-tunnel.png?id=29692504&amp;width=980" medium="image" type="image/png" />
    </item>
    <item>
      <title>Inventing Postscript, the Tech That Took the Pain out of Printing</title>
      <link>https://spectrum.ieee.org/adobe-postscript</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/photo-collage-of-two-smiling-bearded-men-the-background-is-a-spiral-of-text-getting-smaller.jpg?id=29708843&width=1200&coordinates=0%2C69%2C0%2C84&height=800"/><br/><br/><p><strong>Time and again,</strong> in his earliest attempts at controlling laser printers, John Warnock got the message, “Page Too Complex,” from a recalcitrant machine. Any system he designed, he vowed, would have to have a “Print Anything” architecture. That goal led ultimately to a page description language called PostScript, today the de facto standard of desktop publishing.</p><h3></h3><br/><p>This article was first published as "‘PostScript’ prints anything: a case history." It appeared in the May 1988 issue of <em>IEEE Spectrum. </em>A <a href="https://ieeexplore.ieee.org/document/4550" target="_blank">PDF version</a> is available on IEEE Xplore. The diagrams and photographs appeared in the original print version.</p><h3></h3><br/><p>Back then, Warnock already had a rough idea how to “Print Anything.” But later he ran into a different obstacle, when his employer, <a href="https://www.xerox.com/en-us" rel="noopener noreferrer" target="_blank">Xerox Corp</a>., proved loath to support a truly standard language. So off he went, with Charles Geschke and several other colleagues, to found <a href="https://www.adobe.com/" rel="noopener noreferrer" target="_blank">Adobe Systems Inc.</a> in Mountain View, Calif. By that time, PostScript was only two major pieces of research away, although one—the development of type font algorithms—was “a research project that had to succeed,” says Warnock, and the other had been described as one of the world’s most difficult problems.</p><p>The rest is desktop publishing history. PostScript can truly do anything, though extremely complex images can take as much as an hour of computation time. It first appeared in the Apple LaserWriter, which was introduced in January of 1985. Today it has been adopted by 23 manufacturers of laser printers, with more still signing on.</p><h3></h3><br/><p>This story is as much about luck and guts as about matters of principle and brilliant software engineering.</p><h3></h3><br/><p>Still, this story is as much about luck and guts as about matters of principle and brilliant software engineering. It would have been quite different had Warnock and company not been in the right place at the right time to meet the right person.</p><p>The time was right because of the imminence of three hardware developments: the first low-cost, bit-mapped personal computer, the first low-cost laser printer, and a decline in price of high-density memory chips. And the right person was Apple founder Steven Jobs, who invented the first, hoped for the second, and told Adobe to tough out the third.</p><h3>Defining terms</h3><br/><p><strong>Device-independent software</strong></p><p>Software not directly tied to a specific piece of hardware.</p><p><strong>Interpreter</strong></p><p>A program that translates an instruction in the source code of a high-level language into machine language by deciding on the fly what machine instructions best translate it before moving onto the next instruction in source code.</p><p><strong>Laser printer</strong></p><p>A device that, like a xerographic copier, draws an image on a drum, but with a laser beam instead of lenses; applies toner to the charged image area; and transfers the toner to a sheet of paper, melting it into the paper to set the image.</p><p><strong>Page description language</strong></p><p>A method of expressing the appearance of a printed image, including text, lines, and bit-mapped photographs.</p><p><strong>Postfix notation</strong></p><p>Also known as reverse Polish notation, the appearance of operators after the data on which they are to operate; thus 2 + 2 becomes 2 2 +.</p><h3></h3><br/><p>Today laser printers are rapidly replacing the daisy-wheel printers in the office, pushing out letter-quality type as their laser obeys the commands of simple software. But given more sophisticated software like PostScript, laser printers can do far more. They can print many different type fonts and make the letters dance around the page hand in hand with drawings and photographs. PostScript does all this implies—draws lines and curves, tilts text at arbitrary angles, or shades a photograph in various tones of gray. It is as complete and flexible a programming language as Pascal or C or Forth, having variables, loops, conditionals, operators, and routines and offering any number of ways to get the same output.</p><p>The PostScript program is created on the computer either by someone using the language or by desktop publishing software or other applications software that translates, say, the movements of a mouse into a PostScript program. (Other page description languages are optimized for one of these purposes, not both.) That program is sent over a local-area network or through an RS-232 port to the laser printer. There it is converted into instructions for the printer by the PostScript interpreter, software resident in ROM. On the same circuit board as up to 2 megabytes of ROM is a Motorola 68000 series processor, which executes the instructions and causes the pages to be printed.</p><p>Things were more elementary with the first laser printers, which were in regular use at the <a href="https://spectrum.ieee.org/behind-the-scenes-at-xerox-parcs-futures-day40-years-ago" target="_self">Xerox Palo Alto Research Center (PARC)</a> in the mid-1970s. They were controlled by a printing protocol called Press, which was not a programming language but a set of instructions that sent image data to a printer in a steady stream. It handled letters and simple images well, but for anything more detailed, got the printer to return the message: “Page Too Complex.” Thereupon the typical PARC engineer would simplify the image.</p><p>But when Warnock, a computer scientist with a Ph.D. from the <a href="https://www.utah.edu/" target="_blank">University of Utah</a>, joined the center in 1978, he immediately began work on a new printer protocol. Six years of experience at <a href="https://www.es.com/" rel="noopener noreferrer" target="_blank">Evans & Sutherland</a> in Mountain View, Calif., had taught him where to start.</p><h3></h3><br/><img alt="Two men with beards and mustaches seated near a creek bed with concrete sides" class="rm-shortcode" data-rm-shortcode-id="1791474c6c73f77b458141a8afa297f2" data-rm-shortcode-name="rebelmouse-image" id="84038" loading="lazy" src="https://spectrum.ieee.org/media-library/two-men-with-beards-and-mustaches-seated-near-a-creek-bed-with-concrete-sides.jpg?id=29705403&width=980"/><p class="caption">
	Adobe Systems founders John Warnock (right) and Charles Geschke visited Adobe Creek, inspiration for their company’s name. A dry winter has slowed the creek to a trickle, but the company has had anything but a dry year. The entrepreneurs in 1982 found Adobe a suitable name since the creek meandered near both their domes and, even more important, had none of the Qs, Xs, Ys, and Zs then popular with high-tech startups.
	<style class="photo-credit">
Christopher Springmann
	</style>
</p><h3></h3><br/><p>The PostScript program is created on the computer either by someone using the language or by desktop publishing software or other applications software that translates, say, the movements of a mouse into a PostScript program. (Other page description languages are optimized for one of these purposes, not both.) That program is sent over a local-area network or through an RS-232 port to the laser printer. There it is converted into instructions for the printer by the PostScript interpreter, software resident in ROM. On the same circuit board as up to 2 megabytes of ROM is a Motorola 68000 series processor, which executes the instructions and causes the pages to be printed.</p><p>Things were more elementary with the first laser printers, which were in regular use at the <a href="https://spectrum.ieee.org/behind-the-scenes-at-xerox-parcs-futures-day40-years-ago" target="_self">Xerox Palo Alto Research Center (PARC)</a> in the mid-1970s. They were controlled by a printing protocol called Press, which was not a programming language but a set of instructions that sent image data to a printer in a steady stream. It handled letters and simple images well, but for anything more detailed, got the printer to return the message: “Page Too Complex.” Thereupon the typical PARC engineer would simplify the image.</p><p>But when Warnock, a computer scientist with a Ph.D. from the <a href="https://www.utah.edu/" target="_blank">University of Utah</a>, joined the center in 1978, he immediately began work on a new printer protocol. Six years of experience at <a href="https://www.es.com/" rel="noopener noreferrer" target="_blank">Evans & Sutherland</a> in Mountain View, Calif., had taught him where to start.</p><h3>Simulating New York Harbor</h3><br/><p>In 1971, Evans & Sutherland had undertaken to equip the New York Maritime Academy with a simulator for training harbor pilots. The trainees were to sit on the mockup of a ship’s bridge, surrounded by five 12-foot-high, 30-ft-long (3.6-by-9 meter) screens displaying a computer-generated representation of New York Harbor, complete with buildings, piers, movable buoys, changing weather conditions, and other ships to be avoided. The system had to produce images in full color for five projectors at 30 frames a second.</p><p>Evans & Sutherland had never produced anything as complex. It let time slip by until, with only one of the contract’s three years left, “everybody hit the panic button,” Warnock says. So to save time, the company had the hardware and software developed in parallel, the first in Utah and the second by a team led by Warnock in California.</p><p>The rush planted the first two seeds for what was to become PostScript. Obviously, a database listing everything in the harbor was both essential and would have to be built in total ignorance as to the hardware it would eventually run on. So Warnock’s team decided to invent a language unrelated to any computer. Only when the simulator hardware was ready would they build a compiler to translate the database into the appropriate machine language.</p><p>Meanwhile, feeding information about the harbor into the database proved arduous. Putting maps on a digitizing tablet and touching them with a stylus at numerous points was not so bad; but using a keyboard to enter the details—whether the point touched was a pier of a certain type or a building or an island—was slow going. To make this task easier, John Gaffney, one of Warnock’s group, spent a weekend writing a software routine that would generate the information about the objects from menus.</p><h3></h3><br/><img alt="Two spirals of text in ever smaller letters" class="rm-shortcode" data-rm-shortcode-id="70c6520ab741225dba84dd578aececcd" data-rm-shortcode-name="rebelmouse-image" id="70842" loading="lazy" src="https://spectrum.ieee.org/media-library/two-spirals-of-text-in-ever-smaller-letters.jpg?id=29666403&width=979&coordinates=55%2C52%2C63%2C288&height=1277"/><h3></h3><br/><p>By the time the harbor simulator was completed, only slightly behind schedule, Warnock had discovered how powerful an object-oriented language is. Unlike Basic or Fortran, say, which require the user to spell out every last instruction, it packs all those details into modules, or objects, which the user controls with just a few directives. Warnock had also discovered that making software device-independent “gives you a great deal of leverage and flexibility.”</p><p>Those lessons learned, his group turned to expanding Gaffney’s little interpreter into a full programming system for computer-aided design (CAD). In 1977, that project was released by Evans & Sutherland as The Design System. “It had an interactive, stack-oriented architecture,” Gaffney said, “with simple commands for pushing and popping arguments onto and from the stack and a rich dictionary for look-ups.” (Such an architecture stores data as it is received, stacking it like a pile of books. A command like “add” would “pop” the topmost pieces of data from the stack, act on them, and “push” the result back on the pile.)</p><p>Only one copy of The Design System was ever released, as a test bed for the final development, but the other company’s project director died and The Design System died with him. Warnock, however, took the stack and dictionary ideas—along with what he had learned from the harbor project—to PARC.</p><h3>A “Jam” session</h3><br/><p>PARC was then using a programming language called Mesa. In 1978, soon after arriving at the center, Warnock persuaded another Xerox researcher, Martin Newell, to help him re-create The Design System in Mesa. The result, called Jam, for John and Martin, proved the concepts he brought from Evans & Sutherland were appropriate for laser printing.</p><p>Jam was object oriented and device independent, like the harbor simulator, and in some ways simpler than The Design System, because printing requires only two dimensions, versus CAD’s three. But it needed a few features, such as type fonts, found in neither of its ancestors. Moreover, Warnock recalls, “Xerox was using a different printing scheme on every printer. The Star workstations [then being developed] were crumbling under the load of trying to drive them all differently.”</p><p>So Warnock and a group of researchers headed by Charles Geschke set out to merge Jam with the older Press protocol into Interpress, a standard, device-independent language capable of driving all Xerox Corp.’s laser printers. Interpress was completed in 1981, but unhappily, the end was not in sight. Because of the compromise between Jam and Press, “the language became complicated in its redesign,” Warnock says. And Xerox begged the issue of standardization by producing several versions of the language, so the company’s older laser printers could run some form of it.</p><h3></h3><br/><img alt="Large type spelling out Spectrum with lines of Postscript code highlighted in red, blue, yellow, and purple" class="rm-shortcode" data-rm-shortcode-id="52f04472a70f18e8f7d0fd0a5565bfb6" data-rm-shortcode-name="rebelmouse-image" id="5894c" loading="lazy" src="https://spectrum.ieee.org/media-library/large-type-spelling-out-spectrum-with-lines-of-postscript-code-highlighted-in-red-blue-yellow-and-purple.jpg?id=29666417&width=969&coordinates=75%2C70%2C66%2C675&height=1001"/><h3></h3><br/><p>Worst of all, to Warnock, was the insistence that printers always run at their rated speeds. Since a 20-page-per-minute printer could not produce anything very complex in three seconds, he was back facing his “Page Too Complex” nemesis. The constraint derived from the copier business, Geschke explains, where “pricing of leased machines was based on copies per day. But in electronic printing, in our opinion, function was most important, so there was a real variance between our and the Xerox position.”</p><p>All the same, in the belief that any standard was better than none, Warnock and Geschke began promoting Interpress within Xerox Corp. Eventually, they won—sort of. But Xerox added, Warnock recalls, “’We’re going to keep it a secret because it is so wonderful and if we publish it the Japanese might implement it before we do.’ “Gee,’ I said, ‘A secret standard—I find this a hard concept to understand.’”</p><p>Convinced that Xerox was making a mistake, Warnock and Geschke left PARC to implement their page description language once again, but this time within a corporation they controlled. With the help of David Evans of Evans & Sutherland and William Hambrecht of Hambrecht and Quist, a San Francisco-based venture capital firm, they wrote a business plan and incorporated in December of 1982.</p><h3></h3><br/><p>They intended both to sell this setup as a turnkey system and to franchise the publishing equivalent of a one-hour photo store.</p><h3></h3><br/><p>Desktop publishing, though, was not what Warnock and Geschke at first had in mind. The system they foresaw consisted of a workstation linked by a device-independent, page-description language like Jam to a laser printer for draft printing, a photo-typesetter for the final output, and whatever other output device they might later add. No other publishing package then available used the same software for different output devices. And they intended both to sell this setup as a turnkey system and to franchise the publishing equivalent of a one-hour photo store.</p><p>Adobe then consisted of Warnock, Geschke, and a core of other engineers hired from PARC: Daniel Putman, Thomas Boynton, and Douglas Brotz. As they planned to buy whatever hardware they needed after they had perfected their programming language, they focused first on Jam. They worked in C, on a VAX 750 running Berkeley Unix, to develop the language, and they tested in on a Sun workstation driving a full-size laser printer that they had borrowed from Digital Equipment Corp. “At that time,” recalls Putman, “most companies required that we spell our names and pay in cash, so we had to beg, borrow, and steal the tools to prototype PostScript.”</p><p>To avoid copyright problems, they licensed The Design System concepts from Evans & Sutherland. They were free to use their PARC research results, as those had been published.</p><h3></h3><br/><img alt="a cross section of mineral deposits under the earth, with a cutaway showing details. Labels indicated sandstone, limestone, surface stream flows into underground river, sinkhole, and mineral deposits from seepage create stalactites and stalagmites" class="rm-shortcode" data-rm-shortcode-id="65ac850aa8be3de3b2744805959f5cf0" data-rm-shortcode-name="rebelmouse-image" id="4308e" loading="lazy" src="https://spectrum.ieee.org/media-library/a-cross-section-of-mineral-deposits-under-the-earth-with-a-cutaway-showing-details-labels-indicated-sandstone-limestone-surface-stream-flows-into-underground-river-sinkhole-and-mineral-deposits-from-seepage-create-stalactites-and-stalagmites.jpg?id=29666423&width=2035&coordinates=52%2C74%2C65%2C83&height=1207"/><h3></h3><br/><p>Warnock and Geschke were not close-mouthed about their plans, and soon not only Jobs heard (he was then chairman of <a href="https://www.apple.com/" target="_blank">Apple Computer Inc.</a> of Cupertino, Calif.) but also C. Gordon Bell, then vice president of engineering at Digital Equipment in Maynard, Mass. Bell told the pair that six research teams at Digital had been trying for years to devise a decent means of driving its laser printers, and if Adobe could solve the problem, Digital would be interested in licensing the solution.</p><p>Jobs had been facing a similar problem. The Macintosh was well into development, but without a letter-quality printer would go nowhere in the business market. Daisy-wheel printers were out of the question, because they could not produce the bit-mapped graphics basic to the Macintosh. But Apple’s own engineers could not get high-quality graphics out of a laser printer in time for the Macintosh introduction.</p><h3></h3><br/><p>Jobs suggested that Adobe become a software company, sell to manufacturers instead of at retail, and negotiate a licensing agreement with Apple.</p><h3></h3><br/><p>Undeterred, Jobs and Robert Belleville, then director of engineering for Apple and now director of strategic planning for Convergent Technologies Inc., San Jose, Calif., had dreamed up the perfect Macintosh laser printer—one that could produce all the fonts in the world with no help from a disk drive. But they lacked “the slightest idea of how to do this,” says Belleville, until he ran into Putman at a cocktail party, heard what Adobe was doing, and brought Jobs over for a visit.</p><p>“I was overjoyed!” recalls Belleville. “Their system could do simple things fast and also do full graphics and scanned images. And when I saw font scaling was possible across such wide ranges, we were sold.”</p><p><span></span>Jobs suggested that Adobe become a software company, sell to manufacturers instead of at retail, and negotiate a licensing agreement with Apple. Adobe liked the idea, signed the agreement with Apple at the end of 1983, and much to Hambrecht & Quist’s surprise, showed a profit at the end of its first year.</p><h3>Font algorithms</h3><br/><p>Reimplementing the Jam language with its object orientation, stacks, postfix notation (in which operands precede their operators), and dictionary was relatively straightforward. Most of the research had been completed at Evans & Sutherland and at PARC. Basically all Adobe had to do was engineer it into a product, named PostScript after the postfix notation it uses and because it was to be the last thing that happened to an image before it was printed. Also, since the product had to “Print Anything,” it had to put functionality above speed and cost—the three factors traded off in the design of microprocessor systems like the one that would control the laser printer, explains Putman, now vice president of engineering at Adobe. Still, two key breakthroughs remained to be made.</p><p>One of them was creating the font algorithms, proprietary formulas for the creation of text. “Even with Interpress,” says William Paxton, director of advanced development for Adobe, “fonts were a wart on the side of an otherwise elegant design.” Interpress could do arbitrary transformations, like scale and rotate, on images, but in its early versions could not do them on bit-mapped text without degrading its quality.</p><p>PostScript, however, unifies text and graphics by storing the fonts as outline representations of the letters, not as bit maps. Back in early 1983, however, this unification was easier to propose than to realize. “Getting high-quality fonts from outline representations of characters was seen as an insoluble problem,” Warnock says, because it was hard to produce smooth curves of varying widths without jagged edges. Print quality seemed unobtainable from anything less than a phototypesetter.</p><p>But in mid-1983, Warnock says, he had an idea for a fundamentally new set of algorithms that might do the trick. His initial experiments promised success, so he set Paxton to refining the algorithms. The results are proprietary and are encrypted inside the ROMs that contain PostScript instructions because this font technology is the key distinction between Adobe’s product and others.</p><p>So successful was Adobe’s solution to the font problem that Linotype, Letraset, and other owners of the most popular typeface designs were willing for the first time to license the outline representations of their typefaces. No earlier technology had done them justice. (Ironically, Adobe is now licensing its font technology to Linotype, and Linotype is converting its entire library of some 2000 fonts into PostScript representations.)</p><p>Adobe’s other technical breakthrough is the algorithm, called Reducer, that breaks down complex shapes into simpler ones easier for PostScript to describe. Such an algorithm is a key component of any graphics language, and theoretical papers about a universal form of it were numerous: but, says Brotz, “they tended to gloss over the hard cases that arise in real applications—figures with large amounts of data and multiple intersections at the same point, for example.” So when the page printed, certain images would come out badly fragmented or warped, violating Adobe’s “Print Anything” rule.</p><p>“About a week after I had joined Adobe in 1983,” Brotz recalls, “John Warnock mentioned this rather important algorithm that had to be written. And I, with no graphics background, volunteered. Several months later, older and wiser, I realized it truly was one of the world’s hardest problems.”</p><p>But Brotz did not give up, and he says, “We have now an exactly correct reducer algorithm. It is the heart of the graphics system in PostScript.” And a tally Brotz keeps reveals that no bugs have been discovered in the Reducer in more than two years.</p><h3></h3><br/><p>
	“Warnock promptly labeled [the procedure] ‘Andy’s Stupid Input Device'....[but] it turned out that Andy’s Stupid Input Device was the lowest common denominator and all the special-case code could disappear.” —Douglas Brotz
</p><h3></h3><br/><p>Adobe had agreed to deliver its software for installation into the LaserWriter during the summer of 1984. But because of marketing and manufacturing concerns, the LaserWriter itself was to be introduced in January of 1985. So the Adobe engineers used the time to tighten the code (the final release contained some 200,000 bytes) and fine-tune the algorithms. They also made some more specific changes.</p><p>One had to do with handling input devices. As originally conceived, PostScript was to have been independent of the output, but not the input, device. Warnock had thought that PostScript, to take in scanned images, would need to contain information about a wide range of optical scanners. But Brotz, after programming the parameters of just two of many scanner types, realized that the task was not only horrendous and repetitive but ate up a lot of memory.</p><p>Andy Shore, an Adobe computer scientist, overheard him complaining one day and suggested writing a PostScript procedure that would pretend that it was an input device and spit out the image information in a standard format, regardless of the characteristics of the actual standard. Brotz did not think it would work and “Warnock promptly labeled it ‘Andy’s Stupid Input Device.'”</p><p>Still, Brotz thought it might be helpful for generating test patterns, and when he implemented it, “it turned out that Andy’s Stupid Input Device was the lowest common denominator and all the special-case code could disappear.” Problems arise only when the image data has been compressed for transmission or storage; the programmer then has to insert a routine to decompress the data before it is handed to the image algorithm.</p><p>Another improvement involved performance profiling—running various tests to see what frequently used functions slowed down operation. Floating-point routines were the chief culprits because they are computationally intensive. So the team took some of the algorithms for the common operations, such as breaking curves into vectors and drawing outlines, and rewrote them in less flexible fixed-point arithmetic. Now only when fixed-point arithmetic would be too imprecise does the interpreter call the floating-point routine.</p><p>“So with no loss of generality,” says Edward Taft, Adobe senior computer scientist, “we were handling 99 percent of the cases five times faster than we were before.”</p><p>To improve the other 1 percent, Belleville sent one of his engineers over from Apple—<a href="https://people.eecs.berkeley.edu/~wkahan/ieee754status/754story.html" target="_blank">Jerome Coonen, a recognized expert in floating point</a>. He optimized the algorithms so, Taft says, “whereas formerly an algorithm required six multiplies, four divides, and three square roots, now it only required three multiplies, four divides, and some approximation of a square root.”</p><h3></h3><br/><p>
	“We came from the school of thought that software is soft. So if you have problems, you just have another release. But Apple was telling us, ‘Hey, we always ship our system in ROM, why can’t you?’” —Douglas Brotz
</p><h3></h3><br/><p>Throughout the design of PostScript, speed was regularly traded off to ensure that any image would print. The group reasoned that if they built in all this functionality, they could eventually improve the performance; but if they left out functions, they might never be able to add them back in.</p><p>However, says Putman, sometimes they had doubts. So they designed a version of PostScript that spat out information as fast as the laser moved across the page. The expense of the frame buffer was eliminated—along with the ability to print pages too complicated for the software to process in time.</p><p>Adobe called this implementation Subscript, but dropped it after six months. As Taft says, “If you’re trying to promote a standard, there is nothing worse than issuing a subset of the standard. It means that all of the applications are going to be targeted to the lowest common denominator.”</p><p>Debugging throughout the project was strenuous because the Adobe team was “terrified of putting all this code out on ROMs,” Brotz says. “We came from the school of thought that software is soft. So if you have problems, you just have another release. But Apple was telling us, ‘Hey, we always ship our system in ROM, why can’t you?’”</p><p>In January of 1985 the Apple LaserWriter was introduced, virtually bug-free. In 1984, Adobe signed licensing agreements with QMS Inc., <a href="https://www.linotype.com/" target="_blank">Linotype</a>, and Dataproducts Corp. Today, even <a href="https://www.hp.com/" rel="noopener noreferrer" target="_blank">Hewlett-Packard Co.</a>, whose PCL page description language was one of PostScript’s earliest competitors, is among the 23 companies offering PostScript interpreters for their printers.</p><h3>Cheap pays off</h3><br/><p>Although the Adobe group made some key technical breakthroughs, three other components were necessary to make PostScript a runaway success not just in low-volume professional publishing but in the high-volume office environment.</p><p>As noted earlier, one was a cheap laser printer. When Adobe was founded, the cheapest cost around $10,000. It also weighed as much as a desk, so that it had to be serviced on site and sold through a distributor, not on a cash-and-carry basis. Then <a href="https://global.canon/en/" target="_blank">Canon Inc</a>., of Tokyo, Japan, introduced the Canon LBP-CX desktop laser printer, which, moreover, printed beautifully. “If it had been poor xerography,” says Paxton, “it wouldn’t have mattered how good our technology was.”</p><p>Also on the horizon was a bit-map-based personal computer—<a href="https://spectrum.ieee.org/thirty-years-later-the-influence-of-the-macintosh-can-still-be-felt" target="_self">the Apple Macintosh</a>. All previous low-cost personal computers had used character graphics, for which daisy-wheel printers made more sense.</p><h3></h3><br/><p>“The projections were that the RAM prices were going to drop, but you had to have a very strong stomach to be able to go up to the wall and pray that the door was going to open.”—William Paxton</p><h3></h3><br/><p>The third piece of luck was the decline in the price of memory chips. “We started this development on an uneconomic basis,” Warnock says. “The LaserWriter’s first controller needed forty-eight 256K DRAM chips, which up to December of 1984 cost about $30 each. That meant Apple would have had to sell that machine for about $10,000—but its computer cost $2400.”</p><p>But, with Belleville’s and Jobs’s strong support, the Adobe team bet that the memory process would drop. “Sure,” says Paxton, “the projections were that the RAM prices were going to drop, but you had to have a very strong stomach to be able to go up to the wall and pray that the door was going to open.”</p><p>Warnock comments, “Most companies will only deal with present-day technology and known costs. The brilliance of Steve Jobs is that he will say, ‘There will be this chip coming out at that price point at that time, and I will design my product to use it.’” And indeed, when the LaserWriter was announced in January of 1985, 256K RAMs cost about $4 each and the printer could be priced at $6995.</p><p>Today, some 40 companies have announced their equipment is compatible with PostScript and that their interpreters run faster and cost less than Adobe’s version. They cannot offer the same font library, but they say they have fonts and font algorithms as good as Adobe’s. At this writing, however, none of these companies had apparently shipped a PostScript clone to a customer, and they reportedly have found it harder to replicate Adobe’s work than they had anticipated.</p><p>When they do finally ship, and if they can interpret 80 or 90 percent of PostScript programs, Adobe is resigned to facing “good old-fashioned American competition,” says Geschke. The company has no patents to defend, only copyrights and trade secrets, so if other companies can reproduce Adobe’s technology, it has no legal recourse. “The most we can do is to continue to improve our technology,” Geschke says.</p><h3>What’s NeXT?</h3><br/><p>
	Adobe’s latest technical breakthrough, demonstrated in San Francisco in January, is a version of PostScript that controls images on a computer screen as well as on a printed page. Called Display PostScript, this product is the first to provide device-independent graphics for computer screens.
</p><p>
	Display PostScript, like the original PostScript printer protocol, had a nudge from Jobs. His new company, NeXT Inc., Palo Alto, Calif., worked with Adobe to develop it, and it will be the graphics standard for all NeXT’s computers. Digital Equipment has already licensed Display PostScript for its DEC Windows workstation architecture. If other major companies follow, Adobe could be well on the way to setting its second standard.
	<span class="ieee-end-mark"></span>
</p><h3>To probe further</h3><br/><p>Everything a programmer or user might want to know about the PostScript language is provided in “<a href="https://freecomputerbooks.com/PostScript-Language-Tutorial-and-Cookbook.html" rel="noopener noreferrer" target="_blank">PostScript Language Tutorial and Cookbook</a>“ and “<a href="https://www.adobe.com/jp/print/postscript/pdfs/PLRM.pdf" rel="noopener noreferrer" target="_blank">PostScript Language Reference Manual</a>,” both written by Adobe Systems Inc. and published by Addison Wesley Publishing Co. (New York, 1985). In addition, Adobe periodically publishes a newsletter, “Colophon,” with programming tips and news about PostScript products.</p><p>Interpress, the page description language from Xerox Corp.’s Palo Alto Research Center (PARC) that preceded PostScript in the laboratory but followed it in the marketplace, is described in the June 1986 issue of IEEE’s magazine, <em>Computer</em> (pp. 72-77). For more information on Xerox PARC, see “Inside the PARC: the ‘information architects,’” <em>Spectrum</em>, October 1985, p. 62.</p><p>“Window on PostScript” in <em>MacWeek</em>, Feb. 2, 1988, pp. 28-29, contains a discussion of competitors’ attempts to clone the language.</p><h3></h3><br/><p><em><strong>Update April 2022: </strong>While most home and office printers rely on other page description languages these days, PostScript remains the choice of graphics artists and commercial printers for its ability to accurately produce complex images. And the ubiquitous Portable Document Format (PDF) is based on PostScript.</em></p><p><br/><span></span></p>]]></description>
      <pubDate>Sat, 23 Apr 2022 19:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/adobe-postscript</guid>
      <category>Postscript</category>
      <category>Xerox parc</category>
      <category>Software engineering</category>
      <category>Adobe</category>
      <category>Design case history</category>
      <category>John warnock</category>
      <category>Charles geschke</category>
      <category>History of technology</category>
      <dc:creator>Tekla S. Perry</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/photo-collage-of-two-smiling-bearded-men-the-background-is-a-spiral-of-text-getting-smaller.jpg?id=29708843&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Tesla Inside: The Ultimate Vintage Land Rover Retrofit</title>
      <link>https://spectrum.ieee.org/electric-land-rover</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/this-photo-shows-a-parked-land-rover-that-is-plugged-into-a-tesla-charging-station.jpg?id=29696930&width=1200&coordinates=457%2C0%2C457%2C0&height=800"/><br/><br/><p>
<strong>From the outside,</strong> this Land Rover Defender looks like any other example of the <a href="https://www.youtube.com/watch?v=ZdB1tLdTY9E" target="_blank">postwar British classic</a> that conquered the African outback—and the automotive world’s heart. But when I step on the accelerator, my own heart jumps. The Defender charges like a lioness on a wildebeest’s scent, slaying 60 miles per hour (almost 100 kilometers per hour) in about 5 seconds. That acceleration is so out of character for this doughty old truck, and so fun, that I’m forced to do it again.
</p><p>
	Clearly, that’s no lazy Rover diesel chugging below the hood—or even a Chevrolet V-8, a current go-to engine for vintage-car fans seeking a contemporary edge. This Defender, known for
	<a href="https://www.automuse.co.nz/news/land-rover-defender-tomb-raider-up-for-auction-lara-croft-not-included" target="_blank"> raiding tombs</a>, has raided Tesla’s temple of tech.
</p><p>
	The Insta-worthy specimen I’m driving—dubbed “Project Britton” and built by 
	<a href="https://ecdautodesign.com/" target="_blank">E.C.D. Automotive Design</a> (formerly East Coast Defenders), in Kissimmee, Fla.—highlights the small-but-growing phenomenon of people converting fossil-fueled cars to run on electricity. It’s also a plug-in twist on the hottest thing in car customization: “<a href="https://books.google.com/ngrams/graph?content=restomod&year_start=1800&year_end=2019&corpus=26&smoothing=3&direct_url=t1%3B%2Crestomod%3B%2Cc0" target="_blank">restomods</a>,” which update classics with modern power trains, suspensions, and creature comforts, all hidden under their vintage skins.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Photo of the body-off frame of the vehicle." class="rm-shortcode" data-rm-shortcode-id="b89919a48108fbb7968f10fb2d4cb24f" data-rm-shortcode-name="rebelmouse-image" id="b1d01" loading="lazy" src="https://spectrum.ieee.org/media-library/photo-of-the-body-off-frame-of-the-vehicle.jpg?id=29692416&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Refurbishment begins with the vehicle’s frame, which is stripped, galvanized, and repainted.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">E.C.D. Automotive Design</small>
</p><p>
	Around the world, specialists like E.C.D. and its power-train designer and supplier, 
	<a href="https://www.electricclassiccars.co.uk/" target="_blank">Electric Classic Cars,</a> in Newton, Wales, will replace a car’s petroleum-clogged heart and give it a new, electric lease on life.
</p><p>
	For this baby-blue Rover, the conversion includes a powerful electric drive unit from a 
	<a href="https://www.tesla.com/blog/new-tesla-model-s-now-quickest-production-car-world" target="_blank">Tesla Model S P100D,</a> which provides 450 horsepower (331 kilowatts) in this application. That’s three times the output of the <a href="https://www.ultimatespecs.com/car-specs/Land-Rover/417/1979-Land-Rover-Range-Rover-V8.html" target="_blank">Buick-based Rover V-8</a> that first powered these trucks in 1979, and nine times that of the anemic 50-hp gasoline engine the Rover boasted at its birth, in 1948.
</p><p>
	The car holds about 100 kilowatt-hours’ worth of lithium-iron phosphate (LFP) batteries—a lower-cost approach used for the Teslas sold in China and Europe (and 
	<a href="https://www.cnbc.com/2021/10/20/tesla-switching-to-lfp-batteries-in-all-standard-range-cars.html" target="_blank">recently adopted</a> for standard-range Teslas in the United States).
</p><p>
	About 60 percent of those cells go into the front engine bay; the rest reside below the cargo hold. That gives the hardy Rover a range of up to 350 kilometers (about 220 miles)—plenty for weekend joy rides. A port mounted on a rear fender connects a standard CCS (<a href="https://en.wikipedia.org/wiki/Combined_Charging_System" target="_blank">Combined Charging System</a>) plug to an onboard 7-kW charger.
</p><p>
	E.C.D. Automotive Design is the brainchild of three British petrolheads, Scott Wallace and brothers Tom and Elliot Humble, who grew up not far from the 
	<a href="https://en.wikipedia.org/wiki/Solihull_plant" target="_blank">Lode Lane factory</a> that built the Defender. The company was founded in 2013, after a brainstorming session over a case of beer in a Florida garage.
</p><p>
	“We said, ‘Let’s take a British farm vehicle and turn it into a luxury SUV for the American market,’ ” Wallace recounts during my tour of E.C.D.’s “<a href="https://ecdautodesign.com/facility/" target="_blank">Rover Dome</a>,” its 45,000-square-foot (about 4,200-square-meter) production facility. “After every beer, it sounded like a better idea.”
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="Photo of a technician working on wiring harnesses." class="rm-shortcode" data-rm-shortcode-id="78b5ff550405432cfd8c4e3138b6aea7" data-rm-shortcode-name="rebelmouse-image" id="357c7" loading="lazy" src="https://spectrum.ieee.org/media-library/photo-of-a-technician-working-on-wiring-harnesses.jpg?id=29692520&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Technicians revamp the car’s electrical wiring, including the notoriously unreliable 12-volt circuits.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">E.C.D. Automotive Design</small>
</p><p>
	The lads might want to pop another cold one: Business is rocking, as evidenced by a visit to the company’s sparkling 100,000-square-foot (about 9,300-square-meter) 
	<a href="https://ecdautodesign.com/2021/09/07/ecd-new-facility/" target="_blank">production center</a>, set to open in August. There, more than 60 employees and two production lines will have the capacity for 100 conversions a year.
</p><p>
	Wallace figures one in five customers will choose an electric power train, with the rest opting for more-traditional, hot-rod-style upgrades such as “LS swaps,” named after the LS family of Chevrolet V-8 gasoline engines. EV conversions here and elsewhere are seizing both imaginations and wallets, as classic-car fans focus on improved performance, reliability, and ease of maintenance, with the environmental benefits a green icing on the cake.
</p><p>
	Porsches, Jaguars, Fiats, VW Beetles and Buses, even Ferraris, have all gone under the knife, with an increasing number of entrepreneurs serving this growing market. Some major automakers are even getting in on the act. They see a potential sideline in electric versions of the “<a href="https://spectrum.ieee.org/an-electric-motor-that-works-in-any-classic-car" target="_self">crate motors</a>” that they’ve sold for decades to hobbyists, hot-rodders, restorers, and racing teams.
</p><p>
<strong>The Land Rover</strong> Defender is a good candidate for conversion because it has long had a fanatical following, with 2 million units sold around the globe between 1948 and its retirement in 2016. Rover estimates that 70 percent of these hardy survivors—beginning with the Land Rover “Series” models, with the “Defender” name added in 1990—<a href="https://media.landrover.com/news/2015/04/land-rover-heritage-be-launched-techno-classica-show" target="_blank">remain on the road</a>.
</p><p>
	Despite some cosmetic changes, and steadily upgraded power trains, the design of its stout-yet-primitive chassis barely changed for more than half a century. In America, Defenders have typically been weekend playthings for boomers with fond memories of 
	<a href="https://en.wikipedia.org/wiki/Born_Free" target="_blank"><em>Born Free</em></a> or “<a href="https://en.wikipedia.org/wiki/Daktari" target="_blank">Daktari</a>”—a typical SUV buyer might run screaming after five minutes in this crude, jouncy beast. Roughly 7,000 Americans got their hands on a new Defender via the NAS models that Rover sold to Yanks between 1993 and 1995, with a final encore in 1997.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt='A photo of what is seen under the hood: a large metal box marked "Powered by Tesla."' class="rm-shortcode" data-rm-shortcode-id="dd077071781befb42f61bd8f8d867586" data-rm-shortcode-name="rebelmouse-image" id="5ba7c" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-of-what-is-seen-under-the-hood-a-large-metal-box-marked-powered-by-tesla.jpg?id=29692526&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">Running at higher voltage is the car’s new electric power electronics, originally designed to propel a Tesla.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">E.C.D. Automotive Design</small>
</p><p>
	Their rarity only fueled a desire for Defenders among U.S. car buyers, spawning a gray market for imports. Non-NAS Rovers were never officially “federalized” to meet U.S. regulatory standards, so that booming trade led to many confiscations, and at least one Defender crushing by border officials and the Department of Homeland Security.
</p><p>
	To avoid breaking the law, the Defender you import must be at least 25 years old. But even ratty junkyard specimens are now worth serious money as the starting point for Cinderella-like makeovers. Those taking on such a challenge benefit from the Defender’s rust-free aluminum body panels, born from necessity during the steel shortages of postwar England.
</p><p>
	Today’s love affair with the Defender is just part of a larger craze. Nostalgic 4x4 trucks, including Toyota Land Cruisers and Jeeps, have never been more popular or prized. Ford took advantage with a rock-crawling, retro-tinged 
	<a href="https://www.motortrend.com/reviews/2021-ford-bronco-first-drive-review/" target="_blank">Bronco</a>, revived in 2021: Its entire production sold out in advance for two years. And yes, <a href="https://spectrum.ieee.org/2021s-top-ten-tech-cars-land-rover-defender" target="_self">in 2020</a> Land Rover introduced the first fully redesigned Defender since the Second World War, one so posh and powerful that old-school fans might barely recognize it.
</p><p>
	Giving an older Defender an electric powertrain doesn’t alter its charming looks, of course, nor its ability to conquer forbidding terrain. And while restorers are at it, they figure, there’s no harm in addressing long-standing design flaws or adding a few modern conveniences.
</p><p>
	In an outdoor courtyard at E.C.D., sit a motley group of Defenders and Range Rover Classics (an up-market model that Land Rover introduced in 1969) in various stages of construction. Two scabrous Defender pickups languish at one end, both soon to have their steel frames stripped to bare metal, dipped in molten zinc, and powder-coated. The results could pass for brand-new frames.
</p><p class="pull-quote">
	With Tesla now building close to 1 million cars a year, conversion companies need only a tiny percentage to crash to fill their warehouses with needed components with needed components.
</p><p>
	Farther down the line are somewhat newer Defender body panels waiting to be refurbished, hand-sanded, and then covered with Ferrari-quality 
	<a href="https://us.ppgrefinish.com/PPG-Refinish/products.aspx" target="_blank">PPG paint</a>. Many customers choose a custom, one-off shade. Wallace recalls a woman tearing a strip of fabric from her dress to use as a color swatch, then accompanying a tech into the paint booth to help spray samples.
</p><p>
	Each of E.C.D.’s electric conversions spends about 100 days moving through 20 discrete shop bays, where it undergoes about 2,200 person-hours of meticulous restoration.
</p><p>
	In a nearby office, a technician creates interactive animated renderings of ongoing projects, which owners can scrutinize from afar to make adjustments. A dizzying range of bespoke features includes seats upholstered in alligator or ostrich hide, audiophile sound systems, and 
	<a href="https://www.warn.com/" target="_blank">Warn</a> winches for off-road recoveries.
</p><p>
	The buyer of the Defender I test-drove specified a teak-lined cargo area with boxed storage for his ski gear. E.C.D. had to create that yacht-style trim while still maintaining access to the Tesla batteries and cooling system below.
</p><p>
	In one work bay, I see the beefy drive unit from a Tesla peeking from the console space between front seats of this Defender, where the transfer case once lived. This drive unit was designed to send power through two half-shafts to the rear wheels of the Tesla Model S. For this application, the motor is pushed forward and rotated 90 degrees to drive both front and rear Rover axles, with the torque evenly split.
</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="This black-and-white image shows a 1954 Land Rover Series 1 model, a boxy vehicle with a flat windshield and its spare tire mounted on the hood. " class="rm-shortcode rm-resized-image" data-rm-shortcode-id="d30689d4f9f855f9940f4d9d2d23613e" data-rm-shortcode-name="rebelmouse-image" id="47738" loading="lazy" src="https://spectrum.ieee.org/media-library/this-black-and-white-image-shows-a-1954-land-rover-series-1-model-a-boxy-vehicle-with-a-flat-windshield-and-its-spare-tire-mounted-on-the-hood.jpg?id=29709037&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">The Defender is an outgrowth of Land Rover’s original Series 1 model, whose utilitarian lines are evident in this 1954 example.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit..." style="max-width: 100%;">Land Rover</small></p><p>
	For the Defender application, the single-speed Tesla motor unit required adding a limited-slip differential to divvy power between front and rear wheels, with a 50/50 torque split. The Rover’s axles and driveshafts are beefed up to withstand the electric motor’s immense power and torque. Project leaders explain to me that there’s no need for the low-range “crawl” gear typically found on such vehicles, because Tesla’s electric motor provides a whopping 475 newton-meters (350 pound-feet) of torque at zero speed.
</p><p>
	The biggest retrofitting challenge is finding space for motors and batteries in cars that were never designed for them—and ensuring the chassis can carry them safely and securely. Richard Morgan, the founder of Electric Classic Cars, says the stars aligned with the Defender: The drive unit fits perfectly between the Rover’s frame rails, with just a few millimeters to spare on either side. Fitting the batteries was harder, requiring the fabrication of custom battery cases.
</p><p>
	And while safety experts emphasize that EVs are as safe as fossil-fueled cars in crashes, if not more so, customers still want reassurance, Morgan says. His systems look to match OEM safety standards as much as possible, with service disconnects, ground-fault monitors, and layers of redundancy.
</p><p>
	Battery boxes use 3-millimeter-thick steel, unlike some electric conversions that use flimsy transparent plastic cases to show off the cells inside—Morgan will have none of that. “If you’ve got 280 kilos of batteries in a box, that needs to be strong and rigid in an impact,” he says.
</p><p>
	The original 12-volt electrical system remains, but only to run various low-power accessories. But with no engine to drive belts, Tesla’s 400-volt architecture handles the electric motors that provide for power steering, as well as for cooling pumps and the car’'s A/C compressor.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt=" A photo showing a steel battery case being lowered by forklift into the rear of the car during refurbishment." class="rm-shortcode" data-rm-shortcode-id="056654a3af7466ec43fd7b22d7ae1874" data-rm-shortcode-name="rebelmouse-image" id="3712f" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-showing-a-steel-battery-case-being-lowered-by-forklift-into-the-rear-of-the-car-during-refurbishment.jpg?id=29692566&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The traction batteries are split, some being housed under the hood and others [shown at left during installation] going beneath the rear seating.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">E.C.D. Automotive Design</small>
</p><p>
	While such a conversion is plenty challenging, Tesla’s electronics have been jailbroken by enterprising hackers, so E.C.D.’s techs have full access to throttle maps, regenerative-braking levels, thermal management, and so forth.
</p><p>
	Morgan estimates that salvaged Teslas and other EVs provide about 40 percent of his motors and batteries. The rest are sourced new from Chinese suppliers such as 
	<a href="https://www.catl.com/en/" target="_blank">CATL</a> (Contemporary Amperex Technology Co. Ltd.), which manufactures cells that also power new Teslas. With Tesla now building close to 1 million cars a year, conversion companies need only a tiny percentage to crash to fill their warehouses with needed components.
</p><p>
<strong>Morgan has heard</strong> griping from some purists who call what he is doing a sacrilege. They assert that ripping out a car’s internal-combustion-guts also tears out its soul.
</p><p>
	His response: “These are mass-produced classic cars,” not seven-figure Ferraris or other models whose stem-to-stern originality is integral to their value. He points out that removing “all the dirty and smelly bits” eliminates the stress, expense, and TLC required by classic cars—including finicky British and Italian cars. “I like classic cars to be used,” says Morgan.
</p><p>
	To that end, the Rover’s original electricals—from 
	<a href="https://en.wikipedia.org/wiki/Lucas_Industries" target="_blank">Lucas Industries</a>, a company whose founder was sometimes called “the Prince of Darkness” for the notorious unreliability of its products in almost every U.K. car brand—are replaced. Technicians hand-assemble the 23 wiring harnesses required for each conversion. It all looks insanely complicated, but Wallace insists that swapping a fossil-fuel engine is, in many ways, a bigger headache. Electric conversions are far simpler, he asserts: “This is just a motor, a battery, and two driveshafts.”
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo showing wood paneling in the rear of the interior." class="rm-shortcode" data-rm-shortcode-id="f2f27c81ea876f76b8bf466d15abb464" data-rm-shortcode-name="rebelmouse-image" id="e6215" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-showing-wood-paneling-in-the-rear-of-the-interior.jpg?id=29692567&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The rear of this particular car also includes teak storage compartments.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">E.C.D. Automotive Design</small>
</p><p>
	Morgan and his colleagues freely admit that the environmental benefits of powering a car on electricity are largely an afterthought. “I’m a classic-car guy; I’m not coming at it from the save-the-planet side.”
</p><p>
	Yet these conversions 
	<em>do</em> have environmental benefits. The most obvious one is zero tailpipe emissions. The more subtle one is giving second lives to two cars—the vintage Rover and the wrecked Tesla from which the motor and batteries came. A typical gasoline family car produces about 24 tonnes of CO<sub>2</sub> over its lifetime, versus 18 tonnes for a comparable EV. Yet <a href="https://www.zemo.org.uk/assets/workingdocuments/MC-P-11-15a%20Lifecycle%20emissions%20report.pdf" target="_blank">about 46 percent</a> of an EV’s lifetime emissions are generated during manufacturing, double those of an internal-combustion car. So, keeping that electric hardware on the road for as long as possible, where it can pay off through sharply reduced emissions, is indeed being kind to the planet.
</p><p>
<strong>On my test</strong> drive, the Rover turns the tables on late-model gasoline SUVs, this ancient truck transmogrified into a speedy tech avenger. Elliot Humble, riding shotgun, notes that every conversion gets 1,000 miles (about 1,600 km) of shakedown testing, all performed by a single technician.
</p><p>
	This Defender still steers like a farm implement, but that trait is just part of its boundless charm. The telltale hum of the Tesla motor is louder in this Rover than it is in a Model S, despite the many sound-deadening layers of 
	<a href="https://kilmat.com/" target="_blank">Kilmat</a>, jute, and carpet that have been added.
</p><p>
	But an electric motor makes just a whisper compared with the din of a gasoline engine, let alone the clatter of a Rover diesel. A new air suspension enormously improves the car’s notoriously rough ride, and the body barely creaks. The upgraded brakes, a 
	<a href="https://www.brembo.com/en" target="_blank">Brembo</a> system with six-piston front calipers, provide plenty of stopping power.
</p><p class="pull-quote">
	Pull up to the valet line in this whisper-quiet Rover, and you’ll probably get as much attention as if you had arrived in a Ferrari or a Bentley.
</p><p>
	“And it’s got modern fuses and relays—things that actually work,” Humble says as we ride. “No more glass fuses wrapped in tinfoil to stay on.”
</p><p>
	For Project Britton, niceties include 
	<a href="https://www.recaro-automotive.com/us/" target="_blank">Recaro</a> seats swaddled in diamond-stitched leather and an <a href="https://www.alpine-usa.com/product/alpine-halo11-multimedia-receiver-ilxf411" target="_blank">Alpine Halo</a> audio system. The appeal is clear: In such status-conscious places as Napa Valley or the Hamptons, a Tesla Model S might as well be a Toyota Camry now. But pull up to the valet line in this whisper-quiet Rover, and you’ll draw as much attention as if you had arrived in a Ferrari or a Bentley.
</p><p>
	“At the end of the day, it’s a toy, isn’t it?” Humble says. “We could all get by with a 1.6-liter petrol engine. But it’s about having something no one else has.”
</p><p>
	It’s also about having your cake and eating it too—at least for people who can afford the rich frosting. E.C.D. Defenders start from $209,000, and the Tesla-based drivetrain adds roughly $40,000. Add a la carte upgrades, and these electrified dream machines hover around $300,000.
</p><p>
	For do-it-yourselfers who choke on those prices, there are less expensive options. 
	<a href="https://electricgt.com/" target="_blank">Electric GT</a>’s Tesla motor-swap system, for example, costs about $40,000 and includes a drive unit, power module, battery-management system, and more. And Electric Classic Cars is developing a bolt-in conversion kit for vintage Mini Coopers, in tandem with <a href="https://www.supercoopers.com/" target="_blank">Super Coopers</a> in Buellton, Calif. Like Electric GT’s kits, it features connectors-for-dummies that don’t allow, say, a positive lead to plug into a negative terminal.
</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A photo showing the completed car being recharged. " class="rm-shortcode" data-rm-shortcode-id="930278f771a04bde3cfabca7a69842bf" data-rm-shortcode-name="rebelmouse-image" id="6ebe7" loading="lazy" src="https://spectrum.ieee.org/media-library/a-photo-showing-the-completed-car-being-recharged.jpg?id=29692756&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The result is a superbly restored vehicle, but one that the owner can now plug in rather than fuel up. </small><small class="image-media media-photo-credit" placeholder="Add Photo Credit...">E.C.D. Automotive Design</small>
</p><p>
	“With an EV, you’ve got to know more about what you’re doing,” Morgan says. “If you pick up the wrong end of a 400-volt DC cable, something bad’s going to happen. But [with such kits], you don’t need special high-voltage knowledge.”
</p><p>
	Systems can be installed in as little as two days by a pair of experienced technicians—or more slowly by a handy owner with the help of a skilled pal. Such kits are a modern take on the electric conversions that became popular with some enthusiasts starting in the 1970s, before it was possible to buy a new electric car.
</p><p>
	Major automakers, which together 
	<a href="https://www.reuters.com/article/electric-vehicles-investment-idCNL1N2RZ1CB" target="_blank">will be spending hundreds of billions</a> of dollars to evolve into EV companies, may offer such kits themselves in an effort to squeeze as much revenue as possible from that pricey investment. In 2020, for example, General Motors announced it would <a href="https://arstechnica.com/cars/2020/10/chevrolet-readies-an-electric-crate-motor-for-homebuilt-ev-hotrods/" target="_blank">sell a conversion kit</a> based on the Chevrolet Bolt—although that kit is yet to go on sale.
</p><p>
	For now, electric conversions remain a tiny niche in the massive business of restorations and aftermarket equipment. But as EVs mature, the generations that grow up driving them might view today’s plug-ins as the classic cars 
	<em>they </em>aspire to own, improve, and restore—having no fondness at all for those oil-leaking, exhaust-spewing oddities their grandparents once drove. <span class="ieee-end-mark"></span>
</p><p>
<em>This article appears in the May 2022 print issue as “Tesla Inside.”</em>
</p>]]></description>
      <pubDate>Sat, 23 Apr 2022 15:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/electric-land-rover</guid>
      <category>Electric vehicles</category>
      <category>Evs</category>
      <dc:creator>Lawrence Ulrich</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/this-photo-shows-a-parked-land-rover-that-is-plugged-into-a-tesla-charging-station.jpg?id=29696930&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Video Friday: Strandbeest</title>
      <link>https://spectrum.ieee.org/video-friday-strandbeest</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-huge-kite-with-sails-and-mechanical-limbs-soars-in-a-blue-sky.jpg?id=29711375&width=1200&coordinates=0%2C0%2C0%2C0&height=800"/><br/><br/><p>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at IEEE Spectrum robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please <a href="mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday">send us your events</a> for inclusion.<br/></p><h5><a href="https://www.icra2022.org/">ICRA 2022</a>: 23–27 May 2022, Philadelphia</h5><h5><a href="https://attend.ieee.org/arso-2022/">IEEE ARSO 2022</a>: 28–30 May 2022, Long Beach, Calif.</h5><h5><a href="https://roboticsconference.org/">RSS 2022</a>: 21 June–1 July 2022, New York City</h5><h5><a href="https://www.eu-robotics.net/robotics_forum/">ERF 2022</a>: 28–30 June 2022, Rotterdam, Netherlands </h5><h5><a href="https://2022.robocup.org/">RoboCup 2022</a>: 11–17 July 2022, Bangkok</h5><h5><a href="http://www.case2022.org/">IEEE CASE 2022</a>: 20–24 August 2022, Mexico City</h5><h5><a href="https://clawar.org/clawar2022/">CLAWAR 2022</a>: 12–14 September 2022, Azores, Portugal</h5><p>Enjoy today’s videos!</p><hr/><div style="page-break-after: always"><span style="display:none"> </span></div><blockquote><em>Strandbeest Evolution 2021 provides an update on the evolutionary development. Every spring I go to the beach with a new beast. During the summer I do all kinds of experiments with the wind, sand and water. In the fall I grew a bit wiser about how these beasts can survive the circumstances on the beach. At that point I declare them extinct and they go to the bone yard.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="6a045d01665b4a4536d08acc9fe0eb23" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/C97kMKwZ2-g?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://www.strandbeest.com/">Strandbeest</a> ]</p><div class="horizontal-rule"></div><blockquote><em>MIT CSAIL scientists created an algorithm to solve one of the hardest tasks in computer vision: assigning a label to every pixel in the world, without human supervision.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="9ca8fcb8f0f857e9e42b87ea861e3465" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/58uhMDO7dTQ?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>I don’t know how many pixels there are in the world, but I’m guessing it’s kind of a lot. Good luck STEGO!</p><p>[ <a href="https://news.mit.edu/2022/new-unsupervised-computer-vision-algorithm-stego-0421">MIT</a> ]</p><div class="horizontal-rule"></div><p>A clever design for an antidrone drone, although from the look of things, you’ll have to be very talented to catch anything with it.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="fd01edb53a1a0fe890204949584faf26" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/CHqrzPAni58?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://lamat.me/works/interceptor.html">Aleksey Zaitsevsky</a> ] via [ <a href="https://gizmodo.com/quadcopter-shoots-down-other-drones-with-own-propellers-1848817743">Gizmodo</a> ]</p><div class="horizontal-rule"></div><p>Poramate Manoonpong shares his gecko-inspired climbing robot (Nyxbot), which can climb a 30-degree slope and cross over obstacles up to 38 percent of its body height.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="3a7ab387f3a52416ac02ecf0db018835" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/aozm-r9lFBA?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>He’s also been working on this hexapod robot with some of the cutest li’l feet I've ever seen:</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="27b98ef5a006d5c7716cc4354ecc6133" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/QtEAR1LyBp4?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>[ <a href="https://manoonpong.com/">Poramate Manoonpong</a> ]</p><div class="horizontal-rule"></div><p>We wrote about Calmbots a couple of years ago, but no reason not to watch this video and be squigged out again.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="5f2b5a57d52ec4c405346d30b496ccf3" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/sVw0oJgNg9k?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://digitalnature.slis.tsukuba.ac.jp/2020/10/calmbots">Calmbots</a> ]</p><div class="horizontal-rule"></div><blockquote><em>NASA’s Perseverance Mars rover used its Mastcam-Z camera system to shoot video of Phobos, one of Mars’ two moons, eclipsing the Sun. It’s the most zoomed-in, highest frame-rate observation of a Phobos solar eclipse ever taken from the Martian surface.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="a3ef0144833caa5dcf4a14ff88fb10f1" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/aKK7vS2CHC8?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://www.jpl.nasa.gov/news/nasas-perseverance-rover-captures-video-of-solar-eclipse-on-mars">JPL</a> ]</p><div class="horizontal-rule"></div><blockquote><em>Get ready for some dramatic music and experience a day in the life of a busy Starship Robot as it autonomously delivers throughout the city of Milton Keynes from dusk until dawn. Our robots are completing tens of thousands of autonomous deliveries a day all over the world.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="8f011039945784d18986a6dc65cb798b" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/Z417CncwQsg?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://www.starship.xyz/">Starship</a> ]</p><div class="horizontal-rule"></div><blockquote><em>Our purpose-built vehicle is designed and engineered to drive safely in rain, hail, or shine. In this episode of Putting Zoox to the Test</em><em>, members from our Durability team explain how we’re testing our hardware to ensure it functions as it should in wet weather. </em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="37b2df70bcc5976c0e06778e97149e50" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/EzWVRyal5FI?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://zoox.com/">Zoox</a> ]</p><div class="horizontal-rule"></div><p>This video about a partnership between Sarcos and Palantir is astonishing because of how little it manages to say relative to its length and (I’m guessing) budget.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="3659a985fcae4e1b82a89c569c431ada" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/EJG1GDe6XKY?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://blog.palantir.com/sarcos-palantir-24a54593db51">Palantir</a> ]</p><div class="horizontal-rule"></div><blockquote><em>Dr. Heidi from Philippines Flying Labs provides a first report of the drone delivery training in Tawi Tawi along with the very first medical drone deliveries that took place as part of this training.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="2ebb73a6c51c49cb3c99d228a0334e41" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/ULqIMe8lbwk?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://flyinglabs.org/philippines/">PFL</a> ]</p><div class="horizontal-rule"></div><blockquote><em>Stanford was one of the pioneers in artificial intelligence. Hear from professors such as Chris Manning and Fei-Fei Li on the earliest days of natural language processing and computer vision, the work of scholars John McCarthy and Jay McClelland, the launch of the Stanford AI Lab, early robotics at the school, and other pivotal moments in Stanford AI.</em></blockquote><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="14fdde4c9c4ad969333c5177631d0e57" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/Vx9lizr1hdY?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://hai.stanford.edu/">Stanford HAI</a> ]</p><div class="horizontal-rule"></div><p>In honor of ASIMO’s retirement, here’s a 20-minute history about the robot from Honda.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="14684cba74874b02d39c487894897553" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/xt090WrKU3w?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://asimo.honda.com/">ASIMO</a> ]</p><div class="horizontal-rule"></div><p>On this episode of the “Robot Brains Podcast,” Pieter talks with Eric Horvitz of Microsoft about AI for the Greater Good.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="ce450db021bda484df13f88ca93c52d5" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/9dqtwIymkTE?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p>[ <a href="https://www.therobotbrains.ai/">Robot Brains</a> ]</p><div class="horizontal-rule"></div><p>Here are two talks hosted by UPenn’s GRASP Lab, featuring Kevin Lynch from Northwestern University, followed by Robert J. Wood from Harvard University.</p><p class="shortcode-media shortcode-media-youtube"><span class="rm-shortcode" data-rm-shortcode-id="f2f6599992ffb50eff1beabe4429a2b0" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/czhp5Td9Dj4?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span></p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="4bffaaa163840a5d8a280d9afa4ad327" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/2Gb04GStojw?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>[ <a href="https://www.grasp.upenn.edu/events/month/">UPenn</a> ]</p><div class="horizontal-rule"></div>]]></description>
      <pubDate>Fri, 22 Apr 2022 17:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/video-friday-strandbeest</guid>
      <category>Video friday</category>
      <category>Robotics</category>
      <dc:creator>Evan Ackerman</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-huge-kite-with-sails-and-mechanical-limbs-soars-in-a-blue-sky.jpg?id=29711375&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Even as It Retires, ASIMO Still Manages to Impress</title>
      <link>https://spectrum.ieee.org/honda-asimo</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-white-humanoid-robot-with-a-black-helmet-stands-facing-the-camera.jpg?id=29706175&width=1200&coordinates=0%2C138%2C0%2C138&height=800"/><br/><br/><p><a href="https://asimo.honda.com/" target="_blank">Honda’s ASIMO humanoid robot</a> <a href="https://www3.nhk.or.jp/news/html/20220331/k10013561691000.html" target="_blank">is retiring</a>. For the last 20 years, ASIMO had been performing at the Honda showroom in Tokyo, Japan, but these regular demonstrations are now at an end. <a href="https://spectrum.ieee.org/honda-halts-asimo-development-in-favor-of-more-useful-humanoid-robots" target="_blank">We’ve known for a while that this was coming</a>—Honda announced back in 2018 that it was halting ASIMO development in favor of working on robots with more practical applications, <a href="https://spectrum.ieee.org/honda-halts-asimo-development-in-favor-of-more-useful-humanoid-robots" target="_self">like robots for elder care and disaster relief</a>. But what blows me away about ASIMO, even now, is just how <em>impressive</em> it still is.</p><hr/><p><a href="https://spectrum.ieee.org/honda-robotics-unveils-next-generation-asimo-robot" target="_blank">The most recent version of ASIMO was announced in 2011</a>. As I watch this performance now, I have to keep reminding myself that this was all happening <em>more than 10 years ago</em>.</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="256e55e6cc4272c432de2b1fe026f10c" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/Bmglbk_Op64?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>That’s decade-old sensing, actuation, compute, batteries—even still, what ASIMO is demonstrating are things that are absolutely not easy for humanoid robots even now. And like, the robot still looks so futuristic, right? The design is wonderful, all the movements are buttery smooth, and ASIMO would not be out of place in any science-fiction movie. This little robot really did set a (still somewhat aspirational) standard, especially relative to other humanoid robots, which have only within the last few years been able to match and then significantly surpass ASIMO’s performance, if not its looks.</p><p>The current generation of ASIMO is part of a lineage of humanoid robotics research at Honda stretching back to the mid-1980s:</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="33c6e7029395ac346e45aa9df06bb1af" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/8uX7G4oCMu8?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p><a href="https://spectrum.ieee.org/asimo-still-improving-its-hopping-and-jogging-skills" target="_blank">As recently as 2017</a>, Honda was still making improvements to ASIMO’s software and presenting that research at conferences. Here’s a video from ICRA that year, featuring a naked (!) ASIMO being mildly abused:</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="86d5a7a0ccba3d151a9f61eea1b3c442" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/UevFtYEimjw?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>But Honda has more recently seemed to realize that they could take the ASIMO platform and the philosophy of humanoid robotics that it represents only so far, and as of 2018 the company shifted development to a <a href="https://spectrum.ieee.org/iros-2017-honda-unveils-prototype-e2dr-disaster-response-robot" target="_blank">clearly ASIMO-inspired but much more robust robot called E2-DR</a>:</p><p class="shortcode-media shortcode-media-youtube">
<span class="rm-shortcode" data-rm-shortcode-id="7f12c4080a5cdc6474b807c6437aac09" style="display:block;position:relative;padding-top:56.25%;"><iframe frameborder="0" height="auto" lazy-loadable="true" scrolling="no" src="https://www.youtube.com/embed/uat8laSf7gc?rel=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" width="100%"></iframe></span>
</p><p>Clearly, there’s a lot more potential with a rugged platform like E2-DR, both for research and for exploring practical tasks in the near (or at least nearer) term. I’m glad that Honda is continuing the research into legged robots that it pioneered so many decades ago. But E2-DR is not ASIMO. It’s not trying to be, and that’s probably a good thing, but a part of me still mourns the vision of friendly and helpful humanoids that ASIMO represented.</p><p>I’ll miss you, buddy.</p><p class="shortcode-media shortcode-media-rebelmouse-image">
<img alt="A youngish man kneels next to a small white humanoid robot while having one arm around it and shaking its hand" class="rm-shortcode" data-rm-shortcode-id="bc0cdd046a3cd104471299c147abe65a" data-rm-shortcode-name="rebelmouse-image" id="5124c" loading="lazy" src="https://spectrum.ieee.org/media-library/a-youngish-man-kneels-next-to-a-small-white-humanoid-robot-while-having-one-arm-around-it-and-shaking-its-hand.jpg?id=29706168&width=980"/>
<small class="image-media media-caption" placeholder="Add Photo Caption...">The author, a decade younger than he is now, with an earlier version of ASIMO at Stanford University in 2011. Yes, ASIMO is very, very short.</small></p>]]></description>
      <pubDate>Thu, 21 Apr 2022 19:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/honda-asimo</guid>
      <category>Humanoid robots</category>
      <category>Asimo</category>
      <category>Honda</category>
      <category>Robotics</category>
      <dc:creator>Evan Ackerman</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-white-humanoid-robot-with-a-black-helmet-stands-facing-the-camera.jpg?id=29706175&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>How Engineers Can Help Protect Earth From Worsening Climate Change</title>
      <link>https://spectrum.ieee.org/engineers-combatting-climate-change</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-photo-of-green-vegetation-with-glass-globe-sitting-in-the-foreground.jpg?id=29708289&width=1200&coordinates=0%2C104%2C0%2C104&height=800"/><br/><br/><p>Earth Day, which is celebrated annually on 22 April, aims to drive transformative change by educating people about what they can do to help. The day reminds us of the need to protect our planet and its ecosystems against the worsening climate crisis.</p><p>Our planet is no longer the same as it was even just a decade ago. The climate crisis is threatening people across the world, as well as every species of animal and plant life. We need to address the crisis now in a sustainable way. Fortunately, we still have a<a href="https://www.ipcc.ch/report/ar6/wg1/" rel="noopener noreferrer" target="_blank"> narrow window of opportunity</a> to alter the Earth’s climate path, and I believe we can do it.</p><hr/><p>Climate change is a global societal crisis that is causing devastating consequences. Its costs have been projected as high as <a href="https://www.nytimes.com/2021/04/22/climate/climate-change-economy.html" rel="noopener noreferrer" target="_blank">US $23 trillion in reduced annual global economic output</a>, according to Swiss Re, a reinsurance company. Multifaceted collective efforts are necessary to address the crisis.</p><p>Engineers and technologists can and should play major roles in creating a greener planet, creating tools that address environmental degradation.</p><p><strong>HOW THE CRISIS AFFECTS US</strong></p><p>In the past few years, we’ve witnessed devastating cases of extreme weather all over the world, including deadly floods, massive forest fires, and severe droughts. Lives and businesses are being severely affected, and the cost of recovering after each event continues to mount.</p><p>The climate crisis is also having a severe effect on the planet, which is being battered by pollution, deforestation, and soil degradation.</p><p>About 7 million people every year die from diseases caused by air pollution, such as chronic obstructive pulmonary disease, lung cancer, and acute respiratory infections, according to the <a href="https://www.who.int/" rel="noopener noreferrer" target="_blank">World Health Organization</a>. Ninety-nine percent of the global population breathes in air that exceeds WHO-guideline limits on pollutants, with low- and middle-income countries suffering from the highest exposures. More than half the world’s people live in urban areas, yet only 12 percent of cities achieve WHO guidelines for air quality. To create a sustainable environment, we need to contain air pollution.</p><p>Deforestation is contributing to climate change. Trees capture and store atmospheric carbon and help cool the globe’s temperature. Deforestation has caused the Amazon rainforest and similar areas to lose their ability to recover from disturbances such as drought, wildfires, and human development, according to a <a href="https://www.scientificamerican.com/article/amazon-rain-forest-nears-dangerous-tipping-point/" rel="noopener noreferrer" target="_blank">recent article</a> published in <em>Scientific American</em>. The loss of the Amazon rainforest would cause large-scale drying across the region. In response, the circulation of the atmosphere could change—which would alter weather patterns around the world, the article says.</p><p>About 95 percent of food production<a href="https://www.soilassociation.org/causes-campaigns/save-our-soil/10-soil-facts/" rel="noopener noreferrer" target="_blank"> relies</a> on topsoil. The soil also helps to address the climate crisis, as it stores more carbon than the world’s plants combined. The microbes and minerals in soil systems regulate water, cycle nutrients, filter pollutants, physically support plants, and sequester greenhouse gasses.</p><p>But Earth’s soil is being spoiled and degraded, presenting us with several risks. According to a 2017 <a href="https://www.un.org/en/climatechange/climate-adaptation" rel="noopener noreferrer" target="_blank">United Nations</a>–supported study, a third of the planet’s land is severely degraded, and fertile soil is being lost at an alarming rate.</p><p>The climate crisis has serious health consequences, the WHO warned in its recent<a href="https://apps.who.int/iris/bitstream/handle/10665/276405/9789241514972-eng.pdf?" rel="noopener noreferrer" target="_blank"> COP24 report</a>. Direct health impacts include an increase in respiratory and cardiovascular disease and injuries or death due to extreme weather events. Climate change also causes indirect effects on health, such as food and water insecurity, the spread of climate-sensitive infectious diseases, and population displacement.</p><p><strong>TECHNOLOGICAL SOLUTIONS</strong></p><p>There are many ways that IEEE members from the technical and scientific community can help. Engineers and computer professionals can use information technologies such as cloud-based software-as-a-service (SaaS), Earth’s digital twin, and the Internet of Things (IoT) to help make buildings, energy production, farms, health care, and manufacturing greener.</p><p>SaaS platforms, such as <a href="https://www.projectcanary.com/" rel="noopener noreferrer" target="_blank">Project Canary</a> of Denver, help energy companies track, measure, and score the impact of methane and other volatile organic compounds on the environment across the energy supply chain. Canary uses high-fidelity spectroscopy-based methane detection and emissions quantification for the oil and gas sectors. The SaaS platform also uses laser-based gas analyzers to detect methane, formaldehyde, and more.</p><p>The IoT has<a href="https://www.cutter.com/article/leveraging-iot-create-sustainable-environment" rel="noopener noreferrer" target="_blank"> vast potential</a> to address sustainability by making energy systems more connected, improving their operational efficiency, and reducing the carbon intensity of buildings, manufact­uring, and transportation. It also can lower energy consumption through smart operations and improve resource utilization. By using IoT-equipped sensors, deforestation and poaching can be monitored. IoT food container tags can reduce food and water waste.</p><p class="pull-quote">Engineers and technologists can and should play major roles in creating a greener planet with technology that addresses environmental degradation.</p><p>Using a digital model of the Earth—or digital twin—environmental impacts can be studied. A new <a href="https://www.weforum.org/agenda/2021/03/scientists-are-developing-a-digital-twin-of-our-earth-to-fight-climate-change/" rel="noopener noreferrer" target="_blank">model</a> developed by the <a href="https://ec.europa.eu/info/index_en" rel="noopener noreferrer" target="_blank">European Commission</a>’s <a href="https://digital-strategy.ec.europa.eu/en/library/destination-earth" rel="noopener noreferrer" target="_blank">Destination Earth</a> initiative is designed to track the impact of humans on water, food, and energy management. Data collected through the digital twin can help predict environmental impacts and enable remedial measures to be taken.</p><p>Artificial intelligence, data science, and distributed ledger technology can play major roles as well.</p><p>Researchers are developing smart materials, next-generation batteries, autonomous vehicles, carbon capture and storage, hydrogen-powered fuel cells, precision agriculture, and 4D printing that might help solve environmental problems.</p><p>Although information technologies and similar tools leave their own environmental footprint, they are often small compared with their positive contribution toward creating a greener planet. And efforts are underway to make the technologies greener.</p><p><strong>CALL TO ACTION</strong></p><p>Undoubtedly, environmental degradation is a complex, global problem and the defining challenge of our time. Our inaction could jeopardize the well-being of current and future generations.</p><p>We must envision and ensure a sustainable future through responsible planning, development of effective solutions leveraging technological advances, actionable regulations, and sound practices. We need an environmental mindset as well as systemic transformation and individual behavioral changes.</p><p>Let’s be optimistic in what we do. Optimism can drive us to achievement. As German poet <a href="https://www.britannica.com/biography/Johann-Wolfgang-von-Goethe" rel="noopener noreferrer" target="_blank">Johann Wolfgang von Goethe</a> said: “Knowing is not enough; we must apply. Willing is not enough; we must do.”</p><p>If we don’t care about our environment and the future of our planet, then who will? Let’s treat every day as Earth Day. Let’s invest in creating and sustaining a better environment than the one we inherited.</p><p>Let’s pledge—and act now—to create a cleaner, greener planet. If not now, when?</p>]]></description>
      <pubDate>Thu, 21 Apr 2022 18:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/engineers-combatting-climate-change</guid>
      <category>Climate change</category>
      <category>Earth day</category>
      <category>Energy</category>
      <category>Sustainability</category>
      <category>Environment</category>
      <category>Ieee news</category>
      <category>Type:ti</category>
      <dc:creator>San Murugesan</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-photo-of-green-vegetation-with-glass-globe-sitting-in-the-foreground.jpg?id=29708289&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>The Computers Who Brought ENIAC to Life</title>
      <link>https://spectrum.ieee.org/eniac-woman-programmers</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/black-and-white-image-of-three-women-each-in-front-of-a-large-wheeled-cabinet-faced-with-countless-rotary-switches.jpg?id=29705856&width=1200&coordinates=14%2C0%2C0%2C0&height=800"/><br/><br/><p>The Electronic Numerical Integrator and Computer—better known as <a data-linked-post="2650274151" href="https://spectrum.ieee.org/great-computers-never-die" target="_blank">ENIAC</a>—became the world’s first programmable general-purpose electronic computer when it was completed in 1945. ENIAC’s hardware was designed by John Mauchly and J. Presper Eckert, but the programs it ran were largely the creation of <a href="https://penntoday.upenn.edu/news/eniacs-anniversary-nod-its-female-computers" target="_blank">a team of six women</a>. For decades, <a href="https://spectrum.ieee.org/untold-history-of-ai-invisible-woman-programmed-americas-first-electronic-computer" target="_blank">these women were largely unknown</a>, except only as unidentified figures in photographs of ENIAC. But as an undergraduate, <a href="https://www.linkedin.com/in/kathy-kleiman-09832b1/" target="_blank">Kathy Kleiman</a>—who would later help found <a href="https://www.icann.org/" target="_blank">ICANN</a> (Internet Corporation for Assigned Names and Numbers)—started looking into who they were. This weekend at the <a href="https://vcfed.org/events/vintage-computer-festival-east/" target="_blank">Vintage Computer Festival East</a> in Wall, N.J., Kleiman will be screening her short documentary <a href="https://eniacprogrammers.org/documentary-info/" target="_blank"><em>The Computers</em></a>, about the programmers. In advance of her talk, <em>IEEE Spectrum</em> spoke to Kleiman about the ENIAC women and her fascination with them.</p><p><strong>How did these women come to be such a central part of the history of computing?</strong></p><p><strong>Kathy Kleiman:</strong> During World War II, the army needed people to hand-calculate ballistics trajectories or artillery firing tables. And male mathematicians were running short. The Army relocated the project from rural Maryland to Philadelphia and went looking for women math majors in Philadelphia, which has a very high density of schools with coed universities and colleges and all-women schools. </p><p>Later they would go across the country looking for women math majors to come to the Morse School of Electrical Engineering, which is where they located this project and where they hand-calculated ballistic trajectories using mechanical desktop calculators. But it took 30 to 40 hours to calculate a single trajectory for one set of weather conditions for one gun and one projectile, and the Army needed hundreds of trajectories per firing table. </p><p>So in the dark days of the war, early 1943, when there was no end to the war in sight, they agreed to fund the experiment of a visionary guy who also happened to be at the Moore School at that time. His name was Dr. John Mauchly. He partnered with Presper Eckert, who was 23 years old at the time, a young engineering grad. They were yin and yang, a great combination. With Army funding, they built this machine that wasn’t supposed to work—18,000 vacuum tubes were never supposed to be able to work in concert. But they did it, a machine 8 feet tall and 80 feet long. </p><p>But when they’re almost done, they’re like, “Wait a second.” Part of the Army contract was delivering a working ballistic trajectory calculated by the machine. So a mathematician and Army lieutenant at the proving ground called Herman Goldstein picks six out of the 80 to 100 women who’ve been calculating trajectories. They [Kathleen Antonelli, Jean Bartik, Betty Holberton, Marlyn Meltzer, Frances Spence, and Ruth Teitelbaum] are given the wiring diagrams and the block diagrams and told to figure it out so they can do the ballistics trajectory equation. </p><p>The women don’t have security access to even see the actual computer, but they figure it out, doing what is now called <a href="https://studylib.net/doc/8742623/programming-the-eniac-before-its-rewiring." target="_blank">direct programming</a>. There’s looping, there’s conditional logic, and the women collectively mastered all this and made it perform the ballistic trajectory calculation that wound up becoming the climactic moment of demonstration day on 6 February 1946, when ENIAC was unveiled. </p><p><strong>Why did you start looking into their story?</strong></p><p><strong>Kleiman: </strong>I was at Harvard. I was kind of a social theory major. I took computer science from the first classes that I took in college because I was already a programmer because of a Western Electric program when I was in high school. I also noticed that as the levels of the computer science classes went higher, the number of women dropped. And I knew about Ada Lovelace. I knew about Grace Hopper. Ada Lovelace was in the 19th century, then Grace Hopper in the 20th century. And one woman succeeding in computing per century didn’t make me feel warm and fuzzy, so I went looking for more. </p><p>I found the pictures of ENIAC taken before demonstration day and given to the press and published across the country.  These pictures are beautiful black-and-white pictures, and they have men and women in them; some of them just have women! But while some of the men, particularly Eckert and Mauchly, are named in the captions, none of the names of the women are in the captions. I wanted to know who they were. I was told by some computer historians at the time that they were models, and they didn’t look like models to me. I tracked them down, and they weren’t models; they were programmers.</p><p><strong>You’ll be showing your documentary at <a href="https://vcfed.org/events/vintage-computer-festival-east/" target="_blank">VCF East</a>, which features interviews with four of the programmers conducted before they passed away, but you’ll also be <a href="https://www.grandcentralpublishing.com/titles/kathy-kleiman/proving-ground/9781549185458/" target="_blank">releasing a book later this year</a>, called<em> Proving Ground</em>?</strong></p><p><strong>Kleiman:</strong> The documentary raised as many questions as it answered. So I was kind of persuaded to tell the rest of the story, and really sit down and talk about the incredible work, not just of the ENIAC programmers but of millions of women on the home front during World War II. It turned out that is not a story we know very well. I had always known women went to the factories, they went to the farms. I didn’t realize until I sat down in front of newspapers of the period and saw the ads that there was an enormous push for women with science and technology backgrounds. If you had the interest, the aptitude, and some training, these articles made it clear they’d teach you the rest, not just for the military but for industry. That was just a whole part of the story I’d never heard, that women also filled in these gaps in science, technology, and engineering.</p>]]></description>
      <pubDate>Thu, 21 Apr 2022 16:51:16 +0000</pubDate>
      <guid>https://spectrum.ieee.org/eniac-woman-programmers</guid>
      <category>Eniac</category>
      <category>Women who code</category>
      <category>Documentaries</category>
      <dc:creator>Stephen Cass</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/black-and-white-image-of-three-women-each-in-front-of-a-large-wheeled-cabinet-faced-with-countless-rotary-switches.jpg?id=29705856&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Andrew Ng: Unbiggen AI</title>
      <link>https://spectrum.ieee.org/andrew-ng-data-centric-ai</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednesday-october-30-2019.jpg?id=29206806&width=1200&coordinates=0%2C0%2C0%2C210&height=800"/><br/><br/><p><strong><a href="https://en.wikipedia.org/wiki/Andrew_Ng" rel="noopener noreferrer nofollow" target="_blank">Andrew Ng</a> has serious street cred</strong> in artificial intelligence. He pioneered the use of graphics processing units (GPUs) to train deep learning models in the late 2000s with his students at <a href="https://stanfordmlgroup.github.io/" rel="noopener noreferrer nofollow" target="_blank">Stanford University</a>, cofounded <a href="https://research.google/teams/brain/" rel="noopener noreferrer nofollow" target="_blank">Google Brain</a> in 2011, and then served for three years as chief scientist for <a href="https://ir.baidu.com/" rel="noopener noreferrer nofollow" target="_blank">Baidu</a>, where he helped build the Chinese tech giant’s AI group. So when he says he has identified the next big shift in artificial intelligence, people listen. And that’s what he told <em>IEEE Spectrum</em> in an exclusive Q&A.</p><hr/><p>
	Ng’s current efforts are focused on his company 
	<a href="https://landing.ai/about/" rel="noopener noreferrer nofollow" target="_blank">Landing AI</a>, which built a platform called LandingLens to help manufacturers improve visual inspection with computer vision. <a name="top"></a>He has also become something of an evangelist for what he calls the <a href="https://www.youtube.com/watch?v=06-AZXmwHjo" target="_blank">data-centric AI movement</a>, which he says can yield “small data” solutions to big issues in AI, including model efficiency, accuracy, and bias.
</p><p>
	Andrew Ng on...
</p><ul>
<li><a href="#big">What’s next for really big models</a></li>
<li><a href="#career">The career advice he didn’t listen to</a></li>
<li><a href="#defining">Defining the data-centric AI movement</a></li>
<li><a href="#synthetic">Synthetic data</a></li>
<li><a href="#work">Why Landing AI asks its customers to do the work</a></li>
</ul><p>
<a name="big"></a><strong>The great advances in deep learning over the past decade or so have been powered by ever-bigger models crunching ever-bigger amounts of data. Some people argue that that’s an <a href="https://spectrum.ieee.org/deep-learning-computational-cost" target="_self">unsustainable trajectory</a>. Do you agree that it can’t go on that way?</strong>
</p><p>
<strong>Andrew Ng: </strong>This is a big question. We’ve seen foundation models in NLP [natural language processing]. I’m excited about NLP models getting even bigger, and also about the potential of building foundation models in computer vision. I think there’s lots of signal to still be exploited in video: We have not been able to build foundation models yet for video because of compute bandwidth and the cost of processing video, as opposed to tokenized text. So I think that this engine of scaling up deep learning algorithms, which has been running for something like 15 years now, still has steam in it. Having said that, it only applies to certain problems, and there’s a set of other problems that need small data solutions.
</p><p>
<strong>When you say you want a foundation model for computer vision, what do you mean by that?</strong>
</p><p>
<strong>Ng:</strong> This is a term coined by <a href="https://cs.stanford.edu/~pliang/" rel="noopener noreferrer" target="_blank">Percy Liang</a> and <a href="https://crfm.stanford.edu/" rel="noopener noreferrer" target="_blank">some of my friends at Stanford</a> to refer to very large models, trained on very large data sets, that can be tuned for specific applications. For example, <a href="https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business" target="_self">GPT-3</a> is an example of a foundation model [for NLP]. Foundation models offer a lot of promise as a new paradigm in developing machine learning applications, but also challenges in terms of making sure that they’re reasonably fair and free from bias, especially if many of us will be building on top of them.
</p><p>
<strong>What needs to happen for someone to build a foundation model for video?</strong>
</p><p>
<strong>Ng:</strong> I think there is a scalability problem. The compute power needed to process the large volume of images for video is significant, and I think that’s why foundation models have arisen first in NLP. Many researchers are working on this, and I think we’re seeing early signs of such models being developed in computer vision. But I’m confident that if a semiconductor maker gave us 10 times more processor power, we could easily find 10 times more video to build such models for vision.
</p><p>
	Having said that, a lot of what’s happened over the past decade is that deep learning has happened in consumer-facing companies that have large user bases, sometimes billions of users, and therefore very large data sets. While that paradigm of machine learning has driven a lot of economic value in consumer software, I find that that recipe of scale doesn’t work for other industries.
</p><p>
<a href="#top">Back to top</a><a name="career"></a>
</p><p>
<strong>It’s funny to hear you say that, because your early work was at a consumer-facing company with millions of users.</strong>
</p><p>
<strong>Ng: </strong>Over a decade ago, when I proposed starting the <a href="https://research.google/teams/brain/" rel="noopener noreferrer" target="_blank">Google Brain</a> project to use Google’s compute infrastructure to build very large neural networks, it was a controversial step. One very senior person pulled me aside and warned me that starting Google Brain would be bad for my career. I think he felt that the action couldn’t just be in scaling up, and that I should instead focus on architecture innovation.
</p><p class="pull-quote">
	“In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.”<br/>
	—Andrew Ng, CEO & Founder, Landing AI
</p><p>
	I remember when my students and I published the first 
	<a href="https://nips.cc/" rel="noopener noreferrer nofollow" target="_blank">NeurIPS</a> workshop paper advocating using <a href="https://developer.nvidia.com/cuda-zone" rel="noopener noreferrer" target="_blank">CUDA</a>, a platform for processing on GPUs, for deep learning—a different senior person in AI sat me down and said, “CUDA is really complicated to program. As a programming paradigm, this seems like too much work.” I did manage to convince him; the other person I did not convince.
</p><p>
<strong>I expect they’re both convinced now.</strong>
</p><p>
<strong>Ng:</strong> I think so, yes.
</p><p>
	Over the past year as I’ve been speaking to people about the data-centric AI movement, I’ve been getting flashbacks to when I was speaking to people about deep learning and scalability 10 or 15 years ago. In the past year, I’ve been getting the same mix of “there’s nothing new here” and “this seems like the wrong direction.”
</p><p>
<a href="#top">Back to top</a><a name="defining"></a>
</p><p>
<strong>How do you define data-centric AI, and why do you consider it a movement?</strong>
</p><p>
<strong>Ng:</strong> Data-centric AI is the discipline of systematically engineering the data needed to successfully build an AI system. For an AI system, you have to implement some algorithm, say a neural network, in code and then train it on your data set. The dominant paradigm over the last decade was to download the data set while you focus on improving the code. Thanks to that paradigm, over the last decade deep learning networks have improved significantly, to the point where for a lot of applications the code—the neural network architecture—is basically a solved problem. So for many practical applications, it’s now more productive to hold the neural network architecture fixed, and instead find ways to improve the data.
</p><p>
	When I started speaking about this, there were many practitioners who, completely appropriately, raised their hands and said, “Yes, we’ve been doing this for 20 years.” This is the time to take the things that some individuals have been doing intuitively and make it a systematic engineering discipline.
</p><p>
	The data-centric AI movement is much bigger than one company or group of researchers. My collaborators and I organized a 
	<a href="https://neurips.cc/virtual/2021/workshop/21860" rel="noopener noreferrer" target="_blank">data-centric AI workshop at NeurIPS</a>, and I was really delighted at the number of authors and presenters that showed up.
</p><p>
<strong>You often talk about companies or institutions that have only a small amount of data to work with. How can data-centric AI help them?</strong>
</p><p>
<strong>Ng: </strong>You hear a lot about vision systems built with millions of images—I once built a face recognition system using 350 million images. Architectures built for hundreds of millions of images don’t work with only 50 images. But it turns out, if you have 50 really good examples, you can build something valuable, like a defect-inspection system. In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.
</p><p>
<strong>When you talk about training a model with just 50 images, does that really mean you’re taking an existing model that was trained on a very large data set and fine-tuning it? Or do you mean a brand new model that’s designed to learn only from that small data set?</strong>
</p><p>
<strong>Ng: </strong>Let me describe what Landing AI does. When doing visual inspection for manufacturers, we often use our own flavor of <a href="https://developers.arcgis.com/python/guide/how-retinanet-works/" rel="noopener noreferrer" target="_blank">RetinaNet</a>. It is a pretrained model. Having said that, the pretraining is a small piece of the puzzle. What’s a bigger piece of the puzzle is providing tools that enable the manufacturer to pick the right set of images [to use for fine-tuning] and label them in a consistent way. There’s a very practical problem we’ve seen spanning vision, NLP, and speech, where even human annotators don’t agree on the appropriate label. For big data applications, the common response has been: If the data is noisy, let’s just get a lot of data and the algorithm will average over it. But if you can develop tools that flag where the data’s inconsistent and give you a very targeted way to improve the consistency of the data, that turns out to be a more efficient way to get a high-performing system.
</p><p class="pull-quote">
	“Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.”<br/>
	—Andrew Ng
</p><p>
	For example, if you have 10,000 images where 30 images are of one class, and those 30 images are labeled inconsistently, one of the things we do is build tools to draw your attention to the subset of data that’s inconsistent. So you can very quickly relabel those images to be more consistent, and this leads to improvement in performance.
</p><p>
<strong>Could this focus on high-quality data help with bias in data sets? If you’re able to curate the data more before training?</strong>
</p><p>
<strong>Ng:</strong> Very much so. Many researchers have pointed out that biased data is one factor among many leading to biased systems. There have been many thoughtful efforts to engineer the data. At the NeurIPS workshop, <a href="https://www.cs.princeton.edu/~olgarus/" rel="noopener noreferrer" target="_blank">Olga Russakovsky</a> gave a really nice talk on this. At the main NeurIPS conference, I also really enjoyed <a href="https://neurips.cc/virtual/2021/invited-talk/22281" rel="noopener noreferrer" target="_blank">Mary Gray’s presentation,</a> which touched on how data-centric AI is one piece of the solution, but not the entire solution. New tools like <a href="https://www.microsoft.com/en-us/research/project/datasheets-for-datasets/" rel="noopener noreferrer nofollow" target="_blank">Datasheets for Datasets</a> also seem like an important piece of the puzzle.
</p><p>
	One of the powerful tools that data-centric AI gives us is the ability to engineer a subset of the data. Imagine training a machine-learning system and finding that its performance is okay for most of the data set, but its performance is biased for just a subset of the data. If you try to change the whole neural network architecture to improve the performance on just that subset, it’s quite difficult. But if you can engineer a subset of the data you can address the problem in a much more targeted way.
</p><p>
<strong>When you talk about engineering the data, what do you mean exactly?</strong>
</p><p>
<strong>Ng: </strong>In AI, data cleaning is important, but the way the data has been cleaned has often been in very manual ways. In computer vision, someone may visualize images through a <a href="https://jupyter.org/" rel="noopener noreferrer" target="_blank">Jupyter notebook</a> and maybe spot the problem, and maybe fix it. But I’m excited about tools that allow you to have a very large data set, tools that draw your attention quickly and efficiently to the subset of data where, say, the labels are noisy. Or to quickly bring your attention to the one class among 100 classes where it would benefit you to collect more data. Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.
</p><p>
	For example, I once figured out that a speech-recognition system was performing poorly when there was car noise in the background. Knowing that allowed me to collect more data with car noise in the background, rather than trying to collect more data for everything, which would have been expensive and slow.
</p><p>
<a href="#top">Back to top</a><a name="synthetic"></a>
</p><p>
<strong>What about using synthetic data, is that often a good solution?</strong>
</p><p>
<strong>Ng: </strong>I think synthetic data is an important tool in the tool chest of data-centric AI. At the NeurIPS workshop, <a href="http://tensorlab.cms.caltech.edu/users/anima/" rel="noopener noreferrer" target="_blank">Anima Anandkumar</a> gave a great talk that touched on synthetic data. I think there are important uses of synthetic data that go beyond just being a preprocessing step for increasing the data set for a learning algorithm. I’d love to see more tools to let developers use synthetic data generation as part of the closed loop of iterative machine learning development.
</p><p>
<strong>Do you mean that synthetic data would allow you to try the model on more data sets?</strong>
</p><p>
<strong>Ng: </strong>Not really. Here’s an example. Let’s say you’re trying to detect defects in a smartphone casing. There are many different types of defects on smartphones. It could be a scratch, a dent, pit marks, discoloration of the material, other types of blemishes. If you train the model and then find through error analysis that it’s doing well overall but it’s performing poorly on pit marks, then synthetic data generation allows you to address the problem in a more targeted way. You could generate more data just for the pit-mark category.
</p><p class="pull-quote">
	“In the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models.”<br/>
	—Andrew Ng
</p><p>
	Synthetic data generation is a very powerful tool, but there are many simpler tools that I will often try first. Such as data augmentation, improving labeling consistency, or just asking a factory to collect more data.
</p><p>
<a href="#top">Back to top</a><a name="work"></a>
</p><p>
<strong>To make these issues more concrete, can you walk me through an example? When a company approaches <a href="https://landing.ai/" rel="noopener noreferrer nofollow" target="_blank">Landing AI</a> and says it has a problem with visual inspection, how do you onboard them and work toward deployment?</strong>
</p><p>
<strong>Ng: </strong>When a customer approaches us we usually have a conversation about their inspection problem and look at a few images to verify that the problem is feasible with computer vision. Assuming it is, we ask them to upload the data to the <a href="https://landing.ai/platform/" rel="noopener noreferrer nofollow" target="_blank">LandingLens</a> platform. We often advise them on the methodology of data-centric AI and help them label the data.
</p><p>
	One of the foci of Landing AI is to empower manufacturing companies to do the machine learning work themselves. A lot of our work is making sure the software is fast and easy to use. Through the iterative process of machine learning development, we advise customers on things like how to train models on the platform, when and how to improve the labeling of data so the performance of the model improves. Our training and software supports them all the way through deploying the trained model to an edge device in the factory.
</p><p>
<strong>How do you deal with changing needs? If products change or lighting conditions change in the factory, can the model keep up?</strong>
</p><p>
<strong>Ng:</strong> It varies by manufacturer. There is data drift in many contexts. But there are some manufacturers that have been running the same manufacturing line for 20 years now with few changes, so they don’t expect changes in the next five years. Those stable environments make things easier. For other manufacturers, we provide tools to flag when there’s a significant data-drift issue. I find it really important to empower manufacturing customers to correct data, retrain, and update the model. Because if something changes and it’s 3 a.m. in the United States, I want them to be able to adapt their learning algorithm right away to maintain operations.
</p><p>
	In the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models. The challenge is, how do you do that without Landing AI having to hire 10,000 machine learning specialists?
</p><p>
<strong>So you’re saying that to make it scale, you have to empower customers to do a lot of the training and other work.</strong>
</p><p>
<strong>Ng: </strong>Yes, exactly! This is an industry-wide problem in AI, not just in manufacturing. Look at health care. Every hospital has its own slightly different format for electronic health records. How can every hospital train its own custom AI model? Expecting every hospital’s IT personnel to invent new neural-network architectures is unrealistic. The only way out of this dilemma is to build tools that empower the customers to build their own models by giving them tools to engineer the data and express their domain knowledge. That’s what Landing AI is executing in computer vision, and the field of AI needs other teams to execute this in other domains.
</p><p>
<strong>Is there anything else you think it’s important for people to understand about the work you’re doing or the data-centric AI movement?</strong>
</p><p>
<strong>Ng: </strong>In the last decade, the biggest shift in AI was a shift to deep learning. I think it’s quite possible that in this decade the biggest shift will be to data-centric AI. With the maturity of today’s neural network architectures, I think for a lot of the practical applications the bottleneck will be whether we can efficiently get the data we need to develop systems that work well. The data-centric AI movement has tremendous energy and momentum across the whole community. I hope more researchers and developers will jump in and work on it.
</p><p>
<a href="#top">Back to top</a>
</p><p><em>This article appears in the April 2022 print issue as “Andrew Ng, AI Minimalist</em><em>.”</em></p>]]></description>
      <pubDate>Wed, 09 Feb 2022 15:31:12 +0000</pubDate>
      <guid>https://spectrum.ieee.org/andrew-ng-data-centric-ai</guid>
      <category>Andrew ng</category>
      <category>Artificial intelligence</category>
      <category>Deep learning</category>
      <category>Type:cover</category>
      <dc:creator>Eliza Strickland</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednesday-october-30-2019.jpg?id=29206806&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>How AI Will Change Chip Design</title>
      <link>https://spectrum.ieee.org/ai-chip-design-matlab</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&width=1200&coordinates=0%2C0%2C0%2C0&height=800"/><br/><br/><p>The end of <a href="https://spectrum.ieee.org/on-beyond-moores-law-4-new-laws-of-computing" target="_self">Moore’s Law</a> is looming. Engineers and designers can do only so much to <a href="https://spectrum.ieee.org/ibm-introduces-the-worlds-first-2nm-node-chip" target="_self">miniaturize transistors</a> and <a href="https://spectrum.ieee.org/cerebras-giant-ai-chip-now-has-a-trillions-more-transistors" target="_self">pack as many of them as possible into chips</a>. So they’re turning to other approaches to chip design, incorporating technologies like AI into the process.</p><p>Samsung, for instance, is <a href="https://spectrum.ieee.org/processing-in-dram-accelerates-ai" target="_self">adding AI to its memory chips</a> to enable processing in memory, thereby saving energy and speeding up machine learning. Speaking of speed, Google’s TPU V4 AI chip has <a href="https://spectrum.ieee.org/heres-how-googles-tpu-v4-ai-chip-stacked-up-in-training-tests" target="_self">doubled its processing power</a> compared with that of  its previous version.</p><p>But AI holds still more promise and potential for the semiconductor industry. To better understand how AI is set to revolutionize chip design, we spoke with <a href="https://www.linkedin.com/in/heather-gorr-phd" rel="noopener noreferrer" target="_blank">Heather Gorr</a>, senior product manager for <a href="https://www.mathworks.com/" rel="noopener noreferrer" target="_blank">MathWorks</a>’ MATLAB platform.</p><p><strong>How is AI currently being used to design the next generation of chips?</strong></p><p><strong>Heather Gorr:</strong> AI is such an important technology because it’s involved in most parts of the cycle, including the design and manufacturing process. There’s a lot of important applications here, even in the general process engineering where we want to optimize things. I think defect detection is a big one at all phases of the process, especially in manufacturing. But even thinking ahead in the design process, [AI now plays a significant role] when you’re designing the light and the sensors and all the different components. There’s a lot of anomaly detection and fault mitigation that you really want to consider.</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="Portrait of a woman with blonde-red hair smiling at the camera" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="1f18a02ccaf51f5c766af2ebc4af18e1" data-rm-shortcode-name="rebelmouse-image" id="2dc00" loading="lazy" src="https://spectrum.ieee.org/media-library/portrait-of-a-woman-with-blonde-red-hair-smiling-at-the-camera.jpg?id=29288554&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">Heather Gorr</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit..." style="max-width: 100%;">MathWorks</small></p><p>Then, thinking about the logistical modeling that you see in any industry, there is always planned downtime that you want to mitigate; but you also end up having unplanned downtime. So, looking back at that historical data of when you’ve had those moments where maybe it took a bit longer than expected to manufacture something, you can take a look at all of that data and use AI to try to identify the proximate cause or to see  something that might jump out even in the processing and design phases. We think of AI oftentimes as a predictive tool, or as a robot doing something, but a lot of times you get a lot of insight from the data through AI.</p><p><strong>What are the benefits of using AI for chip design?</strong></p><p><strong>Gorr:</strong> Historically, we’ve seen a lot of physics-based modeling, which is a very intensive process. We want to do a <a href="https://en.wikipedia.org/wiki/Model_order_reduction" rel="noopener noreferrer" target="_blank">reduced order model</a>, where instead of solving such a computationally expensive and extensive model, we can do something a little cheaper. You could create a surrogate model, so to speak, of that physics-based model, use the data, and then do your <a href="https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html" rel="noopener noreferrer" target="_blank">parameter sweeps</a>, your optimizations, your <a href="https://www.ibm.com/cloud/learn/monte-carlo-simulation" rel="noopener noreferrer" target="_blank">Monte Carlo simulations</a> using the surrogate model. That takes a lot less time computationally than solving the physics-based equations directly. So, we’re seeing that benefit in many ways, including the efficiency and economy that are the results of iterating quickly on the experiments and the simulations that will really help in the design.</p><p><strong>So it’s like having a digital twin in a sense?</strong></p><p><strong>Gorr:</strong> Exactly. That’s pretty much what people are doing, where you have the physical system model and the experimental data. Then, in conjunction, you have this other model that you could tweak and tune and try different parameters and experiments that let sweep through all of those different situations and come up with a better design in the end.</p><p><strong>So, it’s going to be more efficient and, as you said, cheaper?</strong></p><p><strong>Gorr:</strong> Yeah, definitely. Especially in the experimentation and design phases, where you’re trying different things. That’s obviously going to yield dramatic cost savings if you’re actually manufacturing and producing [the chips]. You want to simulate, test, experiment as much as possible without making something using the actual process engineering.</p><p><strong>We’ve talked about the benefits. How about the drawbacks?</strong></p><p><strong>Gorr: </strong>The [AI-based experimental models] tend to not be as accurate as physics-based models. Of course, that’s why you do many simulations and parameter sweeps. But that’s also the benefit of having that digital twin, where you can keep that in mind—it's not going to be as accurate as that precise model that we’ve developed over the years.</p><p>Both chip design and manufacturing are system intensive; you have to consider every little part. And that can be really challenging. It's a case where you might have models to predict something and different parts of it, but you still need to bring it all together.</p><p>One of the other things to think about too is that you need the data to build the models. You have to incorporate data from all sorts of different sensors and different sorts of teams, and so that heightens the challenge.</p><p><strong>How can engineers use AI to better prepare and extract insights from hardware or sensor data?</strong></p><p><strong>Gorr: </strong>We always think about using AI to predict something or do some robot task, but you can use AI to come up with patterns and pick out things you might not have noticed before on your own. People will use AI when they have high-frequency data coming from many different sensors, and a lot of times it’s useful to explore the frequency domain and things like data synchronization or resampling. Those can be really challenging if you’re not sure where to start.</p><p>One of the things I would say is, use the tools that are available. There’s a vast community of people working on these things, and you can find lots of examples [of applications and techniques] on <a href="https://github.com/" rel="noopener noreferrer" target="_blank">GitHub</a> or <a href="https://www.mathworks.com/matlabcentral/" rel="noopener noreferrer" target="_blank">MATLAB Central</a>, where people have shared nice examples, even little apps they’ve created. I think many of us are buried in data and just not sure what to do with it, so definitely take advantage of what’s already out there in the community. You can explore and see what makes sense to you, and bring in that balance of domain knowledge and the insight you get from the tools and AI.</p><p><strong>What should engineers and designers consider wh</strong><strong>en using AI for chip design?</strong></p><p><strong>Gorr:</strong> Think through what problems you’re trying to solve or what insights you might hope to find, and try to be clear about that. Consider all of the different components, and document and test each of those different parts. Consider all of the people involved, and explain and hand off in a way that is sensible for the whole team.</p><p><strong>How do you think AI will affect chip designers’ jobs?</strong></p><p><strong>Gorr:</strong> It’s going to free up a lot of human capital for more advanced tasks. We can use AI to reduce waste, to optimize the materials, to optimize the design, but then you still have that human involved whenever it comes to decision-making. I think it’s a great example of people and technology working hand in hand. It’s also an industry where all people involved—even on the manufacturing floor—need to have some level of understanding of what’s happening, so this is a great industry for advancing AI because of how we test things and how we think about them before we put them on the chip.</p><p><strong>How do you envision the future of AI and chip design?</strong></p><p><strong>Gorr</strong><strong>:</strong> It's very much dependent on that human element—involving people in the process and having that interpretable model. We can do many things with the mathematical minutiae of modeling, but it comes down to how people are using it, how everybody in the process is understanding and applying it. Communication and involvement of people of all skill levels in the process are going to be really important. We’re going to see less of those superprecise predictions and more transparency of information, sharing, and that digital twin—not only using AI but also using our human knowledge and all of the work that many people have done over the years.</p>]]></description>
      <pubDate>Tue, 08 Feb 2022 14:00:01 +0000</pubDate>
      <guid>https://spectrum.ieee.org/ai-chip-design-matlab</guid>
      <category>Chip fabrication</category>
      <category>Moore’s law</category>
      <category>Chip design</category>
      <category>Ai</category>
      <category>Matlab</category>
      <category>Digital twins</category>
      <dc:creator>Rina Diane Caballar</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&amp;width=980" medium="image" type="image/jpeg" />
    </item>
    <item>
      <title>Atomically Thin Materials Significantly Shrink Qubits</title>
      <link>https://spectrum.ieee.org/2d-hbn-qubit</link>
      <description><![CDATA[
<img src="https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&width=1200&coordinates=0%2C0%2C0%2C0&height=800"/><br/><br/><p>Quantum computing is a devilishly complex technology, with many technical hurdles impacting its development. Of these challenges two critical issues stand out: miniaturization and qubit quality.</p><p>IBM has adopted the superconducting qubit road map of <a href="https://spectrum.ieee.org/ibms-envisons-the-road-to-quantum-computing-like-an-apollo-mission" target="_self">reaching a 1,121-qubit processor by 2023</a>, leading to the expectation that 1,000 qubits with today’s qubit form factor is feasible. However, current approaches will require very large chips (50 millimeters on a side, or larger) at the scale of small wafers, or the use of chiplets on multichip modules. While this approach will work, the aim is to attain a better path toward scalability.</p><p>Now researchers at <a href="https://www.nature.com/articles/s41563-021-01187-w" rel="noopener noreferrer" target="_blank">MIT have been able to both reduce the size of the qubits</a> and done so in a way that reduces the interference that occurs between neighboring qubits. The MIT researchers have increased the number of superconducting qubits that can be added onto a device by a factor of 100.</p><p>“We are addressing both qubit miniaturization and quality,” said <a href="https://equs.mit.edu/william-d-oliver/" rel="noopener noreferrer" target="_blank">William Oliver</a>, the director for the <a href="https://cqe.mit.edu/" target="_blank">Center for Quantum Engineering</a> at MIT. “Unlike conventional transistor scaling, where only the number really matters, for qubits, large numbers are not sufficient, they must also be high-performance. Sacrificing performance for qubit number is not a useful trade in quantum computing. They must go hand in hand.”</p><p>The key to this big increase in qubit density and reduction of interference comes down to the use of two-dimensional materials, in particular the 2D insulator hexagonal boron nitride (hBN). The MIT researchers demonstrated that a few atomic monolayers of hBN can be stacked to form the insulator in the capacitors of a superconducting qubit.</p><p>Just like other capacitors, the capacitors in these superconducting circuits take the form of a sandwich in which an insulator material is sandwiched between two metal plates. The big difference for these capacitors is that the superconducting circuits can operate only at extremely low temperatures—less than 0.02 degrees above absolute zero (-273.15 °C).</p><p class="shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left" data-rm-resized-container="25%" style="float: left;">
<img alt="Golden dilution refrigerator hanging vertically" class="rm-shortcode rm-resized-image" data-rm-shortcode-id="694399af8a1c345e51a695ff73909eda" data-rm-shortcode-name="rebelmouse-image" id="6c615" loading="lazy" src="https://spectrum.ieee.org/media-library/golden-dilution-refrigerator-hanging-vertically.jpg?id=29281593&width=980" style="max-width: 100%"/>
<small class="image-media media-caption" placeholder="Add Photo Caption..." style="max-width: 100%;">Superconducting qubits are measured at temperatures as low as 20 millikelvin in a dilution refrigerator.</small><small class="image-media media-photo-credit" placeholder="Add Photo Credit..." style="max-width: 100%;">Nathan Fiske/MIT</small></p><p>In that environment, insulating materials that are available for the job, such as PE-CVD silicon oxide or silicon nitride, have quite a few defects that are too lossy for quantum computing applications. To get around these material shortcomings, most superconducting circuits use what are called coplanar capacitors. In these capacitors, the plates are positioned laterally to one another, rather than on top of one another.</p><p>As a result, the intrinsic silicon substrate below the plates and to a smaller degree the vacuum above the plates serve as the capacitor dielectric. Intrinsic silicon is chemically pure and therefore has few defects, and the large size dilutes the electric field at the plate interfaces, all of which leads to a low-loss capacitor. The lateral size of each plate in this open-face design ends up being quite large (typically 100 by 100 micrometers) in order to achieve the required capacitance.</p><p>In an effort to move away from the large lateral configuration, the MIT researchers embarked on a search for an insulator that has very few defects and is compatible with superconducting capacitor plates.</p><p>“We chose to study hBN because it is the most widely used insulator in 2D material research due to its cleanliness and chemical inertness,” said colead author <a href="https://equs.mit.edu/joel-wang/" rel="noopener noreferrer" target="_blank">Joel Wang</a>, a research scientist in the Engineering Quantum Systems group of the MIT Research Laboratory for Electronics. </p><p>On either side of the hBN, the MIT researchers used the 2D superconducting material, niobium diselenide. One of the trickiest aspects of fabricating the capacitors was working with the niobium diselenide, which oxidizes in seconds when exposed to air, according to Wang. This necessitates that the assembly of the capacitor occur in a glove box filled with argon gas.</p><p>While this would seemingly complicate the scaling up of the production of these capacitors, Wang doesn’t regard this as a limiting factor.</p><p>“What determines the quality factor of the capacitor are the two interfaces between the two materials,” said Wang. “Once the sandwich is made, the two interfaces are “sealed” and we don’t see any noticeable degradation over time when exposed to the atmosphere.”</p><p>This lack of degradation is because around 90 percent of the electric field is contained within the sandwich structure, so the oxidation of the outer surface of the niobium diselenide does not play a significant role anymore. This ultimately makes the capacitor footprint much smaller, and it accounts for the reduction in cross talk between the neighboring qubits.</p><p>“The main challenge for scaling up the fabrication will be the wafer-scale growth of hBN and 2D superconductors like [niobium diselenide], and how one can do wafer-scale stacking of these films,” added Wang.</p><p>Wang believes that this research has shown 2D hBN to be a good insulator candidate for superconducting qubits. He says that the groundwork the MIT team has done will serve as a road map for using other hybrid 2D materials to build superconducting circuits.</p>]]></description>
      <pubDate>Mon, 07 Feb 2022 16:12:05 +0000</pubDate>
      <guid>https://spectrum.ieee.org/2d-hbn-qubit</guid>
      <category>Qubits</category>
      <category>Mit</category>
      <category>Ibm</category>
      <category>Superconducting qubits</category>
      <category>Hexagonal boron nitride</category>
      <category>2d materials</category>
      <category>Quantum computing</category>
      <dc:creator>Dexter Johnson</dc:creator>
      <media:content url="https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&amp;width=980" medium="image" type="image/jpeg" />
    </item>
  </channel>
</rss>