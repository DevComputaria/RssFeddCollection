{"?xml":{"@version":"1.0","@encoding":"utf-8"},"rss":{"@version":"2.0","@xmlns:atom":"http://www.w3.org/2005/Atom","@xmlns:content":"http://purl.org/rss/1.0/modules/content/","@xmlns:dc":"http://purl.org/dc/elements/1.1/","@xmlns:media":"http://search.yahoo.com/mrss/","channel":{"title":"IEEE Spectrum","link":"https://spectrum.ieee.org/","description":"IEEE Spectrum","atom:link":{"@href":"https://spectrum.ieee.org/feeds/feed.rss","@rel":"self"},"language":"en-us","lastBuildDate":"Sat, 27 Jan 2024 04:49:51 -0000","image":{"url":"https://spectrum.ieee.org/media-library/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpbWFnZSI6Imh0dHBzOi8vYXNzZXRzLnJibC5tcy8yNjg4NDUyMC9vcmlnaW4ucG5nIiwiZXhwaXJlc19hdCI6MTc2MzA3MTQzOX0.SxRBIud_XE2YWQFaIJD9BPB1w-3JsFhiRkJIIe9Yq-g/image.png?width=210","link":"https://spectrum.ieee.org/","title":"IEEE Spectrum"},"item":[{"title":"Video Friday: Medusai","link":"https://spectrum.ieee.org/video-friday-medusai","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/image.png?id=51196963&width=1200&height=800&coordinates=150%2C0%2C150%2C0\"/><br/><br/><p><span style=\"background-color: initial;\">Video Friday is your weekly selection of awesome robotics videos, collected by your friends at <em>IEEE Spectrum</em> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please </span><a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a><span style=\"background-color: initial;\"> for inclusion.</span><br/></p><h5><a href=\"https://cybathlon.ethz.ch/en/events/challenges/Challenges-2024\">Cybathlon Challenges</a>: 2 February 2024, ZURICH</h5><h5><a href=\"https://www.eurobot.org/\">Eurobot Open 2024</a>: 8–11 May 2024, LA ROCHE-SUR-YON, FRANCE</h5><h5><a href=\"https://2024.ieee-icra.org/\">ICRA 2024</a>: 13–17 May 2024, YOKOHAMA, JAPAN</h5><h5><a href=\"https://2024.robocup.org/\">RoboCup 2024</a>: 17–22 July 2024, EINDHOVEN, NETHERLANDS</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><blockquote><em>Made from beautifully fabricated steel and eight mobile arms, medusai can play percussion and strings with human musicians, dance with human dancers, and move in time to multiple human observers. It uses AI-driven computer vision to know what human observers are doing and responds accordingly through snake gestures, music, and light.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"2dea5682a8c05c2e5bd75e51560f59a1\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/ZbpLjxuHeOY?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>If this seems a little bit unsettling, that’s intentional! The project was designed to explore the concepts of trust and risk in the context of robots, and of using technology to influence emotion.</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"f5a30baa34ff48be7b8383a0e0be6dc0\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/bmBexuV2pw4?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>[ <a href=\"https://www.medus.ai/\">medusai</a> ] via [ <a href=\"https://gtcmt.gatech.edu/feature/medusai\">Georgia Tech</a> ]</p><p>Thanks, Gil!</p><div class=\"horizontal-rule\"></div><blockquote><em>On 19 April 2021, NASA’s Ingenuity Mars Helicopter made history when it completed the first powered, controlled flight on the Red Planet. It flew for the last time on 18 January 2024.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5360a1cf3df67c2ace0509538cc63be1\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/qMbHE_VXI-8?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.jpl.nasa.gov/news/after-three-years-on-mars-nasas-ingenuity-helicopter-mission-ends\">NASA JPL</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Teleoperation plays a crucial role in enabling robot operations in challenging environments, yet existing limitations in effectiveness and accuracy necessitate the development of innovative strategies for improving teleoperated tasks. The work illustrated in this video introduces a novel approach that utilizes mixed reality and assistive autonomy to enhance the efficiency and precision of humanoid robot teleoperation.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"b4b34894fe26f27afc0d1e544234ca5c\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/oN-FD6YnF2c?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>Sometimes all it takes is one good punch, and then you can just collapse.</p><p>[ <a href=\"https://ieeexplore.ieee.org/abstract/document/10380694\">Paper</a> ] via [ <a href=\"https://robots.ihmc.us/\">IHMC</a> ]</p><p>Thanks, Robert!</p><div class=\"horizontal-rule\"></div><blockquote><em>The new Dusty Robotics FieldPrinter 2 enhances on-site performance and productivity through its compact design and extended capabilities. Building upon the success of the first-generation FieldPrinter, which has printed over 91 million square feet of layout, the FieldPrint Platform incorporates lessons learned from years of experience in the field to deliver an optimized experience for all trades on site.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"023c88f41a6724143d01efb20cd52c82\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/xIb_yiOHjWY?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.dustyrobotics.com/\">Dusty Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Quadrupedal robots have emerged as a cutting-edge platform for assisting humans, finding applications in tasks related to inspection and exploration in remote areas. Nevertheless, their floating base structure renders them susceptible to failure in cluttered environments, where manual recovery by a human operator may not always be feasible. In this study, we propose a robust all-terrain recovery policy to facilitate rapid and secure recovery in cluttered environments.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"ec994964e305e425572cbdd40e12b3a7\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/NiadpC05M6s?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://sites.google.com/view/dreamriser\">DreamRiser </a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"k2u7wwemldu\">The work that Henry Evans is doing with Stretch (along with Hello Robot and Maya Cakmak’s lab at the University of Washington) will be presented at Humanoids this spring.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"0a22bd7ed1289a7cb7d2069e95a7f70e\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/K2U7wwEMLDU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://hcrlab.cs.washington.edu/\">UW HCRL</a> ]</p><p>Thanks, Stefan!</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"ok4dhssene4\">I like to imagine that these are just excerpts from one very long walk that Digit took around San Francisco.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"52177cfdb5f147afa84b4fcb07ceb0f4\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/ok4DHssENE4?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://hybrid-robotics.berkeley.edu/\">Hybrid Robotics Lab</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Boxing, drumming, stacking boxes, and various other practices...those are the daily teleoperation testing of our humanoid robot. Collaborating with engineers, our humanoid robots collect real-world data from teleoperation for learning to iterate control algorithms. </em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"2abc41109cf691eb0f7b213899dd6209\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/2dmjzMv-y-M?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.limxdynamics.com/en\">LimX Dynamics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>The OpenDR project aims to develop a versatile and open tool kit for fundamental robot functions, using deep learning to enhance their understanding and decision-making abilities. The primary objective is to make robots more intelligent, particularly in critical areas like health care, agriculture, and production. In the health care setting, the TIAGo robot is deployed to offer assistance and support within a health care facility.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"5c6c8714578d0aa6c7df993fc980ab3f\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Z9y8FXwqxbM?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://opendr.eu/\">OpenDR</a> ] via [ <a href=\"https://pal-robotics.com/\">PAL Robotics</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"7b69c618db437c6056ff2addfef55aaf\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/fQ64i9dzj5s?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.arches-projekt.de/projekt-arches/\">ARCHES</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"uletbu3dufu\">Christoph Bartneck gives a talk entitled “Social robots: The end of the beginning or the beginning of the end?”</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"ab20b2e3fca0379c6ca94894b7f4a3c0\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/UleTbu3DufU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.bartneck.de/\">Christoph Bartneck</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Professor Michael Jordan offers his provocative thoughts on the blending of AI and economics and takes us on a tour of Trieste, a beautiful and grand city in northern Italy.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"4d11e959d5117a9bd64859d940f823e9\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/3lXphIYfoBM?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://people.eecs.berkeley.edu/~jordan/\">Berkeley</a> ]</p><div class=\"horizontal-rule\"></div>"},"pubDate":"Fri, 26 Jan 2024 21:11:45 +0000","guid":"https://spectrum.ieee.org/video-friday-medusai","category":["Digit","Quadrupedal robots","Robotics","Video friday","Mixed reality","Nasa","Mars helicopter","Dancing robots"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/image.png?id=51196963&width=980"}},{"title":"IEEE Medal of Honor Goes to Bob Kahn","link":"https://spectrum.ieee.org/medal-of-honor-bob-kahn","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/portrait-of-an-elderly-man-posing-in-a-black-suit-and-blue-shirt-and-tie.jpg?id=51194896&width=1200&height=800&coordinates=0%2C0%2C0%2C101\"/><br/><br/><p>IEEE Life Fellow <a href=\"https://www.cnri.reston.va.us/bios/kahn.html\" rel=\"noopener noreferrer\" target=\"_blank\">Robert E. Kahn</a>, widely known as one of the “fathers of the Internet,” is the recipient of the 2024 <a href=\"https://corporate-awards.ieee.org/recipients/ieee-medal-of-honor-recipients/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Medal of Honor</a>. He is being recognized for “pioneering technical and leadership contributions in packet communication technologies and foundations of the Internet.”</p><p>The <a href=\"https://www.ieeefoundation.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Foundation</a> sponsors the annual award.</p><p>While working as a program manager in the U.S. <a href=\"https://www.darpa.mil/\" rel=\"noopener noreferrer\" target=\"_blank\">Defense Advanced Research Projects Agency</a>’s information processing techniques office in 1973, Kahn and IEEE Life Fellow <a href=\"https://spectrum.ieee.org/vint-cerf\" target=\"_self\">Vint Cerf</a> designed the Transmission Control Protocol and the Internet Protocol. The TCP manages data packets sent over the Internet, making sure they don’t get lost, are received in the proper order, and are reassembled at their destination correctly. The IP manages the addressing and forwarding of data to and from its proper destinations. Together they make up the Internet’s core architecture and enable computers to connect and exchange information.</p><p>“Bob Kahn’s contributions to the lifestyle, commerce, and culture of modern society are extensive and unequaled,” said one of the endorsers of the award. “It was his leadership and dedicated efforts in the application of the packet network concept that led to the development of the Internet, which has become indispensable to our society.”</p><p>Kahn is president and CEO of the <a href=\"https://www.cnri.reston.va.us/\" rel=\"noopener noreferrer\" target=\"_blank\">Corporation for National Research Initiatives</a>, which he founded in 1986. The nonprofit, based in Reston, Va., undertakes, fosters, and promotes research in the strategic development of network-based information technologies. It also provides leadership and funding for information infrastructure research and development.</p><h2>A fruitful career at DARPA</h2><p>Kahn began working in computer networking in 1966 when he joined <a href=\"https://ethw.org/Bolt_Beranek_and_Newman_Inc.\" rel=\"noopener noreferrer\" target=\"_blank\">Bolt Beranek and Newman</a> (BBN) in Cambridge, Mass. There he was responsible for the system design of the <a href=\"https://ethw.org/ARPANET\" rel=\"noopener noreferrer\" target=\"_blank\">ARPANET</a>, the first packet-switched network. The project, funded by the Advanced Research Projects Agency Network, was the precursor to the Internet. (ARPA is now known as DARPA.)</p><p>It was during that time that he met Cerf, who helped write ARPANET’s communication protocol.</p><p>In 1972 Kahn left BBN to become a program manager in DARPA’s information processing techniques office, which invested in computer hardware and software research. He continued to work on the ARPANET and organized the first public demonstration of the network at the 1972 <a href=\"https://en.wikipedia.org/wiki/International_Conference_on_Computer_Communications\" rel=\"noopener noreferrer\" target=\"_blank\">International Conference on Computer Communications</a>, held in Washington, D.C.</p><p>Khan soon after conceived the idea of open-architecture networking. In March 1973 he recruited Cerf to help him make his idea into reality. At the time, Cerf was an assistant professor of computer science and electrical engineering at <a href=\"https://www.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford</a>.</p><p>It took the two of them six months to flesh out what they called the TCP, which provides networks with end-to-end reliability, error recovery, and congestion control. The TCP introduced the concept of IP addresses.</p><p>After a decade of testing, the protocol suite was officially adopted by the ARPANET in 1983.</p><p>That same year Kahn was promoted to director of the information processing techniques office. He launched several initiatives including the U.S. government’s Strategic Computing Program. It funded the development and implementation of multiprocessor computer architectures with major investments in natural language processing, speech understanding, image understanding, and expert systems. </p><p>After 13 years at DARPA, Kahn left the organization in 1986 to launch the Corporation for National Research Initiatives.</p><p>Together with Cerf, Kahn in 1992 founded the <a href=\"https://www.internetsociety.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Internet Society</a>, a nonprofit organization that helps set technical standards, develops Internet infrastructure, and advises policymakers.</p><p>Kahn has received several recognitions for his work, including the 2004 <a href=\"https://amturing.acm.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Turing Award</a> from the <a href=\"https://www.acm.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Association for Computing Machinery</a>. He also received the 1997 <a href=\"https://ethw.org/IEEE_Alexander_Graham_Bell_Medal_History\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Alexander Graham Bell Medal</a> together with Cerf.</p>"},"pubDate":"Fri, 26 Jan 2024 19:00:02 +0000","guid":"https://spectrum.ieee.org/medal-of-honor-bob-kahn","category":["Ieee news","Ieee member news","Ieee medal of honor","Ieee awards","Bob kahn","Internet","Type:ti"],"dc:creator":"Joanna Goodrich","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/portrait-of-an-elderly-man-posing-in-a-black-suit-and-blue-shirt-and-tie.jpg?id=51194896&width=980"}},{"title":"Solid-State EV Batteries Now Face “Production Hell”","link":"https://spectrum.ieee.org/solid-state-battery-production-challenges","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-rectangular-pouch-with-two-pieces-coming-out-of-the-top.jpg?id=51190107&width=1200&height=800&coordinates=95%2C0%2C95%2C0\"/><br/><br/><p>Recent solid-state battery announcements by <a href=\"https://www.vw.com/en.html\" rel=\"noopener noreferrer\" target=\"_blank\">Volkswagen</a> and <a href=\"https://www.quantumscape.com/\" rel=\"noopener noreferrer\" target=\"_blank\">QuantumScape</a> are raising hopes in the electric-vehicle market, but automotive battery experts are warning that the road to widespread, solid-state success is still a long and arduous one. A single breakthrough, as if from above, is not likely to turn the whole industry on its nose anytime soon.  </p><p>“Solid-state is a great technology,” noted Bob Galyen, owner of <a href=\"https://galyenenergy.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Galyen Energy</a> and former chief technology officer for the Chinese battery giant <a href=\"https://www.catl.com/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Contemporary Amperex Technology Ltd</a>. (CATL). “But it’s going to be just like lithium-ion was in terms of the length of time it will take to hit the market. And lithium-ion took a long time to get there.”</p><p class=\"pull-quote\">“I haven’t seen cost numbers that are even close to competing with liquid-state, lithium-ion batteries.“ <strong>—Bob Galyen, Galyen Energy </strong></p><p>Galyen and other experts consulted by <em>IEEE</em> <em>Spectrum </em>noted that recent announcements by <a href=\"https://www.volkswagen-group.com/en/press-releases/powerco-confirms-results-quantumscapes-solid-state-cell-passes-first-endurance-test-18031\" target=\"_blank\">Volkswagen</a>, <a href=\"https://finance.yahoo.com/news/quantumscape-millionaire-maker-103600618.html\" target=\"_blank\">QuantumScape</a>, <a href=\"https://www.reuters.com/business/autos-transportation/toyota-roll-out-solid-state-battery-evs-couple-years-india-executive-says-2024-01-11/\" target=\"_blank\">Toyota</a>, and <a href=\"https://www.pcmag.com/news/semi-solid-state-battery-powers-chinese-evs-650-mile-14-hour-drive\" target=\"_blank\">NIO</a> have resulted in impressive <a href=\"https://www.wsj.com/livecoverage/stock-market-today-dow-jones-01-04-2024/card/quantumscape-stock-surges-40-after-battery-test-results-bSxt2jhJgDbsOiTrPp4X\" rel=\"noopener noreferrer\" target=\"_blank\">stock market performance</a>. However, these same experts noted a pointed skepticism toward the technical merits of these announcements. None could isolate anything on the horizon indicating that solid-state technology can escape the engineering and “production hell” that lies ahead.</p><p>The remaining hurdles will involve validating existing solid-state battery technologies (currently in use for more limited, often medical, applications) for cars and trucks. The adoption curve, experts say, will depend on the product’s ability to be validated in terms of performance, life, and cost characteristics.</p><p>Solid-state cells, so-named for their use of a <a data-linked-post=\"2658810780\" href=\"https://spectrum.ieee.org/solid-state-battery-pressure\" target=\"_blank\">solid electrolyte</a>, are seen as a key to the future of the <a href=\"https://spectrum.ieee.org/the-top-10-ev-battery-makers\" target=\"_blank\">electric car</a> because they potentially offer greater safety and energy, as well as much faster recharge times. Solid-state cells differ from conventional lithium-ion batteries in their use of a <a href=\"https://spectrum.ieee.org/john-goodenough-glass-battery-news-hydroquebec\" target=\"_blank\">glass</a> or <a href=\"https://spectrum.ieee.org/ion-storage-systems-ceramic-electrolyte-news-solid-state-batteries\" target=\"_blank\">ceramic electrolyte</a>, instead of a liquid composed of lithium salts. Automakers are keen on solid-state batteries’ future, because the technology offers greater thermal stability than liquid-based batteries, thus allowing for substantially faster recharge, among other advantages.</p><p>Solid-state has also been the subject of recent announcements from battery manufacturers and mainstream automakers alike. In early January, Volkswagen Group’s <a href=\"https://www.powerco.de/\" rel=\"noopener noreferrer\" target=\"_blank\">PowerCo SE</a> battery company <a href=\"https://www.volkswagen-group.com/en/press-releases/powerco-confirms-results-quantumscapes-solid-state-cell-passes-first-endurance-test-18031\" rel=\"noopener noreferrer\" target=\"_blank\">said it tested lithium-metal cells</a> from <a href=\"https://www.quantumscape.com/\" rel=\"noopener noreferrer\" target=\"_blank\">QuantumScape</a>, achieving 1,000 charging cycles with 95 percent of the cell’s capacity still intact. The company said in a statement that the cell’s life-performance was analogous to “an electric car that could drive more than 500,000 kilometers (300,000 miles) without any noticeable loss of range.”</p><p class=\"pull-quote\">“What happens when you’re driving down I-75 and you hit a big pit in the road? What kind of damage would be done to the solid-state matrix?” <strong>—Bob Galyen, Galyen Energy </strong></p><p>Similarly, Toyota announced in October that it <a href=\"https://spectrum.ieee.org/toyota-solid-state-battery\" target=\"_self\">plans to incorporate solid-state batteries</a> in an unnamed number of production vehicles by 2027. The automaker said it is targeting a 1,000-km (600-mile) range with 80 percent DC fast-charge in 10 minutes or less. In December, Chinese automaker <a href=\"https://www.nio.com/et7\" rel=\"noopener noreferrer\" target=\"_blank\">NIO</a> also got in the game, saying it is introducing a 150-kilowatt-hour “semi-solid-state battery” that would theoretically offer a 1,000-km range as soon as this summer.</p><p>Experts were quick to point out, however, that NIO’s battery, made by <a href=\"http://www.solidstatelion.com/en/about/\" rel=\"noopener noreferrer\" target=\"_blank\">WeLion New Energy Technology Co.</a>, is not solid-state. “This is in fact a fairly conventional NMC (nickel manganese cobalt) cell with a gel electrolyte that has been in production for 15 years and is typically referred to as lithium-polymer,” noted Sam Abuelsamid, principal research analyst for <a href=\"https://guidehouseinsights.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Guidehouse Insights</a>. “Technically the gel is considered a semi-solid because it has properties of both a solid and liquid. But in a cell, it lacks the properties of a true solid-state electrolyte.” Notably, he said, semi-solid-state cells can be punctured on impact, which is closer to the nature of a traditional lithium-ion battery—and in contrast with actual solid-state cells, which would fracture. He also noted that semi-solid-state cells, with a manganese spinel chemistry, were used on a <a href=\"https://www.cnet.com/roadshow/news/hyundai-goes-high-tech-with-sonata-its-first-hybrid/\" rel=\"noopener noreferrer\" target=\"_blank\">Hyundai Sonata hybrid in 2009</a>.</p><h3>Engineering challenge</h3><p>The big challenge facing true solid-state cells, however, is the long climb to engineering validation. Galyen cites five “golden rules” of batteries–safety, performance, life, cost, and environmental–which must be met for solid-state cells to achieve industry-wide adoption.</p><p class=\"pull-quote\">The process is reminiscent of Elon Musk’s reference to “manufacturing hell” in 2018.</p><p>“Most of the solid-state battery companies fall short on at least three of the five golden rules,” he said. “I haven’t seen anyone publish life numbers that make any sense. And I haven’t seen cost numbers that are even close to competing with liquid-state, lithium-ion batteries.” Solid-state costs, he said, are about where conventional lithium-ion batteries were a decade ago.</p><p>Automakers also still need to verify the “performance rule” in three key areas–performance at temperature, performance at altitude, and performance under shock and vibration. Of those, Galyen said, shock and vibration are particularly concerning. “What happens when you’re driving down I-75 and you hit a big pit in the road?” he said. “What kind of damage would be done to the solid-state matrix?”</p><p>Automakers will not move to broad adoption until they are able to verify the new technology’s abilities in all those key areas, Galyen added. “None of these batteries have been validated yet,” he said. “So how do you plan on putting something into automotive production when it hasn’t been validated?”</p><p>Validation will take time, while automakers test factory-built cells in real-world conditions. To do that, manufacturers will first need to build battery factories, which could take two years, and then run a half-year of prototype products and distribute them to customers, who put them through their duty cycles. “Then you put the products into production and find out what your ‘gotchas’ are,” Galyen said of the inevitable problems.</p><p>The process is reminiscent of Elon Musk’s reference to “manufacturing hell” in 2018. Back then, Musk declared his company was about enter into six months of the so-called “hell” as it struggled to work out the kinks in its Model 3 production line. He told <a href=\"https://www.wsj.com/articles/elon-musks-trip-through-hell-inside-the-2018-scramble-to-avoid-the-collapse-of-tesla-11627660800\" rel=\"noopener noreferrer\" target=\"_blank\">reporters at the time</a> that a flood, a tornado, or even a ship sinking anywhere on earth could disrupt his company’s plans.</p><p>Galyen said that such headaches are commonplace in manufacturing, but particularly so in battery production. “There’s not one battery I’ve ever seen that doesn’t have a ton of ‘gotchas,’” he said.</p><p>To do the build-out, production, and validation could easily take seven or more years, Galyen said.</p><h3>Science nearly ready</h3><p>Experts expect the science to keep evolving during that period. Today, there are numerous versions of solid-state batteries using everything from traditional graphite to silicon to lithium metal in the anode, and there are cathodes made from traditional NMC and nickel-rich materials.</p><p class=\"pull-quote\">Most experts assume that more time is needed to run the gauntlet of engineering validation, even for the biggest, most secretive companies.</p><p><span></span>Battery scientists are optimistic that the new breed of batteries can overcome two key drawbacks of conventional lithium-ion. First, they say, nickel-rich cathodes will enable the battery industry to use less cobalt in the cathode. Second, solid-state chemistries will enable battery makers to use lithium metal in the anode.</p><p>The ability to reduce cobalt in the cathode is important because cobalt is scarce, expensive, and <a href=\"https://www.washingtonpost.com/world/interactive/2023/ev-cobalt-mines-congo/\" target=\"_blank\">often mined in countries with weak labor laws</a>. And the ability to use lithium metal in the anode is important because it would boost energy density while promoting safety. Makers of liquid-based lithium-ion batteries currently don’t use lithium metal anodes due to fear of fires.</p><p>“This is why we started this (solid-state) journey in the first place–so we could use lithium metal,” noted <a href=\"https://sigarra.up.pt/feup/en/func_geral.formview?p_codigo=320005\" target=\"_blank\">Helena Braga</a>, an associate professor of engineering physics at the University of Porto, in Portugal, and a well-known researcher who worked with <a href=\"https://www.nobelprize.org/prizes/chemistry/2019/goodenough/facts/\" target=\"_blank\">Nobel Prize</a> winner <a href=\"https://spectrum.ieee.org/john-goodenough-tribute\" target=\"_self\">John Goodenough</a> on solid-state batteries a decade ago. Braga said she is confident that the new chemistries will be ready soon, if they are not already.</p><p>What’s unknown is how far along those chemistries may be within some of the big manufacturing companies that make few public pronouncements, such as <a href=\"https://www.lgchem.com/main/index\" target=\"_blank\">LG Chem</a> and <a href=\"https://www.byd.com/us\" target=\"_blank\">BYD</a>. Some of those companies may be farther along, but it’s hard to know because there is so little reliable information.</p><p>For now, most experts assume that more time is needed to run the gauntlet of engineering validation, even for the biggest, most secretive companies.</p><p>“Most of the companies have great hope that they’re going to achieve success with the five golden rules,” Galyen said. “And they expect it to happen in the next decade.”</p>"},"pubDate":"Fri, 26 Jan 2024 16:44:05 +0000","guid":"https://spectrum.ieee.org/solid-state-battery-production-challenges","category":["Batteries","Cathodes","Electric vehicles","Elon musk","John goodenough","Solid electrolyte"],"dc:creator":"Charles J. Murray","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-rectangular-pouch-with-two-pieces-coming-out-of-the-top.jpg?id=51190107&width=980"}},{"title":"Blade Strike on Landing Ends Mars Helicopter’s Epic Journey","link":"https://spectrum.ieee.org/mars-helicopter-ingenuity-end-mission","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-photo-from-ingenuitys-navigation-camera-shows-the-shadow-of-one-of-its-rotors-with-significant-damage-to-the-tip.jpg?id=51190273&width=1200&height=800&coordinates=0%2C157%2C0%2C158\"/><br/><br/><p>\n\tThe Ingenuity Mars Helicopter made its 72nd and final flight on 18 January. “While the helicopter remains upright and in communication with ground controllers,” NASA’s Jet Propulsion Lab said \n\t<a href=\"https://www.jpl.nasa.gov/news/after-three-years-on-mars-nasas-ingenuity-helicopter-mission-ends\" rel=\"noopener noreferrer\" target=\"_blank\">in a press release this afternoon</a>, “imagery of its Jan. 18 flight sent to Earth this week indicates one or more of its rotor blades sustained damage during landing, and it is no longer capable of flight.” That’s what you’re seeing in <a href=\"https://photojournal.jpl.nasa.gov/catalog/PIA26243\" rel=\"noopener noreferrer\" target=\"_blank\">the picture above</a>: the shadow of a broken tip of one of the helicopter’s four 2-foot-long carbon-fiber rotor blades. NASA is assuming that at least one blade struck the Martian surface during a “rough landing,” and this is not the kind of damage that will allow the helicopter to get back into the air. Ingenuity’s mission is over.</p><hr/><p><br/></p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"a2535f824bfbf7fb54c089d5b9166ac3\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"2d567\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/the-perseverance-rover-took-this-picture-of-ingenuity-on-on-2-u00a0august-u00a02023-just-before-flight-54.jpg?id=51190282&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">The Perseverance rover took this picture of Ingenuity on on 2 August 2023, just before flight 54.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">NASA/JPL-Caltech/ASU/MSSS</small></p><p>\n\tNASA held a press conference earlier this evening to give as much information as they could about exactly what happened to Ingenuity, and what comes next. First, here’s a summary \n\t<a href=\"https://www.nasa.gov/news-release/after-three-years-on-mars-nasas-ingenuity-helicopter-mission-ends/\" rel=\"noopener noreferrer\" target=\"_blank\">from the press release</a>:\n</p><blockquote>\n\tIngenuity’s team planned for the helicopter to make a short vertical flight on Jan. 18 to determine its location after executing an emergency landing on its previous flight. Data shows that, as planned, the helicopter achieved a maximum altitude of 40 feet (12 meters) and hovered for 4.5 seconds before starting its descent at a velocity of 3.3 feet per second (1 meter per second).\n\t<br/>\n<br/>\nHowever, about 3 feet (1 meter) above the surface, Ingenuity lost contact with the rover, which serves as a communications relay for the rotorcraft. The following day, communications were reestablished and more information about the flight was relayed to ground controllers at NASA JPL. Imagery revealing damage to the rotor blade arrived several days later. The cause of the communications dropout and the helicopter’s orientation at time of touchdown are still being investigated.\n</blockquote><p>\n\tWhile NASA doesn’t know for sure what happened, they do have some ideas based on the cause of the emergency landing during the previous flight, Flight 71. “[This location] is some of the hardest terrain we’ve ever had to navigate over,” said \n\t<a href=\"https://spectrum.ieee.org/mars-helicopter-ingenuity-50\" target=\"_self\">Teddy Tzanetos, Ingenuity project manager at NASA JPL</a>, during the NASA press conference. “It’s very featureless—bland, sandy terrain. And that’s why we believe that during Flight 71, we had an emergency landing. She was flying over the surface and was realizing that there weren’t too many rocks to look at or features to navigate from, and that’s why Ingenuity called an emergency landing on her own.”<br/>\n</p><p>\n<a href=\"https://spectrum.ieee.org/nasa-designed-perseverance-helicopter-rover-fly-autonomously-mars\" target=\"_self\">Ingenuity uses a downward-pointing VGA camera running at 30 hertz for monocular feature tracking</a>, and compares the apparent motion of distinct features between frames to determine its motion over the ground. This optical flow technique is used for drones (and other robots) on Earth too, and it’s very reliable, as long as you have enough features to track. Where it starts to go wrong is when your camera is looking at things that are featureless, which is why consumer drones will sometimes warn you about unexpected behavior when flying over water, and why robotics labs often have bizarre carpets and wallpaper—the more features, the better. On Mars, Ingenuity has been reliably navigating by looking for distinctive features like rocks, but flying over a featureless expanse of sand caused serious problems, as <a href=\"https://spectrum.ieee.org/ingenuity-how-to-fly-a-helicopter-on-mars\" target=\"_self\">Ingenuity’s Chief Pilot Emeritus Håvard Grip</a> explained to us during today’s press conference:\n</p><blockquote>\n\tThe way a system like this works is by looking at the consensus of [the features] it sees, and then throwing out the things that don’t really agree with the consensus. The danger is when you run out of features, when you don’t have very many features to navigate on, and you’re not really able to establish what that consensus is, and you end up tracking the wrong kinds of features, and that’s when things can get off track.\n</blockquote><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"dd3d90a1f7d9670fc145ed2b0cf7df0b\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"5b2fb\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/this-view-from-ingenuity-u2019s-navigation-camera-during-flight-70-on-22-u00a0december-u00a0shows-areas-of-nearly-featureless.jpg?id=51190280&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">This view from Ingenuity’s navigation camera during flight 70 (on 22 December) shows areas of nearly featureless terrain that would cause problems during flights 71 and 72.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">NASA/JPL-Caltech</small></p><p>\n\tAfter the Flight 71 emergency landing, the team decided to try a “pop-up” flight next: It was supposed to be about 30 seconds in the air, just straight up to 12 meters and then straight down as a check-out of the helicopter’s systems. As Ingenuity was descending, just before landing, there was a loss of communications with the helicopter. “We have reason to believe that it was facing the same featureless sandy terrain challenges [as in the previous flight],” said Tzanetos. “And because of the navigation challenges, we had a rotor strike with the surface that would have resulted in a power brownout, which caused the communications loss.” Grip describes what he thinks happened in more detail:\n</p><blockquote>\n\tSome of this is speculation because of the sparse telemetry that we have, but what we see in the telemetry is that coming down towards the last part of the flight, on the sand, when we’re closing in on the ground, the helicopter relatively quickly starts to think that it’s moving horizontally away from the landing target. It’s likely that it made an aggressive maneuver to try to correct that right upon landing. And that would have accounted for a sideways motion and tilt of the helicopter that could have led to either striking the blade to the ground and then losing power, or making a maneuver that was aggressive enough to lose power before touching down and striking the blade. We don’t know those details yet. We may never know. But we’re trying as hard as we can with the data that we have to figure out those details.\n</blockquote><p>\n\tWhen the Ingenuity team tried reestablishing contact with the helicopter the next \n\t<a href=\"https://mars.nasa.gov/mars2020/mission/status/365/a-sol-in-the-life-of-a-rover/\" rel=\"noopener noreferrer\" target=\"_blank\">sol</a>, “she was right there where we expected her to be,” Tzanetos said. “Solar panel currents were looking good, which indicated that she was upright.” In fact, everything was “green across the board.” That is, until the team started looking through the images from Ingenuity’s navigation camera, and spotted the shadow of the damaged lower blade. Even if that’s the only damage to Ingenuity, the whole rotor system is now both unbalanced and producing substantially less lift, and further flights will be impossible.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"a3ec91d69ff634dc14045df0d5dfcf09\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"6e577\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-closeup-of-the-shadow-of-the-damaged-blade-tip.png?id=51190277&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A closeup of the shadow of the damaged blade tip.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">NASA/JPL-Caltech </small>\n</p><blockquote>\n\tThere’s always that piece in the back of your head that’s getting ready every downlink—today could be the last day, today could be the last day. So there was an initial moment, obviously, of sadness, seeing that photo come down and pop on-screen, which gives us certainty of what occurred. But that’s very quickly replaced with happiness and pride and a feeling of celebration for what we’ve pulled off. Um, it’s really remarkable the journey that she’s been on and worth celebrating every single one of those sols. Around 9 pm tonight Pacific time will mark 1,000 \n\t<a href=\"https://mars.nasa.gov/mars2020/mission/status/365/a-sol-in-the-life-of-a-rover/\" rel=\"noopener noreferrer\" target=\"_blank\">sols</a> that Ingenuity has been on the surface since her deployment from the Perseverance rover. So she picked a very fitting time to come to the end of her mission. —Teddy Tzanetos\n</blockquote><p>\n\tThe Ingenuity team is guessing that there’s damage to more than one of the helicopter’s blades; the blades spin fast enough that if one hit the surface, others likely did too. The plan is to attempt to slowly spin the blades to bring others into view to try to collect more information. It sounds unlikely that NASA will divert the Perseverance rover to give Ingenuity a closer look. While continuing on its science mission, the rover will come between 200 and 300 meters of Ingenuity and will try to take some pictures, but that’s likely too far away for a good quality image.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"f244e73578f7186821a3188a74ad6b86\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"85a9d\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/perseverance-watches-ingenuity-take-off-on-flight-47-on-14-u00a0march-2023.gif?id=51190293&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Perseverance watches Ingenuity take off on flight 47 on 14 March 2023.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">NASA/JPL-Caltech/ASU/MSSS</small></p><p>\n\tAs a tech demo, Ingenuity’s entire reason for existence was to push the boundaries of what’s possible. And as Grip explains, even in its last flight, the little helicopter was doing exactly that, going above and beyond and trying newer and riskier things until it got as far as it possibly could:\n</p><blockquote>\n\tOverall, the way that Ingenuity has navigated using features of terrain has been incredibly successful. We didn’t design this system to handle this kind of terrain, but nonetheless it’s sort of been invincible until this moment where we flew in this completely bland terrain where you just have nothing to really hold on to. So there are some lessons in that for us: We now know that that particular kind of terrain can be a trap for a system like this. Backing up when encountering this featureless terrain is a functionality that a future helicopter could be equipped with. And then there are solutions like having a higher-resolution camera, which would have likely helped mitigate this situation. But it’s all part of this tech demo, where we equipped this helicopter to do at most five flights in a pre-scouted area and it’s gone on to do so much more than that. And we just worked it all the way up to the line, and then just tipped it right over the line to where it couldn’t handle it anymore.\n</blockquote><p>\n\tArguably, Ingenuity’s most important contribution has been showing that it’s not just possible <a href=\"https://spectrum.ieee.org/mars-perseverance\" target=\"_self\">but practical and valuable</a> to have rotorcraft on Mars. “I don’t think we’d be talking about<a href=\"https://spectrum.ieee.org/nasa-mars-sample-return\" target=\"_self\"> sample recovery helicopters</a> if Ingenuity didn’t fly, period, and if it hadn’t survived for as long as it has,” <a href=\"https://spectrum.ieee.org/mars-helicopter-ingenuity-50\" target=\"_blank\">Teddy Tzanetos told us after Ingenuity’s 50th flight</a>. And it’s not just the sample return mission: JPL is also developing <a href=\"https://spectrum.ieee.org/the-next-mars-helicopter\" target=\"_self\">a much larger Mars Science Helicopter</a>, which will owe its existence to Ingenuity’s success.\n</p><p>\n\tNearly three years on Mars; 128 minutes and 11 miles of flight in the Martian skies. “I look forward to the day that one of our astronauts brings home Ingenuity and we can all visit it in the Smithsonian,” said \n\t<a href=\"https://www.jpl.nasa.gov/who-we-are/executive-council/laurie-leshin-director-of-jpl\" rel=\"noopener noreferrer\" target=\"_blank\">Director of JPL Laurie Leshin</a> at the end of today’s press conference.\n</p><p>\n\tI’ll be first in line.\n</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"d82923507d92dbd1701fd8493287ad94\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/raOA2MX-XLQ?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>\n\tWe’ve written extensively about Ingenuity, including in-depth interviews with both helicopter and rover team members, and they’re well worth rereading today. Thanks, Ingenuity. You did well.\n</p><p>\n<br/>\n</p><h5>\n<a href=\"https://spectrum.ieee.org/mars-helicopter-ingenuity-50\" target=\"_self\">What Flight 50 Means for the Ingenuity Mars Helicopter</a> </h5><p><em>\nTeam lead Teddy Tzanetos on the helicopter’s milestone aerial mission</em></p><p>\n<br/>\n</p><h5>\n<a href=\"https://spectrum.ieee.org/mars-perseverance\" target=\"_self\">Mars Helicopter Is Much More Than a Tech Demo</a>\n</h5><p><em>\n</em><em>A Mars rover driver explains just how much of a difference the little helicopter scout is making to Mars exploration</em>\n</p><p>\n<br/>\n</p><h5>\n<a href=\"https://spectrum.ieee.org/ingenuity-how-to-fly-a-helicopter-on-mars\" target=\"_self\">Ingenuity’s Chief Pilot Explains How to Fly a Helicopter on Mars </a>\n</h5><p><em>\n</em><em>Simulation is the secret to flying a helicopter on Mars</em>\n</p><p>\n<br/>\n</p><h5>\n<a href=\"https://spectrum.ieee.org/nasa-designed-perseverance-helicopter-rover-fly-autonomously-mars\" target=\"_self\">How NASA Designed a Helicopter That Could Fly Autonomously on Mars</a>\n</h5><p><em>\n</em><em>The Perseverance rover’s Mars Helicopter (Ingenuity) will take off, navigate, and land on Mars without human intervention</em>\n</p>"},"pubDate":"Fri, 26 Jan 2024 02:08:41 +0000","guid":"https://spectrum.ieee.org/mars-helicopter-ingenuity-end-mission","category":["Ingenuity","Mars helicopter","Mars","Space robots","Robotics"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-photo-from-ingenuitys-navigation-camera-shows-the-shadow-of-one-of-its-rotors-with-significant-damage-to-the-tip.jpg?id=51190273&width=980"}},{"title":"Design Exploration of RF GaN Amplifier, 3D Packaging, and Thermal Analysis","link":"https://www.ansys.com/webinars/design-exploration-of-rf-gan-amplifier-3d-packaging-and-thermal-analysis?utm_campaign=industry&utm_medium=email-single&utm_source=ieee&utm_content=field_high-tech_ieee-email-and[1]website__webinar-live_register_text-linkEmpty_en_global&campaignID=701Pf000005DvQgIAK&utm_term=","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/image.png?id=26851525&width=980\"/><br/><br/><p>Join us for this webinar on RF GaN amplifier design using electromagnetic/thermal 3D solvers. We will discuss the step-by-step process of building a GaN amplifier, beginning with the transistor model in the circuit simulator.<u></u><u></u></p><p>The webinar will outline the steps required to convert this to a physical layout for electromagnetic simulation and verification while integrating packaging and thermal effects co-simulation to analyze a complete packaged system. Discover how this comprehensive approach yields innovative solutions, important design insights, and their potential impact on packaged performance.<u></u><u></u></p><p><a href=\"https://www.ansys.com/webinars/design-exploration-of-rf-gan-amplifier-3d-packaging-and-thermal-analysis?utm_campaign=industry&utm_medium=email-single&utm_source=ieee&utm_content=field_high-tech_ieee-email-and%5B1%5Dwebsite__webinar-live_register_text-linkEmpty_en_global&campaignID=701Pf000005DvQgIAK&utm_term=\" rel=\"noopener noreferrer\" target=\"_blank\">Register now for this free webinar!</a></p><p><strong>What You Will Learn</strong><u></u><u></u></p><ul><li>Design and layout of a typical GaN amplifier using circuit and 3D EM tools<u></u><u></u></li><li>Incorporation of 3D component models (connectors, packages, etc.) for complete system analysis<u></u><u></u></li><li>Co-simulation of packaged devices with thermal solvers<u></u><u></u></li></ul><p><strong>Who Should Attend</strong><u></u><u></u></p><ul><li>Electromagnetic and circuit design engineers: Delve into the co-simulation nuances between circuit models and full 3D designs<u></u><u></u></li><li>System engineers: Develop an understanding of the packaged PA design and tradeoffs<u></u><u></u></li><li>Professionals in wireless communication: Gain comprehensive insights into the modern circuit/package co-simulation workflows</li></ul>"},"pubDate":"Thu, 25 Jan 2024 23:13:08 +0000","guid":"https://www.ansys.com/webinars/design-exploration-of-rf-gan-amplifier-3d-packaging-and-thermal-analysis?utm_campaign=industry&utm_medium=email-single&utm_source=ieee&utm_content=field_high-tech_ieee-email-and[1]website__webinar-live_register_text-linkEmpty_en_global&campaignID=701Pf000005DvQgIAK&utm_term=","category":["Amplifiers","Ansys","Electromagnetic simulation","Electromagnetism","Simulation","Thermal analysis","Type:webinar"],"dc:creator":"Ansys","media:content":{"@medium":"image","@type":"image/png","@url":"https://assets.rbl.ms/26851525/origin.png"}},{"title":"The Brain Implant That Sidesteps The Competition","link":"https://spectrum.ieee.org/brain-implant-close-to-market","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/image.webp?id=51160803&width=980\"/><br/><br/><iframe frameborder=\"no\" height=\"180\" scrolling=\"no\" seamless=\"\" src=\"https://share.transistor.fm/e/ca9f5468\" width=\"100%\"></iframe><p>\n<strong>Eliza Strickland: </strong>Hi, I’m <a href=\"https://spectrum.ieee.org/u/eliza-strickland\" target=\"_self\">Eliza Strickland</a> for <em>IEEE Spectrum</em>‘s <em>Fixing the Future</em> podcast. Before we start, I want to tell you that you can get the latest coverage from some of <em>Spectrum</em>‘s most important beats, including AI, climate change, and robotics, by signing up for one of our free newsletters. Just go to <a href=\"https://spectrum.ieee.org/newsletters/\" target=\"_self\">spectrum.ieee.org/newsletters</a> to subscribe. You’ve probably heard of <a href=\"https://neuralink.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Neuralink</a>, the buzzy neurotech company founded by Elon Musk that wants to put brain implants in humans this year. But you might not have heard of another company, <a href=\"https://synchron.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Synchron</a>, that’s way ahead of Neuralink. The company has already put 10 of its innovative brain implants into humans during its clinical trials, and it’s pushing ahead to regulatory approval of a commercial system. Synchron’s implant is a type of brain-computer interface, or BCI, that can allow severely paralyzed people to control communication software and other computer programs with their thoughts alone. <a href=\"https://profiles.mountsinai.org/thomas-j-oxley\" rel=\"noopener noreferrer\" target=\"_blank\">Tom Oxley</a> is a practicing neurologist at Mount Sinai Hospital in New York City and the founder and CEO of Synchron. He joined us on <em>Fixing the Future</em> to tell us about the company’s technology and its progress. Tom, thank you so much for joining me on <em>Fixing the Future</em> today. So the enabling technology behind Synchron is something called the Stentrode. Can you explain to listeners how that works?\n</p><p>\n<strong>Tom Oxley: </strong>Yeah, so the concept of the Stentrode was that we can take a endovascular platform that’s been used in medicine for decades and build an electronics layer onto it. And I guess it addresses one of the challenges with implantable neurotechnology in the brain, which is that-- well, firstly, it’s hard to get into the brain. And secondly, it’s hard to remain in the brain without having the brain launch a pretty sophisticated immune response at you. And the blood-brain barrier is a thing. And if you can stay inside on one side of that blood-brain barrier, then you do have a very predictable and contained immune response. That’s how tattoos work in the skin. And the skin is the epithelial and the blood vessels have an endothelial layer and they kind of behave the same way. So if you can convince the endothelial layer of the blood vessel to receive a package and not worry about it and just leave it be, then you’ve got a long-term solution for a electronics package that can use the natural highways to most regions within the brain.\n</p><p>\n<strong>Strickland: </strong>Right. So it’s called a Stentrode because it resembles a stent, right? It’s sort of like a mesh sleeve with electrodes embedded in it, and it’s inserted through the jugular. Is that correct?\n</p><p>\n<strong>Oxley:</strong> We actually called it a Stentrode because, in the early days, we were taking stents. And<a href=\"https://www.linkedin.com/in/professor-nicholas-opie-4603289a/?originalSubdomain=au\" rel=\"noopener noreferrer\" target=\"_blank\"> Nick Opie</a> and Gil Rind and Steve as well were taking these stents that we basically took out of the rubbish bin and cleaned them, and then by hand, we’re weaving electrodes onto the stent. So we just needed a name to call the devices that we were testing back in the early days. So Stentrode was a really organic term that we just started using within the group. And I think then 2016 <em>Wired</em> ran a piece, calling it one of the new words. So we’re like, “Okay, this word seems to be sticking.” Yeah, it goes in the jugular vein. So in what we’re seeking to commercialize as the first product offering for our implantable BCI platform, we’re targeting a particular large blood vessel called the superior sagittal sinus. And yes, the entrance into the body is through the jugular vein to get there.\n</p><p>\n<strong>Strickland: </strong>Yeah, I’m curious about the early days. Can you tell me a little bit about how your team came up with this idea in the first place?\n</p><p>\n<strong>Oxley:</strong> The very early conceptualization of this was: I was going through medical school with my co-founder, <a href=\"https://profiles.stanford.edu/rahul-prakash-sharma\" rel=\"noopener noreferrer\" target=\"_blank\">Rahul Sharma</a>, who’s a cardiologist. And he was very fixated on interventional cardiology, which is a very sexy field in medicine. And I was more obsessed with the brain. And it looked—and this was back around 2010—that intervention was going to become a thing in neurology. And it took until 2015 for a real breakthrough in neurointervention to emerge, which was for the treatment of stroke. And that was basically a stent going up into the brain to pull out a blood clot. But I was always less interested in the plumbing and more interested in how it could be that the electrical activity of the brain created not just health and disease but also wellness and consciousness. And that whole continuum of the brain, mind was why I went into medicine in the first place. But I thought the technology— the speed of technology growth in the interventional domain in medicine is incredible. Relative to the speed of expansion of other surgical domains, the interventional domain, and now into robotics is, I would say, the most fast-moving area in medicine. So I think I was excited about technology in neurointervention, but it was the electrophysiology of the brain that was so enticing. And the brain has remained this black box for a long period of time.\n</p><p>\n\tWhen I started medicine, doing neurology was a joke to the other types of ambitious young medical people because, well, in neurology, you can diagnose everything, but you can’t treat anything. And now implantable neurotechnology is opening up access into the brain in a way which just wasn’t possible 10 or 15 years ago. So that was the early vision. The early vision was, can the blood vessels open up avenues to get to the brain to treat conditions that haven’t previously been treated? So that was the early conceptualization of the idea. And then I was bouncing this idea around in my head, and then I read about brain-computer interfaces, and I read about <a href=\"https://www.braingate.org/team/leigh-hochberg-m-d-ph-d/\" rel=\"noopener noreferrer\" target=\"_blank\">Leigh Hochberg</a> and the <a href=\"https://www.braingate.org/\" rel=\"noopener noreferrer\" target=\"_blank\">BrainGate</a> work. And then I thought, “Oh, well, maybe that’s the first application of functional neurointervention or electronics in neurointervention.” And the early funding came from US defense from DARPA, but we spent four or five years in Melbourne, Australia, Nick Opie hand-building these devices and then doing sheep experiments to prove that we could record brain activity in a way that was going to be meaningful from a signal-to-noise perspective that we felt was going to be sufficient to drive a brain-computer interface for motor control.\n</p><p>\n<strong>Strickland: </strong>Right. So with the Stentrode, you’re recording electrical signals from the brain through the blood vessels. So I guess that’s some remove. And the BrainGate Consortium that you referenced before, they’re one of many, many groups that have been doing implanted electrodes inside the brain tissue where you can get up close to the neurons. So it feels like you have a very different approach. Have you ever doubted it along the way? Feel like, “Oh my gosh, the entire community of BCI is going in this other direction, and we’re going in this one.” Did it ever make you pause?\n</p><p>\n<strong>Oxley:</strong> I think clinical translation is very different to things that can be proven in an experimental setting. And so I think, yeah, there’s a data reduction that occurs if you stay on the surface of the brain, and particularly if you stay in a blood vessel that’s on the surface of the brain. But the things that are solved technically make clinical translation more of a reality. And so the way I think about it more is not, “Well, how does this compete with systems that have proven things out in an experimental domain versus what is required to achieve clinical translation and to solve a problem in a patient setting?” So they’re kind of different questions. So one is kind of getting obsessed with a technology race based upon technology-based metrics, and the other is, “Well, what is the clinical unmet need and what are particular ways that we can solve that?” And I’ll give an example of that, something that we’re learning now. So yeah, this first product is in a large blood vessel that only gives a constrained amount of access to the motor cortex. But there are reasons why we chose that.\n</p><p>\n\tWe know it’s safe. We know it can live in there. We know we can get there. We know we have a procedure that can do that. We know we have lots of people in the country that can do that procedure. And we understand roughly what the safety profile is. And we know that we can deliver enough data that can drive performance of the system. But what’s been interesting is there are advantages to using population-level <a href=\"https://en.wikipedia.org/wiki/Local_field_potential\" rel=\"noopener noreferrer\" target=\"_blank\">LFP-type</a> brain recordings. And that is that they’re more stable. They’re quite robust. They’re easy to detect. They don’t need substantial training. And we have low power requirements, which means our power can go for a long time. And that really matters when you’re talking about helping people who are paralyzed or have motor impairment because you want there to be as little troubleshooting as possible. It has to be as easy to use as possible. It has to work immediately. You can’t spend weeks or months training. You can’t be troubleshooting. You can’t be having to press anything. It just should be working all the time. So these things have only become obvious to us most recently.\n</p><p>\n<strong>Strickland: </strong>So we’ve talked a little bit about hardware. I’m also curious about the software side of things. How has that evolved over the course of your research? The part of your system that looks at the electrical signals and translates them into some kind of meaningful action.\n</p><p>\n<strong>Oxley: </strong>Yeah. It’s been an awesome journey. I was just visiting one of our patients just this week. And watching him go through the experience of trying out different features and having him explain to us— not all of our patients can talk. He can still talk, but he’s lost control of his hands, so he can’t use his iPhone anymore. And hearing what it feels like for him to— we’re trying out different levels of control, in particular in this case with iPad use. And it’s interesting because we are also still feeling very early, but this is not a science experiment. We’re trying to zero in and focus on features that we believe are going to work for everyone and be stable and that feel good in the use of the system. And you can’t really do that in the preclinical setting. You have to wait until you’re in the clinical setting to figure that out. And so it’s been interesting because what do we build? We could build any number of different iterations of control features that are useful, but we have to focus on particular control interaction models that are useful for the patient and which feel good for the patient and which we think can scale over a population. So it’s been a fascinating journey.\n</p><p>\n<strong>Strickland: </strong>Can you tell me a little bit about the people who have participated in your clinical trials so far and why they need this kind of assistive device?\n</p><p>\n<strong>Oxley: </strong>Yeah. So we’ve had a range of levels of disability. We’ve had people on the one end who have been completely locked in, and that’s from a range of different conditions. So locked-in syndrome is where you still may have some residual cranial nerve function, like eye movements or maybe some facial movements, but in whom you can’t move your upper or lower limbs, and often you can’t move your head. And then, on the other end of the spectrum, we’ve had some patients on the neurodegenerative side with ALS, in particular, where limb function has impaired their ability to utilize digital devices. And so really, the way I think about-- how we’re thinking about the problem is: the technology is for people who can’t use their hands to control personal digital devices. And why that matters is because they-- we’ve all become pretty dependent on digital devices for activities of daily living, and the things that matter from a clinically meaningful perspective are things like communication, texting, emailing, messaging, banking, shopping, healthcare access, environmental smart control, and then entertainment.\n</p><p>\n\tAnd so even for the people who can still— we’ve got someone in our study who can still speak and who can actually still walk, but he can’t use a digital device. And he’s been telling us-- like you’d think, “Oh, well, what about Siri? What about Alexa?” And you realize that if you really remove the ability to press any button, it becomes very challenging to engage in even the technology that’s existing. Now, we still don’t know what the exact indication will be for our first application, but even in patients who can still talk, we’re finding that there are major gaps in their capacity to engage in digital devices that I believe BCI is going to solve. And it’s often very simple things. I’ll give you an example. If you try to answer the phone when Siri-- if you try to answer the phone with Siri, you can’t put it on speakerphone. So you can say, “Yes, Siri, answer the phone,” but then you can’t put on the speakerphone. So there are little things like that where you just need to hit a couple of buttons that make the difference to be able to give you that engagement.\n</p><p>\n<strong>Strickland:</strong> I’d like to hear about what the process has been like for these volunteers. Can you tell me about what the surgery was like and then how-- or if you had to calibrate the device to work with their particular brains?\n</p><p>\n<strong>Oxley:</strong> Yeah. So the surgery is in the cath lab in a hospital. It’s the same place you would go to to have a stent put in or a pacemaker. So that involves: first, there are imaging studies to make sure that the brain is appropriate and that all the blood vessels leading up into the brain are appropriate. So we have our physicians identify a suitable patient, talk to the patient. And then, if they’re interested in the study, they’ve joined the study. And then we do brain imaging. The investigators make a determination that they can access that part of the brain. Then the procedure, you come in; it takes a few hours. You lie down; you have an X-ray above you. You’re using X-ray and dye inside the blood vessels to navigate to the right spot. We have a mechanism to make sure that you are in the exact spot you need to be. The Stentrode sort of opens up like a flower in that spot, and it’s got self-expanding capacity, so it stays put. And then there is a device that-- so the lead comes out of the skull through a natural blood vessel passage, and then that gets plugged into an electronics package that sits on the chest under the skin. So the whole thing’s fully implanted. The patients have been then resting for a day or so and then going home. And then, in the setting of this clinical study, we’re having our field clinical engineers going out to the home two to three times per week and practicing with the system and practicing with our new software versions that we keep releasing. And that’s how we’re building-- that’s how we’re building a product.\n</p><p>\n\tBy the time we get to the next stage of the clinical trial, the software is getting more and more automated. From a learning perspective, we have a philosophy that if there’s a substantial learning curve for this patient population, that’s not good. It’s not good for the patient. It’s not good for the caregiver. These patients who are suffering with severe paralysis or motor impairment may not have the capacity to train for weeks to months. So it needs to work straight away. And ideally, you don’t want it to be recalibrated every day. So we’ve had our system-- I mean, we’re going to publish all this, but we’ve working and designing towards having the system working on day one as soon as it’s turned on with level of functionality that lets the user immediately have functionality at some particular level that is enough to let them perform some of the critical activities of daily living, the tasks that I just mentioned earlier. And then I think the vision is that we build a training program within the system that lets users build up their capability to increasing levels of capability, but we’re much more focused on the lowest level of function that everyone can achieve and make it easy to do.\n</p><p>\n<strong>Strickland: </strong>For it to work right out of the box, how do you make that work? Is one person’s brain signals pretty much the same as another person’s?\n</p><p>\n<strong>Oxley: </strong>Yeah, so <a href=\"https://www.linkedin.com/in/petereliyoo/\" rel=\"noopener noreferrer\" target=\"_blank\">Peter Yoo</a> is our superstar head of algorithms and neuroscience. He has pulled together this incredible team of neuroscientists and engineers. I think the team is about 10 people now. And these guys have been working around the clock over the last 12 months to build an automated decoder. And we’ve been talking about this internally recently as what we think is one of the biggest breakthroughs. We’ll publish it at a point that’s at the right time, but we’re really excited about this. We feel like we have built a decoder that does not need to be tuned individually at all and will just work out of the box based upon what we’ve learned so far. And we expect that kind of design ethos to continue over time, but that’s going to be a critical part of the focus on making the system easy to use for our patients.\n</p><p>\n<strong>Strickland: </strong>When a user wants to click on something, what do they do? What’s the mental process that they go through?\n</p><p>\n<strong>Oxley:</strong> Yeah. So I’ve talked about the fact that we do population-level activation of motor cortical neurons. So what does your motor cortex do? Your motor cortex is about 10% of your brain, and you were born with it, and it was connected to all of these muscles in your body. And you learned how to walk. You learned how to run. My daughter just learned how to jump. She’s two and a little bit. And so you spend those early years of your life training your brain on how to utilize the motor cortex, but it’s connected to those certain physically tethered parts of your body. So one theory in BCI, which is what the kind of multi-unit decoding theory is, is that, “Let’s train the neurons to do a certain task.” And it’s often like training it to work within certain trajectories. I guess the way we think about it is, “Let’s not train it to do anything. Let’s activate the motor cortex in the way that the brain already knows how to activate it in really robust, stable ways at a population level.” So probably tens of thousands of neurons, maybe hundreds of thousands of neurons. And so how would you do that? Well, you would make the brain think about what it used to think about to make the body move. And so in people who have had injury or disease, they would have already lived a life where they have thought about pressing down their foot to press the brake pedal on the car, or kicking a ball, or squeezing their fist. We identify robust, strong motor intention contemplations, which we know are going to activate broad populations of neurons robustly.\n</p><p>\n<strong>Strickland:</strong> And so that gives them the ability to click, and I think there’s also something else they can do to scroll. Is that right?\n</p><p>\n<strong>Oxley: </strong>Yeah. So right now, we’re not yet at the point where we’ve got the cursor moving around the screen, but we have a range of— we have multi-select, scroll, click, click and hold, and some other things that are coming down the pipeline, which are pretty cool, but enough for the user to navigate their way around a screen like an Apple on like an iOS and make selections on the screen. And so the way we’re thinking about that is so converting that into a clinical metric. David Petrino at Mount Sinai has recently published this paper on what he’s called the digital motor output, DMO. And so the conversion of those population neurons into these constrained or not constrained, but characterized outputs, we’re calling that a DMO. And so the DMO-- the way I think about a DMO is that is your ability to accurately select a desired item on a screen with a reasonable accuracy and latency. And so the way we’re thinking about this is how well can you make selections in a way that’s clinically meaningful and which serves the completion of those tasks that you couldn’t do before?\n</p><p>\n<strong>Strickland: </strong>Are you aiming for eventually being able to control a cursor as it goes around the screen? Is that on the roadmap?\n</p><p>\n<strong>Oxley: </strong>That is on the roadmap. That’s where we are headed. And I mean, I think ultimately, we have to prove that it’s possible from inside a blood vessel. But I think when we do prove that, I think— I’m excited that there’s a history in medicine that minimally invasive solutions that don’t require open surgery tend to be the desired choice of patients. And so we’ve started this journey in a big blood vessel with a certain amount of access, and we’ve got a lot of other exciting areas that we’re going to go into that give us more and more access to more brain, and we just want to do it in a stepwise and safe fashion. But yeah, we are very excited that that’s the trajectory that we’re on. But we also feel that we’ve got a starting point, which we think is the stepwise fashion, a safe starting point.\n</p><p>\n<strong>Strickland: </strong>I think we’re just about out of time, so maybe just one last question. Where are you on the path towards FDA approval? What do you anticipate happening as next steps there?\n</p><p>\n<strong>Oxley:</strong> So we’ve just finished enrollment of our 10th patient in our feasibility study. Well, we had four patients in our first Australian study and now six patients in an early feasibility study. That will continue to run formally for another, I believe, six months or so. And we’ll be collecting all that data. And we’re having very healthy conversations with the FDA, with Heather Dean’s group in the FDA. And we’ll be discussing what the FDA need to see to demonstrate both safety and efficacy towards a marketing approval with what we hope will be the first commercial implantable BCI system. But we’ve still got a way to go. And there’s a very healthy conversation happening right now about how to think about those outcomes that are meaningful for patients. So I would say over the next few years, we’re just moving our way through the stages of clinical studies. And hopefully, we’ll be opening up more and more sites across the country and maybe globally to enroll more people and hopefully make a difference in the lives of this condition, which really doesn’t have any treatment right now.\n</p><p>\n<strong>Strickland:</strong> Well, Tom, thank you so much for joining me. I really appreciate your time.\n</p><p>\n<strong>Oxley: </strong>Thank you so much, Eliza.\n</p><p>\n<strong>Strickland: </strong>That was Tom Oxley speaking to me about his company, Synchron, and its innovative brain-computer interface. If you want to learn more, we ran <a href=\"https://spectrum.ieee.org/synchron-bci\" target=\"_self\">an article about Synchron</a> in <em>IEEE Spectrum</em>‘s January issue, and we’ve linked to it in the show notes. I’m Eliza Strickland, and I hope you’ll join us next time on Fixing the Future.\n</p>"},"pubDate":"Wed, 24 Jan 2024 10:00:02 +0000","guid":"https://spectrum.ieee.org/brain-implant-close-to-market","category":["Bci","Synchron","Brain computer interface","Brain implant","Fixing the future","Type:podcast"],"dc:creator":"Eliza Strickland","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://assets.rbl.ms/51160803/origin.webp"}},{"title":"A How-To Guide on Acquiring AI Systems","link":"https://spectrum.ieee.org/guide-on-acquiring-ai-systems","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-group-of-people-in-front-of-screens-related-to-ai-and-purchasing.jpg?id=51172897&width=1200&height=800&coordinates=126%2C0%2C0%2C0\"/><br/><br/><p><a href=\"https://www.idc.com/getdoc.jsp?containerId=prUS49670322\" rel=\"noopener noreferrer\" target=\"_blank\">International Data Corp.</a> estimated that US $118 billion was spent globally in 2022 to purchase artificial intelligence hardware, software, and data services. IDC has predicted the figure will nearly triple, to $300 billion, by 2026. But <a href=\"https://www.oecd.org/gov/public-procurement/\" rel=\"noopener noreferrer\" target=\"_blank\">public procurement</a> systems are not ready for the challenges of procuring AI systems, which bring with them new risks to citizens.</p><p>To help address this challenge <a href=\"https://standards.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Standards Association</a> has introduced a pioneering standard for AI procurement. The standard, which is in development, can help government agencies be more responsible about how they acquire AI that serves the public interest.</p><p>Governments today are using AI and <a href=\"https://automatingsociety.algorithmwatch.org/wp-content/uploads/2020/12/Automating-Society-Report-2020.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">automated decision-making</a> systems to <a href=\"https://epic.org/wp-content/uploads/2023/09/FINAL-EPIC-Outsourced-Automated-Report-w-Appendix-Updated-9.26.23.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">aid or replace human-made decisions</a>. The ADM systems’ judgments can impact citizens’ access to education, employment, health care, social services, and more.</p><p>The multilayered <a href=\"https://academic.oup.com/edited-volume/41989/chapter-abstract/355438981?redirectedFrom=fulltext&login=false\" rel=\"noopener noreferrer\" target=\"_blank\">complexity</a> of AI systems, and the datasets they’re built on, challenge people responsible for procurement—who rarely <a href=\"https://doi.org/10.1007/s00146-022-01572-2\" rel=\"noopener noreferrer\" target=\"_blank\">understand</a> the systems they’re purchasing and deploying. The vast majority of government procurement models worldwide have yet to adapt their acquisition processes and laws to the systems’ complexity.</p><p>To assist government agencies in being better stewards of public-use technology, in 2021 the IEEE Standards Association approved the development of a new type of socio-technical standard, the IEEE <a href=\"https://standards.ieee.org/ieee/3119/10729/\" rel=\"noopener noreferrer\" target=\"_blank\">P3119 Standard for the Procurement of AI and Automated Decision Systems</a>. The standard was inspired by the findings of the <a href=\"https://archive.nyu.edu/handle/2451/62255\" rel=\"noopener noreferrer\" target=\"_blank\">AI and Procurement: A Primer</a> report from the New York University <a href=\"https://engineering.nyu.edu/research-innovation/centers/center-responsible-ai\" rel=\"noopener noreferrer\" target=\"_blank\">Center for Responsible AI</a>.</p><p>The new, voluntary standard is designed to help strengthen AI procurement approaches with due-diligence processes to ensure that agencies are critically evaluating the kinds of AI services and tools they acquire. The standard can provide agencies with a method to require transparency from AI vendors about associated risks.</p><p>IEEE P3119 also can help governments use their procuring power to <a href=\"https://uploads.dayoneproject.org/2022/02/14125252/Market-Shaping-Primer.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">shape the market</a>—which could increase demand for more responsible AI solutions.</p><h2>A how-to guide</h2><p>The standard aims to help government agencies strengthen their requirements for AI procurement. Added to existing regulations, it offers complementary how-to guidance that can be applied to a variety of processes including pre-solicitation and contract monitoring.</p><p>Existing AI procurement guidelines such as the ones from the <a href=\"https://www.gao.gov/products/gao-21-519sp\" rel=\"noopener noreferrer\" target=\"_blank\">U.S. Government Accountability Office</a>, the <a href=\"https://www.weforum.org/publications/ai-procurement-in-a-box/ai-government-procurement-guidelines/#report-nav\" rel=\"noopener noreferrer\" target=\"_blank\">World Economic Forum</a>, and the <a href=\"https://www.fordfoundation.org/wp-content/uploads/2023/03/final_ford-foundation-guiding-framework-r3-full-document-final2.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">Ford Foundation</a> cover AI literacy, best practices, and red flags for vetting technology vendors. The IEEE P3119 standard goes further by providing guidance, for example, on determining whether a problem requires an AI solution. It also can help identify an agency’s risk tolerance, assess a vendor’s answers to questions about AI, recommend <a href=\"https://www.inclusivechange.org/ai-governance-solutions/ai-contract-clauses\" rel=\"noopener noreferrer\" target=\"_blank\">curated AI-specific contract language</a>, and evaluate an AI solution across multiple criteria.</p><p>IEEE is currently developing such an AI procurement guidance, one that moves beyond principles and best practices to detailed process recommendations. IEEE P3119 explicitly addresses the technical complexity of most AI models and the potential risks to society while also considering the systems’ capacity to scale for deployment in much larger populations.</p><p>Discussions in the standards working group centered around ways to identify and evaluate AI risks, how to mitigate risks within procurement needs, and how to provoke transparency about AI governance from vendors, with AI-specific best practices for solicitations and contracts.</p><p>The IEEE P3119 processes are meant to complement and optimize existing procurement requirements. The primary goal for the standard is to offer government agencies and AI vendors ways to adapt their procurement practices and solicited proposals to maximize the benefits of AI while minimizing the risks.</p><p>The standard is meant to become part of the “request for proposals” stage, integrated with solicitations in order to raise the bar for AI procurement so that the public interest and citizens’ civil rights are proactively protected.</p><p>Putting the standard into practice, however, could be challenging for some governments that are dealing with historical regulatory regimes and limited institutional capacity. </p><p>A future article will describe the need to test the standard against existing regulations, known as <a href=\"https://pubmed.ncbi.nlm.nih.gov/32025244/\" rel=\"noopener noreferrer\" target=\"_blank\">regulatory sandboxes</a>. </p>"},"pubDate":"Tue, 23 Jan 2024 22:00:04 +0000","guid":"https://spectrum.ieee.org/guide-on-acquiring-ai-systems","category":["Artificial intelligence","Ethics","Ieee products and services","Ieee standards association","Standards","Type:ti"],"dc:creator":"Cari Miller","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-group-of-people-in-front-of-screens-related-to-ai-and-purchasing.jpg?id=51172897&width=980"}},{"title":"That Awesome Robot Demo Could Have a Human in the Loop","link":"https://spectrum.ieee.org/robot-teleoperation-autonomy","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-man-sits-in-a-chair-wearing-vr-googles-and-attached-to-two-robotic-arms-near-him-a-robot-with-two-arms-show-s-the-man-s-face.png?id=51152136&width=1200&height=800&coordinates=0%2C93%2C0%2C94\"/><br/><br/><p>\n\tOver the past few weeks, we’ve seen a couple of high-profile videos of robotic systems doing really impressive things. And I mean, that’s what we’re all here for, right? Being impressed by the awesomeness of robots! But sometimes the awesomeness of robots is more complicated than what you see in a video making the rounds on social media—any robot has a lot of things going on behind the scenes to make it successful, but if you can’t tell what those things are, what you see at first glance might be deceiving you.\n</p><hr/><p>\n\tEarlier this month, a group of researchers from Stanford’s IRIS Lab introduced Mobile ALOHA, which (if you read the YouTube video description) is described as “a low-cost and whole-body teleoperation system for data collection”:\n</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"19f666b1f65caa81761575dc71136416\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/HaaZ8ss-HP4?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>\n\tAnd just last week, Elon Musk posted a video of Tesla’s Optimus robot folding a shirt:\n</p><blockquote class=\"rm-embed twitter-tweet\" data-conversation=\"none\" data-partner=\"rebelmouse\" data-twitter-tweet-id=\"1746964887949934958\">\n<div style=\"margin:1em 0\"></div> —  (@)\n        <a href=\"https://twitter.com/elonmusk/status/1746964887949934958\"></a>\n</blockquote>\n<script async=\"\" charset=\"utf-8\" src=\"https://platform.twitter.com/widgets.js\"></script><p>\n\tMost people who watch these videos without poking around in the descriptions or comments will likely <em>not</em> assume that these robots were being entirely controlled by experienced humans, because why would they? Even for roboticists, it can be tricky to know for sure whether the robot they’re watching has a human in the loop somewhere. This is a problem that’s not unique to the folks behind either of the videos above; it’s a communication issue that the entire robotics community struggles with. But as robots (and robot videos) become more mainstream, it’s important that we get better at it.<br/>\n</p><h2>Why use teleoperation?</h2><p>\n\tHumans are way, way, way, way, <em>way</em> better than robots at almost everything. We’re fragile and expensive, which is why so many people are trying to get robots to do stuff instead, but with a very few exceptions involving speed and precision, humans are the gold standard and are likely to remain so for the foreseeable future. So, if you need a robot to do something complicated or something finicky or something that might require some innovation or creativity, the best solution is to put a human in control.\n</p><h2>What about autonomy, though?</h2><p>\n\tHaving one-to-one human teleoperation of a robot is a great way of getting things done, but it’s not scalable, and aside from some very specific circumstances, the whole point of robots is to do stuff autonomously at scale so that humans don’t have to. One approach to autonomy is to learn as much as you can from human teleoperation: Many robotics companies are betting that they’ll be able to use humans to gradually train their robotic systems, transitioning from full teleoperation to partial teleoperation to supervisory control to full autonomy. <a href=\"https://sanctuary.ai/\" target=\"_blank\">Sanctuary AI</a> is a great example of this: They’ve been teleoperating their humanoid robots <a href=\"https://www.youtube.com/watch?v=SvlHlf1weYw\" rel=\"noopener noreferrer\" target=\"_blank\">through all kinds of tasks</a>, collecting training data as a foundation for later autonomy.\n</p><h2>What’s wrong with teleoperation, then?\n</h2><p>\n\tNothing! Teleoperation is great. But when people see a robot doing something and it <em>looks </em>autonomous but it’s <em>actually</em> teleoperated, that’s a problem, because it’s a misrepresentation of the state of the technology. Not only do people end up with the wrong idea of how your robot functions and what it’s really capable of, it also means that whenever those people see <em>other</em> robots doing similar tasks autonomously, their frame of reference will be completely wrong, minimizing what otherwise may be a significant contribution to the field by other robotics folks. To be clear, I don’t (usually) think that the roboticists making these videos have any intention of misleading people, but that is unfortunately what often ends up happening.\n</p><h2>What can we do about this problem?</h2><p>\n\tLast year, I wrote <a href=\"https://www.ieee-ras.org/publications/how-to-make-a-good-robot-video\" rel=\"noopener noreferrer\" target=\"_blank\">an article for the IEEE Robotics & Automation Society (RAS)</a> with some tips for making a good robot video, which includes arguably the most important thing: <strong>context</strong>. This covers teleoperation, along with other common things that can cause robot videos to mislead an unfamiliar audience. Here’s an excerpt from the RAS article:\n</p><p>\n<em>It’s critical to provide accurate context for videos of robots. It’s not always clear (especially to nonroboticists) what a robot may be doing or not doing on its own, and your video should be as explicit as possible about any assistance that your system is getting. For example, your video should identify:</em>\n</p><ul>\n<li><em>If the video has been sped up or slowed down</em></li>\n<li><em>If the video makes multiple experiments look like one continuous experiment</em></li>\n<li><em>If external power, compute, or localization is being used</em></li>\n<li><em>How the robot is being controlled (e.g., human in the loop, human supervised, scripted actions, partial autonomy, full autonomy)</em></li>\n</ul><p>\n<em>These things should be made explicit on the video itself, not in the video description or in captions. Clearly communicating the limitations of your work is the responsible thing to do, and not doing this is detrimental to the robotics community.</em>\n</p><p>\n\tI want to emphasize that <strong>context should be made explicit on the video itself</strong>. That is, when you edit the video together, add captions or callouts or something that describes the context <strong>on top of the actual footage</strong>. Don’t put it in the description or in the subtitles or in a link, because when videos get popular online, they may be viewed and shared and remixed without any of that stuff being readily available.\n</p><h2>So how can I tell if a robot is being teleoperated?</h2><p>\n\tIf you run across a video of a robot doing some kind of amazing manipulation task and aren’t sure whether it’s autonomous or not, here are some questions to ask that might help you figure it out.\n</p><ul>\n<li><strong>Can you identify an operator? </strong>In both of the videos we mentioned above, if you look very closely, you can tell that there’s a human operator, whether it’s a pair of legs or a wayward hand in a force-sensing glove. This may be the first thing to look for, because sometimes an operator is very obvious, but at the same time, not seeing an operator isn’t particularly meaningful because it’s easy for them to be out of frame. </li>\n</ul><ul>\n<li><strong>Is there any more information? </strong>The second thing to check is whether the video says anywhere what’s actually going on. Does the video have a description? Is there a link to a project page or paper? Are there credits at the end of the video? What account is publishing the video? Even if you can narrow down the institution or company or lab, you might be able to get a sense of whether they’re working on autonomy or teleoperation.</li>\n</ul><ul>\n<li><strong>What kind of task is it? </strong>You’re most likely to see teleoperation in tasks that would be especially difficult for a robot to do autonomously. At the moment, that’s predominantly manipulation tasks that aren’t well structured—for example, getting multiple objects to interact with each other, handling things that are difficult to model (like fabrics), or extended multistep tasks. If you see a robot doing this stuff quickly and well, it’s worth questioning whether it’s autonomous.</li>\n</ul><ul>\n<li><strong>Is the robot just too good? </strong>I always start asking more questions when a robot demo strikes me as just too impressive. But when does impressive become <em>too </em>impressive? Personally, I think a robot demonstrating human-level performance at just about any complex task is too impressive. Some autonomous robots definitely have reached that benchmark, but not many, and the circumstances of them doing so are usually atypical. Furthermore, it takes a lot of work to reach humanlike performance with an autonomous system, so there’s usually some warning in the form of previous work. If you see an impressive demo that comes out of nowhere, showcasing an autonomous capability without any recent precedents, that’s probably too impressive. Remember that it can be tricky with a video because you have no idea whether you’re watching the first take or the 500th, and that itself is a good thing to be aware of—even if it turns out that a demo <em>is</em> fully autonomous, there are many other ways of obfuscating how successful the system actually is.</li>\n</ul><ul>\n<li><strong>Is it too fast? </strong>Autonomous robots are well known for being very fast and precise, but only in the context of structured tasks. For complex manipulation tasks, robots need to sense their environment, decide what to do next, and then plan how to move. This takes time. If you see an extended task that consists of multiple parts but the system never stops moving, that suggests it’s not fully autonomous. </li>\n</ul><ul>\n<li><strong>Does it move like a human?</strong> Robots like to move optimally. Humans might also like to move optimally, but we’re bad at it. Autonomous robots tend to move smoothly and fluidly, while teleoperated robots often display small movements that don’t make sense in the context of the task, but are very humanlike in nature. For example, finger motions that are unrelated to gripping, or returning an arm to a natural rest position for no particular reason, or being just a little bit sloppy in general. If the motions seem humanlike, that’s usually a sign of a human in the loop rather than a robot that’s just so good at doing a task that it <em>looks</em> human.</li>\n</ul><div class=\"horizontal-rule\">\n</div><p>\n\tNone of these points make it impossible for an autonomous robot demo to come out of nowhere and blow everyone away. Improbable, perhaps, but not impossible. And the rare moments when that actually happens is part of what makes robotics so exciting. That’s why it’s so important to understand what’s going on when you see a robot doing something amazing, though—knowing how it’s done, and all of the work that went into it, can only make it more impressive.\n</p><p>\n<em>This article was inspired by <a href=\"https://www.linkedin.com/in/petercorke/\" target=\"_blank\">Peter Corke</a>’s LinkedIn post, <a href=\"https://www.linkedin.com/pulse/whats-all-deceptive-teleoperation-demos-peter-corke-asmyc/\" target=\"_blank\">What’s with all these deceptive teleoperation demos?</a> And extra thanks to Peter for his feedback on an early draft of this article.</em>\n</p>"},"pubDate":"Tue, 23 Jan 2024 21:00:08 +0000","guid":"https://spectrum.ieee.org/robot-teleoperation-autonomy","category":["Autonomous robots","Teleoperated robots","Tesla","Robotics"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/a-man-sits-in-a-chair-wearing-vr-googles-and-attached-to-two-robotic-arms-near-him-a-robot-with-two-arms-show-s-the-man-s-face.png?id=51152136&width=980"}},{"title":"This Engineer’s Hardware Is Inspired by the Brain","link":"https://spectrum.ieee.org/manan-suri-profile","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-man-in-a-suit-standing-in-front-of-a-large-machine-that-has-yellow-wires-coming-from-it.png?id=51098453&width=1200&height=800&coordinates=0%2C0%2C0%2C0\"/><br/><br/><p>\n\tIn work and in life, it’s easy to get stuck in your ways. That’s why <a href=\"https://www.linkedin.com/in/manansuri/\" rel=\"noopener noreferrer\" target=\"_blank\">Manan Suri</a> has always looked to expand his horizons both professionally and personally.\n</p><p>\n\tGrowing up in India, he was used to transitions and new experiences because his family frequently moved around the country as his father relocated for his job as a chemical engineer. Traveling stuck with Suri in adulthood. He studied and worked in Dubai, the United States, France, and Belgium over the course of his twenties.\n</p><h3>Manan Suri</h3><br/><p>\n<strong>Employer:</strong>\n</p><p>\n\tIndian Institute of Technology Delhi\n</p><p>\n<strong>Occupation:</strong>\n</p><p>\n\tAssociate professor and founder of Cyran AI Solutions, New Delhi\n</p><p><strong>Education:</strong></p><p>Bachelor’s and master’s degrees in electrical and computer engineering, both from Cornell; Ph.D. in nanoelectronics from the CEA-Leti research institute in Grenoble, France</p><p>\n\tEventually, Suri moved back to India to become an assistant professor at the <a href=\"https://home.iitd.ac.in/\" rel=\"noopener noreferrer\" target=\"_blank\">Indian Institute of Technology Delhi</a>. There he set up a research group focused on developing brain-inspired (neuromorphic) computer hardware for low-power devices like sensors, drones, and virtual-reality headsets. He is now an associate professor.\n</p><p>\n\tHe also launched a startup to commercialize his lab’s expertise: <a href=\"https://www.cyran.in/\" rel=\"noopener noreferrer\" target=\"_blank\">Cyran AI Solutions</a>, based in New Delhi, works with companies and government agencies on a variety of projects. These include automating the inspection process for identifying defects in semiconductors and developing computer-vision systems to improve crop yields and analyze geospatial Earth-observation data.\n</p><p>\n\tWhile balancing a career in academia and industry is challenging, Suri says, he relishes the opportunity to constantly learn.\n</p><p>\n\t“Once I’ve figured out how a system works, I start getting bored,” he says.\n</p><p>\n\tSuri, an IEEE member, believes that embracing change is a key ingredient for success. This is what has driven him to continually move on to new projects, push into new disciplines, and even move from country to country to experience a different way of life.\n</p><p>\n\t“It accelerates your ability to learn new things,” he says. “It puts you on a fast trajectory and helps shed some of your inhibitions or get over the inertia in what you’re doing or how you’re living.”\n</p><h2>Inspired by Cornell’s semiconductor lab</h2><p>\n\tGrowing up, Suri’s passion was physics, but he quickly realized he was drawn more to the practical applications than theory. This led to a fascination with electronics.\n</p><p>\n\tIn 2005 he initially enrolled at the <a href=\"https://www.bits-pilani.ac.in/dubai/\" rel=\"noopener noreferrer\" target=\"_blank\">Birla Institute of Technology and Science</a>, Pilani, in India, and studied electronics and instrumentation at the institute’s campus in Dubai. After his second year, he transferred to <a href=\"https://www.cornell.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Cornell</a>, in Ithaca, N.Y. His first six months living in the United States, acclimating to a new culture and a different academic environment, were overwhelming, Suri says. What hooked him were Cornell’s high-end facilities available to students studying semiconductor engineering and nanofabrication—in particular, the industry-grade semiconductor clean rooms.\n</p><p>\n\tHe earned a bachelor’s degree in electrical and computer engineering in 2009 and a master’s degree in the same subject the following year.\n</p><h2>New skills in computational neuroscience</h2><p>\n\tAfter graduating, Suri received offers for Ph.D. positions in the United States and Europe to work on conventional electronics projects. But he didn’t want to get pigeonholed as a traditional semiconductor engineer. He was intrigued by an offer to study neuromorphic systems at the <a href=\"https://www.leti-cea.fr/cea-tech/leti\" rel=\"noopener noreferrer\" target=\"_blank\">CEA-Leti</a> research institute in Grenoble, France. He was also eager to broaden his life experience and get a taste of the European way of doing things.\n</p><p>\n\tThe work would push Suri to develop new skills in computational neuroscience and computer science. In 2010 he started a Ph.D. program in the institute’s Advanced Memory Technology Group. There he worked on low-power AI hardware that uses new kinds of nonvolatile memory to emulate how biological synapses process data. This involved using phase-change memory and conductive-bridging RAM to create neural networks for <a href=\"https://ieeexplore.ieee.org/document/6202332\" rel=\"noopener noreferrer\" target=\"_blank\">visual pattern extraction </a>and <a href=\"https://ieeexplore.ieee.org/document/6479017/authors#authors\" rel=\"noopener noreferrer\" target=\"_blank\">auditory pattern sensitivity</a>.\n</p><p>\n\tSuri discovered that his experience with electronics allowed him to approach neuromorphic engineering problems from an entirely different angle than his colleagues had considered. Experts can develop fairly rigid and conventional ways of thinking about their own field, he says, but when those with different skill sets apply them to the same problems, it can often lead to more innovative thinking.\n</p><p>\n\t“You bring a completely different perspective,” he says. “It leads to a lot of creativity.”\n</p><h2>Setting up his own research lab</h2><p>\n\tAfter finishing his doctorate in nanoelectronics, Suri got a job working on high-voltage transistors for automotive applications at the semiconductor designer <a href=\"https://www.nxp.com/\" rel=\"noopener noreferrer\" target=\"_blank\">NXP Semiconductors</a>, in Brussels. Since his role was to take a project all the way from concept to fabrication, it was as close to pure research as he could get in industry. But as interesting as the work was, Suri says, he missed the intellectual freedom of academia.\n</p><p>\n\tWhen the opportunity of setting up his own lab at IIT Delhi came along, he jumped at it. He had also been away from his home country for almost a decade and wanted to be closer to family and contribute to the Indian science and technology ecosystem, he says.\n</p><p class=\"pull-quote\">“Most users don’t really care about what technology we are using. They just want functional performance at the most cost-effective price.”</p><p>\n\t“Moving abroad was more a matter of collecting experiences and seeing how different places work,” he says.\n</p><p>\n\tSuri’s group at IIT Delhi has made contributions to AI hardware, neuromorphic hardware, and hardware security. The group collaborates with industry research teams around the world, including <a href=\"https://about.meta.com/realitylabs/\" rel=\"noopener noreferrer\" target=\"_blank\">Meta Reality Labs</a>, <a href=\"https://www.tcs.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Tata Consultancy Services</a>, and <a href=\"https://gf.com/\" rel=\"noopener noreferrer\" target=\"_blank\">GlobalFoundries</a>.\n</p><h2>Launching a startup</h2><p>\n\tDespite returning to academia, Suri says he has always been interested in developing practical solutions to real-world challenges, and this goal has guided his research. Whatever project he works on, he always asks himself two questions: Will it solve a real problem? And will someone buy it?\n</p><p>\n\tSuri launched his startup in 2018 to turn some of his lab’s work in AI and neuromorphic hardware into commercial products. Cyran AI Solutions’ customers hire the company to solve a range of problems. These have included computer-vision systems for detecting defects in computer chips; hyperspectral data-analysis algorithms designed to run in real time on chips for crop-inspection drones; and AI systems for small, low-power devices and challenging environments like satellites.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A man is sitting at a table working on a circuit board and four machines that have red and black wires inserted into them. \" class=\"rm-shortcode\" data-rm-shortcode-id=\"138ba149fcb1235fbc75b008264e2554\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"e1320\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-man-is-sitting-at-a-table-working-on-a-circuit-board-and-four-machines-that-have-red-and-black-wires-inserted-into-them.png?id=51098471&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Manan Suri and researchers at the Indian Institute of Technology Delhi’s lab designed this custom electrical test setup for the characterization of memory-computing chips. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Manan Suri</small></p><p>\n\tWhile Cyran makes use of its neuromorphic expertise for some problems, it often uses more mature and simpler-to-deploy machine-learning approaches.\n</p><p>\n\t“Most users don’t really care about what technology we are using,” Suri says. “They just want functional performance at the most cost-effective price.”\n</p><p>\n\tOne of the biggest lessons Suri learned from running a startup is to consider the market being served. For earlier projects, he says, the company often devised a solution that was specific to just one customer’s needs and couldn’t be repurposed for other uses. To create a sustainable business, he realized he needed to develop generic solutions that could be deployed more broadly.\n</p><p>\n\t“Running Cyran has been like [pursuing a] mini-MBA,” he says. “You need to really pay attention to the market aspects and not just the technology.”\n</p><p>\n\tIn 2018, <a href=\"https://www.technologyreview.com/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>MIT Technology Review</em></a> named Suri one of its <a href=\"https://www.technologyreview.com/innovator/manan-suri/\" rel=\"noopener noreferrer\" target=\"_blank\">35 Innovators Under 35</a> for his work on neuromorphic computing.\n</p><h2>The need to be hands-on<br/>\n</h2><p>\n\tKeeping a foot in both academia and industry can be challenging, Suri says. Facing resource crunches, whether in time, staffing, or funding, is common. The only way he’s able to manage things is to plan extensively and remain nimble, building in contingencies.\n</p><p>\n\tIf you can manage it, Suri says, having your fingers in many pies can have major benefits. In particular, working on problems that bridge several disciplines can help you break out of rigid thinking and come up with novel solutions.\n</p><p>\n\tIt’s not possible to dedicate equal amounts of time to learning every area, he says, so he advises up-and-coming engineers to carefully pick the topics that are most likely to advance their progress. It’s also crucial to dive in and get your hands dirty, rather than focusing on theory, initially.\n</p><p>\n\t“Take the plunge and try and figure it out,” he recommends. “As the problem unravels, then you can start getting into the theory or the more formal aspects of the project. You also start to appreciate learning more about the theory as it gets more hands-on.”\n</p>"},"pubDate":"Tue, 23 Jan 2024 16:00:06 +0000","guid":"https://spectrum.ieee.org/manan-suri-profile","category":["Artificial intelligence","Brain","Careers","Neuromorphic","Type:departments"],"dc:creator":"Edd Gent","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/a-man-in-a-suit-standing-in-front-of-a-large-machine-that-has-yellow-wires-coming-from-it.png?id=51098453&width=980"}},{"title":"BT Group Converts Telecom Infrastructure to EV Chargers","link":"https://spectrum.ieee.org/ev-charging-station-bt-group","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-car-charges-on-the-street-attached-to-a-vertical-grey-box.jpg?id=51147633&width=1200&height=800&coordinates=1%2C0%2C2%2C0\"/><br/><br/><p>One of the knocks on the potential of electric vehicles has been the <a href=\"https://spectrum.ieee.org/the-ev-transition-explained-2658463735\" target=\"_self\">paucity of charging stations</a> compared with the near-ubiquitous presence of gas stations. The standard question posed by EV naysayers is, “What if an EV’s battery is nearly depleted and the nearest charging station is too far to reach?”</p><p>BT Group, Britain’s largest telecom service provider, has stepped forward with an idea that could ensure EVs are virtually always within range of a charger. The company has announced a pilot project <a href=\"https://www.reuters.com/business/media-telecom/britains-bt-turn-street-cabinets-into-ev-charging-points-2024-01-08/\" target=\"_blank\">to retrofit street cabinets</a> traditionally used to store broadband Internet and telephone cabling. The first such conversion has already been completed in East Lothian, Scotland. BT Group says more cabinets in Scotland, England, Wales, and Northern Ireland <strong> </strong>will be repurposed in the coming months—as many as 600 such conversions by the end of 2024.</p><p>Repurposing the street cabinets, known as DSLAM boxes (short for “digital subscriber line access multiplier” in some countries) makes sense now that more people have “cut the cord” and increasingly <a href=\"https://spectrum.ieee.org/when-our-connected-devices-lack-their-connections\" target=\"_blank\">rely on wireless phone service for calls and Internet access</a>. Interestingly, the BT Group’s upgrade relies on a device that allows electricity from the existing DSLAM power lines to be shared to a charge point alongside the existing broadband service, with no need to create a new power connection.</p><p>The benefit is that the remaining wired telecom connections don’t have to be taken out of service to make way for EV charging, nor do streets have to be dug up to run wires for EV charging. BT says that for a street cabinet to be suitable for double duty in telecom and EV charging, it has to have a 100-ampere power connection and be located within 80 meters of the spot designated for cars to pull up and plug in.</p><p>BT Group’s design will allow each street cabinet to offer two 7.4-kilowatt AC connections that will each provide a full charge of a vehicle’s battery in 6 to 8 hours. A company representative says overnight charging will likely be the standard use case.</p><p>When a driver pulls up to top off their vehicle’s battery, they will pay for the electricity via an app on their phone or with a debit or credit card equipped for contactless payments. BT Group says it is still investigating the feasibility of allowing drivers to reserve charging time slots at a particular box. Pricing information is also not yet available.</p><p>BT Group says that about 60,000 curbside cabinets it owns in the United Kingdom could potentially be upgraded. That would be a significant push toward the goal of 300,000 charging stations set by the U.K. government. There are roughly 54,000 public EV charging stations currently available in the U.K.</p><p>The idea of using existing street infrastructure to advance EV charging efforts has been well received. The organizers of <a data-linked-post=\"2666864140\" href=\"https://spectrum.ieee.org/ces-2024\" target=\"_blank\">CES 2024</a> named BT Group’s pilot an <a href=\"https://www.ces.tech/innovation-awards/honorees/2024/honorees/e/ev-charge.aspx\" target=\"_blank\">innovation honoree </a>for outstanding design and engineering.</p>"},"pubDate":"Mon, 22 Jan 2024 16:02:16 +0000","guid":"https://spectrum.ieee.org/ev-charging-station-bt-group","category":["Charging stations","Electric vehicles","Ev charging","Street cabinets"],"dc:creator":"Willie Jones","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-car-charges-on-the-street-attached-to-a-vertical-grey-box.jpg?id=51147633&width=980"}},{"title":"The Case for Nuclear Cargo Ships","link":"https://spectrum.ieee.org/nuclear-powered-cargo-ship","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/an-illustration-of-a-cargo-ship-on-the-water-with-a-nuclear-icon-in-the-front.png?id=51115515&width=1200&height=800&coordinates=0%2C455%2C0%2C455\"/><br/><br/><p>\n<strong>The shipping industry has</strong> been trying to<a href=\"https://spectrum.ieee.org/the-struggle-to-make-dieselguzzling-cargo-ships-greener\" target=\"_self\"> cut its carbon emissions</a> for years, and with little to show for it. Nearly all of the world’s ship fleet still runs on diesel fuel, with about a quarter of new ships on order being built to run on somewhat lower-carbon alternatives like liquefied natural gas, methanol, or hybrid propulsion.\n</p><p>\n\tThe industry now faces serious pressure to pick up the pace. Shipping uses over\n\t<a href=\"https://www.spglobal.com/marketintelligence/en/mi/research-analysis/shipping-faces-stiff-competition-for-green-fuel-supply.html\" rel=\"noopener noreferrer\" target=\"_blank\"> 300 million tonnes</a> of fossil fuels every year, producing <a href=\"https://sinay.ai/en/how-much-does-the-shipping-industry-contribute-to-global-co2-emissions/\" rel=\"noopener noreferrer\" target=\"_blank\">3 percent of greenhouse gas emissions</a>. At a July meeting of the <a href=\"https://www.imo.org/\" rel=\"noopener noreferrer\" target=\"_blank\">International Maritime Organization</a>, the U.N. body that governs the industry, representatives doubled down on carbon-reduction ambitions, setting a <a href=\"https://www.imo.org/en/MediaCentre/HotTopics/Pages/Cutting-GHG-emissions.aspx\" rel=\"noopener noreferrer\" target=\"_blank\">net-zero emissions goal for 2050</a>. The IMO’s previous goal was a 50 percent reduction by 2050 in comparison with 2008 levels. The European Union plans to <a href=\"https://climate.ec.europa.eu/eu-action/transport/reducing-emissions-shipping-sector_en\" rel=\"noopener noreferrer\" target=\"_blank\">begin charging shippers for carbon emissions</a> this year.\n</p><p>\n\tHedging its bets, the industry is exploring ammonia, batteries, and hydrogen, among other options for powering ships. A small but growing group of analysts, though, are pushing for a zero-emissions technology that already plows the oceans: nuclear propulsion.\n</p><p>\n\tToday, some 200 nuclear reactors are already \n\t<a href=\"https://neutronbytes.com/2023/02/19/south-korean-team-to-develop-smr-powered-ships/\" rel=\"noopener noreferrer\" target=\"_blank\">operating on 160 vessels</a>, mostly naval ships and submarines. Nuclear-powered ships can go years without refueling. They do not need giant fuel tanks, which opens up more space for cargo and passengers. And the reactors themselves are getting better, too: Fourth-generation <a href=\"https://spectrum.ieee.org/small-modular-reactors\" target=\"_self\">small modular reactors</a> (SMRs) being developed by companies including U.S.-based <a href=\"https://www.terrapower.com/\" rel=\"noopener noreferrer\" target=\"_blank\">TerraPower</a> and London-based <a href=\"https://www.newcleo.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Newcleo</a> should be safer and simpler to operate than conventional reactors.\n</p><p>\n\tFor shipping, nuclear is really the only abundant, realistic, carbon-free option, according to Håvard Lien, vice president of research and innovation at the Norwegian shipbuilding company \n\t<a href=\"https://www.vard.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Vard Group</a>. “It’s becoming more and more apparent that we need to do something about emissions,” he notes. “At the same time, it’s becoming apparent that alternative-fuel solutions we’re looking at have big drawbacks, and that producing these fuels will take a lot of green power that will be needed to replace coal and gas on shore. Having an energy source that you can fit onboard a ship and does not compete with shore energy is a very high priority.”\n</p><p>\n\tVard Group is part of \n\t<a href=\"https://klimavenner.no/norway-takes-swedish-nuclear-technology-to-the-high-seas/\" rel=\"noopener noreferrer\" target=\"_blank\">NuProShip</a>, a consortium of the Norwegian maritime authority, universities, shipbuilders, and shipping companies that aims to develop a Generation IV reactor for marine vessels. The group has shortlisted three designs and plan to have picked one by the end of 2024.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"An illustration shows what the basic components of a nuclear-powered cargo ship might look like \" class=\"rm-shortcode\" data-rm-shortcode-id=\"e780c561c2ae7dec2ea91f25676c84da\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"52fb9\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/an-illustration-shows-what-the-basic-components-of-a-nuclear-powered-cargo-ship-might-look-like.png?id=51107340&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A large merchant ship, capable of carrying thousands of containers, could be powered by two (or more) 30-megawatt reactors. This artist’s conception, which is not based on any specific design for a cargo ship, is intended to show the approximate scale of such a vessel. The reactors would be small, modular units. Researchers are considering three different types: a lead-cooled fast reactor, a uranium-fueled, helium-gas-cooled reactor, and a molten-salt-cooled reactor, shown here [above, at bottom]. The reactor would produce steam to spin turbines that would generate electricity to power motors.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">John MacNeill</small>\n</p><p>\n\tAlso later this year, the Italian shipbuilding company \n\t<a href=\"https://www.fincantieri.com/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Fincantieri</a> and Newcleo expect to wrap up a feasibility study to assess the practicality of deploying a 30-megawatt reactor on marine vessels. Japanese shipping giant <a href=\"https://www.imazo.co.jp.e.ajw.hp.transer.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Imabari Shipbuilding</a>, along with a dozen other companies, <a href=\"https://corepower.energy/news/japan%27s-onomichi-dockyard-leads-usd80m-investment-in-core-power\" rel=\"noopener noreferrer\" target=\"_blank\">has invested US $80 million</a> in the British startup <a href=\"https://corepower.energy/\" rel=\"noopener noreferrer\" target=\"_blank\">Core Power</a> to develop a floating nuclear power plant using SMR technology that could also one day <a href=\"https://corepower.energy/maritime-applications/electric-ships\" rel=\"noopener noreferrer\" target=\"_blank\">be used in ships</a>.\n</p><p>\n\tIn South Korea, nine organizations, including shipping companies and the \n\t<a href=\"https://www.kaeri.re.kr/eng/\" rel=\"noopener noreferrer\" target=\"_blank\">Korea Atomic Energy Research Institute</a>, plan to <a href=\"https://world-nuclear-news.org/Articles/South-Korean-partnership-to-develop-SMR-powered-sh\" rel=\"noopener noreferrer\" target=\"_blank\">develop and demonstrate</a> large ships powered by SMRs. The U.S. Department of Energy commissioned the <a href=\"https://ww2.eagle.org/en.html\" rel=\"noopener noreferrer\" target=\"_blank\">American Bureau of Shipping</a> to conduct a study, recently concluded, to identify <a href=\"https://maritime-executive.com/article/abs-completes-groundbreaking-study-on-nuclear-powered-merchant-ships\" rel=\"noopener noreferrer\" target=\"_blank\">suitable reactors</a> for a merchant ship and describe R&D challenges that would have to be overcome before nuclear-powered shipping could become a commercial reality.\n</p><p>\n\t“Based on the number of players in the United States that are quite far advanced in their development, like TerraPower, my rough guess is that in 10 years we will see the first commercial civilian vessel with [next-generation] nuclear power,” says Lien.\n</p><h2>Why nuclear-powered ships?</h2><p>\n\tFour nuclear-powered merchant ships have been built so far, all of them government-led projects begun mostly for developmental and testing reasons rather than purely commercial ones. The first was the American \n\t<a href=\"https://en.wikipedia.org/wiki/NS_Savannah\" rel=\"noopener noreferrer\" target=\"_blank\">NS<em> Savannah</em></a>, <a href=\"https://whatisnuclear.com/news/2023-07-12-the-nuclear-ship-savannah-film-digitized.html\" rel=\"noopener noreferrer\" target=\"_blank\">built in the late 1950s</a> at a cost of $46.9 million (an eye-popping $495 million today). It was in service from 1962 to 1972, but its pressurized light-water reactor (LWR) proved too complex and expensive for the ship to operate profitably. The Russian cargo vessel <em>Sevmorput</em>, commissioned in 1988, is the only nuclear-powered merchant ship still in operation as of early 2024. The other two ships, the Japanese <em>Mutsu</em> (1970) and the German <em>Otto Hahn</em> (1968), were both refitted with diesel engines partway through their service lives.\n</p><p>\n\tNuclear power has been more successfully applied on submarines and ice-breaking vessels. The very first nuclear-powered vessel was the attack submarine \n\t<a href=\"https://en.wikipedia.org/wiki/USS_Nautilus_(SSN-571)\" rel=\"noopener noreferrer\" target=\"_blank\">USS <em>Nautilus</em></a>, in 1954, amid the 1950s heyday of nuclear-power research. Hundreds of nuclear reactors have since been used on ships and submarines. Russia currently operates seven nuclear-powered icebreakers.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A large ship is shown near a bridge with a tugboat and several other smaller ships nearby.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"5a435118d42ec6a3aac4173837770f9f\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"0aefe\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-large-ship-is-shown-near-a-bridge-with-a-tugboat-and-several-other-smaller-ships-nearby.png?id=51116100&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Seen here near the port of Seattle, in 1962, the NS Savannah was the first nuclear-powered merchant ship. Built in the late 1950s, the ship’s costs were too high for it to operate profitably, and it was deactivated at the end of 1971. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Bettmann/Getty Images</small>\n</p><p>\n\tNow, the immense scale of shipping’s decarbonization challenge, along with new reactor technologies, are prompting a reevaluation of nuclear merchant ships. In fact, for commercial shippers, there aren’t any realistic alternatives to nuclear, says \n\t<a href=\"https://www.ntnu.edu/employees/jan.emblemsvag\" rel=\"noopener noreferrer\" target=\"_blank\">Jan Emblemsvåg</a>, professor of ocean operations and civil engineering at the Norwegian University of Science and Technology. “Engines in ordinary ships are the size of houses,” says Emblemsvåg, who is leading NuProShip. And a great deal of space is taken up by fuel: “A container vessel going from Amsterdam to Shanghai requires roughly 4,000 tonnes of fuel.”\n</p><p>\n\tAn SMR would be much more compact and lightweight. According to Emblemsvåg, a \n\t<a href=\"https://world-nuclear.org/information-library/current-and-future-generation/molten-salt-reactors.aspx\" rel=\"noopener noreferrer\" target=\"_blank\">molten-salt reactor</a>—which uses a mixture of thorium and hot liquid salts as both fuel and coolant—would also save about $70 million over the lifetime of a ship, compared with a similar vessel powered by engines that burn diesel fuel (or, more precisely, <a href=\"https://www.forbes.com/sites/nishandegnarain/2020/08/14/what-is-heavy-fuel-oil-and-why-is-it-so-controversial-five-killer-facts/?sh=5ec9b87474c0\" rel=\"noopener noreferrer\" target=\"_blank\">heavy fuel oil</a>). Another plus for nuclear-propelled ships is easy access to an endless supply of cooling water.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A red cargo ship is shown in a harbor surrounded by mountainous terrain.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"c0ef2ec26b17715151195af9669bf87d\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"8779a\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-red-cargo-ship-is-shown-in-a-harbor-surrounded-by-mountainous-terrain.png?id=51116112&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Commissioned in 1988, the Russian ship Sevmorput was the only nuclear-powered cargo ship still operating at the start of 2024. A fire on the ship caused minor damage in December 2023. Russian authorities expected the ship to be decommissioned in 2024. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Alexander Piragis/Alamy</small>\n</p><p>\n\tBatteries are an obvious nonstarter, Emblemsvåg adds. A large container ship needs about 3,000 megawatt-hours a day, which is roughly the capacity of the biggest grid battery ever built. “The battery solution is dead before it starts,” he declares. “The ship will basically go for one day, and it’s over.”\n</p><p>\n\tAmmonia, meanwhile, has half the energy density of diesel fuel, so ships would need twice as much of it. Ammonia is now made using an energy-intensive process, and no vessels are yet capable of using it. Producing enough renewable, carbon-free ammonia for shipping—about 600 million tonnes a year—using electrolyzers that split water molecules to produce hydrogen, would use 12 megawatt-hours per tonne of ammonia. To make 600 million tonnes of it would require almost three times the power production capacity of the entire European Union in 2022, according to Emblemsvåg. “So we can make engines that run on ammonia, but there won’t be enough ammonia.”\n</p><h2>How new reactor technology could change shipping</h2><p>\n\tThe first step in making nuclear merchant ships a reality will be to build the right kind of nuclear reactors. For ship propulsion, engineers have used pressurized-water reactors because they can produce higher power for a given mass compared with the other kind of light-water reactor, the boiling-water reactor. However, the technology comes with major challenges. They depend on complex control systems that need a technically trained operating crew, and they run on solid fuel rods that need to be replaced every 18 months. There’s also a risk, however slight, that the pressure vessel could explode.\n</p><p>\n\tFourth-generation SMRs avoid all that. Emblemsvåg and the NuProShip team picked three reactor designs after analyzing 93 concepts in the International Atomic Energy Agency’s \n\t<a href=\"https://aris.iaea.org/Publications/SMR-booklet.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">SMR handbook</a>. One is a thorium-fueled molten-salt reactor. The second is a lead-cooled <a href=\"https://world-nuclear.org/information-library/current-and-future-generation/fast-neutron-reactors.aspx\" rel=\"noopener noreferrer\" target=\"_blank\">fast reactor</a>, which replaces the water coolant of traditional reactors with molten lead. The third option, likely closest to market, is a helium gas-cooled reactor that uses a type of fuel called tristructural isotropic (TRISO), consisting of uranium particles encased in ultratough carbide and carbon layers that can handle temperatures above 2,000 °C.\n</p><h3></h3><br/><img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"90ca54e10d6165e19a66b734be6a336f\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"3c583\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/image.jpg?id=51116164&width=980\"/><h3></h3><br/><img alt=\"A color diagram shows the inner components of a molten-salt nuclear reactor, as well as a configuration that might in the future be used to power a cargo ship.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"c5ea63e56fda4dddcc05f8cd1a294a85\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1fc91\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-color-diagram-shows-the-inner-components-of-a-molten-salt-nuclear-reactor-as-well-as-a-configuration-that-might-in-the-future.jpg?id=51116166&width=980\"/><p>\n\tAll three reactor types operate at low pressures, making explosion extremely unlikely, Emblemsvåg notes. Also, a meltdown is so unlikely as to be irrelevant, in his view. For example, the melting temperature of TRISO fuel is so high that no realistic scenarios could result in the fuel becoming molten.\n</p><p>\n\tWith the other reactor types, the molten fuel or coolant would solidify before an accident could become a disaster, according to their backers. \n\t<a href=\"https://www.linkedin.com/in/gennaroconsulting/?originalSubdomain=uk\" rel=\"noopener noreferrer\" target=\"_blank\">Giulio Gennaro</a>, technical director at Core Power, likens the molten-chloride-salt reactor the company is codeveloping with TerraPower to a simmering saucepan instead of a pressure cooker: “If you make caramel in a saucepan, it’s extremely hot; you could burn your finger. But if the pan breaks, you have a leakage on the stove, and the molten caramel quickly solidifies.” So contamination would not get far from the reactor in a reactor failure, as opposed to a pressurized vessel explosion that could splatter fissile material kilometers away.\n</p><p>\n\tLead-cooled reactors have a similar advantage: The liquid lead would cool down and solidify in contact with cold water, encasing the reactor core and preventing nuclear material from being released into the environment, says\n\t<a href=\"https://www.linkedin.com/in/andreabarbensi/\" rel=\"noopener noreferrer\" target=\"_blank\"> Andrea Barbensi</a>, engineering director at Newcleo. Launched in 2021, the company has designed a lead-cooled reactor that aims to produce its own fuel by recycling the by-products of conventional reactors, “offering a circular solution to nuclear waste,” he says.\n</p><p>\n\tNewcleo is working with governments and industry partners on a small-reactor prototype for industrial use that should be ready in the next 10 years. The feasibility study with Fincantieri will guide how the two companies develop the technology for marine use. “Small modular reactors are a relatively new technology, but the interest we have seen from governments and industries across the world is very promising,” Barbensi says.\n</p><p>\n\tTo be sure, plenty of shipbuilders remain skeptical about nuclear-powered vessels. Last July, the American Bureau of Shipping and \n\t<a href=\"https://www.herbert.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Herbert Engineering Corp</a>. issued the results of a study addressing shipbuilders’ concerns about nuclear reactors. “There were lots of questions,” says <a href=\"https://www.linkedin.com/in/patrick-ryan-abs/\" rel=\"noopener noreferrer\" target=\"_blank\">Patrick Ryan</a>, ABS’s senior vice president and chief technology officer. “Does the reactor eat up all my cargo space? How is it arranged? Where does the crew go? What are the special training requirements? How do I insert this technology? How do I refuel? Does it change how fast I go? We needed to get the conversation started.”\n</p><p>\n\tThe study suggested that putting two 30-MW lead-cooled reactors on one of the largest container vessels would increase cargo capacity and speed, and eliminate refueling needs during its entire 25-year life-span. If there is sufficient industry interest, the ABS will identify the most promising reactor designs and assess risks and safety, Ryan says.\n</p><p>\n<a href=\"https://www.iaea.org/newscenter/news/what-are-small-modular-reactors-smrs\" rel=\"noopener noreferrer\" target=\"_blank\">More than 80 SMR designs</a> are being developed around the world, with <a href=\"https://c3newsmag.com/five-of-the-worlds-leading-small-modular-reactor-companies/\" rel=\"noopener noreferrer\" target=\"_blank\">the largest</a> share in the United States. Yet the nation’s shipbuilding industry is tiny. The majority of global shipbuilding happens in South Korea, Japan, and China. So while there is a lot of excitement in the United States about the <em>terrestrial</em> use of SMRs to replace coal power plants, Ryan says, “the chatter about nuclear-powered commercial shipping is mostly coming from abroad.”\n</p><p>\n\tAnd yet proving SMRs on land will be necessary before they can go onboard ships, says Core Power’s Gennaro, and bipartisan support for new nuclear plants in the United States is helping move things along. With $170 million in funding from the Department of Energy, Core Power and TerraPower are building a molten-chloride \n\t<a href=\"https://www.terrapower.com/southern-terrapower-mcre-agreement/\" rel=\"noopener noreferrer\" target=\"_blank\">desktop test reactor</a> that will produce up to 500 kilowatts of power at <a href=\"https://inl.gov/\" rel=\"noopener noreferrer\" target=\"_blank\">Idaho National Laboratory</a>; the reactor could start trials in 2025. After that, the companies plan to build a larger reactor for demonstration at sea in the early 2030s.\n</p><h2>The challenges to building nuclear-powered fleets are sobering</h2><p>\n\tEven among supporters of nuclear ship propulsion, not everyone agrees that putting reactors on ships is the best way to go about it. In the near term, they argue, it makes more sense to use nuclear power as a source of electricity to produce alternative low-carbon fuels. “If you use \n\t<a href=\"https://fathom.world/should-we-use-nuclear-power-to-make-hydrogen-fuels-for-shipping/\" rel=\"noopener noreferrer\" target=\"_blank\">nuclear electricity to electrolyze</a> seawater to make hydrogen, and then you use that hydrogen as a feedstock to make ammonia or methanol, the carbon footprint of the production of fuel is effectively zero,” says Ryan.\n</p><p>\n\t“Putting a reactor aboard a marine vessel has a lot of complicating factors that producing fuel with nuclear power doesn’t have,” he adds. Even if molten-chloride reactors manage to avoid the technical problems of the pressurized-water reactors used on the earlier cargo ships—spotty reliability, extremely high operating costs, and challenges related to radioactive waste and decommissioning—you would still have problems associated with public perceptions of nuclear power and the likely refusal of some ports to welcome nuclear ships.\n</p><p>\n\tGennaro is convinced that the advantages of the advanced SMRs will be decisive. “There are technology risks, but as far as molten-salt fast reactors go, everyone agrees there are no showstoppers,” he insists. He adds that SMRs for marine deployment would be built in factories and assembled at shipyards, speeding up construction and lowering cost. Land-based nuclear power plants, for comparison, are constructed on site and typically far exceed their budgets and schedules. Cost also played a big role in NuScale Power Corp.’s plan to \n\t<a href=\"https://www.nuscalepower.com/en/news/press-releases/2023/uamps-and-nuscale-power-agree-to-terminate-the-carbon-free-power-project\" rel=\"noopener noreferrer\" target=\"_blank\">end its attempt</a> to build the first SMR plant in Idaho, which would have used six reactors to generate 462 MW.\n</p><p>\n\tGennaro admits that the perception that nuclear reactors are unsafe will be a problem, but he sees it as a challenge that can be overcome. Ryan points out that traditional fossil fuels also carry risks, which is why the ABS creates rules and guidance on how to use those fuels safely. Regulatory agencies would similarly have to devise rules for new propulsion methods. Ammonia, for instance, is very toxic, so a fuel spill would have a different level of concern than fossil fuels, he says. Nuclear reactors for U.S. commercial ships would not only have oversight from the ABS but would also require licensing from the U.S.\n\t<a href=\"https://www.nrc.gov/about-nrc.html\" rel=\"noopener noreferrer\" target=\"_blank\"> Nuclear Regulatory Commission</a>.\n</p><p>\n\tUnlike land-based use of nuclear power, marine use does bring the challenge of having a reactor on a moving vessel that pitches, rolls, yaws, and slows abruptly when it hits waves. One of NuProShip’s tasks is to evaluate each reactor technology on how well it tolerates motion, according to Vard’s Lien.\n</p><p>\n\tThe project hopes to have an SMR prototype to test around 2030. Vard plans to test the SMR on new ships first, but that isn’t expected to happen \n\t<a href=\"https://www.wired.com/story/nuclear-cargo-ships/\" rel=\"noopener noreferrer\" target=\"_blank\">any sooner than 2035</a>. If that goes well, existing ships could be retrofitted by replacing diesel engines with the SMRs, says Lien. The open-ocean vessels that the company builds—ships that lay telecommunication cable, maintenance ships, and fishing vessels—are ideal candidates for nuclear propulsion, he says. “They need high amounts of power for operation and have to be at sea for months at a time. It would be a big advantage if they don’t have to break off operations and go to port to refuel.”\n</p><p>\n\tOther kinds of ships may also get the nuclear treatment. Although nobody expects to ever see nuclear-powered cruise ships, even they might benefit indirectly. Norwegian shipbuilder \n\t<a href=\"https://ulstein.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Ulstein</a> has <a href=\"https://world-nuclear-news.org/Articles/Ulstein-touts-nuclear-concept-for-decarbonising-cr\" rel=\"noopener noreferrer\" target=\"_blank\">designed a nuclear vessel</a> with a molten-salt reactor that might conceivably serve as a mobile charging station for a future fleet of small, battery-powered cruise ships.\n</p><p>\n\tAs the shipping industry thinks about nuclear propulsion, SMRs are already starting to get vetted offshore. Russia, China, and South Korea are now working on floating nuclear power plants, mainly \n\t<a href=\"https://aris.iaea.org/Publications/SMR_booklet_2022.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">water-cooled SMRs</a> that will be either mounted on barges or submerged underwater close to shore. Russia already has one, the <a href=\"https://www.power-technology.com/projects/akademik-lomonosov-nuclear-co-generation-russia/?cf-view\" rel=\"noopener noreferrer\" target=\"_blank\">Akademik Lomonosov</a>, which has been operating since 2020 in the country’s far east, producing electricity and district heating.\n</p><p>\n\tOne potential snag for future nuclear-powered ships is the problem of fragmented nuclear regulation, says Emblemsvåg. Commercial ships traversing international borders will face different regulations at different ports. Right now, a reactor approved in the United States isn’t automatically approved for use in France, for example. “The good news is that G7 countries with some E.U. countries and the International Energy Agency are working on harmonizing the rules,” he says.\n</p><p>\n\tMeanwhile, Core Power is trying to harmonize support among stakeholders, including SMR makers, shipbuilders, and regulators. Besides selecting a nuclear technology appropriate for the marine environment, Gennaro says, the company is lobbying to create a market for the technologies. It helped organize an IAEA symposium on \n\t<a href=\"https://www.iaea.org/newscenter/news/floating-nuclear-power-plants-benefits-and-challenges-discussed-at-iaea-symposium\" rel=\"noopener noreferrer\" target=\"_blank\">floating nuclear power plants</a> this past November that brought together nuclear and maritime regulators, legal and policy experts, and industry leaders.\n</p><p>\n\t“It’s not just about the technology; it’s about the entire ecosystem,” he adds. “If I have a technology ready for use, but the regulatory framework, market, financing possibility, and business model are not there, then the time to market, which for nuclear technology is already not extremely short, gets lengthened. Our goal is to make sure that once the technology is ready, the [ecosystem] is also ready to deploy.” \n\t<span class=\"ieee-end-mark\"></span>\n</p><p>\n<em>This article was updated on 22 January 2024.</em></p>"},"pubDate":"Sat, 20 Jan 2024 16:00:05 +0000","guid":"https://spectrum.ieee.org/nuclear-powered-cargo-ship","category":["Nuclear cargo ships","Merchant shipping","Cargo shipping","Nuclear reactors","Small modular reactors","Molten-salt reactors","Lead-cooled fast reactor","Helium-gas-cooled reactor"],"dc:creator":"Prachi Patel -","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/an-illustration-of-a-cargo-ship-on-the-water-with-a-nuclear-icon-in-the-front.png?id=51115515&width=980"}},{"title":"Video Friday: Swiss-Mile","link":"https://spectrum.ieee.org/video-friday-swiss-mile","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-silver-four-legged-robot-with-wheels-for-feet-drives-down-a-flight-of-concrete-stairs-outside.png?id=51121645&width=1325&height=830&coordinates=277%2C151%2C318%2C99\"/><br/><br/><p>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at <em>IEEE Spectrum</em> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please <a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a> for inclusion.<br/></p><h5><a href=\"https://cybathlon.ethz.ch/en/events/challenges/Challenges-2024\">Cybathlon Challenges</a>: 2 February 2024, ZURICH</h5><h5><a href=\"https://www.eurobot.org/\">Eurobot Open 2024</a>: 8–11 May 2024, LA ROCHE-SUR-YON, FRANCE</h5><h5><a href=\"https://2024.ieee-icra.org/\">ICRA 2024</a>: 13–17 May 2024, YOKOHAMA, JAPAN</h5><h5><a href=\"https://2024.robocup.org/\">RoboCup 2024</a>: 17–22 July 2024, EINDHOVEN, NETHERLANDS</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><p>You may not be familiar with Swiss-Mile, but you’d almost certainly recognize its robot: it’s the <a data-linked-post=\"2666409159\" href=\"https://spectrum.ieee.org/quadruped-robot-wheels\" target=\"_blank\">ANYmal</a> with wheels on its feet that can do all kinds of amazing things. Swiss-Mile has just announced a seed round to commercialize these capabilities across quadrupedal platforms, including Unitree’s, which means it’s even affordable-ish!</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"54259339f6cb034ddd06a1564bf5eaf5\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/KmXulwvCsZA?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>It’s always so cool to see impressive robotics research move toward commercialization, and I’ve already started saving up for one of these of my own.</p><p>[ <a href=\"https://www.swiss-mile.com/\">Swiss-Mile</a> ]</p><p>Thanks Marko!</p><div class=\"horizontal-rule\"></div><blockquote><em>This video presents the capabilities of PAL Robotics’ TALOS robot as it demonstrates agile and robust walking using Model Predictive Control (MPC) references sent to a Whole-Body Inverse Dynamics (WBID) controller developed in collaboration with Dynamograde. The footage shows TALOS navigating various challenging terrains, including stairs and slopes, while handling unexpected disturbances and additional weight.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"ea83d90dbe2f435aff45dc3b6c729cad\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/qVzHe8FG984?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://pal-robotics.com/robots/talos/\">PAL Robotics</a> ]</p><p>Thanks Lorna!</p><div class=\"horizontal-rule\"></div><p>Do you want to create a spectacular bimanual manipulation demo? All it takes is this teleoperation system and a carefully cropped camera shot! This is based on the Mobile ALOHA system from Stanford that we featured in Video Friday last week.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"4b2a34f5649ea486c86c9fcb260de102\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/mNgqXZ44W9Y?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://global.agilex.ai/\">AgileX</a> ]</p><div class=\"horizontal-rule\"></div><p>Wing is still trying to make the drone-delivery thing work, and it’s got a new, bigger drone to deliver even more stuff at once.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"693d22df87db69fe1680c08b4a5bc205\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/GU1bNw4Z6to?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://blog.wing.com/2024/01/customer-demand-and-wings-aircraft.html\">Wing</a> ]</p><div class=\"horizontal-rule\"></div><p>A lot of robotics research claims to be about search and rescue and disaster relief, but it really looks like RSL’s ANYmal can actually pull it off.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"8f392eaadb60a4c76d4fc6fb272f2924\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/_R29DrAx0Xs?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>And here’s even more impressive video, along with some detail about how the system works.</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"f5ab439384e6902dbc9a3085b4f16142\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/nipH-yl8lR0?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>[ <a href=\"https://arxiv.org/abs/2309.15462\">Paper</a> ]</p><div class=\"horizontal-rule\"></div><p>This might be the most appropriate soundtrack for a robot video that I’ve ever heard.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"29a2dda83d337763ffd031cf682141b2\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/zuhZ-cGFYPs?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><blockquote><em>Snakes have long captivated robotics researchers due to their effective locomotion, flexible body structure, and ability to adapt their skin friction to different terrains. While extensive research has delved into serpentine locomotion, there remains a gap in exploring rectilinear locomotion as a robotic solution for navigating through narrow spaces. In this study, we describe the fundamental principles of rectilinear locomotion and apply them to design a soft crawling robot using origami modules constructed from laminated fabrics.</em></blockquote><p>[ <a href=\"https://www.softrobotics.dk/\">SDU</a> ]</p><div class=\"horizontal-rule\"></div><p>We wrote about Fotokite’s innovative tethered drone seven or eight years ago, and it’s good to see the company is still doing solid work.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"b9d42c15c98c03c25585f73a13c56b90\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/P3zDnxsVkZw?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>I do miss the consumer version, though.</p><p>[ <a href=\"https://fotokite.com/\">Fotokite</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"7fffc2792213510db7daca9e22aadbb3\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/e1uqA-1st_U?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"http://jdp.co.uk/\">JDP</a> ] via [ <a href=\"https://petapixel.com/2024/01/16/mantis-shrimp-pulls-no-punches-in-robot-spy-crab-face-off/\">Petapixel</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>This is SHIVAA the strawberry picking robot of DFKI Robotics Innovation Center. The system is being developed in the RoLand (Robotic Systems in Agriculture) project, coordinated by the #RoboticsInnovationCenter (RIC) of the DFKI Bremen. Within the project we design and develop a semi-autonomous, mobile system that is capable of harvesting strawberries independent of human interaction. </em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"51f203c9af3abfebf0c5867badf85fa4\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/E_yl3-wgckM?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://robotik.dfki-bremen.de/en/research/projects/roland\">DFKI</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>On December 6, 2023, Demarcus Edwards talked to Robotics students as a speaker in the Undergraduate Robotics Pathways & Careers Speaker Series, which aims to answer the question: “What can I do with a robotics degree?”</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"43c95b0ba646afad4c8df366fe343009\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/RAq4tBBXxO8?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://robotics.umich.edu/academics/undergraduate/robotics-pathways-speaker-series/\">Michigan Robotics</a> ]</p><div class=\"horizontal-rule\"></div><p>This movie, <em>Loss of Sensation</em>, was released in Russia in 1935. It seems to be the movie that really, really irritated Karel Čapek, because they made his “robots” into mechanical beings instead of biological ones.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"7b068cb43c69d1788bf37ee1ac5b79c8\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/6GiBhKbYBcU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.imdb.com/title/tt0240539/\">IMDB</a> ]</p><div class=\"horizontal-rule\"></div>"},"pubDate":"Fri, 19 Jan 2024 19:44:22 +0000","guid":"https://spectrum.ieee.org/video-friday-swiss-mile","category":["Anymal","Drone delivery","Pal robotics","Quadruped robots","Robotics","Swiss-mile","Unitree","Video friday"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/a-silver-four-legged-robot-with-wheels-for-feet-drives-down-a-flight-of-concrete-stairs-outside.png?id=51121645&width=980"}},{"title":"How the Inventor of DSL Altered the Course of Connectivity","link":"https://spectrum.ieee.org/inventor-of-dsl-altered-connectivity","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/man-posing-for-a-portrait-in-a-sweater-and-tie-with-a-blurred-university-background.jpg?id=51105425&width=1200&height=800&coordinates=0%2C0%2C0%2C250\"/><br/><br/><p>When 7-year-old<a href=\"https://cioffi-group.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\"> John Cioffi</a> ran up to the <a href=\"https://en.wikipedia.org/wiki/Bell_System\" rel=\"noopener noreferrer\" target=\"_blank\">Bell System</a> pavilion at the <a href=\"https://en.wikipedia.org/wiki/1964_New_York_World%27s_Fair\" rel=\"noopener noreferrer\" target=\"_blank\">1964-1965 World’s Fair</a> in New York City, he couldn’t wait to see the first telephone with video: the much-lauded<a href=\"https://www.smecc.org/picturephone___vistaphone_and_others.htm\" rel=\"noopener noreferrer\" target=\"_blank\"> Picturephone</a>.</p><p>The boy had been disappointed that phone calls provided only audio. He gazed up at the Picturephone’s oval screen, with its grainy, black-and-white video images—the culmination of<a href=\"https://www.nytimes.com/1992/01/12/business/forum-videophone-a-flop-that-wont-die.html\" rel=\"noopener noreferrer\" target=\"_blank\"> US $500 million in R&D</a> by the telecommunications giant—and thought, Wow…that looks terrible!</p><h3>John Cioffi</h3><br/><p>\n<strong>Employer</strong>\n</p><p>\n\tStanford\n</p><p>\n<strong>Title</strong>\n</p><p>\n\tProfessor of electrical engineering\n</p><p>\n<strong>Member grade\n</strong></p><p>\n\tLife Fellow\n</p><p><strong>Alma maters </strong></p><p>University of Illinois Urbana-Champaign, Stanford</p><p>“That memory always stayed in the back of my mind,” Cioffi says. “As I went through my schooling and career, it seemed that the technology should be able to get there, and I was always curious about how we could make it happen.”</p><p>Nearly three decades later, at age 35, Cioffi developed the technology that would ultimately make possible video calls and much more including high-speed Internet. In 1991 he built the first asymmetric digital subscriber line (DSL) modem, which quickly replaced most dial-up connections. DSL meant a user could download data-heavy images and videos while simultaneously browsing the Internet and talking on the telephone, all from a single phone line.</p><p>DSL works by separating digital voice and data signals, then converting them into analog signals that can be sent far more quickly and easily over wires—typically the copper lines already found in landline telephones. Cioffi is known as the “father of DSL” not only because of his creation of the first such modem but also his work to commercialize and popularize the technology. </p><p>For his DSL efforts, Cioffi received a U.S. <a href=\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/24/president-biden-honors-leading-american-scientists-technologists-and-innovators/\" rel=\"noopener noreferrer\" target=\"_blank\">National Medal of Technology and Innovation</a>, one of 12 bestowed in October by President Biden during a White House ceremony. The medal, the nation’s highest award for technological achievement, recognizes U.S. innovators whose “vision, intellect, creativity, and determination have strengthened the country’s economy and improved the quality of life,” according to the White House.</p><p>“I was awestruck and never imagined that they’d select me for this one, as there are so many [people] I can think of who’d be more deserving,” says Cioffi, an IEEE Life Fellow. “I came to learn that several [of my] former students—Dr.<a href=\"https://www.linkedin.com/in/kristasjacobsen/\" rel=\"noopener noreferrer\" target=\"_blank\"> Krista Jacobsen</a>, Professor<a href=\"https://www.linkedin.com/in/katie-wilson-a820041/\" rel=\"noopener noreferrer\" target=\"_blank\"> Katie Wilson</a>, and Dr.<a href=\"https://www.linkedin.com/in/petechow/\" rel=\"noopener noreferrer\" target=\"_blank\"> Pete Chow</a>—were the nominators.”</p><p>The technology led to high-speed Internet, with data capacities and transmission rates that were unimaginable with dial-up systems. What’s more, DSL relied on the copper wires that phone companies insisted to Cioffi were passé, thereby unlocking a future forever altered by connectivity.</p><h2>Fighting for copper in a fiber-obsessed world</h2><p>Cioffi arrived at engineering by way of his love of mathematics. He had always been interested in pushing the boundaries of what was possible based on mathematical equations. After graduating in 1978 with a bachelor’s degree in electrical engineering from the<a href=\"https://illinois.edu/\" rel=\"noopener noreferrer\" target=\"_blank\"> University of Illinois Urbana-Champaign</a>, he began working on data communications as a member of the technical staff at<a href=\"https://www.bell-labs.com/about/history/#gref\" rel=\"noopener noreferrer\" target=\"_blank\"> Bell Labs</a> in Holmdel, N.J.</p><p>There he helped develop the first voice-band modem with echo canceling. It allowed high-speed voice data to be sent over a single telephone circuit—which permitted simultaneous transmission of both callers’ data without either disturbing the other. It was his first taste of maximizing what was possible over just one phone line.</p><p>His improvements to Bell’s modems got him noticed by top leadership. It was the early 1980s, and fiber-optic networks were seen as the future in telecommunications. The company already had digitized most of the process for connecting calls, but last-mile connectivity was still analog: that pair of copper phone lines twisted together. To digitize that last essential bit, Bell engineers were developing the Integrated Services Digital Network, a circuit-switched telephone system to send voice, video, and other data over digitized circuits.</p><p>In one meeting to discuss ISDN, Cioffi listened as senior, well-known Bell scientists and engineers talked about goals such as trying to send 150 kilobits of data per second to enable a few voice channels on a single line. He was befuddled by their approach and wondered why video wasn’t part of the conversation. </p><p class=\"pull-quote\">“We knew the judges wouldn’t select a little company’s technology unless it was really a slam dunk, and it was.”</p><p>He quickly did some back-of-the-envelope calculations and then interrupted the discussion. The system actually could handle 10 times as much data, he explained, so video calls were possible. His boss shot him a look to keep quiet.</p><p>Shutting down Cioffi’s suggestions became a theme at Bell, he says. The company was all in on a lower-speed ISDN, and it wasn’t interested in his ideas for the existing copper wires, which were predicted to be history soon. They said ISDN’s successor would be fiber to every home.</p><p>“The old way is dead. Everything will be fiber within a couple years,” Cioffi was told. “You need to think ‘infinite bandwidth.’ What can someone do with that?”</p><p>Cioffi says that despite the setbacks, he enjoyed his work at Bell, and the company paid the tuition for the Stanford master’s and Ph.D. degrees he pursued during paid leaves.</p><p>After he earned his doctorate in 1984, the U.S. government was in the midst of splitting up the Bell System, so he left the company to work for<a href=\"https://www.ibm.com/\" rel=\"noopener noreferrer\" target=\"_blank\"> IBM</a> in San Jose, Calif., as a research staff member. While there he developed technology that increased the capacity of storage disks by about 50 percent.</p><p>In 1986<a href=\"https://www.cornell.edu/\" rel=\"noopener noreferrer\" target=\"_blank\"> Cornell</a> approached the 30-year-old about teaching electrical engineering. Unsure if it was the right career move, Cioffi asked his Stanford advisor what to do. The advisor said Stanford itself had an opening for an EE professor—and Cioffi accepted the job at his alma mater.</p><h2>Creating the first DSL modem</h2><p>At Stanford, Cioffi and his graduate students worked on <a href=\"https://ieeexplore.ieee.org/document/986875\" rel=\"noopener noreferrer\" target=\"_blank\">discrete multitone modulation</a>, a technique for sending digital information over wires while adapting signals for efficiency. It was, he says, a necessary precursor to DSL.</p><p>Cioffi says he was energized by teaching advanced EE students and being free of the constant no’s he’d received in the corporate world. In 1987 he was given a<a href=\"https://www.nsf.gov/awardsearch/showAward?AWD_ID=8657266&HistoricalAwards=false\" rel=\"noopener noreferrer\" target=\"_blank\"> Presidential Young Investigator Award</a>, which provided financial support to help him advance his work: $312,000 (about $870,000 today) over five years. </p><p>By 1991, he was convinced he and his students had created the technologies needed to build a DSL modem. He took a leave of absence from Stanford to launch <a href=\"https://www.bloomberg.com/profile/company/357645Q:US\" rel=\"noopener noreferrer\" target=\"_blank\">Amati Communications Corp</a>. in Palo Alto, Calif.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"two men standing smiling for the camera in suits against a yellow background\" class=\"rm-shortcode\" data-rm-shortcode-id=\"748364bc238ad11da411a574a5243d40\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"f431c\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/two-men-standing-smiling-for-the-camera-in-suits-against-a-yellow-background.jpg?id=51105901&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">John Cioffi was presented with the U.S. National Medal of Technology and Innovation by President Biden during a ceremony held in October at the White House. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Anna Moneymaker/Getty Images </small></p><p>Cioffi’s current and former students worked with him and other colleagues to build the first DSL modem: the Amati Prelude. It was revolutionary, transmitting about 6 megabits of data per second over more than 2,700 meters of telephone line: enough to support multiple live digital TV streams at the time.</p><p>Meanwhile a number of large companies were trying their own approaches to DSL, including two linked to Bell. In 1993 Bell Communications Research, known as<a href=\"https://journal.businesstoday.org/bt-online/2017/3/18/the-legacy-of-bellcore\" rel=\"noopener noreferrer\" target=\"_blank\"> Bellcore</a>, sponsored a DSL competition. The Amati team entered Prelude, competing against AT&T, Broadcom, and Bellcore itself. </p><p>Amati’s modem sent data more quickly over greater distances while using much less power than the other entries. The competition, according to Cioffi, “wasn’t even close,” as Amati won the gold medal.</p><p>“We knew the judges wouldn’t select a little company’s technology unless it was really a slam dunk, and it was,” Cioffi says. “The rest is history.”</p><p>Dial-up modems indeed were history. DSL vastly reduced load times and eventually led to video calls, streaming video, and the rest of the modern Internet experience as we know it.</p><p>Meanwhile, building out fiber networks wasn’t moving nearly as quickly in the 1990s as the phone companies had predicted. (Decades later, the fiber buildout is still slow going.)</p><p>DSL powered millions of households worldwide for years—and though the technology is being phased out in favor of 5G and fiber in many areas, it remains the only source of broadband internet for Americans in rural communities and is still used in hundreds of millions of homes globally.</p><p>After the Bellcore contest win, Cioffi returned to teaching at Stanford while still participating in Amati, which went public in late 1995. In 1998<a href=\"https://www.ti.com/\" rel=\"noopener noreferrer\" target=\"_blank\"> Texas Instruments</a> bought the company for $440 million (the equivalent of about $854 million today).</p><p>With DSL technology proven, Cioffi’s interests turned to improving its performance. In 2003 he founded <a href=\"https://assia-inc.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Adaptive Spectrum and Signal Alignment</a>—ASSIA, a backronym for his wife and co-founder, Assia Cioffi—to achieve the goal.</p><p>The company employed about 170 people at its peak. Over the years, it evolved to largely licensing its intellectual property for Internet optimization techniques. Cioffi<a href=\"https://www.lightreading.com/broadband/dzs-buys-a-big-piece-of-assia#close-modal\" rel=\"noopener noreferrer\" target=\"_blank\"> sold part of the business to DZS</a> in 2021. He remains chief executive of the remaining business, which is dedicated to innovation and licensing in broadband connectivity improvement.</p><p>Cioffi continued teaching at Stanford full time until 2009, when he moved to the part-time status he maintains today.</p><h2>Staying current and communicative with IEEE</h2><p>Cioffi joined IEEE as a student member in 1976, and he has renewed his membership ever since.</p><p>“It’s been a good way to stay current, meet people, and get to know others with similar interests,” he says.</p><p>The organization has honored him for his work, as he received the 2010 IEEE<a href=\"https://www.ieee.org/content/dam/ieee-org/ieee/web/org/about/awards/recipients/bell-rl.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"> Alexander Graham Bell Medal</a>. He holds other top awards including the<a href=\"https://marconisociety.org/fellow-bio/john-cioffi/\" rel=\"noopener noreferrer\" target=\"_blank\"> 2006 Marconi Prize</a> and a<a href=\"https://www.telecoms.com/broadband/alcatel-lucent-is-a-double-winner-at-broadband-infovision-awards\" rel=\"noopener noreferrer\" target=\"_blank\"> Lifetime Achievement Award</a> from the Broadband World Forum in 2014. He was named to the <a href=\"https://www.internethalloffame.org/inductee/john-cioffi/\" rel=\"noopener noreferrer\" target=\"_blank\">Internet Hall of Fame</a> in 2014 and the<a href=\"https://ieeexplore.ieee.org/document/8684797\" rel=\"noopener noreferrer\" target=\"_blank\"> Consumer Technology Association Hall of Fame</a> in 2018.</p><p>Cioffi is still interested in teaching the next generation of communication engineers, he says. In his part-time work at Stanford he updates and teaches digital communications coursework for graduate students. </p><p>“I tell them that digital communications goes back to smoke signals, and even earlier than that,” he says. “If you look at the opening of Genesis in the Bible, it starts with this darkness and what God sees is not good. Then, God says, ‘Let there be light.’ And he sees that it is good. What’s light? It’s an electromagnetic wave that is the fundamental component of energy and communication. </p><p>“I also tell students, ‘You’re the custodians of God’s great gift to creation, and that’s why it’s immensely satisfying to work in communications.’”</p>"},"pubDate":"Thu, 18 Jan 2024 19:00:04 +0000","guid":"https://spectrum.ieee.org/inventor-of-dsl-altered-connectivity","category":["Ieee member news","Dsl","Telecommunications","Award","Type:ti"],"dc:creator":"Julianne Pepitone","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/man-posing-for-a-portrait-in-a-sweater-and-tie-with-a-blurred-university-background.jpg?id=51105425&width=980"}},{"title":"The Man Who Coined the Word “Robot” Defends Himself","link":"https://spectrum.ieee.org/karel-capek-robots","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-black-and-white-photograph-of-a-man-overlaying-an-orange-tinted-robot-in-the-background-with-rur-printed-on-its-chest.jpg?id=51097752&width=1200&height=800&coordinates=0%2C0%2C0%2C185\"/><br/><br/><p>You’re familiar with Karel Čapek, right? If not, you should be—he’s the guy who (along with his brother Josef) invented the word “robot.” Čapek introduced robots to the world in 1921, when his play “<em>R.U.R.</em>” (subtitled “Rossum’s Universal Robots”) was first performed in Prague. It was performed in New York City the next year, and by the year after that, it had been translated into 30 languages. Translated, that is, except for the word “robot” itself, which originally described artificial humans but within a decade of its introduction came to mean things that were mechanical and electronic in nature.</p><p>Čapek, it turns out, was a little miffed that his “robots” had been so hijacked, and in 1935, he wrote a column in the <a href=\"https://www.lidovky.cz/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>Lidové noviny</em></a> “defending” his vision of what robots should be, while also resigning himself to what they had become. A new translation of this column is included as an afterword in a new English translation of <em>R.U.R. </em> that is accompanied by 20 essays exploring robotics, philosophy, politics, and AI in the context of the play, and it makes for fascinating reading. </p><hr/><p><em><a href=\"https://mitpress.mit.edu/9780262544504/ir-u-r-iand-the-vision-of-artificial-life/\" target=\"_blank\">R.U.R. and the Vision of Artificial Life</a></em> is edited by <a href=\"https://droplets.vscht.cz/people/cejkova\" target=\"_blank\">Jitka Čejková</a>, a professor at the <a href=\"https://chobotix.cz/\" target=\"_blank\">Chemical Robotics Laboratory</a> at the University of Chemistry and Technology Prague, whose research interests arguably make her one of the most qualified people to write about Čapek’s perspective on robots. “The chemical robots in the form of microparticles that we designed and investigated, and that had properties similar to living cells, were much closer to Čapek’s original ideas than any other robots today,” Čejková explains in the book’s introduction. These microparticles can exhibit surprisingly complex autonomous behaviors under specific situations, like solving simple mazes:</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"4fc6340ae9013d41849de7917fae8fb6\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/P5uKRqJIeSs?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>“I started to call these droplets liquid robots,” says Čejková. “Just as Rossum’s robots were artificial human beings that only looked like humans and could imitate only certain characteristics and behaviors of humans, so liquid robots, as artificial cells, only partially imitate the behavior of their living counterparts.”</p><p>What is or is not called a robot is an ongoing debate that most roboticists seem to try to avoid, but personally, I appreciate the idea that very broadly, a robot is something that seems alive but isn’t—something with independent embodied intelligence. Perhaps the requirement that a robot is mechanical and electronic <em>is</em> too strict, although as Čapek himself realized 100 years ago, what defines a robot has escaped from the control of anyone, even its creator. Here then is his column from 1935, excerpted from <em>R.U.R. and the Vision of Artificial Life</em>, released just today:  </p><h3>“THE AUTHOR OF THE ROBOTS DEFENDS HIMSELF”</h3><h3>\nBy Karel Čapek</h3><h5>Published in <a href=\"https://www.lidovky.cz/\" rel=\"noopener noreferrer\" target=\"_blank\">Lidové noviny</a>, June 9, 1935</h5><p>I know it is a sign of ingratitude on the part of the author, if he raises both hands against a certain popularity that has befallen something which is called his spiritual brainchild; for that matter, he is aware that by doing so he can no longer change a thing. The author was silent a goodly time and kept his own counsel, while the notion that robots have limbs of metal and innards of wire and cogwheels (or the like) has become current; he has learned, without any great pleasure, that genuine steel robots have started to appear, robots that move in various directions, tell the time, and even fly airplanes; but when he recently read that, in Moscow, they have shot a major film, in which the world is trampled underfoot by mechanical robots, driven by electromagnetic waves, he developed a strong urge to protest, at least in the name of his own robots. For his robots were not mechanisms. They were not made of sheet metal and cogwheels. They were not a celebration of mechanical engineering. If the author was thinking of any of the marvels of the human spirit during their creation, it was not of technology, but of science. With outright horror, he refuses any responsibility for the thought that machines could take the place of people, or that anything like life, love, or rebellion could ever awaken in their cogwheels. He would regard this somber vision as an unforgivable overvaluation of mechanics or as a severe insult to life.</p><p>The author of the robots appeals to the fact that he must know the most about it: and therefore he pronounces that his robots were created quite differently—that is, by a chemical path. The author was thinking about modern chemistry, which in various emulsions (or whatever they are called) has located substances and forms that in some ways behave like living matter. He was thinking about biological chemistry, which is constantly discovering new chemical agents that have a direct regulatory influence on living matter; about chemistry, which is finding—and to some extent already building—those various enzymes, hormones, and vitamins that give living matter its ability to grow and multiply and arrange all the other necessities of life. Perhaps, as a scientific layman, he might develop an urge to attribute this patient ingenious scholarly tinkering with the ability to one day produce, by artificial means, a living cell in the test tube; but for many reasons, amongst which also belonged a respect for life, he could not resolve to deal so frivolously with this mystery. That is why he created a new kind of matter by chemical synthesis, one which simply behaves a lot like the living; it is an organic substance, different from that from which living cells are made; it is something like another alternative to life, a material substrate in which life could have evolved if it had not, from the beginning, taken a different path. We do not have to suppose that all the different possibilities of creation have been exhausted on our planet. The author of the robots would regard it as an act of scientific bad taste if he had brought something to life with brass cogwheels or created life in the test tube; the way he imagined it, he created only a new foundation for life, which began to behave like living matter, and which could therefore have become a vehicle of life—but a life which remains an unimaginable and incomprehensible mystery. This life will reach its fulfillment only when (with the aid of considerable inaccuracy and mysticism) the robots acquire souls. From which it is evident that the author did not invent his robots with the technological hubris of a mechanical engineer, but with the metaphysical humility of a spiritualist.</p><p>Well then, the author cannot be blamed for what might be called the worldwide humbug over the robots. The author did not intend to furnish the world with plate metal dummies stuffed with cogwheels, photocells, and other mechanical gizmos. It appears, however, that the modern world is not interested in his scientific robots and has replaced them with technological ones; and these are, as is apparent, the true flesh-of-our-flesh of our age. The world needed mechanical robots, for it believes in machines more than it believes in life; it is fascinated more by the marvels of technology than by the miracle of life. For which reason, the author who wanted—through his insurgent robots, striving for a soul—to protest against the mechanical superstition of our times, must in the end claim something which nobody can deny him: the honor that he was defeated.</p><p><em>Excerpted from </em>R.U.R. and the Vision of Artificial Life<em>, by Karel Čapek, edited by Jitka Čejková. Published by The MIT Press. Copyright © 2024 MIT. All rights reserved.</em></p>"},"pubDate":"Tue, 16 Jan 2024 21:42:40 +0000","guid":"https://spectrum.ieee.org/karel-capek-robots","category":["Books","Chemical synthesis","Karel capek","Liquid robots","Robotics","Mechanical engineering","Chemical engineering"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-black-and-white-photograph-of-a-man-overlaying-an-orange-tinted-robot-in-the-background-with-rur-printed-on-its-chest.jpg?id=51097752&width=980"}},{"title":"Is This Hybrid Tech the Future of Power Electronics?","link":"https://spectrum.ieee.org/silicon-carbide-gallium-nitride-hybrid","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-photograph-of-a-fused-jumble-of-grey-but-occasionally-iridescent-hexagonal-flakes.jpg?id=51095469&width=1200&height=800&coordinates=0%2C125%2C0%2C125\"/><br/><br/><p>It’s <a href=\"https://spectrum.ieee.org/silicon-carbide\" target=\"_blank\">heady times in power electronics</a>. After decades of domination by silicon, two newer materials—silicon carbide and gallium nitride—have begun taking over multibillion-dollar markets. Silicon carbide is now the semiconductor of choice for the inverters and chargers in electric vehicles, for example. And if you’ve purchased a wall charger lately for your smartphone or laptop, chances are good that it uses gallium nitride.</p><p>The newer materials, known as <a href=\"https://www.engineering.com/story/si-sic-and-gan-for-power-devices-part-one-electron-energy-and-the-semiconductors\" target=\"_blank\">wide-bandgap</a> semiconductors, are taking over these and other power-electronics applications because they offer many superior characteristics. And yet wide-bandgap technologies still have fundamental weaknesses. For a silicon-carbide transistor, a big one is relatively low mobility of electrons in the channel—the area under the device’s gate through which current flows between the source and the drain. That low mobility prevents SiC transistors from switching at high rates. That, in turn, limits their efficiency in applications such as converting between alternating current and direct current. Gallium-nitride transistors, on the other hand, have a quirk known as “<a href=\"https://ieeexplore.ieee.org/document/10106013\" target=\"_blank\">dynamic on-resistance</a>,” which means that when the device is conducting current, the resistance of the device depends on the voltage—higher voltage means higher on-resistance. Another problem with GaN is that the physical size of the device, and therefore its cost, goes up as its voltage-blocking capability does, a significant flaw for devices expected to turn on and off voltages that are many times higher than those found inside, say, a typical computer.</p><p>What if you could combine GaN and SiC in a single device that minimizes the weaknesses of each and maximizes their strengths? That’s the question that drove a team of 16 researchers at the Hong Kong University of Science and Technology and three other institutions in China. After <a href=\"https://ieeexplore.ieee.org/document/7466844\" rel=\"noopener noreferrer\" target=\"_blank\">years of work</a>, they finally claimed success by fabricating a transistor, which they call a hybrid field-effect transistor, or HyFET. They described their work in a paper presented at the IEEE <a href=\"https://www.ieee-iedm.org/\" target=\"_blank\">International Electron Devices Meeting</a>, held this past December in San Francisco. </p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"Black-and-white images, made with a scanning electron microscope, show key components of an experimental transistor.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"f9c2b6527a3a6a4815e4cec29b59533a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"fb69a\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/black-and-white-images-made-with-a-scanning-electron-microscope-show-key-components-of-an-experimental-transistor.jpg?id=51095471&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">A scanning-electron microscope (SEM) image of a HyFET, looking down at the device [a], clearly shows the gate and a source. A cross-sectional SEM image of the HyFET [b] shows the gallium nitride transistor at the top and the silicon carbide below. Other SEM images show the gate region of the GaN device [c], and the channel of the SiC transistor [d and e]. </small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">   The Hong Kong University of Science and Technology </small></p><p>Experts in wide-bandgap semiconductors not involved with the research were impressed with the technical achievement. “I actually am very excited about the results of <a href=\"https://eekjchen.home.ece.ust.hk/\" rel=\"noopener noreferrer\" target=\"_blank\">Kevin Chen</a>’s group in Hong Kong,” said IEEE Fellow <a href=\"https://www.engineering.cornell.edu/faculty-directory/debdeep-jena\" rel=\"noopener noreferrer\" target=\"_blank\">Debdeep Jena</a>, a professor and laboratory leader at <a href=\"https://www.cornell.edu/\" target=\"_blank\">Cornell University</a>. “It has a lot of merit and promise.” However, these experts’ opinions about the device’s commercial prospects were generally more circumspect.</p><p>In operation, the device uses a low-voltage, high-speed GaN transistor to control a high-voltage SiC junction field-effect transistor (JFET). In a conventional SiC JFET, the drain is at the bottom of the device, connected to the substrate. Current flows vertically, controlled by a gate on top of the device, through a “drift layer” to one or more source terminals, also on top of the device. In the HyFET, that basic configuration is recognizable: There’s a drain at the bottom of the device, connected to the substrate. Current flows upward through a SiC drift layer. However, the gate and source terminals are in a GaN transistor integrated directly above the SiC JFET, at the top of the device. So the current flowing through the SiC JFET is controlled by a gate and source terminals that are in the GaN part of the device.</p><p>The advantage here is that it is the GaN transistor, with its high electron mobility, that controls the switching of the combined device. And built on the foundation of the SiC JFET, with its large drift region, the combined device has the voltage-blocking capabilities of SiC. Testing indicated that the device largely fulfilled the researchers’ expectations. Although the mobility is not quite as high as for a conventional GaN device, it is “suitable for high-frequency switching,” they found. They also demonstrated that in the “off” state, the device could block around 600 volts, depending on temperature—not bad for a first-of-its-kind experimental device.</p><p>Many challenges had to be surmounted to fabricate the device. One of the major ones was growing a GaN transistor directly on top of an SiC one. Gallium nitride devices are routinely fabricated on substrates of SiC. However, these devices are grown “on axis,” meaning they are grown layer by layer with each layer parallel to the substrate. But SiC devices are typically grown <em>off</em> axis with respect to the orientation of their substrate crystal’s lattice. So the researchers had to devise a means of growing a GaN transistor on top of an SiC device with a deviance from the axis, or “miscut,” of 4 degrees.</p><p>To do this they developed a technique that they call two-step biaxial strain release. A fundamental problem with the interfaces between two different semiconductors is the strain created at the boundary where the two dissimilar crystals merge. This strain can create performance-robbing imperfections in the lattice called <a href=\"https://fastercapital.com/keyword/lattice-mismatch.html\" target=\"_blank\">dislocations</a>. The technique refined and exploited by the researchers releases the strain through two specific kinds of dislocations, minimizing its detrimental effects.</p><p>One of the weaknesses of the HyFET is its resistance to current flow when the transistor is in the on state. This value, called specific on-resistance (specific R<sub>on)</sub>, is quite high, at around 50 milliohms - cm<sup>2</sup>. Higher R<sub>on</sub> means lower overall efficiency. Of course, the HyFET is literally the first of its kind, built in a university laboratory.</p><p>“The large R<sub>on</sub> in our paper results from a small device...and a very conservative design in the SiC portion,” wrote author and IEEE Fellow Kevin Chen in an e-mail. “In general, there are no additional obstacles toward the realization of 3 mΩ∙cm<sup>2</sup> (~2.6) for a 1,200-V HyFET with industrial SiC manufacturing facilities.”</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"Photomicrographs show details of an experimental transistor.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"46a99f403f2af6d1762b5ee907329a83\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"31b98\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/photomicrographs-show-details-of-an-experimental-transistor.jpg?id=51095472&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">   Scanning electron images show a hole, or via, in the gallium nitride portion of the device [a]. When filled with metal [c], these vias become conductive pathways, enabling current to flow between the gallium-nitride and silicon-carbide portions of the device. An image made with atomic force microscopy [b] shows the surface of a silicon-carbide layer.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">The Hong Kong University of Science and Technology</small></p><p>For comparison, though, a state-of-the art SiC or GaN transistor capable of blocking more than 600 volts can have R<sub>on</sub> as low as 2 mΩ∙cm<sup>2</sup>, notes IEEE Life Fellow <a href=\"https://ece.ncsu.edu/people/bjbaliga/\" target=\"_blank\">B. Jayant Baliga</a>, the inventor of the insulated-gate bipolar transistor and Distinguished University Professor of Electrical Engineering at <a href=\"https://www.ncsu.edu/\" target=\"_blank\">North Carolina State University</a>. Given these figures, Baliga questions how much demand there would be for a commercial HyFET, when much simpler and probably cheaper SiC transistors are available. “What would motivate someone to shift to something much more complicated, with all these layers being grown, if the specific on-resistance is not reduced below that of the silicon-carbide MOSFET [metal oxide semiconductor FET]?” Baliga asked.</p><p>IEEE Fellow <a href=\"https://engineering.ucsb.edu/people/umesh-mishra\" target=\"_blank\">Umesh Mishra</a>, Dean of the College of Engineering at the <a href=\"https://www.ucsb.edu/\" target=\"_blank\">University of California Santa Barbara</a>, and a pioneer in GaN power devices, questioned whether the advantages of integrating two different semiconductors into a single device—minuscule inductive delays and capacitive losses—were worth the costs in manufacturing complexity and other factors. To manufacture such a device, a company “now has to have two technologies that they’re running in the fab,” he notes. “They have to have silicon-carbide technology, and they have to have gallium-nitride technology. Nobody wants to do that because you now have two complicated technologies that you are simultaneously trying to run”—a costly proposition.</p><p>“To scale something difficult is always hard,” Mishra adds. “Then the question is, what is your benefit?” Mishra notes that most of the advantages of the combined device could be obtained at much lower cost by simply connecting the two different transistors together in a single package, rather than integrating them into a single hybrid device. </p><p>Author Chen, however, suggested that unwanted electronic characteristics, particularly a weakness called parasitic inductance, would plague transistors that are simply packaged together rather than integrated. “Lower parasitic inductance minimizes switching oscillation and reduces switching loss,” he wrote in his e-mail. “Advanced co-packaging techniques could reduce the parasitic inductance to a certain degree, but may not be as cost effective as the integrated device (realized in a batch process).”</p><p>Jena, at Cornell, noted that a potentially insurmountable obstacle for the HyFET is the rate of advancement of GaN devices, in particular. In the foreseeable future, he says, GaN will become so capable that it probably won’t require hybrid schemes to triumph. “The physics tells me that GaN is the winner in the long run,” he says. “I don’t want to take anything away from the [HyFET] paper. It’s a great paper. But whatever they have shown here will also be possible with gallium nitride in the future,” he concludes.</p>"},"pubDate":"Tue, 16 Jan 2024 19:57:17 +0000","guid":"https://spectrum.ieee.org/silicon-carbide-gallium-nitride-hybrid","category":["Gallium nitride","Silicon carbide","Wide bandgap semiconductors","Power electronics"],"dc:creator":"Glenn Zorpette","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-photograph-of-a-fused-jumble-of-grey-but-occasionally-iridescent-hexagonal-flakes.jpg?id=51095469&width=980"}},{"title":"Remembering Roberto Saracco, President of EIT Digital","link":"https://spectrum.ieee.org/roberto-saracco-obituary","description":{"#cdata-section":"\n<p>Robert Saracco, an IEEE senior member dedicated to empowering the next generation of digital innovators in Europe, died unexpectedly on 5 December at the age of 70. </p><p> He was a key figure in the creation of <a href=\"https://www.eitdigital.eu/\" rel=\"noopener noreferrer\" target=\"_blank\">EIT Digital</a>, an organization that invests in research and continuing education to bring new digital technologies to the European market. Saracco also taught courses on technology forecasting and market impact at the <a href=\"https://www.unitn.it/en\" rel=\"noopener noreferrer\" target=\"_blank\">University of Trento</a> in Italy. </p><p> An active IEEE volunteer, he chaired the <a href=\"https://www.ieee.org/about/corporate/initiatives/initiatives-committee.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE New Initiatives Committee</a>, which supports potential IEEE services, products, and other creations that could significantly benefit members, the public, customers, and the technical community. He was also a co-chair of the <a href=\"https://digitalreality.ieee.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Digital Reality</a> initiative, dedicated to facilitating disruptive technological innovations and fostering cross-industry collaborations globally while taking societal impact into consideration.</p><h2>Contributions at Telecom Italia and EIT Digital</h2><p>After receiving a bachelor’s degree in computer science and a master’s degree in mathematics from the <a href=\"https://en.unito.it/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Turin</a>, in Italy, Saracco began his career in 1971 at the <a href=\"https://en.wikipedia.org/wiki/CSELT\" rel=\"noopener noreferrer\" target=\"_blank\">Telecom Italia Lab</a>, in Rome. There he led network management research and helped design Italy’s first electronic exchange and data network.</p><p> Saracco also contributed to standardizing the company’s telecommunications management network. Later, he led the team that developed Italy’s first network management center. </p><p> In 2003 he was promoted to director of long-term research at the lab, focusing on technology’s evolution and its potential impact. Five years later, he changed roles and began serving as director of <a href=\"https://www.gruppotim.it/en/press-archive/corporate/2002/09_12-is.html\" rel=\"noopener noreferrer\" target=\"_blank\">Telecom Italia’s Future Centre</a>, an interactive technology museum, in Venice.</p><p> Saracco left the museum in 2011 to join EIT Digital as the president of its Italian branch in Trento. He held this position until his death. </p><p>In 2017 and 2018 he served as head of <a href=\"https://www.eitmanufacturing.eu/what-we-do/education/education-programmes/empower-programme/doctoral-school/\" rel=\"noopener noreferrer\" target=\"_blank\">EIT’s Industrial Doctoral School</a>, headquartered in Palaiseau, France. The organization supports Ph.D. students from European universities to help them transform their research into marketable products and solutions.  </p><p> From 2015 on, he was also a senior lecturer at the <a href=\"https://www.unitn.it/en\" rel=\"noopener noreferrer\" target=\"_blank\">University of Trento</a>, where he taught a master class called “Technology Foresight and Economic Implications of Technology Evolution.” Beginning in 2020 he served on the advisory board of <a href=\"https://www.reply.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Reply</a>, an international digital technology consulting firm based in Turin. </p><h2>IEEE volunteering and authorship </h2><p>Saracco, an active volunteer, helped lead groups and initiatives at IEEE, including the <a href=\"https://www.comsoc.org/about/committees/technical-committees/network-operations-management\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Technical Committee on Network Operations and Management</a> and <a href=\"https://cmte.ieee.org/futuredirections/projects/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Future Directions</a>, which is responsible for identifying and organizing research on emerging technologies across the organization. He was also a member of the <a href=\"https://www.comsoc.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Communications Society</a> board of governors and served as its director of marketing. </p><p> He authored or coauthored more than 100 papers and 14 books, including <a href=\"https://www.amazon.com/Disappearance-Telecommunications-Roberto-Saracco/dp/0780353870\" rel=\"noopener noreferrer\" target=\"_blank\"><em>The Disappearance of Telecommunications</em></a>, published in 2000 by <a href=\"https://www.ieee.org/publications/books/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Press</a>. Saracco also published a <a href=\"https://cmte.ieee.org/futuredirections/category/blog/\" rel=\"noopener noreferrer\" target=\"_blank\">daily blog</a> on the <a href=\"https://cmte.ieee.org/futuredirections/projects/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Future Directions</a> website, where he mused on the latest technological developments and their impact on humanity. </p><h2>Tribute from a close colleague</h2><p><em>Davide De Palma, co-founder of </em><a href=\"https://hrcoffee.us/\" rel=\"noopener noreferrer\" target=\"_blank\"><em>HR Coffee</em></a><em> and a colleague of Saracco’s, submitted this in-depth portrait of his close friend to </em>The Institute<em>.</em></p><p>Remembering Roberto is to immerse oneself in a world where passion for technology shines brightly. Roberto was not just an expert in his field; he was a man who lived each day with a deep and sincere love for exploring the unknown. His curiosity was not merely academic; it was an emotional journey that took him deeper into the ever-expanding universe of new technologies.</p><p> But what really struck one about Roberto was his immense humanity. He did not just explore the technological world; he delved into the lives of people. He was a man who knew how to listen–truly listen. Every conversation with him was a journey, where words were not just sounds, but bridges to a deeper understanding.</p><p> Roberto had a unique talent for recognizing and valuing the best in each person. He was not just a mentor or a teacher. He was an artist of the human soul, capable of discerning and illuminating the hidden talents in each of us. His approach was never superficial. He was interested in the details, those small nuances that often escape notice, but for him were the key to truly understanding people and the world around him.</p><p> His legacy is not just in the field of technology, but also in the countless lives he touched. Roberto taught many of us not just to be better professionals, but also to be better human beings. His passion, his curiosity, and his humanity will continue to live in the hearts of those fortunate enough to have known him.</p><p> In our conversations, Roberto truly shined. I vividly remember our long talks about <a href=\"https://cmte.ieee.org/futuredirections/2023/05/06/personal-digital-twins-evolving-at-ai-pace/\" rel=\"noopener noreferrer\" target=\"_blank\">personal digital twins</a>, a topic that particularly excited him. His eyes would light up as he talked about how these digital counterparts could transform not just how we interact with technology, but also how we see and understand ourselves in an increasingly digital world. His vision was deep, capable of seeing beyond the mere technological aspect and touching the chords of human essence.</p><p> But it was not just technology that captured his imagination. Roberto placed great importance on organizational processes and knowledge management. He believed that technology, however advanced, could never replace the human value in decision-making and creativity. For him, data and knowledge were like golden threads woven into the vast canvas of technological innovation, essential for creating a more connected and humane future.</p><p> And then there was his passion for training <em>knowledge engineers</em>. Roberto was convinced that the future belonged to those who not only understood technology, but also how it could be harmonized with human wisdom. His vision was clear: to train a new generation of engineers who were not only technically competent but also deeply aware of the value and importance of human knowledge.</p><p> Remembering Roberto Saracco is to remember a man who lived with boundless passion for technology, but even more for the humanity it serves. His legacy is not just in the innovations he helped create, but in the lives he touched and the minds he enlightened. His legacy continues to live in every knowledge engineer he shaped, and in every conversation about technology that transcends the technical to touch the human. Roberto was not just a pioneer in his field, but a true maestro of life, a beacon of wisdom and humanity in an increasingly digital world.</p><p> Sit tibi terra levis [May the earth rest lightly upon you], Roberto.</p>"},"pubDate":"Sun, 14 Jan 2024 19:00:02 +0000","guid":"https://spectrum.ieee.org/roberto-saracco-obituary","category":["Ieee member news","Obituary","Tribute","Type:ti"],"dc:creator":"Amanda Davis"},{"title":"Mesh Wearables Meld Microsensors and LoRa Smarts","link":"https://spectrum.ieee.org/wearable-medical-devices-lora","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/person-sitting-at-a-desk-with-a-laptop-open-and-a-white-mesh-bracelet-wrapped-around-their-right-wrist.jpg?id=51029429&width=1200&height=800&coordinates=0%2C125%2C0%2C125\"/><br/><br/><p>As health care wearables for various medical conditions and situations proliferate, patients inevitably want their wearable tech as inconspicuous and worry free as possible. As a case in point, consider a new wearable <a href=\"https://news.arizona.edu/story/new-wearable-communication-system-offers-potential-reduce-digital-health-divide\" target=\"_blank\">mesh health monitor</a> that does away with the “box and a strap” architecture that is still the industry’s de facto commercial design standard. This tech, developed by researchers at the <a href=\"https://www.arizona.edu/\" target=\"_blank\">University of Arizona</a>, features long-range, low-power data transmission and receiving as well as wireless power charging. As a result of its portability, the device looks to be a compelling choice for remote health monitoring in isolated areas.<br/></p><p><a href=\"https://bme.engineering.arizona.edu/faculty-staff/faculty/philipp-gutruf\" target=\"_blank\">Philipp Gutruf</a>, who directed the research, says his team is working to address the need for clinical-grade health monitors that are made “accessible in all kinds of areas on the globe [while] retaining the imperceptible nature of the device.” Gutruf is an <a href=\"https://gutruf.lab.arizona.edu/home\" target=\"_blank\">assistant professor of biomedical engineering</a> at the university.<br/></p><p class=\"pull-quote\"> “There is no large rigid island in this device. All the electronics are distributed in this mesh.”<br/><strong>—Philipp Gutruf, University of Arizona</strong></p><p>The device measures heart rate and body temperature using a form-fitting, lattice-like mesh of thermoplastic polyurethane. The team 3D printed it, but Gutruf says other manufacturing methods can be used as well. Also part of the kit are a lightweight battery, a duplexing antenna that allows both data transmission and wireless power charging, and sensors, none more than 6 millimeters in diameter. About 15 centimeters long, the device is worn around a user’s forearm. Gutruf likens it to wearing a sock with the toe end cut off, except the mesh is extremely lightweight and comfortable to the point of being almost forgotten. He calls it “biosymbiotic.”</p><p>Design boosts the wearable’s wearability, its chief advocate says. “There is no large rigid island in this device,” Gutruf says. “All the electronics are distributed in this mesh.” It doesn’t rely on adhesives either, he says, but instead conforms to the user’s body. “That allows us to go well beyond the three to four days a patch can do,” Gutruf adds.<br/></p><p>Blood-flow and blood-volume monitoring are furthermore available in the new technology via a technique called <a href=\"https://pubmed.ncbi.nlm.nih.gov/17322588/\" rel=\"noopener noreferrer\" target=\"_blank\">photoplethysmography</a> (PPG). </p><p>Traditional PPG sensors, Gutruf says, have a small mass in it that measure acceleration. This tech, by contrast, uses its body-conforming profile to eliminate what he calls the traditional “brick” strapped to a PPG sensor. The device’s sensor, he says, “Is on a tiny node embedded in the mesh that conforms very well to your skin. So we can drop some of the filtering requirements, oversampling, additional accelerometer processing, and so on...because we have a very good signal to begin with.”</p><h3>Better LoRa with LoRaWAN</h3><p><span></span>In addition to the comfort factors, Gutruf says, the mesh design achieves a better operating efficiency than a typical commercial wearable. To improve transmission via small packets, the device does onboard computing of the raw sensor data. And it uses the long-range (<a href=\"https://www.thethingsnetwork.org/docs/lorawan/what-is-lorawan/#:~:text=LoRa%20is%20a%20wireless%20modulation,be%20received%20across%20great%20distances.\" target=\"_blank\">LoRa</a>) communications protocol, which the researchers demonstrated at 24 kilometers point-to-point in an isolated mountainous area.</p><p>“LoRa has kind of the best community already existing,” he says. “Yes, there are other technologies. But considering the already existing networks in the regions we made this device for, it was pretty much a no-brainer to pick LoRa.”<br/></p><p><a href=\"https://spectrum.ieee.org/loras-bid-to-rule-the-internet-of-things\" target=\"_self\">LoRa</a> is one of the mainstay technologies in <a data-linked-post=\"2650275916\" href=\"https://spectrum.ieee.org/testing-the-internet-of-things\" target=\"_blank\">Internet of Things</a> (IoT) deployments. Originally architected in 2009, the modulation technology is based on a wideband, chirped-pulse standard (<a href=\"https://en.wikipedia.org/wiki/Chirp_spread_spectrum\" target=\"_blank\">chirp spread spectrum</a>) that excels at transmitting small data packets—up to a theoretical maximum of 256 bytes, though that varies by region and application—at long range using little power. </p><p><a href=\"https://lora-alliance.org/about-lorawan/\" target=\"_blank\">LoRaWAN</a>, the <a href=\"https://en.wikipedia.org/wiki/Medium_access_control\" target=\"_blank\">media access control (MAC) protocol</a> that sits atop the LoRa physical layer, was developed and maintained by the LoRa Alliance beginning in 2015. The <a href=\"https://www.ietf.org/\" target=\"_blank\">Internet Engineering Task Force</a> (IETF) published <a href=\"https://www.rfc-editor.org/rfc/rfc9011.html\" target=\"_blank\">RFC 9011,</a> the standard specifying the use of Internet protocols with LoRaWAN, in 2021.<br/></p><p>LoRaWAN is already well established in health care. Calgary, Canada–based <a href=\"https://tektelic.com/\" target=\"_blank\">Tektelic</a> offers a remote monitoring device called <a href=\"https://tektelic.com/products/sensors/e-doctor-health-monitoring-iot-device/\" target=\"_blank\">eDOCTOR,</a> which straps around the chest and monitors temperature, respiration, heart rate, body position, and chest expansion. <a href=\"https://www.linkedin.com/in/christianulrik/\" target=\"_blank\">Christian Ulrik</a>, vice president of sales and business development at Tektelic, says the device is ideal for monitoring patients who have been recently discharged from the hospital. Recent U.S. government <a href=\"https://hcup-us.ahrq.gov/reports/statbriefs/sb304-readmissions-2016-2020.jsp\" target=\"_blank\">statistics</a> show that 13.9 percent of all patients discharged from a hospital between 2016 and 2020 were readmitted within 30 days.<br/></p><p>These LoRaWAN technologies <a href=\"https://ontex.com/our-brands/adult-care/orizon-continence-care/\" target=\"_blank\">plus</a> a <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8307208/\" target=\"_blank\">range</a> of <a href=\"https://www.researchgate.net/publication/345129243_Peace_of_mind_A_community-industry-academic_partnership_to_adapt_dementia_technology_for_Anishinaabe_communities_on_Manitoulin_Island\" target=\"_blank\">others</a>, Gutruf says, provide hope for those the global health care system has otherwise been unable to treat adequately.</p><p>“The more technologies we make available, the more obvious it becomes for the medical community, and the easier it becomes for the medical community to do this,” he says. “The quicker we get acceptance of this, the better we can serve those who would usually have trouble getting quality health care.”</p>"},"pubDate":"Sun, 14 Jan 2024 14:00:02 +0000","guid":"https://spectrum.ieee.org/wearable-medical-devices-lora","category":["Lora","Lorawan","Wearables","Sensors","Health technologies","Ppg"],"dc:creator":"Greg Goth","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/person-sitting-at-a-desk-with-a-laptop-open-and-a-white-mesh-bracelet-wrapped-around-their-right-wrist.jpg?id=51029429&width=980"}},{"title":"Daimler Truck Fuels Big Rigs With Hydrogen","link":"https://spectrum.ieee.org/hydrogen-truck","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-grey-and-black-semi-truck-on-a-highway-is-covered-with-branding-for-genh2-daimler-truck.jpg?id=51033575&width=1200&height=800&coordinates=62%2C0%2C63%2C0\"/><br/><br/><p>At <a href=\"https://www.ces.tech/\" target=\"_blank\">CES</a> this past week, the trucking <a href=\"https://www.prnewswire.com/news-releases/nikola-celebrates-the-commercial-launch-of-hydrogen-fuel-cell-electric-truck-in-coolidge-arizona-301942334.html\" target=\"_blank\">startup</a> Nikola <a href=\"https://techcrunch.com/2024/01/11/hydrogen-is-back-at-least-ces-2024-suggests-it-is/\" target=\"_blank\">showed off</a> a hydrogen-fueled semi truck, one of its first ever built in the United States. But the <a href=\"https://www.theregister.com/2023/08/15/nikola_recalls_its_electric_truck/\" target=\"_blank\">troubled</a> company with a <a href=\"https://www.cbsnews.com/news/trucks-fraud-investors-trevor-milton-nikola-electric-zero-emissions/\" target=\"_blank\">convicted</a> founder is not the only player these days seeing a promising future in fuel-cell fueled big rigs. <a href=\"https://www.daimlertruck.com/en\" target=\"_blank\">Daimler Truck</a> has also recently announced its <a href=\"https://electriccarsreport.com/2023/12/daimler-truck-builds-first-mercedes-benz-genh2-truck-customer-trial-fleet/\" target=\"_blank\">GenH2 electric semi</a>. The GenH2’s motors draw power from a fuel cell that runs on liquid hydrogen, and Daimler has said the vehicle will appear on German roads by mid-2024.</p><p>The company has entered agreements with several companies that have fleet operations in the German region, where <a href=\"https://www.daimlertruck.com/en/newsroom/pressrelease/development-milestone-daimler-truck-tests-fuel-cell-truck-with-liquid-hydrogen-51975637\" target=\"_blank\">Daimler successfully tested a GenH2 prototype</a> on a track and on public roads. Via these early road tests, the company says it has found that a fully loaded GenH2 proved capable of hauling its roughly 25-tonne payload more than <a href=\"https://electriccarsreport.com/2023/10/mercedes-benz-genh2-truck-cracks-1000-kilometer-mark-with-one-fill-of-liquid-hydrogen/\" target=\"_blank\">1,000 kilometers on a single fueling</a>.</p><h2>Under the Hood of the GenH2 Truck</h2><p>The fuel-cell system of the GenH2 Truck, according to the company, delivers 300 kilowatts. The truck also has a battery that can kick in an additional 400 kW in short bursts for quick acceleration and hill climbing. The battery’s 70 kilowatt-hour storage capacity may seem small, but it’s sufficient for recycling kinetic energy that’s converted to electric charge via regenerative braking.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"A person in protective hood gear and thick gloves connects long, thick pipes to the front of a semi truck, where a tank says H2.\" class=\"rm-shortcode\" data-rm-shortcode-id=\"14b38eb2edb13ae6d258e78748e016f6\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"2eedf\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-person-in-protective-hood-gear-and-thick-gloves-connects-long-thick-pipes-to-the-front-of-a-semi-truck-where-a-tank-says-h2.jpg?id=51033600&width=980\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-82032\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Daimler’s GenH2 Truck, according to the company’s initial road tests, can travel 1,000 kilometers on a full tank of liquid hydrogen.  </small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-429115\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Daimler Truck</small></p><p> Daimler, along with <a href=\"https://www.linde.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Linde</a> and <a href=\"https://www.airliquide.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Air Liquide</a>, the German and French multinational suppliers of industrial gases and hydrogen refueling services, are taking advantage of advances in liquid-hydrogen storage that yield notable advantages over using pressurized gas.</p><p>In its liquified state, more hydrogen can be carried per unit volume compared to room-temperature H<sub>2</sub>, which is a gas. As a result,  energy density is significantly higher, while smaller tanks on the vehicle can still yield greater range than is possible than gaseous hydrogen. That space savings and boost in energy density let the truck haul a bigger payload.</p><p>At specially equipped liquid-hydrogen filling stations in Wörth am Rhein and in the Duisburg area, <a href=\"https://en.wikipedia.org/wiki/Liquid_hydrogen\" target=\"_blank\">cryogenic liquid hydrogen</a> cooled to -253 C° can be pumped into two 44-kilogram stainless steel tanks mounted on either side of a GenH2 semi’s chassis. Refueling can be completed within 10 to 15 minutes. According to the company, high-efficiency insulation on the tanks keep the hydrogen below its ultralow boiling point without active cooling.</p><p>“We are also proud to be providing Daimler Truck with some of the necessary refueling infrastructure and hydrogen as part of the trials,” says Caroline Stancell, general manager (Europe and Africa region) of the <a href=\"https://www.airproducts.com/industries/hydrogen-fueling-for-mobility\" target=\"_blank\">Hydrogen for Mobility</a> division at <a href=\"https://www.airproducts.com/\" target=\"_blank\">Air Products</a>, a U.S.-based industrial-gas supplier participating in the project. “Our latest mobile fueling station for liquid hydrogen will be used for the project in the Duisburg area and can therefore operate under real conditions.”</p><h2>Daimler Truck’s Next Steps</h2><p>As it has done in the past with safety technologies it has spearheaded, Daimler has made the recipe for liquid hydrogen (LH<sub>2</sub>) publicly available. It is now an <a href=\"https://www.iso.org/standard/39892.html#:~:text=Abstract,fire%20and%20explosion%20is%20provided.\" target=\"_blank\">ISO standard</a>. What’s more, the automaker plans to work directly with other companies to help it develop their own liquid-hydrogen-refueling and fuel-cell vehicle technologies. The aim, Daimler said in a press release, is to “establish a global mass market for the new refueling process.”</p><p>Daimler Truck is already at work with Linde on another new process for handling hydrogen cooled to the superlow temperatures at which it takes the form of a liquid. The automaker says that process will yield even higher storage (and thus energy) density with easier refueling compared with the LH<sub>2</sub> process.</p><p>Daimler is laying the groundwork for making hydrogen a more broadly available automotive energy modality. The company says it is also planning to work together with BP, Shell, and TotalEnergies to build out hydrogen-refueling infrastructure for major transport routes in Europe.</p><p>Pricing details on the GenH2 Truck were unavailable at press time. For comparison, <em>Fleet Owner </em>magazine <a href=\"https://www.fleetowner.com/emissions-efficiency/article/21274675/nikola-tre-commercial-launch-proves-hydrogen-trucks-viability\" target=\"_blank\">estimates</a> a Nikola fuel-cell semi costs approximately US $750,000—although <em>Fleet Owner</em> adds that incentives from the U.S. <a data-linked-post=\"2657875627\" href=\"https://spectrum.ieee.org/hydrogen-economy-inflation-reduction-act\" target=\"_blank\">Inflation Reduction Act</a> and <a href=\"https://californiahvip.org/\" target=\"_blank\">California HVIP</a> grants could, for some owners, cut the cost back by $40,000 and $288,000, respectively. </p>"},"pubDate":"Sat, 13 Jan 2024 16:24:39 +0000","guid":"https://spectrum.ieee.org/hydrogen-truck","category":["Ces","Daimler","Daimler truck","Fuel cell truck","Genh2","Hydrogen fuel cells","Europe","Germany"],"dc:creator":"Willie Jones","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-grey-and-black-semi-truck-on-a-highway-is-covered-with-branding-for-genh2-daimler-truck.jpg?id=51033575&width=980"}},{"title":"Meet the Candidates Running for 2025 IEEE President-Elect","link":"https://spectrum.ieee.org/candidates-2025-ieee-president-elect","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-photo-of-a-woman-and-two-men.png?id=51057133&width=1200&height=800&coordinates=1572%2C0%2C0%2C0\"/><br/><br/><p>The IEEE Board of Directors has nominated IEEE Fellows Mary Ellen Randall, John Verboncoeur, and S.K. Ramesh as candidates for 2025 IEEE president-elect.</p><p>The winner of this year’s election will serve as IEEE president in 2026. For more information about the election, president-elect candidates, and petition process, visit the <a href=\"https://www.ieee.org/about/corporate/election/index.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE election website</a>.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A photo of a smiling woman \" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"fab20ea4ae98d6b91c25af3666357e7e\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"ac919\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-photo-of-a-smiling-woman.jpg?id=51057952&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Fran Graley Photography</small></p><h2>IEEE Fellow Mary Ellen Randall</h2><p>Nominated by the IEEE Board of Directors</p><p>Randall founded Ascot Technologies in 2000 in Cary, N.C. Ascot develops enterprise applications using mobile data delivery technologies. She serves as the award-winning company’s CEO.</p><p>Before launching Ascot, she worked for IBM, where she held several technical and managerial positions in hardware and software development, digital video chips, and test design automation. She routinely managed international projects.</p><p>Randall has served as IEEE treasurer, director of IEEE Region 3, chair of IEEE Women in Engineering, and vice president of IEEE Member and Geographic Activities.</p><p>In 2016 she created the IEEE MOVE (Mobile Outreach VEhicle) program to assist with disaster relief efforts and for science, technology, engineering, and math educational purposes. </p><p>The IEEE Eta Kappa Nu honor society member has received several honors including the 2020 IEEE Haraden Pratt Award, which recognizes outstanding volunteer service to IEEE.</p><p>She was named a top businesswoman in North Carolina’s Research Triangle Park area, and she made the 2003 <em>Business Leader</em> Impact 100 list.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A photo of a smiling man\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"dad1f906c3c962ab262e7dfe35756174\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"9ad8c\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-photo-of-a-smiling-man.jpg?id=51057975&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Christopher Cote from Edward Fox Photography</small></p><h2>IEEE Fellow John Verboncoeur</h2><p>Nominated by the IEEE Board of Directors</p><p>Verboncoeur is senior associate dean for research and graduate studies in Michigan State University’s (MSU) engineering college, in East Lansing.</p><p>In 2001 he founded the computational engineering science program at the University of California, Berkeley, chairing it until 2010.</p><p>In 2015 he cofounded the MSU computational mathematics, science, and engineering department.</p><p>His area of interest is plasma physics, with over 500 publications and over 6,500 citations.</p><p>He is on the boards of <em>Physics of Plasmas</em> and the American Center for Mobility, and the U.S. Department of Energy Fusion Energy Science Advisory Committee.</p><p>Verboncoeur has led startups developing digital exercise and health systems and the consumer credit report. He also had a role in developing the U.S. Postal Service’s mail-forwarding system.</p><p>His IEEE experience includes 2023 vice-president of Technical Activities, 2020 acting vice-president of Publication Services and Products Board, 2019-2020 Division IV director, and 2015-2016 president of the Nuclear and Plasma Sciences Society. </p><p>He received a Ph.D. in 1992 in nuclear engineering from UC Berkeley.</p><p><br/></p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A photo of a smiling man.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"c5d728bc69b6faaa40fa8a4f1305d66a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"556c4\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-photo-of-a-smiling-man.jpg?id=51057977&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">S K Ramesh</small></p><h2>IEEE Fellow S.K. Ramesh</h2><p>Nominated by the IEEE Board of Directors</p><p>Ramesh is a professor of electrical and computer engineering at California State University Northridge’s college of engineering and computer science, where he served as dean from 2006 to 2017.</p><p>An IEEE volunteer for 42 years, he has served on the IEEE Board of Directors, the Publication Services and Products Board, Awards Board, and the Fellows Committee. Leadership positions he has held include vice president of IEEE Educational Activities, president of the IEEE Eta Kappa Nu honor society, and chair of the IEEE Hearing Board.</p><p>As the 2016–2017 vice president of IEEE Educational Activities, he championed several successful programs including the IEEE Learning Network and the IEEE TryEngineering Summer Institute.</p><p>Ramesh served as the 2022–2023 president of ABET, the global accrediting organization for academic programs in applied science, computing, engineering, and technology.</p><p>He received his bachelor’s degree in electronics and communication engineering from the University of Madras in India. He earned his master’s degree in EE and Ph.D. in molecular science from Southern Illinois University, in Carbondale.</p><p><em><em>This article has been updated from an earlier version.</em></em></p>"},"pubDate":"Fri, 12 Jan 2024 19:00:03 +0000","guid":"https://spectrum.ieee.org/candidates-2025-ieee-president-elect","category":["Ieee president","Ieee election","Ieee news","Type:ti"],"dc:creator":"Joanna Goodrich","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/a-photo-of-a-woman-and-two-men.png?id=51057133&width=980"}},{"title":"Video Friday: Robot, Make Me Coffee","link":"https://spectrum.ieee.org/video-friday-robot-make-me-coffee","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-photograph-of-a-silvery-humanoid-robot-placing-a-pod-into-a-keurig-machine.png?id=51064069&width=1200&height=800&coordinates=200%2C0%2C200%2C0\"/><br/><br/><p>Video Friday is your weekly selection of awesome robotics videos, collected by your friends at <em>IEEE Spectrum</em> robotics. We also post a weekly calendar of upcoming robotics events for the next few months. Please <a href=\"mailto:automaton@ieee.org?subject=Robotics%20event%20suggestion%20for%20Video%20Friday\">send us your events</a> for inclusion.<br/></p><h5><a href=\"https://cybathlon.ethz.ch/en/events/challenges/Challenges-2024\">Cybathlon Challenges</a>: 2 February 2024, ZURICH</h5><h5><a href=\"https://www.eurobot.org/\">Eurobot Open 2024</a>: 8–11 May 2024, LA ROCHE-SUR-YON, FRANCE</h5><h5><a href=\"https://2024.ieee-icra.org/\">ICRA 2024</a>: 13–17 May 2024, YOKOHAMA, JAPAN</h5><h5><a href=\"https://2024.robocup.org/\">RoboCup 2024</a>: 17–22 July 2024, EINDHOVEN, NETHERLANDS</h5><p>Enjoy today’s videos!</p><div class=\"horizontal-rule\"></div><div style=\"page-break-after: always\"><span style=\"display:none\"> </span></div><p class=\"rm-anchors\" id=\"q5mko7idsok\">Figure’s robot is watching videos of humans making coffee, and then making coffee on its own.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"4085d61aa4d7b7dc95e49406607b3211\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Q5MKo7Idsok?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>While this is certainly impressive, just be aware that it’s not at all clear from the video exactly how impressive it is. </p><p>[ <a href=\"https://www.figure.ai/\">Figure</a> ]</p><div class=\"horizontal-rule\"></div><p class=\"rm-anchors\" id=\"\">It’s really the shoes that get me with Westwood’s THEMIS robot.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"54e30c5ee59756a2d61ce3e18febc32d\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/qNbCu5Nc2Ik?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>THEMIS can also deliver a package just as well as a human can, if not better!</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"dfb001f72b17ae943c348c0d77fed1b9\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/p-Rhy8fl2lk?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>And I appreciate the inclusion of all of these outtakes, too:</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"ebcf97fc771295a3b2de96be81dcd2eb\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/zYhRJPO6GDk?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>[ <a href=\"https://www.westwoodrobotics.io/\">Westwood Robotics</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Kepler Exploration Robot recently unveiled its latest innovation, the Kepler Forerunner series of general-purpose humanoid robots. This advanced humanoid stands at a height of 178cm (5’10”), weighs 85kg (187 lbs.), and boasts an intelligent and dexterous hand with 12 degrees of freedom. The entire body has up to 40 degrees of freedom, enabling functionalities such as navigating complex terrains, intelligent obstacle avoidance, flexible manipulation of hands, powerful lifting and carrying of heavy loads, hand-eye coordination, and intelligent interactive communication.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"2bf8296ad38c207efc65b2813f208e6e\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/A5vshTgDbKE?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.gotokepler.com/home\">Kepler Exploration</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Introducing the new Ballie, your true AI companion. With more advanced intelligence, Ballie can come right to you and project visuals on your walls. It can also help you interact with other connected devices or take care of hassles.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"905e3f17f45ca884101744195af29c62\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/YBfSX3QiqDM?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://news.samsung.com/global/video-ces-2024-a-day-in-the-life-with-ballie-an-ai-companion-robot-for-the-home\">Samsung</a> ]</p><div class=\"horizontal-rule\"></div><p>There is a thing called Drone Soccer that got some exposure at CES this week, but apparently it’s been around for several years, and originated in South Korea. Inspired by <a href=\"https://en.wikipedia.org/wiki/Quidditch\" target=\"_blank\">Quiddich</a>, targeted at STEM students.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"cb106d261cf352cdd6993a9f75959b01\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/5Pzx6kv_1MM?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.dronesoccer.us/\">Drone Soccer</a> ]</p><div class=\"horizontal-rule\"></div><p>Every so often, JPL dumps a bunch of raw footage onto YouTube. This time, there’s <a data-linked-post=\"2652903805\" href=\"https://spectrum.ieee.org/nasa-mars-rover-perseverance-landing\" target=\"_blank\">Perseverance</a>’s view of Ingenuity taking off, a test of the EELS robot, and an unusual sample tube drop test.</p><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"b7bc8693444b0e211a1294f202f65f18\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Z3pzmytXZvs?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"dff4929a981d382c8f06b16cec5c98cb\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/V5weg-xzedI?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"5c0d088c544948715fc41c76d04270d7\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/MwoqL321FaU?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n</p><p>[ <a href=\"https://www.jpl.nasa.gov/\">JPL</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Our first months delivering to Walmart customers have made one thing clear: Demand for drone delivery is real. On the heels of our Dallas-wide FAA approvals, today we announced that millions of new DFW-area customers will have access to drone delivery in 2024!</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"79d0bc4f9ffce7245866ea6e90523e73\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/d51c9CpSNqw?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://blog.wing.com/2024/01/wing-and-walmart-expand-service.html\">Wing</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Dave Burke works with Biomechatronics researcher Michael Fernandez to test a prosthesis with neural control, by cutting a sheet of paper with scissors. This is the first time in 30 years that Dave has performed this task with his missing hand.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"822819b94747e030aacd21a18233098e\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/EX3zAY2sEzE?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.media.mit.edu/posts/connected-mind-body-landing-1/\">MIT</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>Meet DJI’s first delivery drone—FlyCart 30. Overcome traditional transport challenges and start a new era of dynamic aerial delivery with large payload capacity, long operation range, high reliability, and intelligent features.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"f3c2ce152228ea097b6d946a865a7ab4\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/Hhp11I-vGHA?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://www.dji.com/delivery?utm_source=youtube-own&utm_medium=social&utm_campaign=socialdaily&utm_term=Global&utm_content=ProductPage\">DJI</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>The Waymo Driver autonomously operating both a passenger vehicle and class 8 truck safely in various freeway scenarios, including on-ramps and off-ramps, lane merges, and sharing the road with others.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"1ff5d5a933d0cac54ae64c9830d22278\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/tgX7yzyfQ6E?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://waymo.com/blog/2024/01/from-surface-streets-to-freeways-safely.html\">Waymo</a> ]</p><div class=\"horizontal-rule\"></div><blockquote><em>In this paper, we present DiffuseBot, a physics-augmented diffusion model that generates soft robot morphologies capable of excelling in a wide spectrum of tasks. DiffuseBot bridges the gap between virtually generated content and physical utility by (i) augmenting the diffusion process with a physical dynamical simulation which provides a certificate of performance, and ii) introducing a co-design procedure that jointly optimizes physical design and control by leveraging information about physical sensitivities from differentiable simulation.</em></blockquote><p class=\"shortcode-media shortcode-media-youtube\"><span class=\"rm-shortcode\" data-rm-shortcode-id=\"495ffb394bca75a3d2829fff395aa147\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/LSzasdvD3Ss?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span></p><p>[ <a href=\"https://openreview.net/pdf?id=1zo4iioUEs\">Paper</a> ]</p><div class=\"horizontal-rule\"></div>"},"pubDate":"Fri, 12 Jan 2024 18:15:53 +0000","guid":"https://spectrum.ieee.org/video-friday-robot-make-me-coffee","category":["Video friday","Jpl","Figure","Samsung","Robotics","Humanoid robots","Drone delivery","Dji","Nasa","Mars rovers"],"dc:creator":"Evan Ackerman","media:content":{"@medium":"image","@type":"image/png","@url":"https://spectrum.ieee.org/media-library/a-photograph-of-a-silvery-humanoid-robot-placing-a-pod-into-a-keurig-machine.png?id=51064069&width=980"}},{"title":"Open-Source AI Is Uniquely Dangerous","link":"https://spectrum.ieee.org/open-source-ai-2666932122","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-glowing-skull-with-colorful-connective-networking-lines-running-through-it-in-an-open-cube-of-cubes.jpg?id=51069635&width=1200&height=800&coordinates=48%2C0%2C48%2C0\"/><br/><br/><p><em>This is a guest post. The views expressed here are solely those of the author and do not represent positions of </em><a href=\"https://spectrum.ieee.org/\" target=\"_self\">IEEE Spectrum</a><em> or the IEEE.</em></p><p>When people think of AI applications these days, they likely think of “closed-source” AI applications like OpenAI’s <a href=\"https://chat.openai.com/\" rel=\"noopener noreferrer\" target=\"_blank\">ChatGPT</a>—where the system’s software is securely held by its maker and a limited set of vetted partners. Everyday users interact with these systems through a Web interface like a chatbot, and business users can access an application programming interface (API) which allows them to embed the AI system in their own applications or workflows. Crucially, these uses allow the company that owns the model to provide access to it as a service, while keeping the underlying software secure. Less well understood by the public is the rapid and uncontrolled release of powerful unsecured (sometimes called open-source) AI systems.</p><p class=\"pull-quote\">A good first step in understanding the threats posed by unsecured AI is to ask secured AI systems like ChatGPT, Bard, or Claude to misbehave. </p><p><a href=\"https://openai.com/\" rel=\"noopener noreferrer\" target=\"_blank\">OpenAI</a>’s brand name adds to the confusion. While the company was originally founded to produce open-source AI systems, its leaders determined in 2019 that it was <a href=\"https://www.wired.com/story/ai-text-generator-too-dangerous-to-make-public/\" rel=\"noopener noreferrer\" target=\"_blank\">too dangerous</a> to continue releasing its GPT systems’ source code and model weights (the numerical representations of relationships between the nodes in its artificial neural network) to the public. OpenAI worried because these text-generating AI systems can be used to generate massive amounts of well-written but misleading or <a href=\"https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business\" rel=\"noopener noreferrer\" target=\"_blank\">toxic</a> content.</p><p>Companies including <a href=\"https://www.meta.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Meta</a> (my former employer) have moved in the opposite direction, choosing to release powerful unsecured AI systems in the name of <a href=\"https://about.fb.com/news/2023/07/llama-2/\" rel=\"noopener noreferrer\" target=\"_blank\">democratizing</a> access to AI. Other examples of companies releasing unsecured AI systems include <a href=\"https://stability.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Stability AI</a>, <a href=\"https://huggingface.co/\" rel=\"noopener noreferrer\" target=\"_blank\">Hugging Face</a>, <a href=\"https://mistral.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Mistral</a>, <a href=\"https://www.eleuther.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">EleutherAI</a>, and the <a href=\"https://www.tii.ae/\" rel=\"noopener noreferrer\" target=\"_blank\">Technology Innovation Institute</a>. These companies and like-minded advocacy groups have made limited progress in <a href=\"https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683\" rel=\"noopener noreferrer\" target=\"_blank\">obtaining exemptions</a> for some unsecured models in the European Union’s <a href=\"https://artificialintelligenceact.eu/\" rel=\"noopener noreferrer\" target=\"_blank\">AI Act</a>, which is designed to reduce the risks of powerful AI systems. They may push for similar exemptions in the United States via the public comment period recently <a href=\"https://docs.google.com/document/d/1u-MUpA7TLO4rnrhE2rceMSjqZK2vN9ltJJ38Uh5uka4/edit#heading=h.t02rblknwe5\" rel=\"noopener noreferrer\" target=\"_blank\">set forth in</a> the White House’s <a href=\"https://spectrum.ieee.org/biden-ai-executive-order\" target=\"_self\">AI Executive Order</a>.</p><p>I think the <a href=\"https://spectrum.ieee.org/tag/open-source\" rel=\"noopener noreferrer\" target=\"_blank\">open-source</a> movement has an important role in AI. With a technology that brings so many new capabilities, it’s important that no single entity acts as a gatekeeper to the technology’s use. However, as things stand today, unsecured AI poses an enormous risk that we are not yet able to contain.</p><h2>Understanding the Threat of Unsecured AI</h2><p>A good first step in understanding the threats posed by unsecured AI is to ask secured AI systems like ChatGPT, <a href=\"https://bard.google.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Bard</a><u>,</u> or <a href=\"https://claude.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Claude</a> to misbehave. You could ask them to design a more deadly coronavirus, provide instructions for making a bomb, make naked pictures of your favorite actor, or write a series of inflammatory text messages designed to make voters in swing states more angry about immigration. You will likely receive polite refusals to all such requests because <a href=\"https://openai.com/policies/usage-policies\" target=\"_blank\">they violate</a> the <a href=\"https://policies.google.com/terms/generative-ai/use-policy\" rel=\"noopener noreferrer\" target=\"_blank\">usage policies</a> of <a href=\"https://console.anthropic.com/legal/aup\" target=\"_blank\">these AI systems</a>. Yes, it is possible to “jailbreak” these <a href=\"https://arxiv.org/abs/2305.13860\" rel=\"noopener noreferrer\" target=\"_blank\">AI systems</a> and get them to misbehave, but as these vulnerabilities are discovered, they can be fixed.</p><p>Enter the unsecured models. Most famous is Meta’s <a href=\"https://ai.meta.com/llama/\" rel=\"noopener noreferrer\" target=\"_blank\">Llama 2</a>. It was released by Meta with a 27-page “<a href=\"https://ai.meta.com/static-resource/responsible-use-guide/\" rel=\"noopener noreferrer\" target=\"_blank\">Responsible Use Guide</a>,” which was promptly ignored by the creators of “<a href=\"https://huggingface.co/jarradh/llama2_70b_chat_uncensored\" rel=\"noopener noreferrer\" target=\"_blank\">Llama 2 Uncensored</a>,” a derivative model with safety features stripped away, and hosted for free download on the Hugging Face AI repository. Once someone releases an “uncensored” version of an unsecured AI system, the original maker of the system is largely powerless to do anything about it.</p><p class=\"pull-quote\">As things stand today, unsecured AI poses an enormous risk that we are not yet able to contain.</p><p>The threat posed by unsecured AI systems lies in the ease of misuse. They are particularly dangerous in the hands of sophisticated threat actors, who could easily download the original versions of these AI systems and disable their safety features, then make their own custom versions and abuse them for a wide variety of tasks. Some of the abuses of unsecured AI systems also involve taking advantage of vulnerable distribution channels, such as social media and messaging platforms. These platforms cannot yet accurately detect AI-generated content at scale and can be used to distribute massive amounts of personalized misinformation and, of course, <a href=\"https://theconversation.com/ai-scam-calls-imitating-familiar-voices-are-a-growing-problem-heres-how-they-work-208221\" rel=\"noopener noreferrer\" target=\"_blank\">scams</a>. This could have catastrophic effects on the information ecosystem, and on <a href=\"https://spectrum.ieee.org/deepfakes-election\" target=\"_self\">elections</a> in particular. Highly damaging <a href=\"https://www.wired.com/story/deepfake-porn-is-out-of-control/\" rel=\"noopener noreferrer\" target=\"_blank\">nonconsensual deepfake pornography</a> is yet another domain where unsecured AI can have deep negative consequences.</p><p>Unsecured AI also has the potential to facilitate production of dangerous materials, such as <a href=\"https://www.axios.com/2023/06/16/pandemic-bioterror-ai-chatgpt-bioattacks\" rel=\"noopener noreferrer\" target=\"_blank\">biological and chemical weapons</a>. The White House Executive Order references chemical, biological, radiological, and nuclear (<a href=\"https://docs.google.com/document/d/1u-MUpA7TLO4rnrhE2rceMSjqZK2vN9ltJJ38Uh5uka4/edit#heading=h.6fkzizejib9o\" rel=\"noopener noreferrer\" target=\"_blank\">CBRN</a>) risks, and <a href=\"https://www.markey.senate.gov/news/press-releases/sens-markey-budd-announce-legislation-to-assess-health-security-risks-of-ai\" rel=\"noopener noreferrer\" target=\"_blank\">multiple bills</a> are now under consideration by the U.S. Congress to address these threats.</p><h2>Recommendations for AI Regulations</h2><p>We don’t need to specifically regulate unsecured AI—nearly all of the regulations that have been publicly discussed apply to secured AI systems as well. The only difference is that it’s much easier for developers of secured AI systems to comply with these regulations because of the inherent properties of secured and unsecured AI. The entities that operate secured AI systems can actively monitor for abuses or failures of their systems (including bias and the production of dangerous or offensive content) and release regular updates that make their systems more fair and safe.</p><p class=\"pull-quote\">“I think how we regulate open-source AI is THE most important unresolved issue in the immediate term.”<br/><strong>—Gary Marcus, New York University</strong></p><p>Almost all the regulations recommended below generalize to all AI systems. Implementing these regulations would make companies think twice before releasing unsecured AI systems that are ripe for abuse.</p><p><u><strong>Regulatory Action for AI Systems</strong></u></p><ol><li><strong>Pause all new releases</strong> of unsecured AI systems until developers have met the requirements below, and in ways that ensure that safety features cannot be easily removed by bad actors.</li><li><strong>Establish registration and licensing</strong> (both retroactive and ongoing) of all AI systems above a certain capability threshold.</li><li><strong>Create liability </strong>for “reasonably foreseeable misuse” and negligence: Developers of AI systems should be legally liable for harms caused to both individuals and to society.</li><li><strong>Establish risk assessment, mitigation, and independent audit</strong> procedures for AI systems crossing the threshold mentioned above.</li><li><strong>Require watermarking and provenance</strong> best practices so that AI-generated content is clearly labeled and authentic content has metadata that lets users understand its provenance.</li><li><strong>Require transparency of training data</strong> and prohibit training systems on personally identifiable information, content designed to generate hateful content, and content related to biological and chemical weapons.</li><li><strong>Require and fund independent researcher access</strong>, giving vetted researchers and civil society organizations predeployment access to generative AI systems for research and testing.</li><li><strong>Require “know your customer” procedures</strong>, similar to those <a href=\"https://www.swift.com/your-needs/financial-crime-cyber-security/know-your-customer-kyc/meaning-kyc\" rel=\"noopener noreferrer\" target=\"_blank\">used by financial institutions</a><u>,</u> for sales of powerful hardware and cloud services designed for AI use; restrict sales in the same way that weapons sales would be restricted.</li><li><strong>Mandatory incident disclosure</strong>: When developers learn of vulnerabilities or failures in their AI systems, they must be <a href=\"https://csrc.nist.gov/pubs/sp/800/61/r2/final\" rel=\"noopener noreferrer\" target=\"_blank\">legally required to report</a> this to a designated government authority.</li></ol><p><u><strong>Regulatory Action for Distribution Channels and Attack Surfaces</strong></u></p><ol><li><strong>Require content credential implementation</strong> for social media, giving companies a deadline to implement the <a href=\"https://contentcredentials.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Content Credentials labeling standard</a> from C2PA.</li><li><strong>Automate digital signatures</strong> so people can rapidly verify their human-generated content.</li><li><strong>Limit the reach of AI-generated content</strong>: Accounts that haven’t been verified as distributors of human-generated content could have certain features disabled, including viral distribution of their content.</li><li><strong>Reduce chemical, biological, radiological, and nuclear risks</strong> by educating all suppliers of custom nucleic acids or other potentially dangerous substances about best practices.</li></ol><p><u><strong>Government Action</strong></u></p><ol><li><strong>Establish a nimble regulatory body</strong> that can act and enforce quickly and update certain enforcement criteria. This entity would have the power to approve or reject risk assessments, mitigations, and audit results and have the authority to block model deployment.</li><li><strong>Support fact-checking organizations</strong> and civil-society groups (including the “<a href=\"https://ec.europa.eu/commission/presscorner/detail/en/QANDA_20_2348\" rel=\"noopener noreferrer\" target=\"_blank\">trusted flaggers</a>” defined by the <a href=\"https://digital-strategy.ec.europa.eu/en/policies/digital-services-act-package\" rel=\"noopener noreferrer\" target=\"_blank\">EU Digital Services Act</a>) and require generative AI companies to work directly with these groups.</li><li><strong>Cooperate internationally</strong> with the goal of eventually creating an international <a href=\"https://www.cigionline.org/articles/voluntary-curbs-arent-enough-ai-risk-requires-a-binding-international-treaty/\" rel=\"noopener noreferrer\" target=\"_blank\">treaty</a> or new international agency to prevent companies from circumventing these regulations. The recent <a href=\"https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023\" rel=\"noopener noreferrer\" target=\"_blank\">Bletchley Declaration</a> was signed by 28 countries, including the home countries of all of the world’s leading AI companies (United States, China, United Kingdom, United Arab Emirates, France, and Germany); this declaration stated shared values and carved out a path for additional meetings.</li><li><strong>Democratize AI access</strong> with public infrastructure: A common concern about regulating AI is that it will limit the number of companies that can produce complicated AI systems to a small handful and tend toward monopolistic business practices. There are many opportunities to democratize access to AI, however, without relying on unsecured AI systems. One is through the creation of <a href=\"https://cdn.vanderbilt.edu/vu-URL/wp-content/uploads/sites/412/2023/10/09151836/VPA-AI-Capacity.10.9.23.pdf\" rel=\"noopener noreferrer\" target=\"_blank\">public AI infrastructure</a> with powerful secured AI models.</li></ol><p>“I think how we regulate open-source AI is THE most important unresolved issue in the immediate term,” <a href=\"http://garymarcus.com/index.html\" target=\"_blank\">Gary Marcus</a>, the cognitive scientist, entrepreneur, and professor emeritus at New York University told me in a recent email exchange.<br/></p><p>I agree, and these recommendations are only a start. They would initially be costly to implement and would require that regulators make certain powerful lobbyists and developers unhappy.</p><p>Unfortunately, given the misaligned incentives in the current AI and information ecosystems, it’s unlikely that industry will take these actions unless forced to do so. If actions like these are not taken, companies producing unsecured AI may bring in billions of dollars in profits while pushing the risks posed by their products onto all of us.</p>"},"pubDate":"Fri, 12 Jan 2024 17:00:02 +0000","guid":"https://spectrum.ieee.org/open-source-ai-2666932122","category":["Open source","Openai","Meta","Ai regulation","Chatgpt","Large language models","Generative ai","Ai regulation"],"dc:creator":"David Evan Harris","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-glowing-skull-with-colorful-connective-networking-lines-running-through-it-in-an-open-cube-of-cubes.jpg?id=51069635&width=980"}},{"title":"Can Electronics Become Compostable?","link":"https://spectrum.ieee.org/boosting-electronics-sustainability","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/image.webp?id=51037295&width=980\"/><br/><br/><iframe frameborder=\"no\" height=\"180\" scrolling=\"no\" seamless=\"\" src=\"https://share.transistor.fm/e/4fea4738\" width=\"100%\"></iframe><p>\n<strong>Stephen Cass: </strong>Hello and welcome to <em>Fixing the Future,</em> an <em>IEEE Spectrum</em> podcast, where we look at concrete solutions to some big problems. I’m your host, Stephen Cass, a senior editor at IEEE Spectrum. And before we start, I just want to tell you that you can get the latest coverage from some of Spectrum’s most important beats, including AI, climate change, and robotics, by signing up for one of our free newsletters. Just go to<a href=\"https://spectrum.ieee.org/newsletters/\" target=\"_self\"> spectrum.ieee.org/newsletters</a> to subscribe. Sustainable electronics is becoming an increasingly important topic around the world, and today we’re going to be talking with<a href=\"https://cris.vtt.fi/en/persons/liisa-hakola\" rel=\"noopener noreferrer\" target=\"_blank\"> Liisa Hakola</a>, a senior scientist at<a href=\"https://www.vttresearch.com/en\" rel=\"noopener noreferrer\" target=\"_blank\"> VTT in Finland</a>, about the European Union’s<a href=\"https://sustronics.eu/\" rel=\"noopener noreferrer\" target=\"_blank\"> Sustronics program</a> aimed at this very topic. I’d like to welcome you to the show. Thank you so much, Liisa.\n</p><p>\n<strong>Liisa Hakola: </strong>Thank you. Nice to be here. Thank you for inviting.\n</p><p>\n<strong>Cass:</strong> You’re very welcome. So as I said, sustainable electronics is becoming a bigger and bigger topic, but it seems to be one of those things that people talk about it more than actually doing anything about it. How is the EU Sustronics project going to help with that, and where does VTT fit into that?\n</p><p>\n<strong>Hakola:</strong> Thank you for the question. Indeed, the Sustronics project is a large initiative with 46 partners from 11 different European countries. And our main topic is about finding ways to make electronics more sustainable throughout their life cycle. So not just focusing on one aspect but taking into account different opportunities that might arise from selection of materials or manufacturing technologies or circular economic strategies that could be used. And VTT’s role is, first of all, to be the technical manager of the project to ensure that the different partners work together and the different activities are interacting with each other in order to have a joint effort. But on top of that, VTT also brings some of its technologies, mainly from printed electronics, to the project.\n</p><p>\n<strong>Cass: </strong>Is it a case that you look for industry partners who then come in and work with you? They look around. They think you’re a good fit within the program. Or are you actively searching out people and going, “Oh, we think we have some technology that might help you out here”?\n</p><p>\n<strong>Hakola: </strong>Well, basically, I think they’re both ways. Of course, there are 46 partners already in the consortium, and over half of them are from the industry, large enterprises and SMEs. So of course, they have specific needs, and we have been already agreeing during the proposal phase that VTT could offer certain technologies for them to then start testing for their products and if that could help with decreasing their environmental footprint.\n</p><p>\n<strong>Cass:</strong> I guess the question is, why would anybody join the program, especially if you’re a manufacturer and so on? I mean, as a citizen of Earth, I think it’s a great idea, but we often hear about bottom-line issues and so on. What’s the incentive, if you are somebody who’s making electronics, to become one of these partners?\n</p><p>\n<strong>Hakola:</strong> Well, first of all, in the EU, we have this<a href=\"https://commission.europa.eu/strategy-and-policy/priorities-2019-2024/european-green-deal_en\" rel=\"noopener noreferrer\" target=\"_blank\"> Green Deal</a>. So the regulations and the legislation is developing into a direction where all of the companies in the EU have to take into account the sustainability aspects of the products they are developing and selling. So in order to achieve that, to be able to meet the requirements coming from the EU side, the companies need to develop new ways to maintain or improve sustainability of their products. And this is one opportunity because collaborating with the research institutes and universities, the companies get access to kind of technologies that have been in development in those, and then they can try them out in their own products, and then in that way to get closer to meeting the sustainability requirements.\n</p><p>\n<strong>Cass:</strong> So we’re based in New York, in the United States, where it’s quite a different regulatory regime. But can you tell me, what is the enforcement mechanism for those sustainability regulations? What happens if you don’t do it? Because I can imagine some people just thinking, oh, it’s just a slap on the wrist, or it’s a fine. It’s just a cost of doing business. How is those rules really enforced?\n</p><p>\n<strong>Hakola:</strong> Well, of course, EU is developing the regulations all the time, so there might come new enforcements in the future. But the upcoming regulation about ecodesign for sustainable products, so that regulation demands that there is going to be a digital product passport that would give information about the environmental impact of the product. And that kind of information would be available even for consumers. So actually, if the consumers are environmentally aware, they would start selecting the products that are environmentally friendly. So that’s, of course, quite strong way to make companies work towards making more sustainable products. Because if consumers start selecting the sustainable products, then the non-sustainable ones will lose their market share.\n</p><p>\n<strong>Cass: </strong>So you talked a little bit earlier about the entire sort of lifecycle and sustainability. Along that life cycle, what are some of the biggest obstacles that currently exist towards making electronics more sustainable?\n</p><p>\n<strong>Hakola: </strong>Well, there are a couple of things that are quite dominant. So first of all, the raw materials that are used for making electronic products, they are mostly fossil-based, like different metals that are needed for making conductive structures. And also, the substrates where the metals are put, they are usually based on some plastics or plastic composite materials. And then we are actually talking about materials that are critical or rare or quite valuable. So it’s quite a challenge to find materials that could substitute the existing materials because we know that those are well-performing. So can we actually find some sustainable alternatives for them?\n</p><p>\n\tAnd another thing is, of course, that the processes that are used for making circuit boards, for example, they consume quite a lot of energy and raw materials. And that, of course, is not very good for the environment because it’s not very energy or material efficient to manufacture in a way that a lot of material is wasted and processed several times. And of course, the whole electronics industry is quite complex and fragmented industry. There are a lot of layers, and it’s really difficult to get them all to work together and sort of transparently transfer data and information between the different players.\n</p><p>\n<strong>Cass: </strong>So I’d like to go into that—and maybe this is some of VTT’s special expertise—and talk a little about the work that you’ve done in materials specifically then.\n</p><p>\n<strong>Hakola: </strong>Yes. So VTT has focused quite a lot on replacing the fossil-based substrate materials with materials that are bio-based or renewable materials. And well, in Finland, the forest industry has typically been quite strong. So of course, we have studied how to use the cellulose-based materials like paper as a substrate for electronics. But there are also a lot of these biopolymer-based substrates that are-- basically, they look and feel like plastics, but they are from bio-based resources, so they are kind of renewable. And some of them are really easy to recycle, or some of them can even be compostable.\n</p><p>\n<strong>Cass: </strong>You said compostable there. I’m a little worried because I have these compostable plastic bags in my kitchen that just don’t last very long. And so when you say that, I’m a little concerned about putting that in my electronics. Or is it for very short-lived sort of disposable electronics, given some of them have very short life cycles?\n</p><p>\n<strong>Hakola: </strong>Yes. If we are talking about using printing as a manufacturing technology, so then of course we are able to manufacture electronics that have a shorter lifetime, and they can be even used just one time. But if you produce a lot of electronics that is for single-use purpose, then actually you are creating a lot of new electronic waste. So you have to somehow tackle this issue with having single-use electronics, but then being able to somehow recycle or dispose that electronics. And in that case, if there is, for example, some diagnostic device where you measure something, then probably there would be a single-use part on that device that could then probably be compostable. But then there would also be a reusable part. So after doing some diagnostic measurements, you change only one piece of the device, and then that changeable part would then be compostable. Or it can also be that the recycling process is established, and it would be easily recyclable. But in that kind of cases, you might think about the compostable solutions also.\n</p><p>\n<strong>Cass: </strong>So I’d like to talk a little bit more about recycling there. Electronic waste is notoriously very difficult to waste. We have to separate out our electronic waste and we have to put it somewhere else. There are special pickup days, which I do dutifully. But then I sometimes think about when all this stuff is put on the valley, how is anybody going to realistically recycle that 10-year-old broken projector or those collection of printers and so on? How do you make recycling work better?\n</p><p>\n<strong>Hakola:</strong> Well, yeah, that’s of course a matter of— first of all, you need to establish the recycling process, and there would have to be different collection bins where people could dispose their electronics. But of course, I come from Finland. Actually, in my apartment where I live, there are something like seven different recycling bins where I put the different type of waste. So adding there eighth bin for electronics wouldn’t be that big of an issue. But if you think recycling also from the scratch, then the electronic devices actually have to be designed in a way that they are better for recycling. So we talk about circular design, for example. Already in the design phase of the products, you actually think about the recycling and then design the electronics in a way that it’s, for example, modular, so you can disintegrate the different components easily and recover the materials. So actually, everything starts in the design phase.\n</p><p>\n<strong>Cass:</strong> Does this also help with things like serviceability or repairability? I find myself that sometimes it’s easier for me to<a href=\"https://spectrum.ieee.org/upcycle-a-vintage-lcd\" target=\"_self\"> repair something that is 40 years old</a>. I’ve brought these products back from the dead. But a product I buy today, it’s a blob. I have to use very specialized tools to get it open, if I can. I often have to send away for a special kit. Is part of this design process also looking at those issues?\n</p><p>\n<strong>Hakola: </strong>Yes, yes. That’s the same thing that already in the design phase. Design the devices in a way that parts can be replaced later on, and people don’t have to buy the new model. I understand that, of course, for the electronics companies, their business to sell new models all the time. But perhaps they can find a suitable business model also from repairing the devices. There could be some business opportunities also.\n</p><p>\n<strong>Cass: </strong>So you talked a little bit about manufacturing processes and making those a little bit more sustainable. Can you expand on that?\n</p><p>\n<strong>Hakola: </strong>So what VTT has been developing for over 20 years is printed electronics. So it means that we are using printing as a manufacturing technology for electronics. And compared to the current state-of-the-art electronics manufacturing, printing is an additive method. So we actually add materials only where they are needed, and we don’t strip them away later on and then try to figure out what to do with that kind of material. So that’s an opportunity for electronic manufacturing to decrease its material but also energy consumption. We have carried out some life cycle assessment analysis where it has been shown that the printed electronics consumes less energy during manufacturing than traditional manufacturing. So there is actually already an opportunity there. But besides this energy issue, the bio-based and renewable substrate materials are already compatible with the printing technology. It’s actually quite challenging to print those, for example, paper as a substrate to traditional electronic manufacturing. But for printing, it’s quite easy because you know that you can print on paper, so using that to make electronics is a kind of easier task.\n</p><p>\n<strong>Cass:</strong> So can you talk a little bit about some of the sort of very concrete examples you’ve developed with some of your partners?\n</p><p>\n<strong>Hakola: </strong>Yes. So if you think about the Sustronics program-- so there are actually a lot of development for these single-use diagnostic devices. So the goal is to develop the kind of devices that people can actually even use at home to measure something from their saliva, or they can monitor how the wound is healing by having just a plaster-type wearable device on the skin. And other things that we are developing are also these other wearable devices that are not for single use, but they are for sports and fitness sector where you can monitor how you are doing when you are exercising and you can even measure your heart rate, and then the app would-- the app you would have in your mobile phone would then tell you based on the measurement data that, okay, you did well today or something else.\n</p><p>\n\tAnd one application area that VTT has been developing quite a lot devices already in the earlier research programs are these solutions for intelligent packaging. So if we talk about the packaging industry, and there is a lot of needs in the logistics of packages to measure, for example, temperature to make sure that the cold chain has not been broken and your products are not spoiling. So VTT has been developing electronics for that, like sensors attached to packages, electronic sensors that can transmit information to mobile phone. But if you think about the packaging industry, the packages are recyclable. So then actually we are adding electronics there, then the sustainability of these kind of smart tags, how we could call them, would be a really important aspect to consider. And there, these new kind of materials like using paper as a substrate for electronics have a really important role.\n</p><p>\n<strong>Cass: </strong>And how long do you think it’ll be before we start seeing these in the marketplace as something that consumers can sort of see and feel for themselves?\n</p><p>\n<strong>Hakola: </strong>Well, actually, some of them are already on the marketplace. Of course, not in really huge volumes. But there are, for example, contract manufacturers for printed electronics that manufacture something that is used as a part of a device that is sold in the market. But of course, we can’t print a mobile phone with these kind of technologies, at least not yet. So it depends. Perhaps some of them are already there. For some of them, it might take three to five years, and some even longer. But let’s say during the next decade, there would certainly be product announcements.\n</p><p>\n<strong>Cass:</strong> And so you mentioned manufacturers. Where are these manufacturers located? Are they local manufacturers, or is this something that we can see that is being integrated into the global supply chain in terms of those great manufacturing centers in China, for example?\n</p><p>\n<strong>Hakola: </strong>Yeah. Well, of course, the printed electronics contract manufacturers, they are not really large companies yet. They are still at the early phase, and they are located all around the world. Probably quite many of them in the Europe, because in Europe, we have been investigating printed electronics quite a lot. But yeah, there is no issue why they couldn’t be part of the global supply chains. But as we think, “What is the strategy of the EU?”, we actually want to-- the EU wants to also move again back to the European supply chains also to sort of maintain the local strategic availability of key technologies. So I think in the EU, there would be probably quite strong support in the future for making more manufacturers coming back to Europe or at least establishing new manufacturing units to Europe.\n</p><p>\n<strong>Cass: </strong>So if you could wave a magic wand and solve one problem right now that’s on your desk, what would that be?\n</p><p>\n<strong>Hakola: </strong>Ah. Well, probably I would make the products more repairable or reusable. I’ve personally had some issues with the devices recently, and it has been a bit of annoying that there is no repair option. So I’ve been forced to buy new devices, although I have not wanted to do so. So probably I would change the business a bit that the repair would always be an option unless you have something that is like 50 years old. Perhaps that would be an issue. But even for a 5-year-old device, it would be nice to have a repair option. So I guess I would develop the kind of design for the electronics that they really can be repaired or reused.\n</p><p>\n<strong>Cass: </strong>Can you talk a little bit more about Finland’s history with— you said it has this history coming out of the cellulose industry. So can you talk a little bit more about that point, about how Finland’s experience with cellulose and paper sort of fed into this program?\n</p><p>\n<strong>Hakola: </strong>Yeah. Perhaps the background is so that Finland has a long history of paper and forest technologies. And the first printed electronics projects that were initiated in Finland more than 20 years ago, there the role of the paper companies in Finland was really strong. So actually, at least in Finland, how we started to investigate printed electronics, the initiative was involving quite a lot of these forest industry companies. And that’s how we also at VTT got involved with using cellulose-based and paper as a substrate for electronics. And if you think about the sustainable electronics, the paper has been there first and only later came the other alternatives like biopolymers. So I guess in the early stage, the paper industry was actually looking for new business opportunities. And they thought that it can be found from printed electronics because printing on paper is something that is being done all the time. So that’s how I think the thing started, at least in Finland.\n</p><p>\n<strong>Cass:</strong> So this is a fascinating topic, which we could talk about all day, but I’m afraid we have to leave it there. Today we were talking with Liisa Hakola from VTT about sustainable electronics. It was so lovely to have you on the show.\n</p><p>\n<strong>Hakola:</strong> Thank you. It was lovely being here.\n</p><p>\n<strong>Cass: </strong>And for <em>IEEE Spectrum</em>, I’m Stephen Cass, and I hope you join us next time on <em>Fixing the Future</em>.\n</p>"},"pubDate":"Wed, 10 Jan 2024 10:00:02 +0000","guid":"https://spectrum.ieee.org/boosting-electronics-sustainability","category":["Fixing the future","Green electronics","Sustainability","Sustainable electronics","Type:podcast","Vtt"],"dc:creator":"Stephen Cass","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://assets.rbl.ms/51037295/origin.webp"}},{"title":"The Global Project to Make a General Robotic Brain","link":"https://spectrum.ieee.org/global-robotic-brain","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-silver-robot-with-one-arm-lifts-a-dinosaur-from-a-table-full-of-a-clutter-of-random-objects.jpg?id=50891347&width=1200&height=800&coordinates=167%2C0%2C168%2C0\"/><br/><br/><p>\n<strong>The generative AI revolution</strong> embodied in tools like <a href=\"https://chat.openai.com/\" rel=\"noopener noreferrer\" target=\"_blank\">ChatGPT</a>, <a href=\"https://www.midjourney.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Midjourney</a>, and many others is at its core based on a simple formula: Take a very large neural network, train it on a huge dataset scraped from the Web, and then use it to fulfill a broad range of user requests. Large language models (<a href=\"https://spectrum.ieee.org/tag/llms\" target=\"_self\">LLM</a>s) can answer questions, write code, and spout poetry, while image-generating systems can create convincing cave paintings or contemporary art.\n</p><p>\n\tSo why haven’t these amazing AI capabilities translated into the kinds of helpful and broadly useful robots we’ve seen in science fiction? Where are the robots that can clean off the table, fold your laundry, and make you breakfast?\n</p><p>\n\tUnfortunately, the highly successful generative AI formula—big models trained on lots of Internet-sourced data—doesn’t easily carry over into robotics, because the Internet is not full of robotic-interaction data in the same way that it’s full of text and images. Robots need robot data to learn from, and this data is typically created slowly and tediously by researchers in laboratory environments for very specific tasks. Despite tremendous progress on robot-learning algorithms, without abundant data we still can’t enable robots to perform real-world tasks (like making breakfast) outside the lab. The most impressive results typically only work in a single laboratory, on a single robot, and often involve only a handful of behaviors.\n</p><p>\n\tIf the abilities of each robot are limited by the time and effort it takes to manually teach it to perform a new task, what if we were to pool together the experiences of many robots, so a new robot could learn from all of them at once? We decided to give it a try. In 2023, our labs at Google and the University of California, Berkeley came together with 32 other robotics laboratories in North America, Europe, and Asia to undertake the \n\t<a href=\"https://robotics-transformer-x.github.io/\" rel=\"noopener noreferrer\" target=\"_blank\">RT-X project</a>, with the goal of assembling data, resources, and code to make general-purpose robots a reality.\n</p><p>\n\tHere is what we learned from the first phase of this effort.\n</p><h2>How to create a generalist robot</h2><p>\n\tHumans are far better at this kind of learning. Our brains can, with a little practice, handle what are essentially changes to our body plan, which happens when we pick up a tool, ride a bicycle, or get in a car. That is, our “embodiment” changes, but our brains adapt. RT-X is aiming for something similar in robots: to enable a single deep neural network to control many different types of robots, a capability called cross-embodiment. The question is whether a deep neural network trained on data from a sufficiently large number of different robots can learn to “drive” all of them—even robots with very different appearances, physical properties, and capabilities. If so, this approach could potentially unlock the power of large datasets for robotic learning.\n</p><p>\n\tThe scale of this project is very large because it has to be. The RT-X dataset currently contains nearly a million robotic trials for 22 types of robots, including many of the most commonly used robotic arms on the market. The robots in this dataset perform a huge range of behaviors, including picking and placing objects, assembly, and specialized tasks like cable routing. In total, there are about 500 different skills and interactions with thousands of different objects. It’s the largest open-source dataset of real robotic actions in existence.\n</p><p>\n\tSurprisingly, we found that our multirobot data could be used with relatively simple machine-learning methods, provided that we follow the recipe of using large neural-network models with large datasets. Leveraging the same kinds of models used in current LLMs like ChatGPT, we were able to train robot-control algorithms that do not require any special features for cross-embodiment. Much like a person can drive a car or ride a bicycle using the same brain, a model trained on the RT-X dataset can simply recognize what kind of robot it’s controlling from what it sees in the robot’s own camera observations. If the robot’s camera sees a \n\t<a href=\"https://www.universal-robots.com/products/ur10-robot/\" rel=\"noopener noreferrer\" target=\"_blank\">UR10 industrial arm</a>, the model sends commands appropriate to a UR10. If the model instead sees a low-cost <a href=\"https://www.trossenrobotics.com/widowxrobotarm\" rel=\"noopener noreferrer\" target=\"_blank\">WidowX hobbyist arm</a>, the model moves it accordingly.\n</p><p>\n\tTo test the capabilities of our model, five of the laboratories involved in the RT-X collaboration each tested it in a head-to-head comparison against the best control system they had developed independently for their own robot. Each lab’s test involved the tasks it was using for its own research, which included things like picking up and moving objects, opening doors, and routing cables through clips. Remarkably, the single unified model provided improved performance over each laboratory’s own best method, succeeding at the tasks about 50 percent more often on average.\n</p><p>\n\tWhile this result might seem surprising, we found that the RT-X controller could leverage the diverse experiences of other robots to improve robustness in different settings. Even within the same laboratory, every time a robot attempts a task, it finds itself in a slightly different situation, and so drawing on the experiences of other robots in other situations helped the RT-X controller with natural variability and edge cases. Here are a few examples of the range of these tasks:\n</p><h3></h3><br/><img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"00e876b7c84501e7c4c62bbcb263e762\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"208c0\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/image.gif?id=51012338&width=980\"/><h3></h3><br/><img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"65e3d7d7fdc36cf6568f50cd8cb740d5\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"ae8a5\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/image.gif?id=51012379&width=980\"/><h3></h3><br/><img alt=\"\" class=\"rm-shortcode\" data-rm-shortcode-id=\"eaa74473d68b631be56f65e342ad6f16\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"d3985\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/image.gif?id=51012395&width=980\"/><h2>Building robots that can reason</h2><p>\n\tEncouraged by our success with combining data from many robot types, we next sought to investigate how such data can be incorporated into a system with more in-depth reasoning capabilities. Complex semantic reasoning is hard to learn from robot data alone. While the robot data can provide a range of \n\t<em>physical</em> capabilities, more complex tasks like “Move apple between can and orange” also require understanding the semantic relationships between objects in an image, basic common sense, and other symbolic knowledge that is not directly related to the robot’s physical capabilities.\n</p><p>\n\tSo we decided to add another massive source of data to the mix: Internet-scale image and text data. We used an existing large vision-language model that is already proficient at many tasks that require some understanding of the connection between natural language and images. The model is similar to the ones available to the public such as ChatGPT or \n\t<a href=\"https://bard.google.com/chat\" rel=\"noopener noreferrer\" target=\"_blank\">Bard</a>. These models are trained to output text in response to prompts containing images, allowing them to solve problems such as visual question-answering, captioning, and other open-ended visual understanding tasks. We discovered that such models can be adapted to robotic control simply by training them to also output robot actions in response to prompts framed as robotic commands (such as “Put the banana on the plate”). We applied this approach to the robotics data from the RT-X collaboration.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"An illustration of a map and robot tasks shown on the right.  \" class=\"rm-shortcode\" data-rm-shortcode-id=\"cef4567b55fe04bd320640ddcdb2779f\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"d785a\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/an-illustration-of-a-map-and-robot-tasks-shown-on-the-right.png?id=51027917&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">The RT-X model uses images or text descriptions of specific robot arms doing different tasks to output a series of discrete actions that will allow any robot arm to do those tasks. By collecting data from many robots doing many tasks from robotics labs around the world, we are building an open-source dataset that can be used to teach robots to be generally useful.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Chris Philpot</small></p><p>\n\tTo evaluate the combination of Internet-acquired smarts and multirobot data, we tested our RT-X model with Google’s mobile manipulator robot. We gave it our hardest generalization benchmark tests. The robot had to recognize objects and successfully manipulate them, and it also had to respond to complex text commands by making logical inferences that required integrating information from both text and images. The latter is one of the things that make humans such good generalists. Could we give our robots at least a hint of such capabilities?</p><p>We conducted two sets of evaluations. As a baseline, we used a model that excluded all of the generalized multirobot RT-X data that didn’t involve Google’s robot. Google’s robot-specific dataset is in fact the largest part of the RT-X dataset, with over 100,000 demonstrations, so the question of whether all the other multirobot data would actually help in this case was very much open. Then we tried again with all that multirobot data included.</p><p>In one of the most difficult evaluation scenarios, the Google robot needed to accomplish a task that involved reasoning about spatial relations (“Move apple between can and orange”); in another task it had to solve rudimentary math problems (“Place an object on top of a paper with the solution to ‘2+3’”). These challenges were meant to test the crucial capabilities of reasoning and drawing conclusions.</p><p>In this case, the reasoning capabilities (such as the meaning of “between” and “on top of”) came from the Web-scale data included in the training of the vision-language model, while the ability to ground the reasoning outputs in robotic behaviors—commands that actually moved the robot arm in the right direction—came from training on cross-embodiment robot data from RT-X. An example of an evaluation where we asked the robot to perform a task not included in its training data is shown in the video below. </p><p class=\"shortcode-media shortcode-media-youtube\">\n<span class=\"rm-shortcode\" data-rm-shortcode-id=\"d363c625358f758679672ff941842fc7\" style=\"display:block;position:relative;padding-top:56.25%;\"><iframe frameborder=\"0\" height=\"auto\" lazy-loadable=\"true\" scrolling=\"no\" src=\"https://www.youtube.com/embed/qSARoad-F-k?rel=0\" style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" width=\"100%\"></iframe></span>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Even without specific training, this Google research robot is able to follow the instruction “move apple between can and orange.” This capability is enabled by RT-X, a large robotic manipulation dataset and the first step towards a general robotic brain.</small>\n</p><p>While these tasks are rudimentary for humans, they present a major challenge for general-purpose robots. Without robotic demonstration data that clearly illustrates concepts like “between,” “near,” and “on top of,” even a system trained on data from many different robots would not be able to figure out what these commands mean. By integrating Web-scale knowledge from the vision-language model, our complete system was able to solve such tasks, deriving the semantic concepts (in this case, spatial relations) from Internet-scale training, and the physical behaviors (picking up and moving objects) from multirobot RT-X data. To our surprise, we found that the inclusion of the multirobot data improved the Google robot’s ability to generalize to such tasks by a factor of three. This result suggests that not only was the multirobot RT-X data useful for acquiring a variety of physical skills, it could also help to better connect such skills to the semantic and symbolic knowledge in vision-language models. These connections give the robot a degree of common sense, which could one day enable robots to understand the meaning of complex and nuanced user commands like “Bring me my breakfast” while carrying out the actions to make it happen.<br/></p><h2>The next steps for RT-X</h2><p>\n\tThe RT-X project shows what is possible when the robot-learning community acts together. Because of this cross-institutional effort, we were able to put together a diverse robotic dataset and carry out comprehensive multirobot evaluations that wouldn’t be possible at any single institution. Since the robotics community can’t rely on scraping the Internet for training data, we need to create that data ourselves. We hope that more researchers will contribute their data to the \n\t<a href=\"https://robotics-transformer-x.github.io/\" target=\"_blank\">RT-X database</a> and join this collaborative effort. We also hope to provide tools, models, and infrastructure to support cross-embodiment research. We plan to go beyond sharing data across labs, and we hope that RT-X will grow into a collaborative effort to develop data standards, reusable models, and new techniques and algorithms.\n</p><p>\n\tOur early results hint at how large cross-embodiment robotics models could transform the field. Much as large language models have mastered a wide range of language-based tasks, in the future we might use the same foundation model as the basis for many real-world robotic tasks. Perhaps new robotic skills could be enabled by fine-tuning or even prompting a pretrained foundation model. In a similar way to how you can prompt ChatGPT to tell a story without first training it on that particular story, you could ask a robot to write “Happy Birthday” on a cake without having to tell it how to use a piping bag or what handwritten text looks like. Of course, much more research is needed for these models to take on that kind of general capability, as our experiments have focused on single arms with two-finger grippers doing simple manipulation tasks.\n</p><p>\n\tAs more labs engage in cross-embodiment research, we hope to further push the frontier on what is possible with a single neural network that can control many robots. These advances might include adding diverse simulated data from generated environments, handling robots with different numbers of arms or fingers, using different sensor suites (such as depth cameras and tactile sensing), and even combining manipulation and locomotion behaviors. RT-X has opened the door for such work, but the most exciting technical developments are still ahead.\n</p><p>\n\tThis is just the beginning. We hope that with this first step, we can together create the future of robotics: where general robotic brains can power any robot, benefiting from data shared by all robots around the world. \n\t<span class=\"ieee-end-mark\"></span>\n</p><p><em>This article appears in the February 2024 print issue as “The Global Project to Make a General Robotic Brain.”</em></p>"},"pubDate":"Tue, 09 Jan 2024 16:05:50 +0000","guid":"https://spectrum.ieee.org/global-robotic-brain","category":["Deep learning","Robotic learning","General purpose robots","Robotics"],"dc:creator":"Karol Hausman","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-silver-robot-with-one-arm-lifts-a-dinosaur-from-a-table-full-of-a-clutter-of-random-objects.jpg?id=50891347&width=980"}},{"title":"CES 2024: Neuchips Demos Low-Power AI Upgrade for PCs","link":"https://spectrum.ieee.org/neuchips-low-power-ai","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/silver-square-against-a-blue-background-with-llm-above.jpg?id=51029508&width=1200&height=800&coordinates=0%2C50%2C0%2C51\"/><br/><br/><p>What if any desktop PC could become an AI inference beast with a single upgrade? And what if that transformed beast still sipped power like it was enjoying a martini? <br/></p><p>That’s the idea pitched by <a href=\"https://neuchips.ai/\" target=\"_blank\">Neuchips</a>, a Taiwanese startup founded in 2019 and known for delivering<a href=\"https://neuchips.ai/page/mlperf\" target=\"_blank\"> top-class AI efficiency</a>. It came to <a href=\"https://www.ces.tech/events-programs/ces-events/las-vegas.aspx\" target=\"_blank\">CES Unveiled 2024</a>—the media pregame show before the <a href=\"https://www.ces.tech/\" target=\"_blank\">main event</a>—with a PCIe add-on card that can upgrade the AI capabilities of a typical desktop computer while adding just 55 watts to the PC’s power budget. </p><p>It’s not just a concept. The card was plugged into a desktop computer on the show floor and offered real-time, offline conversation with a chatbot powered by <a href=\"https://spectrum.ieee.org/llama-2-llm\" target=\"_self\">Meta’s popular Llama 2 7B large language model</a> (Neuchips says the card will also run Llama 2 13B).</p><p>Neuchips’ card, the Evo PCIe accelerator, is built around the company’s Raptor Gen AI accelerator chip. The Raptor chip delivers up to 200 teraoperations per second measured with <a href=\"https://ai.meta.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/\" target=\"_blank\">Meta’s DLRM benchmark</a>, and the company says it’s optimized for transformer-based models.. </p><p>The card that Neuchips demonstrated had the Raptor chip, but a single chip isn’t the card’s final form. <a href=\"https://www.linkedin.com/in/ken-lau-6948662/\" rel=\"noopener noreferrer\" target=\"_blank\">Neuchips’ CEO Ken Lau</a>, an Intel veteran of 26 years, says Raptor can be used to design cards with varying numbers of chips onboard. </p><p>“The chip is actually scalable,” says Lau. “So we start with one chip. And then we have four chips. And then eight chips.” Each chip provides up to 200 trillion operations per second (TOPS), according to <a href=\"https://www.neuchips.ai/news/article/711ZY14mZahw7StF/press-releases\" rel=\"noopener noreferrer\" target=\"_blank\">Neuchip’s press release</a>. The card also carries 32 GB of LPDDR5 memory and reaches 1.6 terabits of memory bandwidth. Memory bandwidth is important, because it’s often a factor when handling AI inference on a single PC.</p><p>Neuchips wants to give owners the tools needed to use the card effectively as well, although with many months until release the details here remain a bit sparse. A Neuchips representative said the company has compiler software and will provide a driver. The demonstration I saw had a custom interface for interacting with the Llama 2 7B model. Neuchips’ card was running, but it appeared bare-bones.</p><h2>A focus on efficiency </h2><p>There’s already hardware that anyone can plug into a desktop’s PCIe slot to greatly improve AI performance. It’s called a GPU, and Nvidia has a stranglehold on the market. Going toe-to-toe with Nvidia on performance would be difficult. In fact, <a href=\"https://nvidianews.nvidia.com/news/geforce-rtx-40-super-series\" rel=\"noopener noreferrer\" target=\"_blank\">Nvidia announced new cards with a focus on AI at CES 2024</a>; the RTX 4080 Super, which will retail for US $999 starting on 31 January, quotes AI performance of up to 836 TOPS.</p><p>Neuchips, however, sees an opening. “We are focused on power efficiency,” says Lau, “and on handling the many different models that are out there.”</p><p>Modern graphics cards are powerful, but also power hungry. The RTX 4080 Super can draw up to 320 W of power and will typically require a computer with a power supply that can deliver at least 750 W. Neuchips’ Evo PCIe accelerator, by contrast, consumes just 55 W of power. It consumes so little power, in fact, that the card Neuchips demonstrated at CES didn’t have an external PCIe power connection. Such connectors are a must for most GPU cards. </p><p>I was also told that the final card, which should ship in the latter half of 2024, will be roughly half the size of the card shown at CES. That’s an important detail, as the card I saw was as large as most current Nvidia GPU cards, and too large to fit most small form-factor desktop computers. A smaller card would make the Evo PCIe accelerator usable in a wide range of modern PC hardware.<br/></p><p>Neuchips’ accelerator, though perhaps the most high-profile AI accelerator card at CES 2024, was far from alone at the show. Several startups came with their own AI accelerators packing unique features. <a href=\"https://panmnesia.com/news_en/#news-en-2023-11-22-ces24-innovation\" rel=\"noopener noreferrer\" target=\"_blank\">Panmnesia won a CES Innovation Award for an AI accelerator</a> that includes a Compute eXpress Link interface for access to huge pools of memory. Other companies with AI accelerators include <a href=\"https://deepx.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">DeepX</a> and <a href=\"https://memryx.com/\" rel=\"noopener noreferrer\" target=\"_blank\">MemryX</a>. <a href=\"https://www.intel.com/content/www/us/en/products/docs/processors/core-ultra/ai-pc.html\" rel=\"noopener noreferrer\" target=\"_blank\">Intel </a>and <a href=\"https://www.amd.com/en/products/processors/consumer/ryzen-ai.html\" rel=\"noopener noreferrer\" target=\"_blank\">AMD </a>are in on it, too; each offers an AI accelerator in its latest CPU architecture. </p><p>Make no mistake: Nvidia remains the 800-pound gorilla in this arena, and that’s not going to change overnight. Still, new AI accelerators like Neuchips’ Raptor and the Evo PCIe card look ready to deliver new options for developers who don’t care about graphics or have a need for improved power efficiency while running AI inference. </p><p>Neuchips’ Evo PCI accelerator is due for full release in the second half of 2024. Pricing remains to be announced. </p><p><em>This post was update on 12 January to clarify benchmark operation speeds and correct the system’s memory bandwidth.</em></p>"},"pubDate":"Tue, 09 Jan 2024 14:00:04 +0000","guid":"https://spectrum.ieee.org/neuchips-low-power-ai","category":["Inferencing","Desktop","Pcie","Neuchips","Ai accelerators","Ces 2024"],"dc:creator":"Matthew S. Smith","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/silver-square-against-a-blue-background-with-llm-above.jpg?id=51029508&width=980"}},{"title":"This Rice University Professor Developed Cancer-Detection Technology","link":"https://spectrum.ieee.org/rice-university-cancer-detection-technology","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/portrait-of-a-woman-in-a-lab-coat-smiling-for-the-camera-with-a-whiteboard-and-text-in-the-background.jpg?id=51025724&width=1200&height=800&coordinates=0%2C0%2C0%2C366\"/><br/><br/><p>\n<a href=\"https://www.linkedin.com/in/rebecca-richards-kortum-b4798a8/\" rel=\"noopener noreferrer\" target=\"_blank\">Rebecca Richards-Kortum</a> has spent most of her 30-year career developing technology to help improve medical care in underserved communities worldwide. Among her achievements: She invented an inexpensive, battery-operated optical imaging system that can detect premalignant tissues—no biopsy required—to help prevent oral and cervical cancer.\n</p><p>\n\tRichards-Kortum is a professor of bioengineering at <a href=\"https://www.rice.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Rice University</a>, in Houston, and codirector of the <a href=\"https://www.rice360.rice.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">Rice360 Institute for Global Health Technologies</a>, which is developing affordable medical equipment for underresourced hospitals. Her team created a suite of low-cost medical devices, the <a href=\"https://www.newborntoolkit.org/\" rel=\"noopener noreferrer\" target=\"_blank\">NEST360</a> newborn tool kit, to improve neonatal health in sub-Saharan Africa.\n</p><h3>Rebecca Richards-Kortum</h3><br/><p><strong></strong><strong>Employer </strong></p><p>Rice University in Houston</p>\n<p><strong>Title </strong></p><p>Director of the Rice360 Institute for Global Health Technologies</p><p><strong>Member grade</strong></p><p>Senior member</p><p><strong>Alma maters </strong></p><p>University of Nebraska–Lincoln; MIT</p><p>\n\tFor her “contributions to optical solutions for cancer detection and leadership in establishing the field of global health engineering,” Richards-Kortum is the recipient of the 2023 <a href=\"https://corporate-awards.ieee.org/award/ieee-medal-for-innovations-in-healthcare-technology-2/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Medal for Innovations in Healthcare Technology</a>. The award is sponsored by the <a href=\"https://www.embs.org/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Engineering in Medicine and Biology Society</a>.\n</p><p>\n\tRichards-Kortum, an IEEE senior member, says the award is a wonderful honor that she never imagined receiving.\n</p><p>\n\t“I’m humbled and grateful to all the amazing people with whom I work,” she says. “This is an honor that wouldn’t be possible without them and extends to all of them.”\n</p><h2>Finding a passion for medical physics research</h2><p>\n\tRichards-Kortum has been passionate about mathematics and science since she was a youngster. When she was a high school student, she thought she would want to become a math teacher. But during her first year at the <a href=\"https://www.unl.edu/home/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Nebraska–Lincoln</a>, she took a physics class and fell in love with the field thanks to her professor, she says.\n</p><p>\n\tShe decided she wanted to major in physics, but during her second semester, she became concerned about job security as a physicist. She spoke with <a href=\"https://news.unl.edu/newsrooms/today/article/sellmyer-remembered-for-impacts-in-research-on-students/\" rel=\"noopener noreferrer\" target=\"_blank\">David Sellmyer</a>, who chaired the university’s physics department, about her concerns. He reassured her by offering her a job as a student researcher in his laboratory.\n</p><p>\n\t“I am so grateful to him because he really opened my eyes to the world of research and development,” she says. “I worked for him for two years, and it completely changed my life. Before, I had no idea that college professors did something called <em>research</em>. Once I discovered it, I found that I loved it.”\n</p><p>\n\tAfter graduating in 1985 with bachelor’s degrees in physics and mathematics, she headed to <a href=\"https://www.mit.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">MIT</a> as a graduate student with the goal of pursuing a career in medical engineering. She earned a master’s degree in physics in 1987 and was accepted into the institute’s medical physics Ph.D. program.\n</p><p class=\"pull-quote\">“Being part of a team that is providing care to patients who have been traditionally not served well by our existing health system is a privilege.”</p><p>\n\tShe did her doctoral research under the guidance of <a href=\"https://news.mit.edu/2010/obit-feld\" rel=\"noopener noreferrer\" target=\"_blank\">Michael S. Feld</a>, who founded MIT’s <a href=\"https://ilp.mit.edu/node/36470\" rel=\"noopener noreferrer\" target=\"_blank\">Laser Biomedical Research Center</a> to develop fluorescence and spectroscopy tools for disease diagnosis and endoscopy and optical tomography tools for imaging. Richards-Kortum worked with clinicians to develop such tools.\n</p><p>\n\t“I learned so much about how to work with clinicians and collaborate with them,” she says, adding that working in the research center helped her “understand the barriers clinicians face when caring for patients and how technologists could help improve medical care with better devices.”\n</p><p>\n\tAfter earning her Ph.D. in 1990, she joined the <a href=\"https://www.utexas.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Texas at Austin</a> as a professor of biomedical engineering. She spent the next 15 years there, conducting optical imaging research geared toward early detection of cervical, oral, and esophageal cancers. Early detection, she notes, can significantly reduce mortality rates.\n</p><p>\n\tShe left the University of Texas in 2005 to join Rice University.\n</p><h2>Providing cancer care to underserved communities</h2><p>\n\tRichards-Kortum became interested in developing technology for underserved communities in Africa in 2006 after attending the opening of the <a href=\"https://www.texaschildrens.org/baylor-international-pediatric-aids-initiative-bipai\" rel=\"noopener noreferrer\" target=\"_blank\">Baylor International Pediatric AIDS Initiative</a> clinic in Lilongwe, Malawi. The experience changed her life, she says.\n</p><p>\n\tWhat struck her the most while visiting the clinics, she says, was that each one had rooms full of broken equipment. The imported machines couldn’t withstand Malawi’s heat, dust, and humidity, and they couldn’t be repaired because the country lacked parts and trained technicians.\n</p><p class=\"shortcode-media shortcode-media-rebelmouse-image\">\n<img alt=\"a group of women smiling and talking to each other in a hospital setting\" class=\"rm-shortcode\" data-rm-shortcode-id=\"1a34dc20911de3d2e7f3334f339e396b\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"f0f46\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-group-of-women-smiling-and-talking-to-each-other-in-a-hospital-setting.jpg?id=51025729&width=980\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Joe Langton [left], Maria Oden, and Rebecca Richards-Kortum talk to a new mother about the continuous positive airway pressure (CPAP) machine being used at Chatinkha Nursery in Blantyre, Malawi.</small></p><p>\n\tRichards-Kortum returned to Texas with a new mission: designing medical equipment for clinics in underserved communities that could withstand harsh climate conditions and be easily repaired. She also wanted to get students involved in the work.\n</p><p>\n\tTo help her cause, she and colleague <a href=\"https://profiles.rice.edu/faculty/z-maria-oden\" rel=\"noopener noreferrer\" target=\"_blank\">Z. Maria Oden</a>, also a bioengineering professor, founded the Rice360 Institute for Global Health Technologies. Undergraduate and graduate students at the institute develop affordable medical technologies to help solve health challenges worldwide.\n</p><p>\n\tRichards-Kortum formed an institute team of researchers, physicians, and students to design a tool that could detect precancerous cells to help prevent oral and cervical cancer.\n</p><p>\n\tPrecancerous cells, which have grown abnormally in size, shape, or appearance, have a high chance of becoming cancerous. Precancerous epithelial cells in the mouth and the cervix, in particular, are likely to develop into <a href=\"https://www.verywellhealth.com/what-are-precancerous-cells-2248796#:~:text=The%20majority%20of%20cancers%20(roughly,develop%20into%20cervical%20cancer2\" rel=\"noopener noreferrer\" target=\"_blank\">cancer</a>. The most common sign epithelial cells are precancerous is that their nuclei are enlarged, according to the <a href=\"https://www.cancer.org/cancer/diagnosis-staging/tests/biopsy-and-cytology-tests/testing-biopsy-and-cytology-samples-for-cancer/what-doctors-look-for.html\" rel=\"noopener noreferrer\" target=\"_blank\">American Cancer Society</a>.\n</p><p>\n\tWhen precancerous tissue forms, new blood vessels grow to supply it with blood. Because hemoglobin in the red blood cells absorbs visible light, Richards-Kortum’s team developed a fiber-optic probe that can produce images of the underlying network of new vessels. The tool also can image epithelial cells and their nuclei.\n</p><p>\n\tThe high-resolution micro-endoscope (HRME) provides answers about a person’s intracellular structure without the need for a biopsy. The device, which is about the size of a DVD player, houses a 475-nanometer mirror, an optical sensor, and a 150-millimeter tube lens. Connected on one side is a flexible fiber bundle, just 1 mm in diameter, with a light source and a digital CCD camera inside. The light source is a blue LED with a peak wavelength of 455 nm. On the other side of the device is a cable that can be connected to a laptop, a tablet, or a smartphone.\n</p><p>\n\tTo image a patient’s tissue, a physician applies topical contrast gel to the area to be tested, then places the fiber bundle on the tissue. Some of the light from the fiber bounces back from the tissue, and those emissions are transmitted through the mirror and focused onto the optical sensor and the tube lens. Images of the epithelial cells are transferred to a laptop, tablet, or phone. The HRME can image the area at 80 frames per second. The device correctly identifies precancerous tissue 95 percent of the time, Richards-Kortum reports, and AI-based algorithms are being incorporated into the tool to further improve its performance.\n</p><p>\n\t“By [using the tool] physicians can correlate the changes in nuclear structure and the changes in the vascular structure to see if there are a large number of precancerous cells,” Richards-Kortum says. Health care workers are using the HRME to screen patients for cervical, oral, and esophageal cancer in clinics around the world, including in Botswana, Brazil, and El Salvador.\n</p><h2>Improving neonatal care in sub-Saharan Africa</h2><p>\n\tIn 2007 Richards-Kortum, Oden, and their team began developing technology to improve neonatal health care and reduce death rates in sub-Saharan Africa.\n</p><p>\n\tTheir first invention was a continuous positive airway pressure (CPAP) machine for newborns with breathing problems. It consists of a shoe box that houses a 900-gram reusable water bottle, which is connected to a pump that sends air through the bottle and into the baby’s airways. Their CPAP machine was commercialized in 2014 and is now being used in more than 35 countries.\n</p><p>\n\tBut that tool helped with only one health issue newborns might face, she says. To develop medical devices to improve comprehensive care for newborns, she and Oden helped launch <a href=\"https://nest360.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Newborn Essential Solutions and Technologies</a>, known as NEST360, in 2017. The initiative brings together engineers, physicians, health care experts, and entrepreneurs from 12 organizations including the <a href=\"https://advancingmnch.org/partners/university-malawi-college-medicine\" rel=\"noopener noreferrer\" target=\"_blank\">Malawi College of Medicine</a>, the <a href=\"https://www.lshtm.ac.uk/\" rel=\"noopener noreferrer\" target=\"_blank\">London School of Hygiene and Tropical Medicine</a>, and the <a href=\"https://www.ihi.or.tz/\" rel=\"noopener noreferrer\" target=\"_blank\">Ifakara Health Institute</a>.\n</p><p>\n\tThe initiative developed the NEST360 newborn tool kit. It includes 17 machines including a radiant warmer and incubator to help maintain an infant’s body temperature; diagnostic tools for sepsis and infections; and a low-power syringe pump to dispense medicine, fluid, or formula. The group has trained 10,000 medical professionals on how to use the kits.\n</p><p>\n\tToday, 65 hospitals and clinics across Kenya, Malawi, Nigeria, and Tanzania are using the tool kits, which will soon be supplied to hospitals in Ethiopia, officials say.\n</p><p>\n\tNEST360 <a href=\"https://news.rice.edu/news/2021/nest360-wins-2021-innovating-impact-partnership-award\" rel=\"noopener noreferrer\" target=\"_blank\">estimates</a> that the kit is improving the lives of 500,000 newborns annually.\n</p><p>\n\t“Being part of a team that is providing care to patients who have not been traditionally well served by our existing health system is a privilege,” Richards-Kortum says.\n</p><h2>A bridge between EE and health care</h2><p>\n\tRichards-Kortum joined IEEE while teaching at the University of Texas.\n</p><p>\n\t“I really appreciate the way the organization has thought about the intersectionality between electrical engineering and health care technology,” she says. “IEEE has been an important voice in moving that field forward for faculty members and students, and doing that in a way that prioritizes equity.”\n</p><p>\n\tProfessional networking opportunities are also an important benefit, she says. Richards-Kortum recommends her students join IEEE not only for the networking avenues but also for the professional development and continuing education programs, as well as the ability to share and learn about advances in research.\n</p>"},"pubDate":"Mon, 08 Jan 2024 19:00:03 +0000","guid":"https://spectrum.ieee.org/rice-university-cancer-detection-technology","category":["Health care","Ieee awards","Ieee member news","Neonatal health","Optical imaging","Type:ti"],"dc:creator":"Joanna Goodrich","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/portrait-of-a-woman-in-a-lab-coat-smiling-for-the-camera-with-a-whiteboard-and-text-in-the-background.jpg?id=51025724&width=980"}},{"title":"CES 2024 Preview: A Tricorder, Magic Mirrors, and a Solar EV","link":"https://spectrum.ieee.org/ces-2024","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-large-sign-reading-ces-backlit-against-blue-and-green-colors.jpg?id=51008997&width=1200&height=800&coordinates=0%2C104%2C0%2C105\"/><br/><br/><p><a href=\"https://www.ces.tech/\" rel=\"noopener noreferrer\" target=\"_blank\">CES 2024</a> kicks off on 9 January, but if you’re reading this on Monday, I’m already wandering through this technological wonderland, thanks to early media showcases. And over the past couple months, I’ve been combing through hundreds of advance announcements and embargoed news releases.</p><p>CES, like just about everything else in tech these days, will be AI heavy. Some of those AI applications will be useful, but I’m guessing some of them will be just plain dumb—I’ll be telling you more about AI at CES later this week. There will be some innovations that are at the “technology looking for a product” stage. In this category, my things-to-look-at list includes new variations of spatial audio, <a href=\"https://ambientphotonics.com/\" rel=\"noopener noreferrer\" target=\"_blank\">more efficient solar cells</a> and other energy harvesters, <a href=\"https://opteran.com/\" rel=\"noopener noreferrer\" target=\"_blank\">a neural network</a> based on insect brains, and <a href=\"https://www.ces.tech/innovation-awards/honorees/2024/best-of/m/mems-hybrid-micromotor-for-electronics.aspx\" rel=\"noopener noreferrer\" target=\"_blank\">a silicon micromotor</a>.</p><p>These enabling technologies, for me, are the big game of CES. But CES also features a host of cute and colorful creatures—those tech gadgets you never knew you needed. Here in no particular order, are seven of the (hopefully) clever products I’ll be tracking down. I’ll update with pricing when those numbers become available.</p><h2>Is this finally the “Tricorder” we’ve been waiting for?</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"hands hold a rectangular box. Illustrations on the background show measurments related to the heart and lungs.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"29da4f32fcfb69ba3ffa86cb829cf728\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"85d5f\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/hands-hold-a-rectangular-box-illustrations-on-the-background-show-measurments-related-to-the-heart-and-lungs.jpg?id=51012910&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">The BeamO is a compact health monitor for at-home checkups.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">Withings</small></p><p>A real-world version of <a href=\"https://spectrum.ieee.org/the-race-to-build-a-reallife-version-of-the-star-trek-tricorder\" target=\"_self\">the Star Trek Tricorder</a> has long been a grail for the consumer electronics industry. A decade ago, Qualcomm offered a multimillion-dollar prize for any team that could create such a mobile diagnostic device, and <a href=\"https://spectrum.ieee.org/brothers-win-xprize-for-star-trekinspired-tricorder\" target=\"_self\">in 2017 it crowned the winners</a>. But that development didn’t quickly lead to a useful, multifunction health monitor arriving on pharmacy shelves.</p><p>Perhaps, however, that gadget is about to hit the market. Smart scale–maker <a href=\"https://www.withings.com/us/en/\" rel=\"noopener noreferrer\" target=\"_blank\">Withings</a> isn’t calling its new product a tricorder; instead, it calls its BeamO device a “multiscope” that is designed to monitor key vital signs—acting as a thermometer, oximeter, stethoscope, and electrocardiograph machine. The company says the package is smaller than a smartphone and intended for informal at-home checkups and telehealth visits. Withings says that its BeamO can perform blood oxygenation and heart-rate readings at the same time that it conducts a medical-grade electrocardiogram (ECG), and then can be raised to take a temperature reading via an infrared scan of the temporal artery. To gather heart and lung sounds, the BeamO needs to touch the chest or back, where a piezoelectric disk in the device picks up sound waves; the sounds can be streamed to a remote physician. (Last year, the company <a href=\"https://spectrum.ieee.org/ces-2023\" target=\"_self\">introduced urinalysis in a toilet seat</a>. That function is decidedly <em>not</em> included in this handheld device.)</p><h2>Mirror, mirror, do I look stressed or depressed?</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A round mirror surrounded by light above a sink.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"141035b63ada91475e6f47b80323f03a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"75b43\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-round-mirror-surrounded-by-light-above-a-sink.jpg?id=51008734&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-348230\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Gaze into the BMind smart mirror to gauge your mental state.</small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-101107\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Baracoda</small></p><p>I’m not sure I want my mirror telling me I need to calm down. But maybe that’s just me, so I’m trying to keep an open mind about <a href=\"http://www.care-os.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Baracoda</a>‘s BMind smart mirror. The BMind, the company indicates, will not only recognize when a user’s mental state is less than par, but will suggest exercises and activities to improve it, including light therapy, guided meditation, and self-affirmations. Baracoda reports that the mirror uses the company’s AI-based CareOS operating system to interpret expressions, gestures, and spoken words, adapting to the user’s mood in real time.</p><h2>Or, magic mirror, am I getting sick?</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"a man sitting in front of a rectangular tabletop mirror\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"69d98e267afa99baed6859f86364f4b1\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"207d8\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-man-sitting-in-front-of-a-rectangular-tabletop-mirror.jpg?id=51012907&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">Or let the Anura MagicMirror check your vital signs.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">NuraLogix</small></p><p>I debated whether to include another mirror—and another health-monitoring device—on this list. But the pandemic made many of us more concerned about variations in our own health, so it may be the right time for <a href=\"https://www.nuralogix.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">NuraLogix’s</a> Anura MagicMirror. The MagicMirror captures blood-flow patterns and analyzes them to determine heart rate, respiratory rate, blood pressure, cardiac workload, mental stress, diabetes risk, fatty liver disease risk, and other vital signs and disease potentialities. (<a href=\"https://spectrum.ieee.org/ces-2023\" target=\"_self\">Last year</a>, the company introduced some of these capabilities in a smartphone app.) It also assesses facial skin age—after a couple of days of moisture-sucking Vegas air, late nights, and fluorescent lights I can’t imagine that that assessment will go well. But I will check it out.</p><h2>Look Ma, no plug! This EV runs on solar</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A blue buggy the size of a golf cart with a surfboard in back.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"1f81be9a06f796f930da7efbe5750fa8\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"4b3f0\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-blue-buggy-the-size-of-a-golf-cart-with-a-surfboard-in-back.jpg?id=51008755&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-903017\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Get around town in Squad Mobility’s plugless Solar Buggy.</small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-60240\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Squad Mobility</small></p><p>When I’ve been on vacation in recent years, I’ve noticed more people getting around beach towns in electric golf carts. <a href=\"https://www.squadmobility.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Squad Mobility</a>, based in the Netherlands, is taking the concept a step further: Its plugless EV charges directly from solar panels on the vehicle’s roof. That makes sense, given that these types of vehicles are mostly used in good weather. At CES, Squad plans to demonstrate its Solar Buggy, a compact low-speed car that can carry two passengers (along with two surf boards) and is expected to retail for US $6,250.</p><h2>The glove fits—and fights the tremors of Parkinson’s</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Two senior women each wear a black glove like device, which they are looking at.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"2d731c5e69a4c0e608294f942f77ed39\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"125cc\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/two-senior-women-each-wear-a-black-glove-like-device-which-they-are-looking-at.jpg?id=51012909&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\">The  GyroGlove dampens tremors in the wearer’s hand.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\">GyroGear</small></p><p>I’ve had Parkinson’s on my mind lately, since a friend was recently diagnosed and is already finding that hand tremors make it harder for her to perform simple tasks. So I’m very excited to try on the GyroGlove from <a href=\"https://www.visitingfromspace.com/gyrogear/\" rel=\"noopener noreferrer\" target=\"_blank\">GyroGear</a>. The concept seems straightforward, and it may be one of the few wearables at CES that doesn’t have an AI angle. The doctor who developed the device reports that it took eight years to make it work. The glove incorporates a battery-operated gyroscope that resists hand movements, dampening tremors but allowing intentional movements to push through.</p><h2>Do we really need a new way to cook?</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A woman in a kitchen facing away from camera, a square appliance slightly bigger than a breadbox on the counter.\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"c1679882199aaa8fa8f71edbb9f0ff8f\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"1daff\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-woman-in-a-kitchen-facing-away-from-camera-a-square-appliance-slightly-bigger-than-a-breadbox-on-the-counter.jpg?id=51008796&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-383654\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Sevvy’s Smart Cooker uses pulsed electric fields to cook food more efficiently.</small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-596463\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Sevvy</small></p><p>We’ve got microwaves, toaster ovens, steam ovens, sous vide, and air fryers, along with traditional gas and electric stoves—so do we really need another cooking technology? It’ll take a lot to convince me I need another countertop appliance, but I am curious about Sevvy’s attempt to use pulsed electric fields (PEF) for cooking and baking. To date, the technology has been used in the commercial food industry, mainly <a href=\"https://ohioline.osu.edu/factsheet/fst-fabe-1002\" rel=\"noopener noreferrer\" target=\"_blank\">for pasteurization</a> of liquid and semisolid foods. But as far as I can tell, this Netherlands-based startup’s Smart Cooker represents the first attempt to use PEF in a consumer appliance.</p><p><a href=\"https://www.sevvy.nl/\" rel=\"noopener noreferrer\" target=\"_blank\">Sevvy</a> says its patented approach uses 90 percent less energy than traditional ovens do and retains more nutrients. The company promises a CES demo of baking blueberry muffins in 3 minutes.</p><h2>Beware of cats bearing “gifts”</h2><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"A white cat door with rounded edges on an orange background\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"a479aa1ba1e35e51a019266b9bff8f0a\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"f25da\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/a-white-cat-door-with-rounded-edges-on-an-orange-background.jpg?id=51008798&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" data-gramm=\"false\" data-lt-tmp-id=\"lt-616966\" placeholder=\"Add Photo Caption...\" spellcheck=\"false\">Flappie’s intelligent cat door filters out kitty’s hunting trophies.</small><small class=\"image-media media-photo-credit\" data-gramm=\"false\" data-lt-tmp-id=\"lt-116253\" placeholder=\"Add Photo Credit...\" spellcheck=\"false\">Flappie</small></p><p>Admittedly, this gadget will be of interest to only a small subset of consumers, but for those affected, it addresses a real problem. And isn’t finding solutions to real problems what engineering is all about?</p><p>The problem: Some cats like to bring their owners “gifts”—gifts of prey, that is, from their hunting expeditions. The cats will carry the critters into the house, leaving owners to either dispose of the remains or chase a creature that had only been stunned. I do know people who have regular adventures involving the mice and lizards gifted by their cats.</p><p>The product, <a href=\"https://www.flappie.ch/en/\" target=\"_blank\">Flappie</a>, is a cat door that recognizes a cat by its RFID chip and opens only when the cat is not carrying a “gift.” If it spots such a gift, it sends a photo to the owner’s phone, just in case the owner wants to override the device’s decision and let that lizard in. Flappie began as a student engineering project at <a href=\"https://ethz.ch/en.html\" rel=\"noopener noreferrer\" target=\"_blank\">ETH Zurich</a>, and is expected to be available in the second quarter of 2024, at a presale price of $199 and a list price of $399.</p>"},"pubDate":"Mon, 08 Jan 2024 14:00:03 +0000","guid":"https://spectrum.ieee.org/ces-2024","category":["Ces 2024","Consumer electronics","Healthmonitoringdevice","Multiscope","Parkinson's disease","Pulsedelectricfields","Solar car","Tricorder","Ces","Ces"],"dc:creator":"Tekla S. Perry","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-large-sign-reading-ces-backlit-against-blue-and-green-colors.jpg?id=51008997&width=980"}},{"title":"The LEO Satellite Industry Needs More Engineers","link":"https://spectrum.ieee.org/leo-satellite-needs-more-engineers","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/space-image-of-earth-with-multiple-satellites-around-the-middle-on-a-black-background.jpg?id=51009284&width=1200&height=800&coordinates=477%2C0%2C477%2C0\"/><br/><br/><p>\n\tLook up. The odds are good that one or more low-Earth-orbit satellites are above you right now. Some 5,000 LEO satellites currently orbit 500 to 1,500 kilometers above the Earth, helping to forecast the weather, transmit data, and provide broadband Internet to underserved areas.\n</p><p>\n\tIt’s relatively inexpensive to launch the small spacecraft, and more are being built.\n</p><p>\n\tSpaceX’s <a href=\"https://www.starlink.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Starlink</a> broadband communications LEO satellites are probably the most famous, but Amazon has begun launching its competing <a href=\"https://www.aboutamazon.com/news/innovation-at-amazon/what-is-amazon-project-kuiper\" rel=\"noopener noreferrer\" target=\"_blank\">Project Kuiper</a> satellites and expects to begin service this year. Other companies are entering the market, not only to provide broadband access but also to build the smaller rockets. They include<a href=\"https://www.airbus.com/en/space/telecom/constellations\" rel=\"noopener noreferrer\" target=\"_blank\"> Airbus</a>,<a href=\"https://www.ariane.group/en/\" rel=\"noopener noreferrer\" target=\"_blank\"> ArianeGroup</a>, the<a href=\"https://spacenews.com/china-to-begin-constructing-its-own-megaconstellation-later-this-year/\" rel=\"noopener noreferrer\" target=\"_blank\"> China Aerospace Science and Technology Corp</a>., and<a href=\"https://www.satellitetoday.com/imagery-and-sensing/2023/11/29/tata-advanced-systems-and-satellogic-to-build-leo-satellites-in-india/\" rel=\"noopener noreferrer\" target=\"_blank\"> Tata Advanced Systems</a>.\n</p><p>\n\tThe LEO satellite market is likely to grow from more than US $4 billion in 2022 to<a href=\"https://www.businessresearchinsights.com/market-reports/leo-satellite-market-100025\" rel=\"noopener noreferrer\" target=\"_blank\"> nearly $7 billion in 2031</a>, according to Business Research Insights.\n</p><p>\n\tAlthough the market is growing, the number of engineers and technologists who understand the complicated systems is not. That’s why in 2021 IEEE launched the Low-Earth-Orbit Satellites and Systems (LEO SatS) project under the leadership of <a href=\"https://www.linkedin.com/in/witold-kinsner-314304a0/?originalSubdomain=ca\" rel=\"noopener noreferrer\" target=\"_blank\">Witold Kinsner</a>. The IEEE Fellow is a professor of electrical and computer engineering at the <a href=\"https://umanitoba.ca/\" rel=\"noopener noreferrer\" target=\"_blank\">University of Manitoba</a>, Canada, and past vice president of <a href=\"https://www.ieee.org/education/eab.html\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE Educational Activities</a>.\n</p><p>\n\t“The scope of the project is not to start a new space-related movement but to coordinate and expand the existing activities,” says<a href=\"https://markus.gardill.net/\" rel=\"noopener noreferrer\" target=\"_blank\"> Markus Gardill</a>, LEO SatS cochair. The IEEE senior member is a professor and chair of electronic systems and sensors at the <a href=\"https://www.b-tu.de/en/fg-ess/\" rel=\"noopener noreferrer\" target=\"_blank\">Brandenburg University of Technology Cottbus-Senftenberg</a>, in Germany.\n</p><p>\n\t“There are excellent researchers and educators working in the LEO satellite area, including those from various IEEE societies, but they are not communicating with each other,” Gardill says. “We have to bring together people from different disciplines and create one point of contact within IEEE to coordinate and consolidate what is happening in the field.”\n</p><h2>Educating current and future technologists</h2><p>\n\tTo date, LEO SatS has held several workshops and events to educate engineers and students about career opportunities in the realm. The project’s leaders also are looking to increase collaborations among academia, industry, governments, and space agencies.\n</p><p>\n\tThe LEO SatS education and contest working group has held several seminars, now available on<a href=\"http://www.ieee.tv/\" rel=\"noopener noreferrer\" target=\"_blank\"> IEEE.tv</a>. An <a href=\"https://cmte.ieee.org/futuredirections/projects/leo-satellites-systems/ieee-leo-sats-fall-ws/\" rel=\"noopener noreferrer\" target=\"_blank\">introductory workshop on the satellites</a> held in 2021 covered <a href=\"https://www.youtube.com/watch?v=-fcY8sSUU8w\" rel=\"noopener noreferrer\" target=\"_blank\">nanosatellites</a>, <a href=\"https://www.youtube.com/watch?v=iGxWr92M4fo\" rel=\"noopener noreferrer\" target=\"_blank\">communication security challenges</a>, and<a href=\"https://youtu.be/ikJM87wp4K0\" rel=\"noopener noreferrer\" target=\"_blank\"> data centers and time synchronization</a>.\n</p><p>\n\tDuring the<a href=\"https://ieee-edusociety.org/ieee-education-week-2022\" rel=\"noopener noreferrer\" target=\"_blank\"> 2022 IEEE Education Week</a>, the group hosted a <a href=\"https://ieee.webex.com/recordingservice/sites/ieee/recording/18ced09898a9103aa95f9a94dbc9df3c/playback\" rel=\"noopener noreferrer\" target=\"_blank\">virtual panel discussion on space education</a>. Panelists discussed the spacecraft, applications, and career paths.\n</p><p class=\"pull-quote\">“The scope of the project’s activities is not to start a new space-related movement but to coordinate and expand the existing activities.” <strong>—Markus Gardill</strong> </p><p>\n\tPresenters at a June workshop on using<a href=\"https://cmte.ieee.org/futuredirections/projects/leo-satellites-systems/leo-sats-2023-spring-workshop/\" rel=\"noopener noreferrer\" target=\"_blank\"> edge computing and AI aboard the satellites</a> discussed <a href=\"https://ieeetv.ieee.org/channels/ieee-future-directions/ieee-leo-sats-ai-techniques-for-massive-satellite-networks-akram-al-hourani\" rel=\"noopener noreferrer\" target=\"_blank\">techniques for massive satellite networks</a>, <a href=\"https://ieeetv.ieee.org/channels/ieee-future-directions/ieee-leo-sats-benchmarking-deep-learning-models-and-running-memory-checkers-on-edge-processors-onboard-the-iss-emily-dunkel\" rel=\"noopener noreferrer\" target=\"_blank\">benchmarking deep learning models</a>, and the experiments that took place with<a href=\"https://ieeetv.ieee.org/channels/ieee-future-directions/ieee-leo-sats-ops-sat-space-lab-the-perfect-space-to-experiment-with-edge-computing-onboard-ai-david-evans\" rel=\"noopener noreferrer\" target=\"_blank\"> edge computing on the European Space Agency’s OPS-SAT</a> laboratory. Several presenters later collaborated on “<a href=\"https://bibbase.org/network/publication/gardill-kinsner-budroweit-alhourani-dunkel-swope-evans-staebler-towardsspaceedgecomputingandonboardaiforrealtimeteleoperations-2023\" rel=\"noopener noreferrer\" target=\"_blank\">Towards Space Edge Computing and Onboard AI for Real-Time Teleoperations</a>,” which received a Best Paper prize at the 2023 <a href=\"https://easychair.org/cfp/IEEE_ICCI-CC_2023\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE International Conference on Cognitive Informatics and Cognitive Computing</a>.\n</p><p>\n\tThe working group also is developing educational materials about the space industry for preuniversity and university instructors to encourage students to pursue a career in the field. The group is building a database of the lesson plans to simplify matters, Gardill says.\n</p><p>\n\tHe says lesson plans also are being developed for<a href=\"https://spectrum.ieee.org/how-small-satellites-are-providing-lowcost-access-to-space\" target=\"_self\"> CubeSats</a>, which are designed in a modular fashion based on the 10-by-10-by-10-centimeter base unit referred to as 1U. CubeSats are being used to teach students about the technology by showing them how to build and launch the small rockets themselves. Researchers are testing larger CubeSats, from 3U to 6U, for commercial missions. Universities are studying the sixth generation of the satellites, Kinsner says, with many being placed in the shell of a LEO satellite.\n</p><p>\n\t“This type of experiential learning is a unique opportunity in the field of STEM education,” Gardill says.\n</p><h2>The satellite ground game</h2><p>\n\tLEOs SatS doesn’t have its eyes only on the skies. It’s also making more down-to-earth strides, such as the workshop it held in November on<a href=\"https://cmte.ieee.org/futuredirections/projects/leo-satellites-systems/leo-sats-2023-fall-workshop/\" rel=\"noopener noreferrer\" target=\"_blank\"> LEO ground stations</a>.\n</p><p>\n\tThe ground stations are composed of a series of antennas, communications networks, and processing facilities that provide command and control capabilities. The LEO SatS project leaders believe more cooperation is needed in designing new types of ground stations, Gardill says.\n</p><p>\n\t“LEO satellites are continuously moving, so you need ground stations distributed around the globe if you want 24/7 access to your satellite,” he says. “It would be very inefficient, if not even infeasible, if every group working on a satellite mission had to establish its own ground-station infrastructure. This presents the demand to work together on a global scale to create a network of ground stations that everyone can access.”\n</p><h2>New terrestrial-satellite networks</h2><p>\n\tThe recent emergence of constellations of thousands of LEO satellites has resulted not only in almost complete communications coverage with low latency but also in new, fast, inter-satellite optical communications, Kinsner says.\n</p><p>\n\tWhen combined with the artificial intelligence–augmented edge computing in space, he says, a new opportunity is on the horizon for intertwining traditional terrestrial networks with the new inter-satellite networks (terra-sat-nets) to develop real-time (RT) teleoperations.\n</p><p>\n\t“The extracurricular competitions involving the design, implementation, and deployment of CubeSats at various educational institutions around the globe have already prepared many new young students for the space industry and research,” Kinsner says. “Our LEO SatS initiative intends to develop similar competitions through capstone projects to develop the smart links between the terra-sat-nets to facilitate the RT teleoperations.”\n</p><h2>Standards and technology roadmaps</h2><p>\n\tThe group is encouraging space agencies, industry interests, governments, and academia to collaborate on developing technology roadmaps and technical standards.\n</p><p>\n\tTo that end, the IEEE LEO SatS team is working on white papers to identify existing technologies and policy gaps to address the lack of laws that govern satellite systems, Kinsner says.\n</p><p>\n\t“It’s very important for the IEEE LEO SatS project to broaden our network,” Gardill says, “because we think these satellite systems will have a large impact and are simultaneously a great challenge.”\n</p><p>To join the project, contact the organizers via the <a href=\"https://cmte.ieee.org/futuredirections/projects/leo-satellites-systems/\" rel=\"noopener noreferrer\" target=\"_blank\">IEEE LEO SatS website</a>.</p>"},"pubDate":"Sun, 07 Jan 2024 19:00:02 +0000","guid":"https://spectrum.ieee.org/leo-satellite-needs-more-engineers","category":["Ieee products services","Leo","Satellites","Space","Type:ti"],"dc:creator":"Kathy Pretz","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/space-image-of-earth-with-multiple-satellites-around-the-middle-on-a-black-background.jpg?id=51009284&width=980"}},{"title":"Andrew Ng: Unbiggen AI","link":"https://spectrum.ieee.org/andrew-ng-data-centric-ai","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednes.jpg?id=29206806&width=1200&height=800&coordinates=0%2C0%2C0%2C210\"/><br/><br/><p><strong><a href=\"https://en.wikipedia.org/wiki/Andrew_Ng\" rel=\"noopener noreferrer\" target=\"_blank\">Andrew Ng</a> has serious street cred</strong> in artificial intelligence. He pioneered the use of graphics processing units (GPUs) to train deep learning models in the late 2000s with his students at <a href=\"https://stanfordmlgroup.github.io/\" rel=\"noopener noreferrer\" target=\"_blank\">Stanford University</a>, cofounded <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer\" target=\"_blank\">Google Brain</a> in 2011, and then served for three years as chief scientist for <a href=\"https://ir.baidu.com/\" rel=\"noopener noreferrer\" target=\"_blank\">Baidu</a>, where he helped build the Chinese tech giant’s AI group. So when he says he has identified the next big shift in artificial intelligence, people listen. And that’s what he told <em>IEEE Spectrum</em> in an exclusive Q&A.</p><hr/><p>\n\tNg’s current efforts are focused on his company \n\t<a href=\"https://landing.ai/about/\" rel=\"noopener noreferrer\" target=\"_blank\">Landing AI</a>, which built a platform called LandingLens to help manufacturers improve visual inspection with computer vision. <a name=\"top\"></a>He has also become something of an evangelist for what he calls the <a href=\"https://www.youtube.com/watch?v=06-AZXmwHjo\" target=\"_blank\">data-centric AI movement</a>, which he says can yield “small data” solutions to big issues in AI, including model efficiency, accuracy, and bias.\n</p><p>\n\tAndrew Ng on...\n</p><ul>\n<li><a href=\"#big\">What’s next for really big models</a></li>\n<li><a href=\"#career\">The career advice he didn’t listen to</a></li>\n<li><a href=\"#defining\">Defining the data-centric AI movement</a></li>\n<li><a href=\"#synthetic\">Synthetic data</a></li>\n<li><a href=\"#work\">Why Landing AI asks its customers to do the work</a></li>\n</ul><p>\n<a name=\"big\"></a><strong>The great advances in deep learning over the past decade or so have been powered by ever-bigger models crunching ever-bigger amounts of data. Some people argue that that’s an <a href=\"https://spectrum.ieee.org/deep-learning-computational-cost\" target=\"_self\">unsustainable trajectory</a>. Do you agree that it can’t go on that way?</strong>\n</p><p>\n<strong>Andrew Ng: </strong>This is a big question. We’ve seen foundation models in NLP [natural language processing]. I’m excited about NLP models getting even bigger, and also about the potential of building foundation models in computer vision. I think there’s lots of signal to still be exploited in video: We have not been able to build foundation models yet for video because of compute bandwidth and the cost of processing video, as opposed to tokenized text. So I think that this engine of scaling up deep learning algorithms, which has been running for something like 15 years now, still has steam in it. Having said that, it only applies to certain problems, and there’s a set of other problems that need small data solutions.\n</p><p>\n<strong>When you say you want a foundation model for computer vision, what do you mean by that?</strong>\n</p><p>\n<strong>Ng:</strong> This is a term coined by <a href=\"https://cs.stanford.edu/~pliang/\" rel=\"noopener noreferrer\" target=\"_blank\">Percy Liang</a> and <a href=\"https://crfm.stanford.edu/\" rel=\"noopener noreferrer\" target=\"_blank\">some of my friends at Stanford</a> to refer to very large models, trained on very large data sets, that can be tuned for specific applications. For example, <a href=\"https://spectrum.ieee.org/open-ais-powerful-text-generating-tool-is-ready-for-business\" target=\"_self\">GPT-3</a> is an example of a foundation model [for NLP]. Foundation models offer a lot of promise as a new paradigm in developing machine learning applications, but also challenges in terms of making sure that they’re reasonably fair and free from bias, especially if many of us will be building on top of them.\n</p><p>\n<strong>What needs to happen for someone to build a foundation model for video?</strong>\n</p><p>\n<strong>Ng:</strong> I think there is a scalability problem. The compute power needed to process the large volume of images for video is significant, and I think that’s why foundation models have arisen first in NLP. Many researchers are working on this, and I think we’re seeing early signs of such models being developed in computer vision. But I’m confident that if a semiconductor maker gave us 10 times more processor power, we could easily find 10 times more video to build such models for vision.\n</p><p>\n\tHaving said that, a lot of what’s happened over the past decade is that deep learning has happened in consumer-facing companies that have large user bases, sometimes billions of users, and therefore very large data sets. While that paradigm of machine learning has driven a lot of economic value in consumer software, I find that that recipe of scale doesn’t work for other industries.\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"career\"></a>\n</p><p>\n<strong>It’s funny to hear you say that, because your early work was at a consumer-facing company with millions of users.</strong>\n</p><p>\n<strong>Ng: </strong>Over a decade ago, when I proposed starting the <a href=\"https://research.google/teams/brain/\" rel=\"noopener noreferrer\" target=\"_blank\">Google Brain</a> project to use Google’s compute infrastructure to build very large neural networks, it was a controversial step. One very senior person pulled me aside and warned me that starting Google Brain would be bad for my career. I think he felt that the action couldn’t just be in scaling up, and that I should instead focus on architecture innovation.\n</p><p class=\"pull-quote\">\n\t“In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.”<br/>\n\t—Andrew Ng, CEO & Founder, Landing AI\n</p><p>\n\tI remember when my students and I published the first \n\t<a href=\"https://nips.cc/\" rel=\"noopener noreferrer\" target=\"_blank\">NeurIPS</a> workshop paper advocating using <a href=\"https://developer.nvidia.com/cuda-zone\" rel=\"noopener noreferrer\" target=\"_blank\">CUDA</a>, a platform for processing on GPUs, for deep learning—a different senior person in AI sat me down and said, “CUDA is really complicated to program. As a programming paradigm, this seems like too much work.” I did manage to convince him; the other person I did not convince.\n</p><p>\n<strong>I expect they’re both convinced now.</strong>\n</p><p>\n<strong>Ng:</strong> I think so, yes.\n</p><p>\n\tOver the past year as I’ve been speaking to people about the data-centric AI movement, I’ve been getting flashbacks to when I was speaking to people about deep learning and scalability 10 or 15 years ago. In the past year, I’ve been getting the same mix of “there’s nothing new here” and “this seems like the wrong direction.”\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"defining\"></a>\n</p><p>\n<strong>How do you define data-centric AI, and why do you consider it a movement?</strong>\n</p><p>\n<strong>Ng:</strong> Data-centric AI is the discipline of systematically engineering the data needed to successfully build an AI system. For an AI system, you have to implement some algorithm, say a neural network, in code and then train it on your data set. The dominant paradigm over the last decade was to download the data set while you focus on improving the code. Thanks to that paradigm, over the last decade deep learning networks have improved significantly, to the point where for a lot of applications the code—the neural network architecture—is basically a solved problem. So for many practical applications, it’s now more productive to hold the neural network architecture fixed, and instead find ways to improve the data.\n</p><p>\n\tWhen I started speaking about this, there were many practitioners who, completely appropriately, raised their hands and said, “Yes, we’ve been doing this for 20 years.” This is the time to take the things that some individuals have been doing intuitively and make it a systematic engineering discipline.\n</p><p>\n\tThe data-centric AI movement is much bigger than one company or group of researchers. My collaborators and I organized a \n\t<a href=\"https://neurips.cc/virtual/2021/workshop/21860\" rel=\"noopener noreferrer\" target=\"_blank\">data-centric AI workshop at NeurIPS</a>, and I was really delighted at the number of authors and presenters that showed up.\n</p><p>\n<strong>You often talk about companies or institutions that have only a small amount of data to work with. How can data-centric AI help them?</strong>\n</p><p>\n<strong>Ng: </strong>You hear a lot about vision systems built with millions of images—I once built a face recognition system using 350 million images. Architectures built for hundreds of millions of images don’t work with only 50 images. But it turns out, if you have 50 really good examples, you can build something valuable, like a defect-inspection system. In many industries where giant data sets simply don’t exist, I think the focus has to shift from big data to good data. Having 50 thoughtfully engineered examples can be sufficient to explain to the neural network what you want it to learn.\n</p><p>\n<strong>When you talk about training a model with just 50 images, does that really mean you’re taking an existing model that was trained on a very large data set and fine-tuning it? Or do you mean a brand new model that’s designed to learn only from that small data set?</strong>\n</p><p>\n<strong>Ng: </strong>Let me describe what Landing AI does. When doing visual inspection for manufacturers, we often use our own flavor of <a href=\"https://developers.arcgis.com/python/guide/how-retinanet-works/\" rel=\"noopener noreferrer\" target=\"_blank\">RetinaNet</a>. It is a pretrained model. Having said that, the pretraining is a small piece of the puzzle. What’s a bigger piece of the puzzle is providing tools that enable the manufacturer to pick the right set of images [to use for fine-tuning] and label them in a consistent way. There’s a very practical problem we’ve seen spanning vision, NLP, and speech, where even human annotators don’t agree on the appropriate label. For big data applications, the common response has been: If the data is noisy, let’s just get a lot of data and the algorithm will average over it. But if you can develop tools that flag where the data’s inconsistent and give you a very targeted way to improve the consistency of the data, that turns out to be a more efficient way to get a high-performing system.\n</p><p class=\"pull-quote\">\n\t“Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.”<br/>\n\t—Andrew Ng\n</p><p>\n\tFor example, if you have 10,000 images where 30 images are of one class, and those 30 images are labeled inconsistently, one of the things we do is build tools to draw your attention to the subset of data that’s inconsistent. So you can very quickly relabel those images to be more consistent, and this leads to improvement in performance.\n</p><p>\n<strong>Could this focus on high-quality data help with bias in data sets? If you’re able to curate the data more before training?</strong>\n</p><p>\n<strong>Ng:</strong> Very much so. Many researchers have pointed out that biased data is one factor among many leading to biased systems. There have been many thoughtful efforts to engineer the data. At the NeurIPS workshop, <a href=\"https://www.cs.princeton.edu/~olgarus/\" rel=\"noopener noreferrer\" target=\"_blank\">Olga Russakovsky</a> gave a really nice talk on this. At the main NeurIPS conference, I also really enjoyed <a href=\"https://neurips.cc/virtual/2021/invited-talk/22281\" rel=\"noopener noreferrer\" target=\"_blank\">Mary Gray’s presentation,</a> which touched on how data-centric AI is one piece of the solution, but not the entire solution. New tools like <a href=\"https://www.microsoft.com/en-us/research/project/datasheets-for-datasets/\" rel=\"noopener noreferrer\" target=\"_blank\">Datasheets for Datasets</a> also seem like an important piece of the puzzle.\n</p><p>\n\tOne of the powerful tools that data-centric AI gives us is the ability to engineer a subset of the data. Imagine training a machine-learning system and finding that its performance is okay for most of the data set, but its performance is biased for just a subset of the data. If you try to change the whole neural network architecture to improve the performance on just that subset, it’s quite difficult. But if you can engineer a subset of the data you can address the problem in a much more targeted way.\n</p><p>\n<strong>When you talk about engineering the data, what do you mean exactly?</strong>\n</p><p>\n<strong>Ng: </strong>In AI, data cleaning is important, but the way the data has been cleaned has often been in very manual ways. In computer vision, someone may visualize images through a <a href=\"https://jupyter.org/\" rel=\"noopener noreferrer\" target=\"_blank\">Jupyter notebook</a> and maybe spot the problem, and maybe fix it. But I’m excited about tools that allow you to have a very large data set, tools that draw your attention quickly and efficiently to the subset of data where, say, the labels are noisy. Or to quickly bring your attention to the one class among 100 classes where it would benefit you to collect more data. Collecting more data often helps, but if you try to collect more data for everything, that can be a very expensive activity.\n</p><p>\n\tFor example, I once figured out that a speech-recognition system was performing poorly when there was car noise in the background. Knowing that allowed me to collect more data with car noise in the background, rather than trying to collect more data for everything, which would have been expensive and slow.\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"synthetic\"></a>\n</p><p>\n<strong>What about using synthetic data, is that often a good solution?</strong>\n</p><p>\n<strong>Ng: </strong>I think synthetic data is an important tool in the tool chest of data-centric AI. At the NeurIPS workshop, <a href=\"https://tensorlab.cms.caltech.edu/users/anima/\" rel=\"noopener noreferrer\" target=\"_blank\">Anima Anandkumar</a> gave a great talk that touched on synthetic data. I think there are important uses of synthetic data that go beyond just being a preprocessing step for increasing the data set for a learning algorithm. I’d love to see more tools to let developers use synthetic data generation as part of the closed loop of iterative machine learning development.\n</p><p>\n<strong>Do you mean that synthetic data would allow you to try the model on more data sets?</strong>\n</p><p>\n<strong>Ng: </strong>Not really. Here’s an example. Let’s say you’re trying to detect defects in a smartphone casing. There are many different types of defects on smartphones. It could be a scratch, a dent, pit marks, discoloration of the material, other types of blemishes. If you train the model and then find through error analysis that it’s doing well overall but it’s performing poorly on pit marks, then synthetic data generation allows you to address the problem in a more targeted way. You could generate more data just for the pit-mark category.\n</p><p class=\"pull-quote\">\n\t“In the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models.”<br/>\n\t—Andrew Ng\n</p><p>\n\tSynthetic data generation is a very powerful tool, but there are many simpler tools that I will often try first. Such as data augmentation, improving labeling consistency, or just asking a factory to collect more data.\n</p><p>\n<a href=\"#top\">Back to top</a><a name=\"work\"></a>\n</p><p>\n<strong>To make these issues more concrete, can you walk me through an example? When a company approaches <a href=\"https://landing.ai/\" rel=\"noopener noreferrer\" target=\"_blank\">Landing AI</a> and says it has a problem with visual inspection, how do you onboard them and work toward deployment?</strong>\n</p><p>\n<strong>Ng: </strong>When a customer approaches us we usually have a conversation about their inspection problem and look at a few images to verify that the problem is feasible with computer vision. Assuming it is, we ask them to upload the data to the <a href=\"https://landing.ai/platform/\" rel=\"noopener noreferrer\" target=\"_blank\">LandingLens</a> platform. We often advise them on the methodology of data-centric AI and help them label the data.\n</p><p>\n\tOne of the foci of Landing AI is to empower manufacturing companies to do the machine learning work themselves. A lot of our work is making sure the software is fast and easy to use. Through the iterative process of machine learning development, we advise customers on things like how to train models on the platform, when and how to improve the labeling of data so the performance of the model improves. Our training and software supports them all the way through deploying the trained model to an edge device in the factory.\n</p><p>\n<strong>How do you deal with changing needs? If products change or lighting conditions change in the factory, can the model keep up?</strong>\n</p><p>\n<strong>Ng:</strong> It varies by manufacturer. There is data drift in many contexts. But there are some manufacturers that have been running the same manufacturing line for 20 years now with few changes, so they don’t expect changes in the next five years. Those stable environments make things easier. For other manufacturers, we provide tools to flag when there’s a significant data-drift issue. I find it really important to empower manufacturing customers to correct data, retrain, and update the model. Because if something changes and it’s 3 a.m. in the United States, I want them to be able to adapt their learning algorithm right away to maintain operations.\n</p><p>\n\tIn the consumer software Internet, we could train a handful of machine-learning models to serve a billion users. In manufacturing, you might have 10,000 manufacturers building 10,000 custom AI models. The challenge is, how do you do that without Landing AI having to hire 10,000 machine learning specialists?\n</p><p>\n<strong>So you’re saying that to make it scale, you have to empower customers to do a lot of the training and other work.</strong>\n</p><p>\n<strong>Ng: </strong>Yes, exactly! This is an industry-wide problem in AI, not just in manufacturing. Look at health care. Every hospital has its own slightly different format for electronic health records. How can every hospital train its own custom AI model? Expecting every hospital’s IT personnel to invent new neural-network architectures is unrealistic. The only way out of this dilemma is to build tools that empower the customers to build their own models by giving them tools to engineer the data and express their domain knowledge. That’s what Landing AI is executing in computer vision, and the field of AI needs other teams to execute this in other domains.\n</p><p>\n<strong>Is there anything else you think it’s important for people to understand about the work you’re doing or the data-centric AI movement?</strong>\n</p><p>\n<strong>Ng: </strong>In the last decade, the biggest shift in AI was a shift to deep learning. I think it’s quite possible that in this decade the biggest shift will be to data-centric AI. With the maturity of today’s neural network architectures, I think for a lot of the practical applications the bottleneck will be whether we can efficiently get the data we need to develop systems that work well. The data-centric AI movement has tremendous energy and momentum across the whole community. I hope more researchers and developers will jump in and work on it.\n</p><p>\n<a href=\"#top\">Back to top</a>\n</p><p><em>This article appears in the April 2022 print issue as “Andrew Ng, AI Minimalist</em><em>.”</em></p>"},"pubDate":"Wed, 09 Feb 2022 15:31:12 +0000","guid":"https://spectrum.ieee.org/andrew-ng-data-centric-ai","category":["Andrew ng","Artificial intelligence","Deep learning","Type:cover"],"dc:creator":"Eliza Strickland","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/andrew-ng-listens-during-the-power-of-data-sooner-than-you-think-global-technology-conference-in-brooklyn-new-york-on-wednes.jpg?id=29206806&width=980"}},{"title":"How AI Will Change Chip Design","link":"https://spectrum.ieee.org/ai-chip-design-matlab","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&width=1200&height=800&coordinates=0%2C0%2C0%2C0\"/><br/><br/><p>The end of <a href=\"https://spectrum.ieee.org/on-beyond-moores-law-4-new-laws-of-computing\" target=\"_self\">Moore’s Law</a> is looming. Engineers and designers can do only so much to <a href=\"https://spectrum.ieee.org/ibm-introduces-the-worlds-first-2nm-node-chip\" target=\"_self\">miniaturize transistors</a> and <a href=\"https://spectrum.ieee.org/cerebras-giant-ai-chip-now-has-a-trillions-more-transistors\" target=\"_self\">pack as many of them as possible into chips</a>. So they’re turning to other approaches to chip design, incorporating technologies like AI into the process.</p><p>Samsung, for instance, is <a href=\"https://spectrum.ieee.org/processing-in-dram-accelerates-ai\" target=\"_self\">adding AI to its memory chips</a> to enable processing in memory, thereby saving energy and speeding up machine learning. Speaking of speed, Google’s TPU V4 AI chip has <a href=\"https://spectrum.ieee.org/heres-how-googles-tpu-v4-ai-chip-stacked-up-in-training-tests\" target=\"_self\">doubled its processing power</a> compared with that of  its previous version.</p><p>But AI holds still more promise and potential for the semiconductor industry. To better understand how AI is set to revolutionize chip design, we spoke with <a href=\"https://www.linkedin.com/in/heather-gorr-phd\" rel=\"noopener noreferrer\" target=\"_blank\">Heather Gorr</a>, senior product manager for <a href=\"https://www.mathworks.com/\" rel=\"noopener noreferrer\" target=\"_blank\">MathWorks</a>’ MATLAB platform.</p><p><strong>How is AI currently being used to design the next generation of chips?</strong></p><p><strong>Heather Gorr:</strong> AI is such an important technology because it’s involved in most parts of the cycle, including the design and manufacturing process. There’s a lot of important applications here, even in the general process engineering where we want to optimize things. I think defect detection is a big one at all phases of the process, especially in manufacturing. But even thinking ahead in the design process, [AI now plays a significant role] when you’re designing the light and the sensors and all the different components. There’s a lot of anomaly detection and fault mitigation that you really want to consider.</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Portrait of a woman with blonde-red hair smiling at the camera\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"1f18a02ccaf51f5c766af2ebc4af18e1\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"2dc00\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/portrait-of-a-woman-with-blonde-red-hair-smiling-at-the-camera.jpg?id=29288554&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\" style=\"max-width: 100%;\">Heather Gorr</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">MathWorks</small></p><p>Then, thinking about the logistical modeling that you see in any industry, there is always planned downtime that you want to mitigate; but you also end up having unplanned downtime. So, looking back at that historical data of when you’ve had those moments where maybe it took a bit longer than expected to manufacture something, you can take a look at all of that data and use AI to try to identify the proximate cause or to see  something that might jump out even in the processing and design phases. We think of AI oftentimes as a predictive tool, or as a robot doing something, but a lot of times you get a lot of insight from the data through AI.</p><p><strong>What are the benefits of using AI for chip design?</strong></p><p><strong>Gorr:</strong> Historically, we’ve seen a lot of physics-based modeling, which is a very intensive process. We want to do a <a href=\"https://en.wikipedia.org/wiki/Model_order_reduction\" rel=\"noopener noreferrer\" target=\"_blank\">reduced order model</a>, where instead of solving such a computationally expensive and extensive model, we can do something a little cheaper. You could create a surrogate model, so to speak, of that physics-based model, use the data, and then do your <a href=\"https://institutefordiseasemodeling.github.io/idmtools/parameter-sweeps.html\" rel=\"noopener noreferrer\" target=\"_blank\">parameter sweeps</a>, your optimizations, your <a href=\"https://www.ibm.com/cloud/learn/monte-carlo-simulation\" rel=\"noopener noreferrer\" target=\"_blank\">Monte Carlo simulations</a> using the surrogate model. That takes a lot less time computationally than solving the physics-based equations directly. So, we’re seeing that benefit in many ways, including the efficiency and economy that are the results of iterating quickly on the experiments and the simulations that will really help in the design.</p><p><strong>So it’s like having a digital twin in a sense?</strong></p><p><strong>Gorr:</strong> Exactly. That’s pretty much what people are doing, where you have the physical system model and the experimental data. Then, in conjunction, you have this other model that you could tweak and tune and try different parameters and experiments that let sweep through all of those different situations and come up with a better design in the end.</p><p><strong>So, it’s going to be more efficient and, as you said, cheaper?</strong></p><p><strong>Gorr:</strong> Yeah, definitely. Especially in the experimentation and design phases, where you’re trying different things. That’s obviously going to yield dramatic cost savings if you’re actually manufacturing and producing [the chips]. You want to simulate, test, experiment as much as possible without making something using the actual process engineering.</p><p><strong>We’ve talked about the benefits. How about the drawbacks?</strong></p><p><strong>Gorr: </strong>The [AI-based experimental models] tend to not be as accurate as physics-based models. Of course, that’s why you do many simulations and parameter sweeps. But that’s also the benefit of having that digital twin, where you can keep that in mind—it’s not going to be as accurate as that precise model that we’ve developed over the years.</p><p>Both chip design and manufacturing are system intensive; you have to consider every little part. And that can be really challenging. It’s a case where you might have models to predict something and different parts of it, but you still need to bring it all together.</p><p>One of the other things to think about too is that you need the data to build the models. You have to incorporate data from all sorts of different sensors and different sorts of teams, and so that heightens the challenge.</p><p><strong>How can engineers use AI to better prepare and extract insights from hardware or sensor data?</strong></p><p><strong>Gorr: </strong>We always think about using AI to predict something or do some robot task, but you can use AI to come up with patterns and pick out things you might not have noticed before on your own. People will use AI when they have high-frequency data coming from many different sensors, and a lot of times it’s useful to explore the frequency domain and things like data synchronization or resampling. Those can be really challenging if you’re not sure where to start.</p><p>One of the things I would say is, use the tools that are available. There’s a vast community of people working on these things, and you can find lots of examples [of applications and techniques] on <a href=\"https://github.com/\" rel=\"noopener noreferrer\" target=\"_blank\">GitHub</a> or <a href=\"https://www.mathworks.com/matlabcentral/\" rel=\"noopener noreferrer\" target=\"_blank\">MATLAB Central</a>, where people have shared nice examples, even little apps they’ve created. I think many of us are buried in data and just not sure what to do with it, so definitely take advantage of what’s already out there in the community. You can explore and see what makes sense to you, and bring in that balance of domain knowledge and the insight you get from the tools and AI.</p><p><strong>What should engineers and designers consider wh</strong><strong>en using AI for chip design?</strong></p><p><strong>Gorr:</strong> Think through what problems you’re trying to solve or what insights you might hope to find, and try to be clear about that. Consider all of the different components, and document and test each of those different parts. Consider all of the people involved, and explain and hand off in a way that is sensible for the whole team.</p><p><strong>How do you think AI will affect chip designers’ jobs?</strong></p><p><strong>Gorr:</strong> It’s going to free up a lot of human capital for more advanced tasks. We can use AI to reduce waste, to optimize the materials, to optimize the design, but then you still have that human involved whenever it comes to decision-making. I think it’s a great example of people and technology working hand in hand. It’s also an industry where all people involved—even on the manufacturing floor—need to have some level of understanding of what’s happening, so this is a great industry for advancing AI because of how we test things and how we think about them before we put them on the chip.</p><p><strong>How do you envision the future of AI and chip design?</strong></p><p><strong>Gorr</strong><strong>:</strong> It’s very much dependent on that human element—involving people in the process and having that interpretable model. We can do many things with the mathematical minutiae of modeling, but it comes down to how people are using it, how everybody in the process is understanding and applying it. Communication and involvement of people of all skill levels in the process are going to be really important. We’re going to see less of those superprecise predictions and more transparency of information, sharing, and that digital twin—not only using AI but also using our human knowledge and all of the work that many people have done over the years.</p>"},"pubDate":"Tue, 08 Feb 2022 14:00:01 +0000","guid":"https://spectrum.ieee.org/ai-chip-design-matlab","category":["Chip fabrication","Moore’s law","Chip design","Ai","Matlab","Digital twins"],"dc:creator":"Rina Diane Caballar","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/layered-rendering-of-colorful-semiconductor-wafers-with-a-bright-white-light-sitting-on-one.jpg?id=29285079&width=980"}},{"title":"Atomically Thin Materials Significantly Shrink Qubits","link":"https://spectrum.ieee.org/2d-hbn-qubit","description":{"#cdata-section":"\n<img src=\"https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&width=1200&height=800&coordinates=0%2C0%2C0%2C0\"/><br/><br/><p>Quantum computing is a devilishly complex technology, with many technical hurdles impacting its development. Of these challenges two critical issues stand out: miniaturization and qubit quality.</p><p>IBM has adopted the superconducting qubit road map of <a href=\"https://spectrum.ieee.org/ibms-envisons-the-road-to-quantum-computing-like-an-apollo-mission\" target=\"_self\">reaching a 1,121-qubit processor by 2023</a>, leading to the expectation that 1,000 qubits with today’s qubit form factor is feasible. However, current approaches will require very large chips (50 millimeters on a side, or larger) at the scale of small wafers, or the use of chiplets on multichip modules. While this approach will work, the aim is to attain a better path toward scalability.</p><p>Now researchers at <a href=\"https://www.nature.com/articles/s41563-021-01187-w\" rel=\"noopener noreferrer\" target=\"_blank\">MIT have been able to both reduce the size of the qubits</a> and done so in a way that reduces the interference that occurs between neighboring qubits. The MIT researchers have increased the number of superconducting qubits that can be added onto a device by a factor of 100.</p><p>“We are addressing both qubit miniaturization and quality,” said <a href=\"https://equs.mit.edu/william-d-oliver/\" rel=\"noopener noreferrer\" target=\"_blank\">William Oliver</a>, the director for the <a href=\"https://cqe.mit.edu/\" target=\"_blank\">Center for Quantum Engineering</a> at MIT. “Unlike conventional transistor scaling, where only the number really matters, for qubits, large numbers are not sufficient, they must also be high-performance. Sacrificing performance for qubit number is not a useful trade in quantum computing. They must go hand in hand.”</p><p>The key to this big increase in qubit density and reduction of interference comes down to the use of two-dimensional materials, in particular the 2D insulator hexagonal boron nitride (hBN). The MIT researchers demonstrated that a few atomic monolayers of hBN can be stacked to form the insulator in the capacitors of a superconducting qubit.</p><p>Just like other capacitors, the capacitors in these superconducting circuits take the form of a sandwich in which an insulator material is sandwiched between two metal plates. The big difference for these capacitors is that the superconducting circuits can operate only at extremely low temperatures—less than 0.02 degrees above absolute zero (-273.15 °C).</p><p class=\"shortcode-media shortcode-media-rebelmouse-image rm-resized-container rm-resized-container-25 rm-float-left\" data-rm-resized-container=\"25%\" style=\"float: left;\">\n<img alt=\"Golden dilution refrigerator hanging vertically\" class=\"rm-shortcode rm-resized-image\" data-rm-shortcode-id=\"694399af8a1c345e51a695ff73909eda\" data-rm-shortcode-name=\"rebelmouse-image\" id=\"6c615\" loading=\"lazy\" src=\"https://spectrum.ieee.org/media-library/golden-dilution-refrigerator-hanging-vertically.jpg?id=29281593&width=980\" style=\"max-width: 100%\"/>\n<small class=\"image-media media-caption\" placeholder=\"Add Photo Caption...\" style=\"max-width: 100%;\">Superconducting qubits are measured at temperatures as low as 20 millikelvin in a dilution refrigerator.</small><small class=\"image-media media-photo-credit\" placeholder=\"Add Photo Credit...\" style=\"max-width: 100%;\">Nathan Fiske/MIT</small></p><p>In that environment, insulating materials that are available for the job, such as PE-CVD silicon oxide or silicon nitride, have quite a few defects that are too lossy for quantum computing applications. To get around these material shortcomings, most superconducting circuits use what are called coplanar capacitors. In these capacitors, the plates are positioned laterally to one another, rather than on top of one another.</p><p>As a result, the intrinsic silicon substrate below the plates and to a smaller degree the vacuum above the plates serve as the capacitor dielectric. Intrinsic silicon is chemically pure and therefore has few defects, and the large size dilutes the electric field at the plate interfaces, all of which leads to a low-loss capacitor. The lateral size of each plate in this open-face design ends up being quite large (typically 100 by 100 micrometers) in order to achieve the required capacitance.</p><p>In an effort to move away from the large lateral configuration, the MIT researchers embarked on a search for an insulator that has very few defects and is compatible with superconducting capacitor plates.</p><p>“We chose to study hBN because it is the most widely used insulator in 2D material research due to its cleanliness and chemical inertness,” said colead author <a href=\"https://equs.mit.edu/joel-wang/\" rel=\"noopener noreferrer\" target=\"_blank\">Joel Wang</a>, a research scientist in the Engineering Quantum Systems group of the MIT Research Laboratory for Electronics. </p><p>On either side of the hBN, the MIT researchers used the 2D superconducting material, niobium diselenide. One of the trickiest aspects of fabricating the capacitors was working with the niobium diselenide, which oxidizes in seconds when exposed to air, according to Wang. This necessitates that the assembly of the capacitor occur in a glove box filled with argon gas.</p><p>While this would seemingly complicate the scaling up of the production of these capacitors, Wang doesn’t regard this as a limiting factor.</p><p>“What determines the quality factor of the capacitor are the two interfaces between the two materials,” said Wang. “Once the sandwich is made, the two interfaces are “sealed” and we don’t see any noticeable degradation over time when exposed to the atmosphere.”</p><p>This lack of degradation is because around 90 percent of the electric field is contained within the sandwich structure, so the oxidation of the outer surface of the niobium diselenide does not play a significant role anymore. This ultimately makes the capacitor footprint much smaller, and it accounts for the reduction in cross talk between the neighboring qubits.</p><p>“The main challenge for scaling up the fabrication will be the wafer-scale growth of hBN and 2D superconductors like [niobium diselenide], and how one can do wafer-scale stacking of these films,” added Wang.</p><p>Wang believes that this research has shown 2D hBN to be a good insulator candidate for superconducting qubits. He says that the groundwork the MIT team has done will serve as a road map for using other hybrid 2D materials to build superconducting circuits.</p>"},"pubDate":"Mon, 07 Feb 2022 16:12:05 +0000","guid":"https://spectrum.ieee.org/2d-hbn-qubit","category":["Qubits","Mit","Ibm","Superconducting qubits","Hexagonal boron nitride","2d materials","Quantum computing"],"dc:creator":"Dexter Johnson","media:content":{"@medium":"image","@type":"image/jpeg","@url":"https://spectrum.ieee.org/media-library/a-golden-square-package-holds-a-small-processor-sitting-on-top-is-a-metal-square-with-mit-etched-into-it.jpg?id=29281587&width=980"}}]}}}